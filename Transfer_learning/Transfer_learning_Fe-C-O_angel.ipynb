{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import copy\n",
    "import csv\n",
    "import glob\n",
    "import sklearn.metrics as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义函数获取mape\n",
    "def mape(yyy_true,yyy_pred):\n",
    "    return np.mean(np.abs((yyy_pred-yyy_true)/yyy_pred))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 33) [1.0631710e+02 3.7500000e-02 1.6067000e+00 1.2096880e+02 6.0400000e-02\n",
      " 1.0170000e+00 1.8513360e+02 1.9717000e+00 3.1245000e+00 3.2458180e+02\n",
      " 1.2710100e+01 1.6871000e+00 3.5199950e+02 9.5712000e+00 2.8620000e-01\n",
      " 5.4923080e+02 7.9768000e+00 7.0191000e+00 5.5241580e+02 1.1305900e+01\n",
      " 4.3898000e+00 6.1353660e+02 3.0382700e+01 5.4885000e+00 1.9294498e+03\n",
      " 1.0850777e+03 9.2627800e+01]\n",
      "(375, 33)\n",
      "[ 6.70000000e+01  7.00000000e+01  1.15702100e+02  3.57000000e-02\n",
      "  1.76730000e+00  1.31048100e+02  1.40400000e-01  1.37350000e+00\n",
      "  1.83730000e+02  1.38360000e+00  5.13330000e+00  3.21120900e+02\n",
      "  1.15992000e+01  1.61240000e+00  3.60361100e+02  9.77540000e+00\n",
      "  6.95900000e-01  5.27415900e+02  1.35021000e+01  6.18370000e+00\n",
      "  5.61739400e+02  3.28700000e+00  4.53800000e-01  6.05895800e+02\n",
      "  3.34429000e+01  1.94710000e+00  1.86905260e+03  1.10336050e+03\n",
      "  1.00106400e+02 -1.11458326e+01  1.71601600e+00  1.18242700e+00\n",
      "  1.67108124e+02]\n"
     ]
    }
   ],
   "source": [
    "FePc_CO = './CO-FeP-water.csv'\n",
    "data_sets = (pd.read_csv(FePc_CO)).values\n",
    "print(data_sets.shape,data_sets[0,2:29])\n",
    "# FePc_CO = np.random.permutation(FePc_CO)\n",
    "bad_data_set = np.where(data_sets[:,2:28]<0)[0]\n",
    "bad_data_set = np.unique(bad_data_set)\n",
    "data_sets = np.delete(data_sets,bad_data_set,axis=0)  #删除描述符小于0的样本\n",
    "FePc_CO = data_sets[:,:]\n",
    "print(FePc_CO.shape)\n",
    "#用固定随机种子打乱二维数组的行顺序\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(FePc_CO) #  打乱数据的第一维度\n",
    "print(FePc_CO[0,:])\n",
    "data_sets = FePc_CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1570210e+02 3.5700000e-02 1.7673000e+00 1.3104810e+02 1.4040000e-01\n",
      " 1.3735000e+00 1.8373000e+02 1.3836000e+00 5.1333000e+00 3.2112090e+02\n",
      " 1.1599200e+01 1.6124000e+00 3.6036110e+02 9.7754000e+00 6.9590000e-01\n",
      " 5.2741590e+02 1.3502100e+01 6.1837000e+00 5.6173940e+02 3.2870000e+00\n",
      " 4.5380000e-01 6.0589580e+02 3.3442900e+01 1.9471000e+00 1.8690526e+03\n",
      " 1.1033605e+03 1.0010640e+02]\n",
      "[167.108124]\n",
      "(375, 27) (375, 1)\n",
      "[ 9.48913975e-01 -6.31179039e-01 -5.24537798e-02  1.36125786e+00\n",
      "  7.83476010e-01 -5.36407899e-01 -3.28288794e-01 -2.01087962e-01\n",
      "  2.27149356e-01  5.59119216e-03  8.95366484e-02  2.16392709e+00\n",
      "  4.69592014e-01 -1.82192639e+00 -2.64062479e-01 -5.79830163e-01\n",
      "  2.10538633e-01  1.75077020e+00  2.61331327e-01 -1.26763446e+00\n",
      " -1.38814520e+00 -5.09688016e-01  5.71135893e-02 -1.39009950e+00\n",
      " -1.15958694e+00 -6.97198965e-01 -3.22136756e-01  1.67108124e+02]\n"
     ]
    }
   ],
   "source": [
    "standar_scaler = preprocessing.StandardScaler()\n",
    "x = FePc_CO[:,2:29]\n",
    "y = FePc_CO[:,32].reshape(-1,1)\n",
    "print(x[0,:])\n",
    "print(y[0])\n",
    "print(x.shape,y.shape)\n",
    "x = standar_scaler.fit_transform(x)\n",
    "data_sets = np.hstack((x,y))\n",
    "print(data_sets[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75         0\n"
     ]
    }
   ],
   "source": [
    "k_fold = 5\n",
    "one_fold = int(data_sets.shape[0]/k_fold)\n",
    "redundant = data_sets.shape[0] - one_fold*k_fold\n",
    "print(one_fold,'       ',redundant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 28) (75, 28) (75, 28) (75, 28) (75, 28)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data_sets_1 = data_sets[0:75,:]\n",
    "data_sets_2 = data_sets[75:150,:]\n",
    "data_sets_3 = data_sets[150:225,:]\n",
    "data_sets_4 = data_sets[225:300,:]\n",
    "data_sets_5 = data_sets[300:375,:]\n",
    "print(data_sets_1.shape,data_sets_2.shape,data_sets_3.shape,data_sets_4.shape,data_sets_5.shape)\n",
    "data_sets_new = np.vstack((data_sets_1,data_sets_2))\n",
    "data_sets_new = np.vstack((data_sets_new,data_sets_3))\n",
    "data_sets_new = np.vstack((data_sets_new,data_sets_4))\n",
    "data_sets_new = np.vstack((data_sets_new,data_sets_5))\n",
    "# print(data_sets_new.shape,data_sets_new[0,:])\n",
    "print((data_sets == data_sets_new).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 28) (75, 28)\n",
      "(300, 27) (300,) (75, 27) (75,)\n"
     ]
    }
   ],
   "source": [
    "data_sets_train = np.vstack((data_sets_2,data_sets_3))\n",
    "data_sets_train = np.vstack((data_sets_train,data_sets_4))\n",
    "data_sets_train = np.vstack((data_sets_train,data_sets_5))\n",
    "data_sets_test  = data_sets_1\n",
    "print(data_sets_train.shape,data_sets_test.shape)\n",
    "x_train = data_sets_train[:,:-1]\n",
    "y_train = data_sets_train[:,-1]\n",
    "x_test = data_sets_test[:,:-1]\n",
    "y_test = data_sets_test[:,-1]\n",
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 128)               3584      \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 13,953\n",
      "Trainable params: 13,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128,input_shape=(x_train.shape[1],),activation='relu'\n",
    "                          ,kernel_regularizer=tf.keras.regularizers.l2(0.03),name=\"layer1\"),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'\n",
    "                          ,kernel_regularizer=tf.keras.regularizers.l2(0.02),name=\"layer2\"),\n",
    "#     tf.keras.layers.Dropout(0.05),\n",
    "    tf.keras.layers.Dense(32, activation='relu'\n",
    "                          ,kernel_regularizer=tf.keras.regularizers.l2(0.01),name=\"layer3\"),\n",
    "\n",
    "    tf.keras.layers.Dense(1,name=\"layer4\")\n",
    "    ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18529767 0.0\n",
      "-0.21233338 0.0\n",
      "0.11401689 0.0\n"
     ]
    }
   ],
   "source": [
    "#模型搭建好之后就会给每个参数赋予初值\n",
    "layer0 = model.layers[0].get_weights()    #这里的layer0对应模型中name里面的layer1\n",
    "# print(layer0[0].shape)       #权重\n",
    "# print(layer0[1].shape)       #偏置\n",
    "print(layer0[0][0,0],layer0[1][0])        #每次初始化的权重值都不一样\n",
    "# print(layer0[1])   \n",
    "# print(model.layers[1].get_weights)\n",
    "layer2 = model.layers[2].get_weights()\n",
    "layer3 = model.layers[3].get_weights()\n",
    "print(layer2[0][0,0],layer2[1][0])\n",
    "print(layer3[0][0,0],layer3[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一种调整学习率的方法，当指标停止提升时，降低学习速率。\n",
    "Reduce=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=5,\n",
    "                         verbose=1,\n",
    "                         mode='auto',\n",
    "                         min_delta=0.000001,\n",
    "                         cooldown=0,\n",
    "                         min_lr=0)\n",
    "# 学习率指数衰减\n",
    "exponential_decay = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.05\n",
    "                                                                    , decay_steps=50\n",
    "                                                                    , decay_rate=0.9\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16884716 0.30571434\n",
      "-0.011399869 0.11268022\n",
      "0.43325108 0.09707121\n"
     ]
    }
   ],
   "source": [
    "#加载模型，加载完模型后必须重新compile一次，如果不compile而直接fit，模型参数不会优化\n",
    "model.load_weights( \"../CO-FeP/Fe-C-O/Fe-C-O.ckpt\")\n",
    "layer0 = model.layers[0].get_weights()\n",
    "layer2 = model.layers[2].get_weights()\n",
    "layer3 = model.layers[3].get_weights()\n",
    "print(layer0[0][0,0],layer0[1][0])\n",
    "print(layer2[0][0,0],layer2[1][0])\n",
    "print(layer3[0][0,0],layer3[1][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save_path_transfer_fix_last_layer=\"./Fe-C-O_angel/transfer_fix_last_layer/checkpoint.ckpt\"   \n",
    "#读取模型\n",
    "if os.path.exists(checkpoint_save_path_transfer_fix_last_layer + '.index'):\n",
    "    print('- - - - - - - - - - - -load the model- - - - - - - - - - - -')\n",
    "    model.load_weights(checkpoint_save_path_transfer_fix_last_layer)\n",
    "#在每个训练期（epoch）后保存模型\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path_transfer_fix_last_layer,\n",
    "                                                save_weights_only=True,\n",
    "                                                save_best_only=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.6784 - val_loss: 17.6316\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.6782 - val_loss: 17.6314\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 16.6780 - val_loss: 17.6310\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.6776 - val_loss: 17.6306\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 16.6771 - val_loss: 17.6301\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.6765 - val_loss: 17.6295\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.6759 - val_loss: 17.6288\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.6751 - val_loss: 17.6281\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 16.6744 - val_loss: 17.6274\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.6735 - val_loss: 17.6266\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.6726 - val_loss: 17.6258\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.6717 - val_loss: 17.6249\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.6707 - val_loss: 17.6240\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.6697 - val_loss: 17.6231\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.6687 - val_loss: 17.6222\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.6677 - val_loss: 17.6212\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.6666 - val_loss: 17.6202\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.6655 - val_loss: 17.6192\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.6644 - val_loss: 17.6182\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 16.6633 - val_loss: 17.6172\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 16.6621 - val_loss: 17.6162\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.6610 - val_loss: 17.6152\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.6598 - val_loss: 17.6141\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.6587 - val_loss: 17.6131\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.6575 - val_loss: 17.6120\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.6563 - val_loss: 17.6110\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.6552 - val_loss: 17.6100\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.6540 - val_loss: 17.6089\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.6528 - val_loss: 17.6079\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.6517 - val_loss: 17.6068\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.6505 - val_loss: 17.6058\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.6493 - val_loss: 17.6047\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 16.6481 - val_loss: 17.6037\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 16.6470 - val_loss: 17.6026\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 16.6458 - val_loss: 17.6016\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.6446 - val_loss: 17.6006\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.6435 - val_loss: 17.5995\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.6423 - val_loss: 17.5985\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.6411 - val_loss: 17.5975\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.6400 - val_loss: 17.5965\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.6388 - val_loss: 17.5954\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 16.6377 - val_loss: 17.5944\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.6365 - val_loss: 17.5934\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.6354 - val_loss: 17.5924\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.6343 - val_loss: 17.5914\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.6331 - val_loss: 17.5904\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.6320 - val_loss: 17.5894\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.6309 - val_loss: 17.5884\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.6298 - val_loss: 17.5874\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.6286 - val_loss: 17.5864\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.6275 - val_loss: 17.5854\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.6264 - val_loss: 17.5844\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.6253 - val_loss: 17.5835\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.6242 - val_loss: 17.5825\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.6231 - val_loss: 17.5815\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.6220 - val_loss: 17.5806\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.6210 - val_loss: 17.5796\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.6199 - val_loss: 17.5786\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.6188 - val_loss: 17.5777\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.6177 - val_loss: 17.5767\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.6167 - val_loss: 17.5758\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.6156 - val_loss: 17.5749\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.6146 - val_loss: 17.5739\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.6135 - val_loss: 17.5730\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.6125 - val_loss: 17.5721\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.6114 - val_loss: 17.5712\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 16.6104 - val_loss: 17.5703\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 16.6094 - val_loss: 17.5694\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.6083 - val_loss: 17.5684\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.6073 - val_loss: 17.5675\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.6063 - val_loss: 17.5666\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.6053 - val_loss: 17.5657\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.6043 - val_loss: 17.5648\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.6033 - val_loss: 17.5640\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.6023 - val_loss: 17.5631\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.6013 - val_loss: 17.5622\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.6003 - val_loss: 17.5613\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.5993 - val_loss: 17.5605\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.5983 - val_loss: 17.5596\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.5973 - val_loss: 17.5587\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 160ms/step - loss: 16.5963 - val_loss: 17.5578\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 16.5954 - val_loss: 17.5570\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.5944 - val_loss: 17.5561\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 16.5934 - val_loss: 17.5553\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.5925 - val_loss: 17.5545\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.5915 - val_loss: 17.5536\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.5906 - val_loss: 17.5528\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.5896 - val_loss: 17.5519\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.5887 - val_loss: 17.5511\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.5878 - val_loss: 17.5503\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.5868 - val_loss: 17.5495\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.5859 - val_loss: 17.5486\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.5850 - val_loss: 17.5478\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.5841 - val_loss: 17.5470\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.5831 - val_loss: 17.5462\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.5822 - val_loss: 17.5454\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.5813 - val_loss: 17.5446\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.5804 - val_loss: 17.5438\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.5795 - val_loss: 17.5430\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.5786 - val_loss: 17.5422\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.5777 - val_loss: 17.5414\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.5768 - val_loss: 17.5406\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.5759 - val_loss: 17.5399\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.5751 - val_loss: 17.5391\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.5742 - val_loss: 17.5383\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.5733 - val_loss: 17.5376\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 16.5724 - val_loss: 17.5368\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.5716 - val_loss: 17.5360\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.5707 - val_loss: 17.5353\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.5698 - val_loss: 17.5345\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.5690 - val_loss: 17.5338\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 16.5681 - val_loss: 17.5330\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 16.5673 - val_loss: 17.5323\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 16.5664 - val_loss: 17.5315\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.5656 - val_loss: 17.5308\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.5647 - val_loss: 17.5300\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.5639 - val_loss: 17.5293\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 16.5631 - val_loss: 17.5286\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.5622 - val_loss: 17.5278\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 16.5614 - val_loss: 17.5271\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.5606 - val_loss: 17.5264\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.5598 - val_loss: 17.5257\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.5590 - val_loss: 17.5250\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 16.5581 - val_loss: 17.5242\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 16.5573 - val_loss: 17.5235\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.5565 - val_loss: 17.5228\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.5557 - val_loss: 17.5221\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.5549 - val_loss: 17.5214\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.5541 - val_loss: 17.5207\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.5533 - val_loss: 17.5200\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.5526 - val_loss: 17.5193\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.5518 - val_loss: 17.5186\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.5510 - val_loss: 17.5179\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.5502 - val_loss: 17.5173\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.5494 - val_loss: 17.5166\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.5486 - val_loss: 17.5159\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.5479 - val_loss: 17.5152\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.5471 - val_loss: 17.5145\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.5463 - val_loss: 17.5139\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.5456 - val_loss: 17.5132\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.5448 - val_loss: 17.5125\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.5441 - val_loss: 17.5119\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.5433 - val_loss: 17.5112\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.5425 - val_loss: 17.5106\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.5418 - val_loss: 17.5099\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.5410 - val_loss: 17.5092\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.5403 - val_loss: 17.5086\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.5396 - val_loss: 17.5079\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.5388 - val_loss: 17.5073\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.5381 - val_loss: 17.5066\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.5374 - val_loss: 17.5060\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.5366 - val_loss: 17.5054\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.5359 - val_loss: 17.5047\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.5352 - val_loss: 17.5041\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.5345 - val_loss: 17.5035\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.5338 - val_loss: 17.5029\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.5331 - val_loss: 17.5022\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.5323 - val_loss: 17.5016\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.5316 - val_loss: 17.5010\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.5309 - val_loss: 17.5004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.5302 - val_loss: 17.4998\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.5295 - val_loss: 17.4991\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.5288 - val_loss: 17.4985\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.5281 - val_loss: 17.4979\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.5274 - val_loss: 17.4973\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.5268 - val_loss: 17.4967\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.5261 - val_loss: 17.4961\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.5254 - val_loss: 17.4955\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.5247 - val_loss: 17.4949\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.5240 - val_loss: 17.4943\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.5234 - val_loss: 17.4938\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.5227 - val_loss: 17.4932\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.5220 - val_loss: 17.4926\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.5213 - val_loss: 17.4920\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 16.5207 - val_loss: 17.4914\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.5200 - val_loss: 17.4908\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.5194 - val_loss: 17.4903\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.5187 - val_loss: 17.4897\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.5181 - val_loss: 17.4891\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.5174 - val_loss: 17.4885\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 16.5167 - val_loss: 17.4880\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.5161 - val_loss: 17.4874\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.5154 - val_loss: 17.4868\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.5148 - val_loss: 17.4863\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.5142 - val_loss: 17.4857\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.5135 - val_loss: 17.4852\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.5129 - val_loss: 17.4846\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.5123 - val_loss: 17.4841\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.5116 - val_loss: 17.4835\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.5110 - val_loss: 17.4830\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.5104 - val_loss: 17.4824\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.5097 - val_loss: 17.4819\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 16.5091 - val_loss: 17.4813\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.5085 - val_loss: 17.4808\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.5079 - val_loss: 17.4802\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.5073 - val_loss: 17.4797\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.5066 - val_loss: 17.4792\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.5060 - val_loss: 17.4786\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.5054 - val_loss: 17.4781\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.5048 - val_loss: 17.4776\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.5042 - val_loss: 17.4770\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.5036 - val_loss: 17.4765\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.5030 - val_loss: 17.4760\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.5024 - val_loss: 17.4755\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.5018 - val_loss: 17.4749\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.5012 - val_loss: 17.4744\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.5006 - val_loss: 17.4739\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.5001 - val_loss: 17.4734\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.4995 - val_loss: 17.4729\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.4989 - val_loss: 17.4724\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4983 - val_loss: 17.4719\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.4977 - val_loss: 17.4714\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.4971 - val_loss: 17.4709\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4966 - val_loss: 17.4704\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4960 - val_loss: 17.4699\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4954 - val_loss: 17.4694\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4949 - val_loss: 17.4689\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.4943 - val_loss: 17.4684\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4937 - val_loss: 17.4679\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4931 - val_loss: 17.4674\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.4926 - val_loss: 17.4669\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4920 - val_loss: 17.4664\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4915 - val_loss: 17.4659\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.4909 - val_loss: 17.4654\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4903 - val_loss: 17.4650\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.4898 - val_loss: 17.4645\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4893 - val_loss: 17.4640\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4887 - val_loss: 17.4635\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.4882 - val_loss: 17.4630\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 16.4876 - val_loss: 17.4626\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 16.4871 - val_loss: 17.4621\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.4865 - val_loss: 17.4616\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.4860 - val_loss: 17.4612\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4854 - val_loss: 17.4607\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4849 - val_loss: 17.4602\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.4844 - val_loss: 17.4598\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 16.4839 - val_loss: 17.4593\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4833 - val_loss: 17.4588\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.4828 - val_loss: 17.4584\n",
      "Epoch 240/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4823 - val_loss: 17.4579\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4817 - val_loss: 17.4575\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4812 - val_loss: 17.4570\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.4807 - val_loss: 17.4566\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4802 - val_loss: 17.4561\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4797 - val_loss: 17.4557\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.4792 - val_loss: 17.4552\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4786 - val_loss: 17.4548\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4781 - val_loss: 17.4543\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4776 - val_loss: 17.4539\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.4771 - val_loss: 17.4534\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4766 - val_loss: 17.4530\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4761 - val_loss: 17.4526\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4756 - val_loss: 17.4521\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4751 - val_loss: 17.4517\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4746 - val_loss: 17.4513\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.4741 - val_loss: 17.4508\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.4736 - val_loss: 17.4504\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 16.4731 - val_loss: 17.4500\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4726 - val_loss: 17.4495\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.4721 - val_loss: 17.4491\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4716 - val_loss: 17.4487\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4712 - val_loss: 17.4483\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.4707 - val_loss: 17.4478\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4702 - val_loss: 17.4474\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4697 - val_loss: 17.4470\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4692 - val_loss: 17.4466\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.4688 - val_loss: 17.4462\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.4683 - val_loss: 17.4458\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.4678 - val_loss: 17.4454\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4673 - val_loss: 17.4449\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4669 - val_loss: 17.4445\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.4664 - val_loss: 17.4441\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4659 - val_loss: 17.4437\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4654 - val_loss: 17.4433\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 16.4650 - val_loss: 17.4429\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.4645 - val_loss: 17.4425\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4641 - val_loss: 17.4421\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.4636 - val_loss: 17.4417\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.4631 - val_loss: 17.4413\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.4627 - val_loss: 17.4409\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 16.4622 - val_loss: 17.4405\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.4618 - val_loss: 17.4401\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.4613 - val_loss: 17.4397\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.4608 - val_loss: 17.4393\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.4604 - val_loss: 17.4389\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.4599 - val_loss: 17.4386\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 16.4595 - val_loss: 17.4382\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 16.4591 - val_loss: 17.4378\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4586 - val_loss: 17.4374\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4582 - val_loss: 17.4370\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.4577 - val_loss: 17.4366\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.4573 - val_loss: 17.4363\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 16.4569 - val_loss: 17.4359\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.4564 - val_loss: 17.4355\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.4560 - val_loss: 17.4351\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4556 - val_loss: 17.4347\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4551 - val_loss: 17.4344\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.4547 - val_loss: 17.4340\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 16.4542 - val_loss: 17.4336\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.4538 - val_loss: 17.4333\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.4534 - val_loss: 17.4329\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.4530 - val_loss: 17.4325\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 16.4525 - val_loss: 17.4321\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.4521 - val_loss: 17.4318\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.4517 - val_loss: 17.4314\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.4513 - val_loss: 17.4310\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.4509 - val_loss: 17.4307\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.4504 - val_loss: 17.4303\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 16.4500 - val_loss: 17.4300\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 16.4496 - val_loss: 17.4296\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.4492 - val_loss: 17.4293\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4488 - val_loss: 17.4289\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.4484 - val_loss: 17.4285\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4480 - val_loss: 17.4282\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 16.4475 - val_loss: 17.4278\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 16.4471 - val_loss: 17.4275\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.44 - 0s 48ms/step - loss: 16.4467 - val_loss: 17.4271\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4463 - val_loss: 17.4268\n",
      "Epoch 319/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4459 - val_loss: 17.4264\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.4455 - val_loss: 17.4261\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 16.4451 - val_loss: 17.4257\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.4447 - val_loss: 17.4254\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4443 - val_loss: 17.4250\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4439 - val_loss: 17.4247\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.4435 - val_loss: 17.4243\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.4431 - val_loss: 17.4240\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.4427 - val_loss: 17.4237\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.4424 - val_loss: 17.4233\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.4420 - val_loss: 17.4230\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4416 - val_loss: 17.4227\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4412 - val_loss: 17.4223\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4408 - val_loss: 17.4220\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.4404 - val_loss: 17.4216\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4400 - val_loss: 17.4213\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4396 - val_loss: 17.4210\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.4393 - val_loss: 17.4207\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.4389 - val_loss: 17.4203\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.4385 - val_loss: 17.4200\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.4381 - val_loss: 17.4197\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4377 - val_loss: 17.4194\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4374 - val_loss: 17.4190\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.4370 - val_loss: 17.4187\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.4366 - val_loss: 17.4184\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.4363 - val_loss: 17.4181\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 16.4359 - val_loss: 17.4177\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4355 - val_loss: 17.4174\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4351 - val_loss: 17.4171\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 16.4348 - val_loss: 17.4168\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4344 - val_loss: 17.4165\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.4340 - val_loss: 17.4162\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 16.4337 - val_loss: 17.4158\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.4333 - val_loss: 17.4155\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4329 - val_loss: 17.4152\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4326 - val_loss: 17.4149\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4322 - val_loss: 17.4146\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.4319 - val_loss: 17.4143\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.4315 - val_loss: 17.4140\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.4312 - val_loss: 17.4137\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4308 - val_loss: 17.4134\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.4304 - val_loss: 17.4131\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.4301 - val_loss: 17.4128\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4298 - val_loss: 17.4125\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4294 - val_loss: 17.4122\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.4290 - val_loss: 17.4119\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4287 - val_loss: 17.4116\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4284 - val_loss: 17.4113\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.4280 - val_loss: 17.4110\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4277 - val_loss: 17.4107\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.4273 - val_loss: 17.4104\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4270 - val_loss: 17.4101\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.4266 - val_loss: 17.4098\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.4263 - val_loss: 17.4095\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 16.4259 - val_loss: 17.4092\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 16.4256 - val_loss: 17.4089\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 16.4253 - val_loss: 17.4086\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4249 - val_loss: 17.4083\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4246 - val_loss: 17.4080\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 16.4243 - val_loss: 17.4077\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 16.4239 - val_loss: 17.4074\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 16.4236 - val_loss: 17.4072\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.4233 - val_loss: 17.4069\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.4229 - val_loss: 17.4066\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.4226 - val_loss: 17.4063\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4223 - val_loss: 17.4060\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 16.4219 - val_loss: 17.4057\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 16.4216 - val_loss: 17.4055\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 16.4213 - val_loss: 17.4052\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.4210 - val_loss: 17.4049\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.4206 - val_loss: 17.4046\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4203 - val_loss: 17.4043\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4200 - val_loss: 17.4041\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.4197 - val_loss: 17.4038\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4193 - val_loss: 17.4035\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.4190 - val_loss: 17.4032\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.4187 - val_loss: 17.4030\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.4184 - val_loss: 17.4027\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4181 - val_loss: 17.4024\n",
      "Epoch 398/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step - loss: 16.4178 - val_loss: 17.4022\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.4175 - val_loss: 17.4019\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 16.4171 - val_loss: 17.4016\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.4168 - val_loss: 17.4014\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.4165 - val_loss: 17.4011\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.4162 - val_loss: 17.4008\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.4159 - val_loss: 17.4006\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4156 - val_loss: 17.4003\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.4153 - val_loss: 17.4000\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.4150 - val_loss: 17.3998\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4147 - val_loss: 17.3995\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4144 - val_loss: 17.3992\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.4141 - val_loss: 17.3990\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.4138 - val_loss: 17.3987\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.4135 - val_loss: 17.3985\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.4132 - val_loss: 17.3982\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.4129 - val_loss: 17.3979\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.4126 - val_loss: 17.3977\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.4123 - val_loss: 17.3974\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.4120 - val_loss: 17.3972\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.4117 - val_loss: 17.3969\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.4114 - val_loss: 17.3967\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.4111 - val_loss: 17.3964\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4108 - val_loss: 17.3961\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.4105 - val_loss: 17.3959\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.4102 - val_loss: 17.3956\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.4099 - val_loss: 17.3954\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4096 - val_loss: 17.3952\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4093 - val_loss: 17.3949\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.4090 - val_loss: 17.3946\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 16.4087 - val_loss: 17.3944\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.4085 - val_loss: 17.3942\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.4082 - val_loss: 17.3939\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 16.4079 - val_loss: 17.3937\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.4076 - val_loss: 17.3934\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.4073 - val_loss: 17.3932\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 16.4070 - val_loss: 17.3929\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4067 - val_loss: 17.3927\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.4065 - val_loss: 17.3925\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.4062 - val_loss: 17.3922\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.4059 - val_loss: 17.3920\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.4056 - val_loss: 17.3917\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4053 - val_loss: 17.3915\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.4051 - val_loss: 17.3913\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4048 - val_loss: 17.3910\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.4045 - val_loss: 17.3908\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.4042 - val_loss: 17.3905\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4040 - val_loss: 17.3903\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.4037 - val_loss: 17.3901\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 16.4034 - val_loss: 17.3898\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.4032 - val_loss: 17.3896\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.4029 - val_loss: 17.3894\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.4026 - val_loss: 17.3891\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.4023 - val_loss: 17.3889\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4021 - val_loss: 17.3887\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.4018 - val_loss: 17.3885\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.4015 - val_loss: 17.3882\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4013 - val_loss: 17.3880\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.4010 - val_loss: 17.3878\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.4007 - val_loss: 17.3875\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.4005 - val_loss: 17.3873\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.4002 - val_loss: 17.3871\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3999 - val_loss: 17.3869\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3997 - val_loss: 17.3866\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.3994 - val_loss: 17.3864\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3992 - val_loss: 17.3862\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3989 - val_loss: 17.3860\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3986 - val_loss: 17.3857\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3984 - val_loss: 17.3855\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3981 - val_loss: 17.3853\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3979 - val_loss: 17.3851\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3976 - val_loss: 17.3848\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3973 - val_loss: 17.3846\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3971 - val_loss: 17.3844\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3968 - val_loss: 17.3842\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3966 - val_loss: 17.3840\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3963 - val_loss: 17.3838\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3961 - val_loss: 17.3836\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3958 - val_loss: 17.3833\n",
      "Epoch 477/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3956 - val_loss: 17.3831\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3953 - val_loss: 17.3829\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3951 - val_loss: 17.3827\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3948 - val_loss: 17.3825\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3946 - val_loss: 17.3823\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3943 - val_loss: 17.3821\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3941 - val_loss: 17.3819\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3939 - val_loss: 17.3816\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3936 - val_loss: 17.3814\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.3934 - val_loss: 17.3812\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3931 - val_loss: 17.3810\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3929 - val_loss: 17.3808\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3926 - val_loss: 17.3806\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3924 - val_loss: 17.3804\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3922 - val_loss: 17.3802\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3919 - val_loss: 17.3800\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3917 - val_loss: 17.3798\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3914 - val_loss: 17.3796\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.3912 - val_loss: 17.3794\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3910 - val_loss: 17.3792\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3907 - val_loss: 17.3790\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3905 - val_loss: 17.3788\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3903 - val_loss: 17.3786\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3900 - val_loss: 17.3784\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3898 - val_loss: 17.3782\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3896 - val_loss: 17.3780\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3893 - val_loss: 17.3778\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3891 - val_loss: 17.3776\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.3889 - val_loss: 17.3774\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3886 - val_loss: 17.3772\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3884 - val_loss: 17.3770\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3882 - val_loss: 17.3768\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3880 - val_loss: 17.3766\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3877 - val_loss: 17.3764\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3875 - val_loss: 17.3762\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3873 - val_loss: 17.3760\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3870 - val_loss: 17.3758\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3868 - val_loss: 17.3756\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3866 - val_loss: 17.3754\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3864 - val_loss: 17.3753\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3861 - val_loss: 17.3751\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3859 - val_loss: 17.3749\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3857 - val_loss: 17.3747\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3855 - val_loss: 17.3745\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3852 - val_loss: 17.3743\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3850 - val_loss: 17.3741\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3848 - val_loss: 17.3739\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.3846 - val_loss: 17.3737\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3844 - val_loss: 17.3735\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3841 - val_loss: 17.3734\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3839 - val_loss: 17.3732\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3837 - val_loss: 17.3730\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3835 - val_loss: 17.3728\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.3833 - val_loss: 17.3726\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3831 - val_loss: 17.3724\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.3829 - val_loss: 17.3723\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3826 - val_loss: 17.3721\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3824 - val_loss: 17.3719\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.3822 - val_loss: 17.3717\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3820 - val_loss: 17.3715\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3818 - val_loss: 17.3713\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3816 - val_loss: 17.3712\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3814 - val_loss: 17.3710\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.3812 - val_loss: 17.3708\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3809 - val_loss: 17.3706\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.3807 - val_loss: 17.3705\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 16.3805 - val_loss: 17.3703\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3803 - val_loss: 17.3701\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3801 - val_loss: 17.3699\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3799 - val_loss: 17.3698\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3797 - val_loss: 17.3696\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3795 - val_loss: 17.3694\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3793 - val_loss: 17.3692\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3791 - val_loss: 17.3690\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3789 - val_loss: 17.3689\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3787 - val_loss: 17.3687\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3785 - val_loss: 17.3685\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3783 - val_loss: 17.3683\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3781 - val_loss: 17.3682\n",
      "Epoch 556/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3779 - val_loss: 17.3680\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3777 - val_loss: 17.3678\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3775 - val_loss: 17.3677\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3773 - val_loss: 17.3675\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3771 - val_loss: 17.3673\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3769 - val_loss: 17.3672\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3767 - val_loss: 17.3670\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3765 - val_loss: 17.3668\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3763 - val_loss: 17.3667\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3761 - val_loss: 17.3665\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3759 - val_loss: 17.3663\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3757 - val_loss: 17.3662\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3755 - val_loss: 17.3660\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3753 - val_loss: 17.3658\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3751 - val_loss: 17.3657\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3749 - val_loss: 17.3655\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3747 - val_loss: 17.3653\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3745 - val_loss: 17.3652\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3744 - val_loss: 17.3650\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3742 - val_loss: 17.3649\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 16.3740 - val_loss: 17.3647\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3738 - val_loss: 17.3645\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3736 - val_loss: 17.3644\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3734 - val_loss: 17.3642\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3732 - val_loss: 17.3640\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 16.3730 - val_loss: 17.3639\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 16.3728 - val_loss: 17.3637\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3727 - val_loss: 17.3636\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3725 - val_loss: 17.3634\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3723 - val_loss: 17.3632\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3721 - val_loss: 17.3631\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 16.3719 - val_loss: 17.3629\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 16.3717 - val_loss: 17.3628\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3715 - val_loss: 17.3626\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3713 - val_loss: 17.3625\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3712 - val_loss: 17.3623\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.3710 - val_loss: 17.3621\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 16.3708 - val_loss: 17.3620\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3706 - val_loss: 17.3618\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3704 - val_loss: 17.3617\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3703 - val_loss: 17.3615\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3701 - val_loss: 17.3614\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 16.3699 - val_loss: 17.3612\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.3697 - val_loss: 17.3611\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3695 - val_loss: 17.3609\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3694 - val_loss: 17.3608\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3692 - val_loss: 17.3606\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3690 - val_loss: 17.3605\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3688 - val_loss: 17.3603\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3687 - val_loss: 17.3602\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3685 - val_loss: 17.3600\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3683 - val_loss: 17.3599\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.3681 - val_loss: 17.3597\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3680 - val_loss: 17.3596\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3678 - val_loss: 17.3594\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3676 - val_loss: 17.3593\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3674 - val_loss: 17.3591\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3673 - val_loss: 17.3590\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3671 - val_loss: 17.3588\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3669 - val_loss: 17.3587\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3667 - val_loss: 17.3585\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3666 - val_loss: 17.3584\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3664 - val_loss: 17.3582\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3662 - val_loss: 17.3581\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3661 - val_loss: 17.3580\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3659 - val_loss: 17.3578\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3657 - val_loss: 17.3577\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3656 - val_loss: 17.3575\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3654 - val_loss: 17.3574\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3652 - val_loss: 17.3573\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3651 - val_loss: 17.3571\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3649 - val_loss: 17.3570\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3647 - val_loss: 17.3568\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3646 - val_loss: 17.3567\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3644 - val_loss: 17.3565\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.3642 - val_loss: 17.3564\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.36 - 0s 35ms/step - loss: 16.3641 - val_loss: 17.3563\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3639 - val_loss: 17.3561\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3637 - val_loss: 17.3560\n",
      "Epoch 635/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 16.3636 - val_loss: 17.3558\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3634 - val_loss: 17.3557\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3632 - val_loss: 17.3556\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.3631 - val_loss: 17.3554\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3629 - val_loss: 17.3553\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.3628 - val_loss: 17.3552\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3626 - val_loss: 17.3550\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3624 - val_loss: 17.3549\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3623 - val_loss: 17.3548\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3621 - val_loss: 17.3546\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.3620 - val_loss: 17.3545\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 16.3618 - val_loss: 17.3543\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3616 - val_loss: 17.3542\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3615 - val_loss: 17.3541\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.3613 - val_loss: 17.3539\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3612 - val_loss: 17.3538\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3610 - val_loss: 17.3537\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3609 - val_loss: 17.3535\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3607 - val_loss: 17.3534\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3605 - val_loss: 17.3533\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3604 - val_loss: 17.3531\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3602 - val_loss: 17.3530\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3601 - val_loss: 17.3529\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3599 - val_loss: 17.3527\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3598 - val_loss: 17.3526\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3596 - val_loss: 17.3525\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3595 - val_loss: 17.3524\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3593 - val_loss: 17.3522\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3592 - val_loss: 17.3521\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3590 - val_loss: 17.3520\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3589 - val_loss: 17.3519\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3587 - val_loss: 17.3517\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3586 - val_loss: 17.3516\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3584 - val_loss: 17.3515\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3583 - val_loss: 17.3513\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3581 - val_loss: 17.3512\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3580 - val_loss: 17.3511\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3578 - val_loss: 17.3510\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3577 - val_loss: 17.3508\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3575 - val_loss: 17.3507\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3574 - val_loss: 17.3506\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3572 - val_loss: 17.3505\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3571 - val_loss: 17.3503\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3569 - val_loss: 17.3502\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3568 - val_loss: 17.3501\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3566 - val_loss: 17.3500\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.3565 - val_loss: 17.3498\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3563 - val_loss: 17.3497\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3562 - val_loss: 17.3496\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.3560 - val_loss: 17.3495\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3559 - val_loss: 17.3494\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3558 - val_loss: 17.3492\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3556 - val_loss: 17.3491\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3555 - val_loss: 17.3490\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3553 - val_loss: 17.3489\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3552 - val_loss: 17.3487\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3551 - val_loss: 17.3486\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3549 - val_loss: 17.3485\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3548 - val_loss: 17.3484\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 16.3546 - val_loss: 17.3483\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.3545 - val_loss: 17.3481\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.3544 - val_loss: 17.3480\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3542 - val_loss: 17.3479\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3541 - val_loss: 17.3478\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3539 - val_loss: 17.3477\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3538 - val_loss: 17.3475\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3537 - val_loss: 17.3474\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3535 - val_loss: 17.3473\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3534 - val_loss: 17.3472\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3532 - val_loss: 17.3471\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3531 - val_loss: 17.3470\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3530 - val_loss: 17.3469\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3528 - val_loss: 17.3468\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3527 - val_loss: 17.3466\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3526 - val_loss: 17.3465\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3524 - val_loss: 17.3464\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3523 - val_loss: 17.3463\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3522 - val_loss: 17.3462\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3520 - val_loss: 17.3461\n",
      "Epoch 714/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3519 - val_loss: 17.3460\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3518 - val_loss: 17.3458\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3516 - val_loss: 17.3457\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3515 - val_loss: 17.3456\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3514 - val_loss: 17.3455\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3512 - val_loss: 17.3454\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.3511 - val_loss: 17.3453\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3510 - val_loss: 17.3452\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3508 - val_loss: 17.3450\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3507 - val_loss: 17.3449\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3506 - val_loss: 17.3448\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3505 - val_loss: 17.3447\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3503 - val_loss: 17.3446\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.3502 - val_loss: 17.3445\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 16.3501 - val_loss: 17.3444\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3499 - val_loss: 17.3443\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3498 - val_loss: 17.3442\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.3497 - val_loss: 17.3441\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.3496 - val_loss: 17.3440\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3494 - val_loss: 17.3439\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3493 - val_loss: 17.3437\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3492 - val_loss: 17.3436\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3491 - val_loss: 17.3435\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3489 - val_loss: 17.3434\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3488 - val_loss: 17.3433\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.3487 - val_loss: 17.3432\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3485 - val_loss: 17.3431\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3484 - val_loss: 17.3430\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3483 - val_loss: 17.3429\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.3482 - val_loss: 17.3428\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3481 - val_loss: 17.3427\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3479 - val_loss: 17.3426\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3478 - val_loss: 17.3425\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3477 - val_loss: 17.3424\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3476 - val_loss: 17.3423\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3474 - val_loss: 17.3422\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3473 - val_loss: 17.3421\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3472 - val_loss: 17.3420\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3471 - val_loss: 17.3419\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3470 - val_loss: 17.3418\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3468 - val_loss: 17.3417\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3467 - val_loss: 17.3416\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3466 - val_loss: 17.3415\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3465 - val_loss: 17.3414\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3464 - val_loss: 17.3413\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3462 - val_loss: 17.3412\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3461 - val_loss: 17.3411\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3460 - val_loss: 17.3410\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3459 - val_loss: 17.3409\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3458 - val_loss: 17.3408\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3457 - val_loss: 17.3407\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3455 - val_loss: 17.3406\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3454 - val_loss: 17.3405\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3453 - val_loss: 17.3404\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3452 - val_loss: 17.3403\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3451 - val_loss: 17.3402\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3449 - val_loss: 17.3401\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3448 - val_loss: 17.3400\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3447 - val_loss: 17.3399\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3446 - val_loss: 17.3398\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3445 - val_loss: 17.3397\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 16.3444 - val_loss: 17.3396\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.3443 - val_loss: 17.3395\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3441 - val_loss: 17.3394\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 16.3440 - val_loss: 17.3393\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.3439 - val_loss: 17.3392\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 16.3438 - val_loss: 17.3391\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 16.3437 - val_loss: 17.3390\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3436 - val_loss: 17.3389\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3434 - val_loss: 17.3388\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3433 - val_loss: 17.3387\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.3432 - val_loss: 17.3386\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 16.3431 - val_loss: 17.3385\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.3430 - val_loss: 17.3384\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3429 - val_loss: 17.3383\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3428 - val_loss: 17.3382\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.3427 - val_loss: 17.3381\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 16.3425 - val_loss: 17.3380\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.3424 - val_loss: 17.3379\n",
      "Epoch 793/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3423 - val_loss: 17.3378\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3422 - val_loss: 17.3378\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3421 - val_loss: 17.3377\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3420 - val_loss: 17.3376\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.3419 - val_loss: 17.3375\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3418 - val_loss: 17.3374\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3417 - val_loss: 17.3373\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.3416 - val_loss: 17.3372\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.3415 - val_loss: 17.3371\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.3413 - val_loss: 17.3370\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3412 - val_loss: 17.3370\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3411 - val_loss: 17.3369\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3410 - val_loss: 17.3368\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3409 - val_loss: 17.3367\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3408 - val_loss: 17.3366\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3407 - val_loss: 17.3365\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3406 - val_loss: 17.3364\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3405 - val_loss: 17.3363\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3404 - val_loss: 17.3362\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3403 - val_loss: 17.3361\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3402 - val_loss: 17.3360\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3401 - val_loss: 17.3360\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3400 - val_loss: 17.3359\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3399 - val_loss: 17.3358\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3398 - val_loss: 17.3357\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3397 - val_loss: 17.3356\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3396 - val_loss: 17.3355\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3395 - val_loss: 17.3354\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3394 - val_loss: 17.3354\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3393 - val_loss: 17.3353\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3392 - val_loss: 17.3352\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3391 - val_loss: 17.3351\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3390 - val_loss: 17.3350\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3389 - val_loss: 17.3349\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3388 - val_loss: 17.3348\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3386 - val_loss: 17.3347\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3386 - val_loss: 17.3347\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3385 - val_loss: 17.3346\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3383 - val_loss: 17.3345\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.3382 - val_loss: 17.3344\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 16.3382 - val_loss: 17.3343\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3381 - val_loss: 17.3342\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.3379 - val_loss: 17.3342\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3378 - val_loss: 17.3341\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3378 - val_loss: 17.3340\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3377 - val_loss: 17.3339\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3376 - val_loss: 17.3338\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3375 - val_loss: 17.3338\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3374 - val_loss: 17.3337\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3373 - val_loss: 17.3336\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3372 - val_loss: 17.3335\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 16.3371 - val_loss: 17.3334\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3370 - val_loss: 17.3333\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3369 - val_loss: 17.3333\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3368 - val_loss: 17.3332\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.3367 - val_loss: 17.3331\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3366 - val_loss: 17.3330\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3365 - val_loss: 17.3329\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3364 - val_loss: 17.3328\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3363 - val_loss: 17.3328\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3362 - val_loss: 17.3327\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3361 - val_loss: 17.3326\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3360 - val_loss: 17.3325\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3359 - val_loss: 17.3324\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3358 - val_loss: 17.3324\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3357 - val_loss: 17.3323\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3356 - val_loss: 17.3322\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3355 - val_loss: 17.3321\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3354 - val_loss: 17.3320\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3353 - val_loss: 17.3320\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3353 - val_loss: 17.3319\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3352 - val_loss: 17.3318\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3351 - val_loss: 17.3317\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3350 - val_loss: 17.3317\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3349 - val_loss: 17.3316\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3348 - val_loss: 17.3315\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3347 - val_loss: 17.3314\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3346 - val_loss: 17.3314\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3345 - val_loss: 17.3313\n",
      "Epoch 872/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3344 - val_loss: 17.3312\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3344 - val_loss: 17.3311\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3343 - val_loss: 17.3310\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3342 - val_loss: 17.3310\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3341 - val_loss: 17.3309\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.3340 - val_loss: 17.3308\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3339 - val_loss: 17.3307\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3338 - val_loss: 17.3307\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 16.3337 - val_loss: 17.3306\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 16.3336 - val_loss: 17.3305\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3335 - val_loss: 17.3305\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3335 - val_loss: 17.3304\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 16.3334 - val_loss: 17.3303\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 16.3333 - val_loss: 17.3302\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3332 - val_loss: 17.3302\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3331 - val_loss: 17.3301\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3330 - val_loss: 17.3300\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3329 - val_loss: 17.3299\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.3329 - val_loss: 17.3299\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.3328 - val_loss: 17.3298\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3327 - val_loss: 17.3297\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3326 - val_loss: 17.3297\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 16.3325 - val_loss: 17.3296\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 16.3324 - val_loss: 17.3295\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 16.3323 - val_loss: 17.3294\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3322 - val_loss: 17.3294\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3322 - val_loss: 17.3293\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3321 - val_loss: 17.3292\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3320 - val_loss: 17.3291\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3319 - val_loss: 17.3291\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3318 - val_loss: 17.3290\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3317 - val_loss: 17.3289\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3317 - val_loss: 17.3289\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3316 - val_loss: 17.3288\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3315 - val_loss: 17.3287\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3314 - val_loss: 17.3286\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3313 - val_loss: 17.3286\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3312 - val_loss: 17.3285\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3311 - val_loss: 17.3284\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3311 - val_loss: 17.3284\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3310 - val_loss: 17.3283\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3309 - val_loss: 17.3282\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3308 - val_loss: 17.3281\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3307 - val_loss: 17.3281\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3306 - val_loss: 17.3280\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3305 - val_loss: 17.3279\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3304 - val_loss: 17.3278\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3304 - val_loss: 17.3278\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3303 - val_loss: 17.3277\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3302 - val_loss: 17.3276\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3301 - val_loss: 17.3276\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3300 - val_loss: 17.3275\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3300 - val_loss: 17.3274\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3299 - val_loss: 17.3274\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3298 - val_loss: 17.3273\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.3297 - val_loss: 17.3272\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 16.3296 - val_loss: 17.3271\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3295 - val_loss: 17.3271\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3295 - val_loss: 17.3270\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3294 - val_loss: 17.3269\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.3293 - val_loss: 17.3269\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3292 - val_loss: 17.3268\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3291 - val_loss: 17.3267\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3291 - val_loss: 17.3267\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3290 - val_loss: 17.3266\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 16.3289 - val_loss: 17.3265\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 16.3288 - val_loss: 17.3265\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3288 - val_loss: 17.3264\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3287 - val_loss: 17.3264\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 16.3286 - val_loss: 17.3263\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3285 - val_loss: 17.3262\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3284 - val_loss: 17.3262\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3284 - val_loss: 17.3261\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3283 - val_loss: 17.3260\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3282 - val_loss: 17.3260\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3281 - val_loss: 17.3259\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3281 - val_loss: 17.3258\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3280 - val_loss: 17.3258\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3279 - val_loss: 17.3257\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3278 - val_loss: 17.3256\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3278 - val_loss: 17.3256\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3277 - val_loss: 17.3255\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3276 - val_loss: 17.3255\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3275 - val_loss: 17.3254\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3275 - val_loss: 17.3253\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3274 - val_loss: 17.3253\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3273 - val_loss: 17.3252\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3272 - val_loss: 17.3252\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3272 - val_loss: 17.3251\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3271 - val_loss: 17.3250\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.3270 - val_loss: 17.3250\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.3270 - val_loss: 17.3249\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3269 - val_loss: 17.3249\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3268 - val_loss: 17.3248\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3267 - val_loss: 17.3247\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3267 - val_loss: 17.3246\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.3266 - val_loss: 17.3246\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3265 - val_loss: 17.3245\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3264 - val_loss: 17.3245\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.3264 - val_loss: 17.3244\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3263 - val_loss: 17.3243\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3262 - val_loss: 17.3243\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 16.3262 - val_loss: 17.3242\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.3261 - val_loss: 17.3242\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3260 - val_loss: 17.3241\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 16.3259 - val_loss: 17.3241\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 16.3259 - val_loss: 17.3240\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3258 - val_loss: 17.3239\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3257 - val_loss: 17.3239\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3257 - val_loss: 17.3238\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 16.3256 - val_loss: 17.3238\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 16.3255 - val_loss: 17.3237\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 16.3255 - val_loss: 17.3236\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3254 - val_loss: 17.3236\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3253 - val_loss: 17.3235\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 16.3252 - val_loss: 17.3235\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16.3252 - val_loss: 17.3234\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 16.3251 - val_loss: 17.3234\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 16.3250 - val_loss: 17.3233\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 16.3250 - val_loss: 17.3232\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3249 - val_loss: 17.3232\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3248 - val_loss: 17.3231\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 16.3248 - val_loss: 17.3231\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3247 - val_loss: 17.3230\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3246 - val_loss: 17.3230\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3245 - val_loss: 17.3229\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.3245 - val_loss: 17.3228\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 16.3244 - val_loss: 17.3228\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 16.3243 - val_loss: 17.3227\n",
      "0.16884716 0.30571434\n",
      "-0.011399869 0.11268022\n",
      "0.43270373 0.09695864\n"
     ]
    }
   ],
   "source": [
    "#把除最后一层外的神经网络层固定优化，这里固定住后面要重新编译模型，不然这部分的参数不起作用\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "#加载模型，加载完模型后必须重新compile一次，如果不compile而直接fit，模型参数不会优化\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(exponential_decay)\n",
    "              ,loss='mse'\n",
    "#               ,metrics=['mae','lr_mertic']\n",
    "             )    \n",
    "history = model.fit(x_train, y_train, batch_size=y_train.shape[0], epochs=1000, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    validation_freq=1,\n",
    "                    callbacks=[cp_callback]\n",
    "#                     ,callbacks=[reduce_lr]\n",
    "                   )\n",
    "layer0 = model.layers[0].get_weights()\n",
    "layer2 = model.layers[2].get_weights()\n",
    "layer3 = model.layers[3].get_weights()\n",
    "print(layer0[0][0,0],layer0[1][0])\n",
    "print(layer2[0][0,0],layer2[1][0])\n",
    "print(layer3[0][0,0],layer3[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save_path_transfer_free=\"./Fe-C-O_angel/transfer_free/checkpoint.ckpt\"   \n",
    "#读取模型\n",
    "if os.path.exists(checkpoint_save_path_transfer_free + '.index'):\n",
    "    print('- - - - - - - - - - - -load the model- - - - - - - - - - - -')\n",
    "    model.load_weights(checkpoint_save_path_transfer_free)\n",
    "#保存模型\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path_transfer_free,\n",
    "                                                save_weights_only=True,\n",
    "                                                save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16884716 0.30571434\n",
      "-0.011399869 0.11268022\n",
      "0.43270373 0.09695864\n"
     ]
    }
   ],
   "source": [
    "layer0 = model.layers[0].get_weights()\n",
    "layer2 = model.layers[2].get_weights()\n",
    "layer3 = model.layers[3].get_weights()\n",
    "print(layer0[0][0,0],layer0[1][0])\n",
    "print(layer2[0][0,0],layer2[1][0])\n",
    "print(layer3[0][0,0],layer3[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Epoch 1/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 16.3243 - val_loss: 17.1837\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.1781 - val_loss: 17.0508\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.0384 - val_loss: 16.9238\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.9051 - val_loss: 16.8028\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.7779 - val_loss: 16.6874\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 15.6566 - val_loss: 16.5774\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15.5410 - val_loss: 16.4724\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 15.4306 - val_loss: 16.3723\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 15.3251 - val_loss: 16.2767\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 15.2241 - val_loss: 16.1853\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 15.1274 - val_loss: 16.0977\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 15.0345 - val_loss: 16.0136\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 14.9450 - val_loss: 15.9324\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 14.8585 - val_loss: 15.8539\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 14.7745 - val_loss: 15.7775\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 14.6929 - val_loss: 15.7032\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 14.6133 - val_loss: 15.6303\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 14.5353 - val_loss: 15.5587\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 14.4588 - val_loss: 15.4880\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.3834 - val_loss: 15.4181\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 14.3091 - val_loss: 15.3489\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 14.2357 - val_loss: 15.2803\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 14.1631 - val_loss: 15.2122\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 14.0912 - val_loss: 15.1447\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 14.0199 - val_loss: 15.0776\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 13.9494 - val_loss: 15.0107\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 13.8795 - val_loss: 14.9443\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.8104 - val_loss: 14.8786\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 13.7421 - val_loss: 14.8135\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 13.6746 - val_loss: 14.7491\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 13.6080 - val_loss: 14.6856\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 13.5424 - val_loss: 14.6228\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 13.4778 - val_loss: 14.5610\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 13.4142 - val_loss: 14.5001\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 13.3518 - val_loss: 14.4401\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.2905 - val_loss: 14.3811\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.2303 - val_loss: 14.3231\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 13.1711 - val_loss: 14.2661\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 13.1129 - val_loss: 14.2101\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.0556 - val_loss: 14.1549\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 12.9994 - val_loss: 14.1006\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12.9440 - val_loss: 14.0471\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 12.8895 - val_loss: 13.9944\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 12.8358 - val_loss: 13.9426\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.78 - 0s 52ms/step - loss: 12.7829 - val_loss: 13.8915\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 12.7308 - val_loss: 13.8413\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 12.6795 - val_loss: 13.7918\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 12.6290 - val_loss: 13.7432\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 12.5791 - val_loss: 13.6953\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 12.5300 - val_loss: 13.6481\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 12.4817 - val_loss: 13.6017\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 12.4341 - val_loss: 13.5561\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.3872 - val_loss: 13.5112\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 12.3410 - val_loss: 13.4670\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 12.2956 - val_loss: 13.4237\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 12.2509 - val_loss: 13.3810\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 12.2069 - val_loss: 13.3390\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 12.1635 - val_loss: 13.2978\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 12.1210 - val_loss: 13.2573\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.0790 - val_loss: 13.2174\n",
      "Epoch 61/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 12.0377 - val_loss: 13.1782\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11.9970 - val_loss: 13.1396\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 11.9570 - val_loss: 13.1017\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 11.9176 - val_loss: 13.0644\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 11.8787 - val_loss: 13.0277\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 11.8404 - val_loss: 12.9915\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 11.8028 - val_loss: 12.9560\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 11.7657 - val_loss: 12.9211\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 11.7292 - val_loss: 12.8867\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 11.6932 - val_loss: 12.8530\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 11.6578 - val_loss: 12.8199\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 11.6229 - val_loss: 12.7873\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 11.5885 - val_loss: 12.7553\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 11.5545 - val_loss: 12.7237\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 11.5211 - val_loss: 12.6927\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 11.4881 - val_loss: 12.6620\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 11.4556 - val_loss: 12.6319\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.4236 - val_loss: 12.6023\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.3921 - val_loss: 12.5731\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.3610 - val_loss: 12.5443\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.3303 - val_loss: 12.5160\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.3002 - val_loss: 12.4881\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 11.2704 - val_loss: 12.4606\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 11.2411 - val_loss: 12.4335\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11.2122 - val_loss: 12.4067\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 11.1837 - val_loss: 12.3804\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.1557 - val_loss: 12.3544\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.1280 - val_loss: 12.3288\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 11.1007 - val_loss: 12.3036\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 11.0738 - val_loss: 12.2787\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 11.0473 - val_loss: 12.2542\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.0211 - val_loss: 12.2300\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.9954 - val_loss: 12.2063\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.9699 - val_loss: 12.1828\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.9449 - val_loss: 12.1597\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 10.9201 - val_loss: 12.1369\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10.8957 - val_loss: 12.1143\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 10.8717 - val_loss: 12.0918\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10.8479 - val_loss: 12.0696\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10.8245 - val_loss: 12.0477\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 10.8014 - val_loss: 12.0261\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10.7786 - val_loss: 12.0048\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10.7561 - val_loss: 11.9838\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 10.7339 - val_loss: 11.9631\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10.7120 - val_loss: 11.9427\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10.6903 - val_loss: 11.9225\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10.6691 - val_loss: 11.9026\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 10.6482 - val_loss: 11.8830\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10.6277 - val_loss: 11.8637\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10.6074 - val_loss: 11.8447\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 10.5873 - val_loss: 11.8259\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10.5675 - val_loss: 11.8074\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10.5479 - val_loss: 11.7892\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10.5286 - val_loss: 11.7711\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 10.5095 - val_loss: 11.7534\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10.4906 - val_loss: 11.7358\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10.4719 - val_loss: 11.7185\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10.4534 - val_loss: 11.7014\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 10.4352 - val_loss: 11.6845\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 10.4172 - val_loss: 11.6678\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.3993 - val_loss: 11.6514\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 10.3817 - val_loss: 11.6352\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10.3642 - val_loss: 11.6192\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10.3469 - val_loss: 11.6034\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 10.3298 - val_loss: 11.5878\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 10.3129 - val_loss: 11.5725\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 10.2961 - val_loss: 11.5572\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.2796 - val_loss: 11.5422\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 10.2633 - val_loss: 11.5273\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 10.2471 - val_loss: 11.5126\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.2311 - val_loss: 11.4981\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10.2153 - val_loss: 11.4837\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.1996 - val_loss: 11.4696\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.1841 - val_loss: 11.4556\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 10.1688 - val_loss: 11.4419\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 10.1536 - val_loss: 11.4283\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 10.1385 - val_loss: 11.4149\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.1236 - val_loss: 11.4017\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.1089 - val_loss: 11.3886\n",
      "Epoch 140/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 10.0943 - val_loss: 11.3757\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.0798 - val_loss: 11.3630\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.0655 - val_loss: 11.3504\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 10.0513 - val_loss: 11.3379\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 10.0373 - val_loss: 11.3256\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10.0234 - val_loss: 11.3135\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10.0097 - val_loss: 11.3015\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.9961 - val_loss: 11.2896\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9.9826 - val_loss: 11.2779\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9.9692 - val_loss: 11.2664\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.9560 - val_loss: 11.2549\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.9429 - val_loss: 11.2436\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.9298 - val_loss: 11.2324\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.9169 - val_loss: 11.2213\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.9041 - val_loss: 11.2104\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.8915 - val_loss: 11.1996\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.8789 - val_loss: 11.1889\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.8664 - val_loss: 11.1782\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.8540 - val_loss: 11.1676\n",
      "Epoch 159/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.8417 - val_loss: 11.1572\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.8295 - val_loss: 11.1468\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.8174 - val_loss: 11.1366\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.8054 - val_loss: 11.1264\n",
      "Epoch 163/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.7935 - val_loss: 11.1164\n",
      "Epoch 164/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.7817 - val_loss: 11.1064\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.7700 - val_loss: 11.0966\n",
      "Epoch 166/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7583 - val_loss: 11.0868\n",
      "Epoch 167/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7468 - val_loss: 11.0771\n",
      "Epoch 168/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.7353 - val_loss: 11.0676\n",
      "Epoch 169/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7240 - val_loss: 11.0581\n",
      "Epoch 170/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.7127 - val_loss: 11.0486\n",
      "Epoch 171/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.7014 - val_loss: 11.0393\n",
      "Epoch 172/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.6903 - val_loss: 11.0300\n",
      "Epoch 173/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6793 - val_loss: 11.0209\n",
      "Epoch 174/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6683 - val_loss: 11.0118\n",
      "Epoch 175/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.6574 - val_loss: 11.0027\n",
      "Epoch 176/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.6465 - val_loss: 10.9938\n",
      "Epoch 177/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6358 - val_loss: 10.9849\n",
      "Epoch 178/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.6251 - val_loss: 10.9761\n",
      "Epoch 179/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6145 - val_loss: 10.9674\n",
      "Epoch 180/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.6039 - val_loss: 10.9588\n",
      "Epoch 181/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.5934 - val_loss: 10.9502\n",
      "Epoch 182/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.5830 - val_loss: 10.9417\n",
      "Epoch 183/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.5726 - val_loss: 10.9333\n",
      "Epoch 184/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5624 - val_loss: 10.9250\n",
      "Epoch 185/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5522 - val_loss: 10.9168\n",
      "Epoch 186/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5420 - val_loss: 10.9086\n",
      "Epoch 187/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.5320 - val_loss: 10.9005\n",
      "Epoch 188/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5219 - val_loss: 10.8924\n",
      "Epoch 189/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.5119 - val_loss: 10.8844\n",
      "Epoch 190/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5020 - val_loss: 10.8765\n",
      "Epoch 191/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.4922 - val_loss: 10.8686\n",
      "Epoch 192/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4824 - val_loss: 10.8608\n",
      "Epoch 193/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.4726 - val_loss: 10.8531\n",
      "Epoch 194/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4629 - val_loss: 10.8454\n",
      "Epoch 195/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.4533 - val_loss: 10.8378\n",
      "Epoch 196/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.4437 - val_loss: 10.8302\n",
      "Epoch 197/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.4341 - val_loss: 10.8227\n",
      "Epoch 198/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.4247 - val_loss: 10.8153\n",
      "Epoch 199/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.4152 - val_loss: 10.8079\n",
      "Epoch 200/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.4058 - val_loss: 10.8006\n",
      "Epoch 201/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.3965 - val_loss: 10.7933\n",
      "Epoch 202/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.3872 - val_loss: 10.7860\n",
      "Epoch 203/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.3780 - val_loss: 10.7789\n",
      "Epoch 204/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.3688 - val_loss: 10.7718\n",
      "Epoch 205/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.3597 - val_loss: 10.7647\n",
      "Epoch 206/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.3506 - val_loss: 10.7577\n",
      "Epoch 207/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.3415 - val_loss: 10.7508\n",
      "Epoch 208/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.3325 - val_loss: 10.7439\n",
      "Epoch 209/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.3235 - val_loss: 10.7370\n",
      "Epoch 210/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3146 - val_loss: 10.7302\n",
      "Epoch 211/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3057 - val_loss: 10.7235\n",
      "Epoch 212/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.2969 - val_loss: 10.7168\n",
      "Epoch 213/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.2882 - val_loss: 10.7101\n",
      "Epoch 214/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.2797 - val_loss: 10.7035\n",
      "Epoch 215/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2714 - val_loss: 10.6970\n",
      "Epoch 216/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.2630 - val_loss: 10.6906\n",
      "Epoch 217/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2547 - val_loss: 10.6842\n",
      "Epoch 218/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.2465 - val_loss: 10.6779\n",
      "Epoch 219/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step - loss: 9.2383 - val_loss: 10.6717\n",
      "Epoch 220/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.2301 - val_loss: 10.6655\n",
      "Epoch 221/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.2220 - val_loss: 10.6595\n",
      "Epoch 222/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.2139 - val_loss: 10.6534\n",
      "Epoch 223/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2058 - val_loss: 10.6475\n",
      "Epoch 224/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.1978 - val_loss: 10.6416\n",
      "Epoch 225/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.1898 - val_loss: 10.6358\n",
      "Epoch 226/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.1819 - val_loss: 10.6301\n",
      "Epoch 227/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.1740 - val_loss: 10.6244\n",
      "Epoch 228/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.1661 - val_loss: 10.6187\n",
      "Epoch 229/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.1583 - val_loss: 10.6132\n",
      "Epoch 230/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.1505 - val_loss: 10.6076\n",
      "Epoch 231/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.1428 - val_loss: 10.6021\n",
      "Epoch 232/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.1350 - val_loss: 10.5965\n",
      "Epoch 233/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.1274 - val_loss: 10.5908\n",
      "Epoch 234/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.1197 - val_loss: 10.5852\n",
      "Epoch 235/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1121 - val_loss: 10.5796\n",
      "Epoch 236/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.1045 - val_loss: 10.5740\n",
      "Epoch 237/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.0970 - val_loss: 10.5684\n",
      "Epoch 238/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.0895 - val_loss: 10.5628\n",
      "Epoch 239/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.0820 - val_loss: 10.5573\n",
      "Epoch 240/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.0745 - val_loss: 10.5517\n",
      "Epoch 241/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.0671 - val_loss: 10.5461\n",
      "Epoch 242/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.0597 - val_loss: 10.5406\n",
      "Epoch 243/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0524 - val_loss: 10.5351\n",
      "Epoch 244/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.0450 - val_loss: 10.5296\n",
      "Epoch 245/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9.0377 - val_loss: 10.5241\n",
      "Epoch 246/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.0304 - val_loss: 10.5186\n",
      "Epoch 247/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.0232 - val_loss: 10.5132\n",
      "Epoch 248/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.0159 - val_loss: 10.5078\n",
      "Epoch 249/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.0087 - val_loss: 10.5024\n",
      "Epoch 250/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 9.0016 - val_loss: 10.4970\n",
      "Epoch 251/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 8.9944 - val_loss: 10.4917\n",
      "Epoch 252/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.9873 - val_loss: 10.4865\n",
      "Epoch 253/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.9802 - val_loss: 10.4812\n",
      "Epoch 254/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.9732 - val_loss: 10.4760\n",
      "Epoch 255/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.9661 - val_loss: 10.4709\n",
      "Epoch 256/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.9591 - val_loss: 10.4657\n",
      "Epoch 257/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.9521 - val_loss: 10.4606\n",
      "Epoch 258/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.9452 - val_loss: 10.4555\n",
      "Epoch 259/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.9382 - val_loss: 10.4505\n",
      "Epoch 260/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.9313 - val_loss: 10.4454\n",
      "Epoch 261/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.9244 - val_loss: 10.4404\n",
      "Epoch 262/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.9175 - val_loss: 10.4354\n",
      "Epoch 263/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.9107 - val_loss: 10.4304\n",
      "Epoch 264/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.9038 - val_loss: 10.4254\n",
      "Epoch 265/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.8970 - val_loss: 10.4204\n",
      "Epoch 266/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.8903 - val_loss: 10.4155\n",
      "Epoch 267/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.8835 - val_loss: 10.4107\n",
      "Epoch 268/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.8768 - val_loss: 10.4059\n",
      "Epoch 269/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.8701 - val_loss: 10.4011\n",
      "Epoch 270/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.8634 - val_loss: 10.3964\n",
      "Epoch 271/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.8568 - val_loss: 10.3916\n",
      "Epoch 272/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.8502 - val_loss: 10.3869\n",
      "Epoch 273/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.8436 - val_loss: 10.3822\n",
      "Epoch 274/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.8370 - val_loss: 10.3775\n",
      "Epoch 275/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8305 - val_loss: 10.3728\n",
      "Epoch 276/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.8239 - val_loss: 10.3682\n",
      "Epoch 277/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.8174 - val_loss: 10.3635\n",
      "Epoch 278/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.8109 - val_loss: 10.3590\n",
      "Epoch 279/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.8044 - val_loss: 10.3544\n",
      "Epoch 280/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.7980 - val_loss: 10.3499\n",
      "Epoch 281/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.7915 - val_loss: 10.3454\n",
      "Epoch 282/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.7851 - val_loss: 10.3409\n",
      "Epoch 283/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.7787 - val_loss: 10.3364\n",
      "Epoch 284/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.7723 - val_loss: 10.3320\n",
      "Epoch 285/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7660 - val_loss: 10.3275\n",
      "Epoch 286/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.7596 - val_loss: 10.3231\n",
      "Epoch 287/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.7533 - val_loss: 10.3187\n",
      "Epoch 288/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7469 - val_loss: 10.3143\n",
      "Epoch 289/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.7406 - val_loss: 10.3099\n",
      "Epoch 290/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.7343 - val_loss: 10.3055\n",
      "Epoch 291/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.7281 - val_loss: 10.3012\n",
      "Epoch 292/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.7218 - val_loss: 10.2968\n",
      "Epoch 293/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.7156 - val_loss: 10.2925\n",
      "Epoch 294/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.7094 - val_loss: 10.2881\n",
      "Epoch 295/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.7031 - val_loss: 10.2838\n",
      "Epoch 296/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.6969 - val_loss: 10.2795\n",
      "Epoch 297/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.6908 - val_loss: 10.2752\n",
      "Epoch 298/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step - loss: 8.6846 - val_loss: 10.2709\n",
      "Epoch 299/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.6785 - val_loss: 10.2666\n",
      "Epoch 300/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.6724 - val_loss: 10.2624\n",
      "Epoch 301/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.6663 - val_loss: 10.2582\n",
      "Epoch 302/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.6602 - val_loss: 10.2540\n",
      "Epoch 303/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.6542 - val_loss: 10.2498\n",
      "Epoch 304/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.6481 - val_loss: 10.2457\n",
      "Epoch 305/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.6421 - val_loss: 10.2416\n",
      "Epoch 306/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.6361 - val_loss: 10.2375\n",
      "Epoch 307/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.6301 - val_loss: 10.2334\n",
      "Epoch 308/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.6241 - val_loss: 10.2293\n",
      "Epoch 309/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.6182 - val_loss: 10.2251\n",
      "Epoch 310/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6123 - val_loss: 10.2210\n",
      "Epoch 311/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.6064 - val_loss: 10.2168\n",
      "Epoch 312/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.6005 - val_loss: 10.2127\n",
      "Epoch 313/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.5946 - val_loss: 10.2085\n",
      "Epoch 314/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5887 - val_loss: 10.2042\n",
      "Epoch 315/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5829 - val_loss: 10.1998\n",
      "Epoch 316/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.5770 - val_loss: 10.1954\n",
      "Epoch 317/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.5712 - val_loss: 10.1910\n",
      "Epoch 318/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5654 - val_loss: 10.1865\n",
      "Epoch 319/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.5595 - val_loss: 10.1821\n",
      "Epoch 320/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.5538 - val_loss: 10.1777\n",
      "Epoch 321/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.5480 - val_loss: 10.1734\n",
      "Epoch 322/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5422 - val_loss: 10.1691\n",
      "Epoch 323/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.5365 - val_loss: 10.1648\n",
      "Epoch 324/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.5308 - val_loss: 10.1606\n",
      "Epoch 325/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5251 - val_loss: 10.1565\n",
      "Epoch 326/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.5194 - val_loss: 10.1524\n",
      "Epoch 327/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.5137 - val_loss: 10.1483\n",
      "Epoch 328/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.5081 - val_loss: 10.1443\n",
      "Epoch 329/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5025 - val_loss: 10.1404\n",
      "Epoch 330/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.4968 - val_loss: 10.1365\n",
      "Epoch 331/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.4912 - val_loss: 10.1325\n",
      "Epoch 332/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.4857 - val_loss: 10.1287\n",
      "Epoch 333/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.4801 - val_loss: 10.1248\n",
      "Epoch 334/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.4745 - val_loss: 10.1210\n",
      "Epoch 335/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.4690 - val_loss: 10.1171\n",
      "Epoch 336/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.4635 - val_loss: 10.1133\n",
      "Epoch 337/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.4580 - val_loss: 10.1094\n",
      "Epoch 338/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.4525 - val_loss: 10.1055\n",
      "Epoch 339/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.4470 - val_loss: 10.1017\n",
      "Epoch 340/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.4415 - val_loss: 10.0978\n",
      "Epoch 341/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.4361 - val_loss: 10.0939\n",
      "Epoch 342/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.4307 - val_loss: 10.0901\n",
      "Epoch 343/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.4253 - val_loss: 10.0862\n",
      "Epoch 344/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.4199 - val_loss: 10.0824\n",
      "Epoch 345/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.4145 - val_loss: 10.0786\n",
      "Epoch 346/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.4092 - val_loss: 10.0748\n",
      "Epoch 347/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.4038 - val_loss: 10.0710\n",
      "Epoch 348/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.3985 - val_loss: 10.0672\n",
      "Epoch 349/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.3932 - val_loss: 10.0634\n",
      "Epoch 350/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.3879 - val_loss: 10.0597\n",
      "Epoch 351/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.3826 - val_loss: 10.0559\n",
      "Epoch 352/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.3774 - val_loss: 10.0522\n",
      "Epoch 353/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.3721 - val_loss: 10.0485\n",
      "Epoch 354/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.3669 - val_loss: 10.0448\n",
      "Epoch 355/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.3617 - val_loss: 10.0411\n",
      "Epoch 356/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.3565 - val_loss: 10.0374\n",
      "Epoch 357/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.3513 - val_loss: 10.0337\n",
      "Epoch 358/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.3462 - val_loss: 10.0301\n",
      "Epoch 359/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.3410 - val_loss: 10.0264\n",
      "Epoch 360/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.3359 - val_loss: 10.0228\n",
      "Epoch 361/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.3308 - val_loss: 10.0191\n",
      "Epoch 362/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.3257 - val_loss: 10.0155\n",
      "Epoch 363/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.3206 - val_loss: 10.0119\n",
      "Epoch 364/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.3155 - val_loss: 10.0083\n",
      "Epoch 365/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.3104 - val_loss: 10.0047\n",
      "Epoch 366/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.3054 - val_loss: 10.0011\n",
      "Epoch 367/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.3004 - val_loss: 9.9976\n",
      "Epoch 368/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.2953 - val_loss: 9.9940\n",
      "Epoch 369/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.2903 - val_loss: 9.9905\n",
      "Epoch 370/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.2853 - val_loss: 9.9870\n",
      "Epoch 371/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.2804 - val_loss: 9.9835\n",
      "Epoch 372/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.2754 - val_loss: 9.9800\n",
      "Epoch 373/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 8.2705 - val_loss: 9.9766\n",
      "Epoch 374/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.2655 - val_loss: 9.9731\n",
      "Epoch 375/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.2606 - val_loss: 9.9697\n",
      "Epoch 376/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.2557 - val_loss: 9.9663\n",
      "Epoch 377/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.2508 - val_loss: 9.9629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.2459 - val_loss: 9.9596\n",
      "Epoch 379/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.2411 - val_loss: 9.9562\n",
      "Epoch 380/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.2362 - val_loss: 9.9529\n",
      "Epoch 381/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.2314 - val_loss: 9.9495\n",
      "Epoch 382/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.2265 - val_loss: 9.9462\n",
      "Epoch 383/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.2218 - val_loss: 9.9429\n",
      "Epoch 384/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.2170 - val_loss: 9.9395\n",
      "Epoch 385/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.2122 - val_loss: 9.9362\n",
      "Epoch 386/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.2075 - val_loss: 9.9329\n",
      "Epoch 387/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.2027 - val_loss: 9.9297\n",
      "Epoch 388/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.1980 - val_loss: 9.9264\n",
      "Epoch 389/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.1933 - val_loss: 9.9231\n",
      "Epoch 390/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.1886 - val_loss: 9.9199\n",
      "Epoch 391/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.1839 - val_loss: 9.9167\n",
      "Epoch 392/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.1793 - val_loss: 9.9134\n",
      "Epoch 393/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.1746 - val_loss: 9.9102\n",
      "Epoch 394/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.1699 - val_loss: 9.9071\n",
      "Epoch 395/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.1653 - val_loss: 9.9039\n",
      "Epoch 396/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.1607 - val_loss: 9.9007\n",
      "Epoch 397/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.1561 - val_loss: 9.8975\n",
      "Epoch 398/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.1515 - val_loss: 9.8944\n",
      "Epoch 399/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.1469 - val_loss: 9.8912\n",
      "Epoch 400/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1423 - val_loss: 9.8881\n",
      "Epoch 401/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.1377 - val_loss: 9.8850\n",
      "Epoch 402/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.1332 - val_loss: 9.8819\n",
      "Epoch 403/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.1286 - val_loss: 9.8788\n",
      "Epoch 404/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.1241 - val_loss: 9.8757\n",
      "Epoch 405/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.1196 - val_loss: 9.8727\n",
      "Epoch 406/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.1151 - val_loss: 9.8697\n",
      "Epoch 407/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.1106 - val_loss: 9.8667\n",
      "Epoch 408/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.1061 - val_loss: 9.8636\n",
      "Epoch 409/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.1016 - val_loss: 9.8606\n",
      "Epoch 410/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.0971 - val_loss: 9.8577\n",
      "Epoch 411/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.0927 - val_loss: 9.8547\n",
      "Epoch 412/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.0882 - val_loss: 9.8517\n",
      "Epoch 413/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.0838 - val_loss: 9.8488\n",
      "Epoch 414/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.0794 - val_loss: 9.8458\n",
      "Epoch 415/10000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 8.0750 - val_loss: 9.8429\n",
      "Epoch 416/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.0706 - val_loss: 9.8399\n",
      "Epoch 417/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.0662 - val_loss: 9.8370\n",
      "Epoch 418/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.0618 - val_loss: 9.8341\n",
      "Epoch 419/10000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.0575 - val_loss: 9.8312\n",
      "Epoch 420/10000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 8.0531 - val_loss: 9.8283\n",
      "Epoch 421/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.0488 - val_loss: 9.8254\n",
      "Epoch 422/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.0445 - val_loss: 9.8225\n",
      "Epoch 423/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.0402 - val_loss: 9.8196\n",
      "Epoch 424/10000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.0359 - val_loss: 9.8168\n",
      "Epoch 425/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.0316 - val_loss: 9.8139\n",
      "Epoch 426/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.0273 - val_loss: 9.8111\n",
      "Epoch 427/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.0230 - val_loss: 9.8082\n",
      "Epoch 428/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.0188 - val_loss: 9.8054\n",
      "Epoch 429/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.0145 - val_loss: 9.8026\n",
      "Epoch 430/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.0103 - val_loss: 9.7998\n",
      "Epoch 431/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.0061 - val_loss: 9.7970\n",
      "Epoch 432/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.0018 - val_loss: 9.7942\n",
      "Epoch 433/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.9976 - val_loss: 9.7914\n",
      "Epoch 434/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.9934 - val_loss: 9.7887\n",
      "Epoch 435/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.9893 - val_loss: 9.7859\n",
      "Epoch 436/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.9851 - val_loss: 9.7831\n",
      "Epoch 437/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.9809 - val_loss: 9.7804\n",
      "Epoch 438/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.9768 - val_loss: 9.7776\n",
      "Epoch 439/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.9726 - val_loss: 9.7749\n",
      "Epoch 440/10000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 7.9685 - val_loss: 9.7721\n",
      "Epoch 441/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.9644 - val_loss: 9.7694\n",
      "Epoch 442/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9603 - val_loss: 9.7667\n",
      "Epoch 443/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9562 - val_loss: 9.7640\n",
      "Epoch 444/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9521 - val_loss: 9.7613\n",
      "Epoch 445/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.9480 - val_loss: 9.7586\n",
      "Epoch 446/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.9439 - val_loss: 9.7559\n",
      "Epoch 447/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9399 - val_loss: 9.7532\n",
      "Epoch 448/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.9358 - val_loss: 9.7505\n",
      "Epoch 449/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9318 - val_loss: 9.7479\n",
      "Epoch 450/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.9277 - val_loss: 9.7452\n",
      "Epoch 451/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9237 - val_loss: 9.7425\n",
      "Epoch 452/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.9197 - val_loss: 9.7399\n",
      "Epoch 453/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9157 - val_loss: 9.7372\n",
      "Epoch 454/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.9117 - val_loss: 9.7346\n",
      "Epoch 455/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.9077 - val_loss: 9.7320\n",
      "Epoch 456/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.9037 - val_loss: 9.7294\n",
      "Epoch 457/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.8997 - val_loss: 9.7267\n",
      "Epoch 458/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 7.8958 - val_loss: 9.7241\n",
      "Epoch 459/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.8918 - val_loss: 9.7215\n",
      "Epoch 460/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.8879 - val_loss: 9.7189\n",
      "Epoch 461/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.8839 - val_loss: 9.7163\n",
      "Epoch 462/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.8800 - val_loss: 9.7137\n",
      "Epoch 463/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.8761 - val_loss: 9.7112\n",
      "Epoch 464/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.8721 - val_loss: 9.7086\n",
      "Epoch 465/10000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 7.8682 - val_loss: 9.7061\n",
      "Epoch 466/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.8643 - val_loss: 9.7035\n",
      "Epoch 467/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.8605 - val_loss: 9.7010\n",
      "Epoch 468/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.8566 - val_loss: 9.6985\n",
      "Epoch 469/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.8527 - val_loss: 9.6960\n",
      "Epoch 470/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.8489 - val_loss: 9.6935\n",
      "Epoch 471/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.8450 - val_loss: 9.6910\n",
      "Epoch 472/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.8412 - val_loss: 9.6885\n",
      "Epoch 473/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.8374 - val_loss: 9.6860\n",
      "Epoch 474/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.8335 - val_loss: 9.6836\n",
      "Epoch 475/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.8297 - val_loss: 9.6811\n",
      "Epoch 476/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.8259 - val_loss: 9.6787\n",
      "Epoch 477/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.8221 - val_loss: 9.6762\n",
      "Epoch 478/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.8183 - val_loss: 9.6738\n",
      "Epoch 479/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.8145 - val_loss: 9.6714\n",
      "Epoch 480/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.8108 - val_loss: 9.6690\n",
      "Epoch 481/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.8070 - val_loss: 9.6666\n",
      "Epoch 482/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.8033 - val_loss: 9.6643\n",
      "Epoch 483/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7995 - val_loss: 9.6619\n",
      "Epoch 484/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7958 - val_loss: 9.6595\n",
      "Epoch 485/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7921 - val_loss: 9.6572\n",
      "Epoch 486/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7883 - val_loss: 9.6548\n",
      "Epoch 487/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.7846 - val_loss: 9.6525\n",
      "Epoch 488/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7809 - val_loss: 9.6502\n",
      "Epoch 489/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7773 - val_loss: 9.6479\n",
      "Epoch 490/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.7736 - val_loss: 9.6455\n",
      "Epoch 491/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.7699 - val_loss: 9.6432\n",
      "Epoch 492/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.7662 - val_loss: 9.6409\n",
      "Epoch 493/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.7626 - val_loss: 9.6386\n",
      "Epoch 494/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.7589 - val_loss: 9.6364\n",
      "Epoch 495/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.7553 - val_loss: 9.6341\n",
      "Epoch 496/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7517 - val_loss: 9.6318\n",
      "Epoch 497/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.7481 - val_loss: 9.6296\n",
      "Epoch 498/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7445 - val_loss: 9.6273\n",
      "Epoch 499/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.7409 - val_loss: 9.6250\n",
      "Epoch 500/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.7373 - val_loss: 9.6228\n",
      "Epoch 501/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.7337 - val_loss: 9.6205\n",
      "Epoch 502/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7301 - val_loss: 9.6183\n",
      "Epoch 503/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.7265 - val_loss: 9.6161\n",
      "Epoch 504/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.7230 - val_loss: 9.6139\n",
      "Epoch 505/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7194 - val_loss: 9.6117\n",
      "Epoch 506/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7159 - val_loss: 9.6095\n",
      "Epoch 507/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.7124 - val_loss: 9.6073\n",
      "Epoch 508/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.7088 - val_loss: 9.6051\n",
      "Epoch 509/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.7053 - val_loss: 9.6029\n",
      "Epoch 510/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7018 - val_loss: 9.6007\n",
      "Epoch 511/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.6983 - val_loss: 9.5985\n",
      "Epoch 512/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.6949 - val_loss: 9.5963\n",
      "Epoch 513/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.6914 - val_loss: 9.5941\n",
      "Epoch 514/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.6879 - val_loss: 9.5920\n",
      "Epoch 515/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.6845 - val_loss: 9.5898\n",
      "Epoch 516/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.6810 - val_loss: 9.5876\n",
      "Epoch 517/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.6776 - val_loss: 9.5854\n",
      "Epoch 518/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.6741 - val_loss: 9.5833\n",
      "Epoch 519/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.6707 - val_loss: 9.5811\n",
      "Epoch 520/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.6673 - val_loss: 9.5789\n",
      "Epoch 521/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.6639 - val_loss: 9.5768\n",
      "Epoch 522/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.6605 - val_loss: 9.5746\n",
      "Epoch 523/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.6571 - val_loss: 9.5725\n",
      "Epoch 524/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.6537 - val_loss: 9.5703\n",
      "Epoch 525/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.6503 - val_loss: 9.5682\n",
      "Epoch 526/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.6469 - val_loss: 9.5660\n",
      "Epoch 527/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.6436 - val_loss: 9.5639\n",
      "Epoch 528/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.6402 - val_loss: 9.5618\n",
      "Epoch 529/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.6369 - val_loss: 9.5597\n",
      "Epoch 530/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.6335 - val_loss: 9.5576\n",
      "Epoch 531/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 7.6302 - val_loss: 9.5554\n",
      "Epoch 532/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.6268 - val_loss: 9.5533\n",
      "Epoch 533/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.6235 - val_loss: 9.5512\n",
      "Epoch 534/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.6202 - val_loss: 9.5491\n",
      "Epoch 535/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.6169 - val_loss: 9.5470\n",
      "Epoch 536/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 7.6136 - val_loss: 9.5449\n",
      "Epoch 537/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.6103 - val_loss: 9.5429\n",
      "Epoch 538/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step - loss: 7.6070 - val_loss: 9.5408\n",
      "Epoch 539/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.6037 - val_loss: 9.5387\n",
      "Epoch 540/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.6004 - val_loss: 9.5367\n",
      "Epoch 541/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.5971 - val_loss: 9.5347\n",
      "Epoch 542/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.5938 - val_loss: 9.5328\n",
      "Epoch 543/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5904 - val_loss: 9.5309\n",
      "Epoch 544/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5871 - val_loss: 9.5290\n",
      "Epoch 545/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5837 - val_loss: 9.5272\n",
      "Epoch 546/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.5804 - val_loss: 9.5253\n",
      "Epoch 547/10000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 7.5770 - val_loss: 9.5237\n",
      "Epoch 548/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.5737 - val_loss: 9.5219\n",
      "Epoch 549/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.5704 - val_loss: 9.5202\n",
      "Epoch 550/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.5670 - val_loss: 9.5185\n",
      "Epoch 551/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5637 - val_loss: 9.5168\n",
      "Epoch 552/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.5603 - val_loss: 9.5150\n",
      "Epoch 553/10000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 7.5570 - val_loss: 9.5132\n",
      "Epoch 554/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.5537 - val_loss: 9.5114\n",
      "Epoch 555/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.5504 - val_loss: 9.5095\n",
      "Epoch 556/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.5471 - val_loss: 9.5076\n",
      "Epoch 557/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.5438 - val_loss: 9.5057\n",
      "Epoch 558/10000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 7.5404 - val_loss: 9.5038\n",
      "Epoch 559/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.5372 - val_loss: 9.5019\n",
      "Epoch 560/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.5339 - val_loss: 9.5000\n",
      "Epoch 561/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.5306 - val_loss: 9.4981\n",
      "Epoch 562/10000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 7.5273 - val_loss: 9.4962\n",
      "Epoch 563/10000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 7.5240 - val_loss: 9.4943\n",
      "Epoch 564/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 7.5208 - val_loss: 9.4924\n",
      "Epoch 565/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.5175 - val_loss: 9.4906\n",
      "Epoch 566/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 7.5143 - val_loss: 9.4887\n",
      "Epoch 567/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.5110 - val_loss: 9.4869\n",
      "Epoch 568/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.5078 - val_loss: 9.4851\n",
      "Epoch 569/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.5045 - val_loss: 9.4833\n",
      "Epoch 570/10000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 7.5013 - val_loss: 9.4816\n",
      "Epoch 571/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.4981 - val_loss: 9.4798\n",
      "Epoch 572/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.4949 - val_loss: 9.4780\n",
      "Epoch 573/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.4917 - val_loss: 9.4763\n",
      "Epoch 574/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.4885 - val_loss: 9.4745\n",
      "Epoch 575/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.4853 - val_loss: 9.4728\n",
      "Epoch 576/10000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 7.4821 - val_loss: 9.4711\n",
      "Epoch 577/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.4790 - val_loss: 9.4694\n",
      "Epoch 578/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.4758 - val_loss: 9.4677\n",
      "Epoch 579/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.4726 - val_loss: 9.4660\n",
      "Epoch 580/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.4695 - val_loss: 9.4643\n",
      "Epoch 581/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.4664 - val_loss: 9.4626\n",
      "Epoch 582/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.4632 - val_loss: 9.4610\n",
      "Epoch 583/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.4601 - val_loss: 9.4593\n",
      "Epoch 584/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.4570 - val_loss: 9.4576\n",
      "Epoch 585/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 7.4539 - val_loss: 9.4560\n",
      "Epoch 586/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.4508 - val_loss: 9.4544\n",
      "Epoch 587/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.447 - 0s 67ms/step - loss: 7.4477 - val_loss: 9.4528\n",
      "Epoch 588/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4446 - val_loss: 9.4511\n",
      "Epoch 589/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.4415 - val_loss: 9.4495\n",
      "Epoch 590/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.4384 - val_loss: 9.4480\n",
      "Epoch 591/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.4354 - val_loss: 9.4464\n",
      "Epoch 592/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.4323 - val_loss: 9.4448\n",
      "Epoch 593/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.4293 - val_loss: 9.4432\n",
      "Epoch 594/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.4262 - val_loss: 9.4417\n",
      "Epoch 595/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4232 - val_loss: 9.4401\n",
      "Epoch 596/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.4201 - val_loss: 9.4386\n",
      "Epoch 597/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.4171 - val_loss: 9.4371\n",
      "Epoch 598/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.4141 - val_loss: 9.4356\n",
      "Epoch 599/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.4111 - val_loss: 9.4341\n",
      "Epoch 600/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.4081 - val_loss: 9.4325\n",
      "Epoch 601/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.4051 - val_loss: 9.4310\n",
      "Epoch 602/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.4021 - val_loss: 9.4295\n",
      "Epoch 603/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.3991 - val_loss: 9.4279\n",
      "Epoch 604/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.3961 - val_loss: 9.4264\n",
      "Epoch 605/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3932 - val_loss: 9.4248\n",
      "Epoch 606/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.3902 - val_loss: 9.4233\n",
      "Epoch 607/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.3873 - val_loss: 9.4217\n",
      "Epoch 608/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.3843 - val_loss: 9.4202\n",
      "Epoch 609/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.3814 - val_loss: 9.4185\n",
      "Epoch 610/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.3785 - val_loss: 9.4169\n",
      "Epoch 611/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.3755 - val_loss: 9.4154\n",
      "Epoch 612/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.3726 - val_loss: 9.4138\n",
      "Epoch 613/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.3697 - val_loss: 9.4122\n",
      "Epoch 614/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.3668 - val_loss: 9.4106\n",
      "Epoch 615/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.3639 - val_loss: 9.4090\n",
      "Epoch 616/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.3610 - val_loss: 9.4074\n",
      "Epoch 617/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.3581 - val_loss: 9.4059\n",
      "Epoch 618/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3552 - val_loss: 9.4043\n",
      "Epoch 619/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3524 - val_loss: 9.4027\n",
      "Epoch 620/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.3495 - val_loss: 9.4012\n",
      "Epoch 621/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.3466 - val_loss: 9.3996\n",
      "Epoch 622/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.3438 - val_loss: 9.3981\n",
      "Epoch 623/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.3409 - val_loss: 9.3965\n",
      "Epoch 624/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.3381 - val_loss: 9.3950\n",
      "Epoch 625/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.3353 - val_loss: 9.3935\n",
      "Epoch 626/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.3324 - val_loss: 9.3920\n",
      "Epoch 627/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.3296 - val_loss: 9.3905\n",
      "Epoch 628/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.3268 - val_loss: 9.3890\n",
      "Epoch 629/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.3240 - val_loss: 9.3875\n",
      "Epoch 630/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.3212 - val_loss: 9.3860\n",
      "Epoch 631/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.3184 - val_loss: 9.3845\n",
      "Epoch 632/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.3156 - val_loss: 9.3830\n",
      "Epoch 633/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.3128 - val_loss: 9.3815\n",
      "Epoch 634/10000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 7.3100 - val_loss: 9.3800\n",
      "Epoch 635/10000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 7.3072 - val_loss: 9.3785\n",
      "Epoch 636/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.3044 - val_loss: 9.3770\n",
      "Epoch 637/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.3017 - val_loss: 9.3756\n",
      "Epoch 638/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.2989 - val_loss: 9.3741\n",
      "Epoch 639/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.2961 - val_loss: 9.3726\n",
      "Epoch 640/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.2934 - val_loss: 9.3712\n",
      "Epoch 641/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.2906 - val_loss: 9.3697\n",
      "Epoch 642/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.2879 - val_loss: 9.3682\n",
      "Epoch 643/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2852 - val_loss: 9.3668\n",
      "Epoch 644/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.2824 - val_loss: 9.3653\n",
      "Epoch 645/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.2797 - val_loss: 9.3639\n",
      "Epoch 646/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.2770 - val_loss: 9.3625\n",
      "Epoch 647/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.2742 - val_loss: 9.3610\n",
      "Epoch 648/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.2715 - val_loss: 9.3596\n",
      "Epoch 649/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.2688 - val_loss: 9.3582\n",
      "Epoch 650/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.2661 - val_loss: 9.3567\n",
      "Epoch 651/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.2634 - val_loss: 9.3553\n",
      "Epoch 652/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.2607 - val_loss: 9.3538\n",
      "Epoch 653/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2580 - val_loss: 9.3524\n",
      "Epoch 654/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.2553 - val_loss: 9.3509\n",
      "Epoch 655/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.2526 - val_loss: 9.3495\n",
      "Epoch 656/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.2500 - val_loss: 9.3481\n",
      "Epoch 657/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.2473 - val_loss: 9.3466\n",
      "Epoch 658/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.2446 - val_loss: 9.3452\n",
      "Epoch 659/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.2420 - val_loss: 9.3438\n",
      "Epoch 660/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.2393 - val_loss: 9.3424\n",
      "Epoch 661/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.2367 - val_loss: 9.3410\n",
      "Epoch 662/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.2340 - val_loss: 9.3396\n",
      "Epoch 663/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.2314 - val_loss: 9.3382\n",
      "Epoch 664/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.2288 - val_loss: 9.3368\n",
      "Epoch 665/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.2262 - val_loss: 9.3354\n",
      "Epoch 666/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.2235 - val_loss: 9.3340\n",
      "Epoch 667/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.2209 - val_loss: 9.3327\n",
      "Epoch 668/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.2183 - val_loss: 9.3313\n",
      "Epoch 669/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.2157 - val_loss: 9.3299\n",
      "Epoch 670/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.2132 - val_loss: 9.3285\n",
      "Epoch 671/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.2106 - val_loss: 9.3271\n",
      "Epoch 672/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.2080 - val_loss: 9.3258\n",
      "Epoch 673/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.2054 - val_loss: 9.3244\n",
      "Epoch 674/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.2029 - val_loss: 9.3231\n",
      "Epoch 675/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.2003 - val_loss: 9.3217\n",
      "Epoch 676/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1977 - val_loss: 9.3204\n",
      "Epoch 677/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.1952 - val_loss: 9.3191\n",
      "Epoch 678/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.1926 - val_loss: 9.3178\n",
      "Epoch 679/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1901 - val_loss: 9.3164\n",
      "Epoch 680/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.1876 - val_loss: 9.3151\n",
      "Epoch 681/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.1850 - val_loss: 9.3138\n",
      "Epoch 682/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.1825 - val_loss: 9.3124\n",
      "Epoch 683/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.1800 - val_loss: 9.3111\n",
      "Epoch 684/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.1775 - val_loss: 9.3098\n",
      "Epoch 685/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.1750 - val_loss: 9.3085\n",
      "Epoch 686/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.1725 - val_loss: 9.3072\n",
      "Epoch 687/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.1700 - val_loss: 9.3058\n",
      "Epoch 688/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.1675 - val_loss: 9.3046\n",
      "Epoch 689/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.1650 - val_loss: 9.3033\n",
      "Epoch 690/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.1625 - val_loss: 9.3020\n",
      "Epoch 691/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1601 - val_loss: 9.3007\n",
      "Epoch 692/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.1576 - val_loss: 9.2994\n",
      "Epoch 693/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1552 - val_loss: 9.2981\n",
      "Epoch 694/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1527 - val_loss: 9.2969\n",
      "Epoch 695/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.1503 - val_loss: 9.2956\n",
      "Epoch 696/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1478 - val_loss: 9.2943\n",
      "Epoch 697/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.1454 - val_loss: 9.2931\n",
      "Epoch 698/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 7.1429 - val_loss: 9.2918\n",
      "Epoch 699/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.1405 - val_loss: 9.2905\n",
      "Epoch 700/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1381 - val_loss: 9.2893\n",
      "Epoch 701/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.1357 - val_loss: 9.2880\n",
      "Epoch 702/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.1333 - val_loss: 9.2868\n",
      "Epoch 703/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 7.1309 - val_loss: 9.2855\n",
      "Epoch 704/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.1285 - val_loss: 9.2843\n",
      "Epoch 705/10000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 7.1261 - val_loss: 9.2830\n",
      "Epoch 706/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.1236 - val_loss: 9.2817\n",
      "Epoch 707/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.1212 - val_loss: 9.2804\n",
      "Epoch 708/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.1188 - val_loss: 9.2791\n",
      "Epoch 709/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1164 - val_loss: 9.2777\n",
      "Epoch 710/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.1140 - val_loss: 9.2764\n",
      "Epoch 711/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1116 - val_loss: 9.2750\n",
      "Epoch 712/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.1092 - val_loss: 9.2737\n",
      "Epoch 713/10000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 7.1069 - val_loss: 9.2723\n",
      "Epoch 714/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.1045 - val_loss: 9.2710\n",
      "Epoch 715/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.1021 - val_loss: 9.2697\n",
      "Epoch 716/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.0997 - val_loss: 9.2684\n",
      "Epoch 717/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.0973 - val_loss: 9.2671\n",
      "Epoch 718/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.0949 - val_loss: 9.2658\n",
      "Epoch 719/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.0926 - val_loss: 9.2645\n",
      "Epoch 720/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.0902 - val_loss: 9.2632\n",
      "Epoch 721/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.0878 - val_loss: 9.2619\n",
      "Epoch 722/10000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.0855 - val_loss: 9.2606\n",
      "Epoch 723/10000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 7.0831 - val_loss: 9.2594\n",
      "Epoch 724/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.0808 - val_loss: 9.2581\n",
      "Epoch 725/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.0785 - val_loss: 9.2568\n",
      "Epoch 726/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.0761 - val_loss: 9.2555\n",
      "Epoch 727/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.0738 - val_loss: 9.2543\n",
      "Epoch 728/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.0715 - val_loss: 9.2530\n",
      "Epoch 729/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.0692 - val_loss: 9.2517\n",
      "Epoch 730/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.0669 - val_loss: 9.2504\n",
      "Epoch 731/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.0646 - val_loss: 9.2492\n",
      "Epoch 732/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.0623 - val_loss: 9.2479\n",
      "Epoch 733/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.0600 - val_loss: 9.2466\n",
      "Epoch 734/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.0577 - val_loss: 9.2453\n",
      "Epoch 735/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.0554 - val_loss: 9.2440\n",
      "Epoch 736/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.0531 - val_loss: 9.2427\n",
      "Epoch 737/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.0508 - val_loss: 9.2415\n",
      "Epoch 738/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.0486 - val_loss: 9.2402\n",
      "Epoch 739/10000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.0463 - val_loss: 9.2389\n",
      "Epoch 740/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.0440 - val_loss: 9.2377\n",
      "Epoch 741/10000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 7.0418 - val_loss: 9.2364\n",
      "Epoch 742/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.0395 - val_loss: 9.2352\n",
      "Epoch 743/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.0373 - val_loss: 9.2340\n",
      "Epoch 744/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.0350 - val_loss: 9.2328\n",
      "Epoch 745/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.0328 - val_loss: 9.2316\n",
      "Epoch 746/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.0306 - val_loss: 9.2304\n",
      "Epoch 747/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.0284 - val_loss: 9.2292\n",
      "Epoch 748/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.0261 - val_loss: 9.2281\n",
      "Epoch 749/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.0239 - val_loss: 9.2269\n",
      "Epoch 750/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.0217 - val_loss: 9.2258\n",
      "Epoch 751/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.0195 - val_loss: 9.2246\n",
      "Epoch 752/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.0173 - val_loss: 9.2235\n",
      "Epoch 753/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.0151 - val_loss: 9.2223\n",
      "Epoch 754/10000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 7.0129 - val_loss: 9.2212\n",
      "Epoch 755/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.0107 - val_loss: 9.2200\n",
      "Epoch 756/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.0085 - val_loss: 9.2188\n",
      "Epoch 757/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.0063 - val_loss: 9.2176\n",
      "Epoch 758/10000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 7.0042 - val_loss: 9.2164\n",
      "Epoch 759/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.0020 - val_loss: 9.2152\n",
      "Epoch 760/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.9998 - val_loss: 9.2140\n",
      "Epoch 761/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.9976 - val_loss: 9.2128\n",
      "Epoch 762/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.9955 - val_loss: 9.2116\n",
      "Epoch 763/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.9933 - val_loss: 9.2104\n",
      "Epoch 764/10000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 6.9911 - val_loss: 9.2092\n",
      "Epoch 765/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.9890 - val_loss: 9.2079\n",
      "Epoch 766/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9868 - val_loss: 9.2067\n",
      "Epoch 767/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.9847 - val_loss: 9.2055\n",
      "Epoch 768/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.9826 - val_loss: 9.2044\n",
      "Epoch 769/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.9804 - val_loss: 9.2032\n",
      "Epoch 770/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.9783 - val_loss: 9.2020\n",
      "Epoch 771/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.9761 - val_loss: 9.2009\n",
      "Epoch 772/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.9740 - val_loss: 9.1998\n",
      "Epoch 773/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.9719 - val_loss: 9.1986\n",
      "Epoch 774/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9697 - val_loss: 9.1975\n",
      "Epoch 775/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9676 - val_loss: 9.1964\n",
      "Epoch 776/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9655 - val_loss: 9.1952\n",
      "Epoch 777/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.9634 - val_loss: 9.1941\n",
      "Epoch 778/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9612 - val_loss: 9.1930\n",
      "Epoch 779/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9591 - val_loss: 9.1919\n",
      "Epoch 780/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9570 - val_loss: 9.1907\n",
      "Epoch 781/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.9549 - val_loss: 9.1895\n",
      "Epoch 782/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.9528 - val_loss: 9.1883\n",
      "Epoch 783/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.9507 - val_loss: 9.1872\n",
      "Epoch 784/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.9486 - val_loss: 9.1860\n",
      "Epoch 785/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9465 - val_loss: 9.1848\n",
      "Epoch 786/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.9444 - val_loss: 9.1837\n",
      "Epoch 787/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9424 - val_loss: 9.1825\n",
      "Epoch 788/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.9403 - val_loss: 9.1814\n",
      "Epoch 789/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.9382 - val_loss: 9.1802\n",
      "Epoch 790/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.9361 - val_loss: 9.1791\n",
      "Epoch 791/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.9341 - val_loss: 9.1780\n",
      "Epoch 792/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.9320 - val_loss: 9.1768\n",
      "Epoch 793/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.9299 - val_loss: 9.1757\n",
      "Epoch 794/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.9279 - val_loss: 9.1745\n",
      "Epoch 795/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.9258 - val_loss: 9.1734\n",
      "Epoch 796/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.9238 - val_loss: 9.1722\n",
      "Epoch 797/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.9217 - val_loss: 9.1711\n",
      "Epoch 798/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.9197 - val_loss: 9.1700\n",
      "Epoch 799/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.9176 - val_loss: 9.1689\n",
      "Epoch 800/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.915 - 0s 81ms/step - loss: 6.9156 - val_loss: 9.1678\n",
      "Epoch 801/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9135 - val_loss: 9.1667\n",
      "Epoch 802/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.9115 - val_loss: 9.1656\n",
      "Epoch 803/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.9095 - val_loss: 9.1645\n",
      "Epoch 804/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.9075 - val_loss: 9.1635\n",
      "Epoch 805/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.9055 - val_loss: 9.1624\n",
      "Epoch 806/10000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.9036 - val_loss: 9.1613\n",
      "Epoch 807/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.9017 - val_loss: 9.1601\n",
      "Epoch 808/10000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 6.8999 - val_loss: 9.1589\n",
      "Epoch 809/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.8980 - val_loss: 9.1577\n",
      "Epoch 810/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.8962 - val_loss: 9.1565\n",
      "Epoch 811/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.8944 - val_loss: 9.1553\n",
      "Epoch 812/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.8926 - val_loss: 9.1541\n",
      "Epoch 813/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.8908 - val_loss: 9.1530\n",
      "Epoch 814/10000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 6.8890 - val_loss: 9.1518\n",
      "Epoch 815/10000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.8872 - val_loss: 9.1507\n",
      "Epoch 816/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.8854 - val_loss: 9.1496\n",
      "Epoch 817/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.8836 - val_loss: 9.1485\n",
      "Epoch 818/10000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 6.8818 - val_loss: 9.1475\n",
      "Epoch 819/10000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 6.8800 - val_loss: 9.1465\n",
      "Epoch 820/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8782 - val_loss: 9.1456\n",
      "Epoch 821/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.8764 - val_loss: 9.1447\n",
      "Epoch 822/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.8746 - val_loss: 9.1440\n",
      "Epoch 823/10000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 6.8727 - val_loss: 9.1432\n",
      "Epoch 824/10000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 6.8710 - val_loss: 9.1426\n",
      "Epoch 825/10000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 6.8692 - val_loss: 9.1420\n",
      "Epoch 826/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.8674 - val_loss: 9.1414\n",
      "Epoch 827/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.8656 - val_loss: 9.1409\n",
      "Epoch 828/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.8638 - val_loss: 9.1403\n",
      "Epoch 829/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.8620 - val_loss: 9.1398\n",
      "Epoch 830/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.8602 - val_loss: 9.1392\n",
      "Epoch 831/10000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 6.8584 - val_loss: 9.1387\n",
      "Epoch 832/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.8566 - val_loss: 9.1381\n",
      "Epoch 833/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.8549 - val_loss: 9.1375\n",
      "Epoch 834/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.8531 - val_loss: 9.1368\n",
      "Epoch 835/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.8513 - val_loss: 9.1361\n",
      "Epoch 836/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.8495 - val_loss: 9.1354\n",
      "Epoch 837/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.8478 - val_loss: 9.1347\n",
      "Epoch 838/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.8460 - val_loss: 9.1339\n",
      "Epoch 839/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8442 - val_loss: 9.1330\n",
      "Epoch 840/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.8425 - val_loss: 9.1322\n",
      "Epoch 841/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.8407 - val_loss: 9.1313\n",
      "Epoch 842/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.8390 - val_loss: 9.1304\n",
      "Epoch 843/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.8372 - val_loss: 9.1295\n",
      "Epoch 844/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.8355 - val_loss: 9.1286\n",
      "Epoch 845/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.8338 - val_loss: 9.1277\n",
      "Epoch 846/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.8320 - val_loss: 9.1268\n",
      "Epoch 847/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.8303 - val_loss: 9.1259\n",
      "Epoch 848/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.8286 - val_loss: 9.1251\n",
      "Epoch 849/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.8269 - val_loss: 9.1242\n",
      "Epoch 850/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.8252 - val_loss: 9.1234\n",
      "Epoch 851/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.8234 - val_loss: 9.1226\n",
      "Epoch 852/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8217 - val_loss: 9.1219\n",
      "Epoch 853/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.8200 - val_loss: 9.1211\n",
      "Epoch 854/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.8183 - val_loss: 9.1203\n",
      "Epoch 855/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.8166 - val_loss: 9.1196\n",
      "Epoch 856/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.8149 - val_loss: 9.1189\n",
      "Epoch 857/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.8132 - val_loss: 9.1182\n",
      "Epoch 858/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 6.8115 - val_loss: 9.1175\n",
      "Epoch 859/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.8098 - val_loss: 9.1167\n",
      "Epoch 860/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.8081 - val_loss: 9.1160\n",
      "Epoch 861/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.8064 - val_loss: 9.1153\n",
      "Epoch 862/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8047 - val_loss: 9.1146\n",
      "Epoch 863/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.8031 - val_loss: 9.1139\n",
      "Epoch 864/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.8014 - val_loss: 9.1132\n",
      "Epoch 865/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.7997 - val_loss: 9.1125\n",
      "Epoch 866/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.7980 - val_loss: 9.1118\n",
      "Epoch 867/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.7963 - val_loss: 9.1111\n",
      "Epoch 868/10000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 6.7947 - val_loss: 9.1104\n",
      "Epoch 869/10000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.7930 - val_loss: 9.1097\n",
      "Epoch 870/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.7913 - val_loss: 9.1090\n",
      "Epoch 871/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.7896 - val_loss: 9.1083\n",
      "Epoch 872/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.7880 - val_loss: 9.1076\n",
      "Epoch 873/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.7863 - val_loss: 9.1069\n",
      "Epoch 874/10000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.7847 - val_loss: 9.1062\n",
      "Epoch 875/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.7830 - val_loss: 9.1055\n",
      "Epoch 876/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.7813 - val_loss: 9.1048\n",
      "Epoch 877/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.7797 - val_loss: 9.1041\n",
      "Epoch 878/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7780 - val_loss: 9.1034\n",
      "Epoch 879/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.7764 - val_loss: 9.1027\n",
      "Epoch 880/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.7747 - val_loss: 9.1020\n",
      "Epoch 881/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7731 - val_loss: 9.1013\n",
      "Epoch 882/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.7715 - val_loss: 9.1006\n",
      "Epoch 883/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.7698 - val_loss: 9.1000\n",
      "Epoch 884/10000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.7682 - val_loss: 9.0993\n",
      "Epoch 885/10000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.7665 - val_loss: 9.0986\n",
      "Epoch 886/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.7649 - val_loss: 9.0980\n",
      "Epoch 887/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.7633 - val_loss: 9.0973\n",
      "Epoch 888/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.7617 - val_loss: 9.0966\n",
      "Epoch 889/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.7600 - val_loss: 9.0960\n",
      "Epoch 890/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.7584 - val_loss: 9.0953\n",
      "Epoch 891/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.7568 - val_loss: 9.0947\n",
      "Epoch 892/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.7552 - val_loss: 9.0940\n",
      "Epoch 893/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.7536 - val_loss: 9.0933\n",
      "Epoch 894/10000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 6.7520 - val_loss: 9.0925\n",
      "Epoch 895/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.7505 - val_loss: 9.0918\n",
      "Epoch 896/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.7489 - val_loss: 9.0910\n",
      "Epoch 897/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.7473 - val_loss: 9.0903\n",
      "Epoch 898/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7457 - val_loss: 9.0895\n",
      "Epoch 899/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.7441 - val_loss: 9.0888\n",
      "Epoch 900/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.7425 - val_loss: 9.0880\n",
      "Epoch 901/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.7410 - val_loss: 9.0873\n",
      "Epoch 902/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.7394 - val_loss: 9.0865\n",
      "Epoch 903/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.7378 - val_loss: 9.0858\n",
      "Epoch 904/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.7363 - val_loss: 9.0850\n",
      "Epoch 905/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.7347 - val_loss: 9.0843\n",
      "Epoch 906/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.7331 - val_loss: 9.0835\n",
      "Epoch 907/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.7316 - val_loss: 9.0827\n",
      "Epoch 908/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.7300 - val_loss: 9.0820\n",
      "Epoch 909/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.7284 - val_loss: 9.0812\n",
      "Epoch 910/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.7269 - val_loss: 9.0804\n",
      "Epoch 911/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.7253 - val_loss: 9.0796\n",
      "Epoch 912/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.7238 - val_loss: 9.0789\n",
      "Epoch 913/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.7222 - val_loss: 9.0782\n",
      "Epoch 914/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.7207 - val_loss: 9.0775\n",
      "Epoch 915/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.7191 - val_loss: 9.0767\n",
      "Epoch 916/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.7176 - val_loss: 9.0760\n",
      "Epoch 917/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.7161 - val_loss: 9.0753\n",
      "Epoch 918/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.7145 - val_loss: 9.0746\n",
      "Epoch 919/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.7130 - val_loss: 9.0739\n",
      "Epoch 920/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.7114 - val_loss: 9.0731\n",
      "Epoch 921/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.7099 - val_loss: 9.0724\n",
      "Epoch 922/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.7084 - val_loss: 9.0717\n",
      "Epoch 923/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.7068 - val_loss: 9.0710\n",
      "Epoch 924/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.7053 - val_loss: 9.0703\n",
      "Epoch 925/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.7038 - val_loss: 9.0696\n",
      "Epoch 926/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7023 - val_loss: 9.0689\n",
      "Epoch 927/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.7007 - val_loss: 9.0682\n",
      "Epoch 928/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.6992 - val_loss: 9.0675\n",
      "Epoch 929/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.6977 - val_loss: 9.0669\n",
      "Epoch 930/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.6962 - val_loss: 9.0662\n",
      "Epoch 931/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.6947 - val_loss: 9.0655\n",
      "Epoch 932/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.6932 - val_loss: 9.0648\n",
      "Epoch 933/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.6917 - val_loss: 9.0641\n",
      "Epoch 934/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.6902 - val_loss: 9.0634\n",
      "Epoch 935/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.6887 - val_loss: 9.0627\n",
      "Epoch 936/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.6872 - val_loss: 9.0620\n",
      "Epoch 937/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.6857 - val_loss: 9.0613\n",
      "Epoch 938/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step - loss: 6.6842 - val_loss: 9.0606\n",
      "Epoch 939/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.6827 - val_loss: 9.0599\n",
      "Epoch 940/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.6812 - val_loss: 9.0591\n",
      "Epoch 941/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.6797 - val_loss: 9.0584\n",
      "Epoch 942/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.6783 - val_loss: 9.0576\n",
      "Epoch 943/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6768 - val_loss: 9.0569\n",
      "Epoch 944/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.6753 - val_loss: 9.0562\n",
      "Epoch 945/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.6739 - val_loss: 9.0555\n",
      "Epoch 946/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6724 - val_loss: 9.0547\n",
      "Epoch 947/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.6709 - val_loss: 9.0540\n",
      "Epoch 948/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.6695 - val_loss: 9.0533\n",
      "Epoch 949/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.6680 - val_loss: 9.0526\n",
      "Epoch 950/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.6666 - val_loss: 9.0519\n",
      "Epoch 951/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.6651 - val_loss: 9.0513\n",
      "Epoch 952/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.6637 - val_loss: 9.0506\n",
      "Epoch 953/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.6622 - val_loss: 9.0499\n",
      "Epoch 954/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.6608 - val_loss: 9.0492\n",
      "Epoch 955/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6593 - val_loss: 9.0485\n",
      "Epoch 956/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.6579 - val_loss: 9.0478\n",
      "Epoch 957/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.6564 - val_loss: 9.0471\n",
      "Epoch 958/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.6550 - val_loss: 9.0464\n",
      "Epoch 959/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.6536 - val_loss: 9.0457\n",
      "Epoch 960/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6521 - val_loss: 9.0450\n",
      "Epoch 961/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.6507 - val_loss: 9.0443\n",
      "Epoch 962/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.6493 - val_loss: 9.0435\n",
      "Epoch 963/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6479 - val_loss: 9.0428\n",
      "Epoch 964/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6464 - val_loss: 9.0421\n",
      "Epoch 965/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6450 - val_loss: 9.0414\n",
      "Epoch 966/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6436 - val_loss: 9.0407\n",
      "Epoch 967/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.6422 - val_loss: 9.0400\n",
      "Epoch 968/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.6408 - val_loss: 9.0393\n",
      "Epoch 969/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.6393 - val_loss: 9.0386\n",
      "Epoch 970/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.6379 - val_loss: 9.0379\n",
      "Epoch 971/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6365 - val_loss: 9.0372\n",
      "Epoch 972/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.6351 - val_loss: 9.0365\n",
      "Epoch 973/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6337 - val_loss: 9.0358\n",
      "Epoch 974/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.6323 - val_loss: 9.0351\n",
      "Epoch 975/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.6309 - val_loss: 9.0344\n",
      "Epoch 976/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.6295 - val_loss: 9.0336\n",
      "Epoch 977/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.6281 - val_loss: 9.0329\n",
      "Epoch 978/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.6267 - val_loss: 9.0321\n",
      "Epoch 979/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.6253 - val_loss: 9.0314\n",
      "Epoch 980/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.6239 - val_loss: 9.0307\n",
      "Epoch 981/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6225 - val_loss: 9.0299\n",
      "Epoch 982/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.6211 - val_loss: 9.0292\n",
      "Epoch 983/10000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 6.6198 - val_loss: 9.0284\n",
      "Epoch 984/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.6184 - val_loss: 9.0276\n",
      "Epoch 985/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.6170 - val_loss: 9.0269\n",
      "Epoch 986/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.6156 - val_loss: 9.0261\n",
      "Epoch 987/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.6142 - val_loss: 9.0254\n",
      "Epoch 988/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.6128 - val_loss: 9.0246\n",
      "Epoch 989/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.6115 - val_loss: 9.0239\n",
      "Epoch 990/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.6101 - val_loss: 9.0231\n",
      "Epoch 991/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.6087 - val_loss: 9.0224\n",
      "Epoch 992/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.6073 - val_loss: 9.0217\n",
      "Epoch 993/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.6060 - val_loss: 9.0209\n",
      "Epoch 994/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.6046 - val_loss: 9.0201\n",
      "Epoch 995/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.6032 - val_loss: 9.0194\n",
      "Epoch 996/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.6019 - val_loss: 9.0186\n",
      "Epoch 997/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.6005 - val_loss: 9.0179\n",
      "Epoch 998/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.5992 - val_loss: 9.0171\n",
      "Epoch 999/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.5978 - val_loss: 9.0164\n",
      "Epoch 1000/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.5964 - val_loss: 9.0156\n",
      "Epoch 1001/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.5951 - val_loss: 9.0148\n",
      "Epoch 1002/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.5937 - val_loss: 9.0141\n",
      "Epoch 1003/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5924 - val_loss: 9.0133\n",
      "Epoch 1004/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.5910 - val_loss: 9.0125\n",
      "Epoch 1005/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5897 - val_loss: 9.0118\n",
      "Epoch 1006/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5883 - val_loss: 9.0110\n",
      "Epoch 1007/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5870 - val_loss: 9.0102\n",
      "Epoch 1008/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5857 - val_loss: 9.0095\n",
      "Epoch 1009/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.5843 - val_loss: 9.0087\n",
      "Epoch 1010/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.5830 - val_loss: 9.0079\n",
      "Epoch 1011/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.5817 - val_loss: 9.0071\n",
      "Epoch 1012/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.5803 - val_loss: 9.0063\n",
      "Epoch 1013/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.5790 - val_loss: 9.0055\n",
      "Epoch 1014/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.5777 - val_loss: 9.0047\n",
      "Epoch 1015/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.5763 - val_loss: 9.0040\n",
      "Epoch 1016/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5750 - val_loss: 9.0032\n",
      "Epoch 1017/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5737 - val_loss: 9.0024\n",
      "Epoch 1018/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step - loss: 6.5724 - val_loss: 9.0016\n",
      "Epoch 1019/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.5711 - val_loss: 9.0009\n",
      "Epoch 1020/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5697 - val_loss: 9.0001\n",
      "Epoch 1021/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5684 - val_loss: 8.9993\n",
      "Epoch 1022/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.5671 - val_loss: 8.9986\n",
      "Epoch 1023/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5658 - val_loss: 8.9976\n",
      "Epoch 1024/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.5645 - val_loss: 8.9964\n",
      "Epoch 1025/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.5632 - val_loss: 8.9953\n",
      "Epoch 1026/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.5619 - val_loss: 8.9943\n",
      "Epoch 1027/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.5606 - val_loss: 8.9933\n",
      "Epoch 1028/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.5593 - val_loss: 8.9925\n",
      "Epoch 1029/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.5580 - val_loss: 8.9917\n",
      "Epoch 1030/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.5567 - val_loss: 8.9910\n",
      "Epoch 1031/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5554 - val_loss: 8.9903\n",
      "Epoch 1032/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.5541 - val_loss: 8.9897\n",
      "Epoch 1033/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5528 - val_loss: 8.9891\n",
      "Epoch 1034/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.5516 - val_loss: 8.9885\n",
      "Epoch 1035/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5503 - val_loss: 8.9879\n",
      "Epoch 1036/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5490 - val_loss: 8.9873\n",
      "Epoch 1037/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.5477 - val_loss: 8.9866\n",
      "Epoch 1038/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5464 - val_loss: 8.9860\n",
      "Epoch 1039/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5451 - val_loss: 8.9854\n",
      "Epoch 1040/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.5439 - val_loss: 8.9848\n",
      "Epoch 1041/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.5426 - val_loss: 8.9841\n",
      "Epoch 1042/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5413 - val_loss: 8.9834\n",
      "Epoch 1043/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5400 - val_loss: 8.9827\n",
      "Epoch 1044/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.5388 - val_loss: 8.9820\n",
      "Epoch 1045/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5375 - val_loss: 8.9812\n",
      "Epoch 1046/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5362 - val_loss: 8.9805\n",
      "Epoch 1047/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5350 - val_loss: 8.9798\n",
      "Epoch 1048/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.5337 - val_loss: 8.9790\n",
      "Epoch 1049/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.5324 - val_loss: 8.9781\n",
      "Epoch 1050/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.5312 - val_loss: 8.9771\n",
      "Epoch 1051/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5299 - val_loss: 8.9762\n",
      "Epoch 1052/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.5286 - val_loss: 8.9753\n",
      "Epoch 1053/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.5274 - val_loss: 8.9745\n",
      "Epoch 1054/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5261 - val_loss: 8.9737\n",
      "Epoch 1055/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5249 - val_loss: 8.9729\n",
      "Epoch 1056/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.5236 - val_loss: 8.9722\n",
      "Epoch 1057/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.5224 - val_loss: 8.9715\n",
      "Epoch 1058/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.5211 - val_loss: 8.9708\n",
      "Epoch 1059/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.5199 - val_loss: 8.9702\n",
      "Epoch 1060/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.5186 - val_loss: 8.9695\n",
      "Epoch 1061/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.5174 - val_loss: 8.9687\n",
      "Epoch 1062/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.5161 - val_loss: 8.9678\n",
      "Epoch 1063/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.5149 - val_loss: 8.9671\n",
      "Epoch 1064/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.5137 - val_loss: 8.9663\n",
      "Epoch 1065/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5124 - val_loss: 8.9656\n",
      "Epoch 1066/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.5112 - val_loss: 8.9649\n",
      "Epoch 1067/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.5099 - val_loss: 8.9642\n",
      "Epoch 1068/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.5087 - val_loss: 8.9636\n",
      "Epoch 1069/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.5075 - val_loss: 8.9629\n",
      "Epoch 1070/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5062 - val_loss: 8.9623\n",
      "Epoch 1071/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.5050 - val_loss: 8.9617\n",
      "Epoch 1072/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.5038 - val_loss: 8.9611\n",
      "Epoch 1073/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.5025 - val_loss: 8.9604\n",
      "Epoch 1074/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.5013 - val_loss: 8.9598\n",
      "Epoch 1075/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.5001 - val_loss: 8.9589\n",
      "Epoch 1076/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.4989 - val_loss: 8.9581\n",
      "Epoch 1077/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.4977 - val_loss: 8.9573\n",
      "Epoch 1078/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.4964 - val_loss: 8.9565\n",
      "Epoch 1079/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4952 - val_loss: 8.9557\n",
      "Epoch 1080/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.4940 - val_loss: 8.9550\n",
      "Epoch 1081/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.4928 - val_loss: 8.9543\n",
      "Epoch 1082/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4916 - val_loss: 8.9536\n",
      "Epoch 1083/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.4903 - val_loss: 8.9529\n",
      "Epoch 1084/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.4891 - val_loss: 8.9523\n",
      "Epoch 1085/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.4879 - val_loss: 8.9517\n",
      "Epoch 1086/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4867 - val_loss: 8.9511\n",
      "Epoch 1087/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4855 - val_loss: 8.9504\n",
      "Epoch 1088/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.4843 - val_loss: 8.9496\n",
      "Epoch 1089/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4831 - val_loss: 8.9488\n",
      "Epoch 1090/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4819 - val_loss: 8.9480\n",
      "Epoch 1091/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4807 - val_loss: 8.9473\n",
      "Epoch 1092/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4795 - val_loss: 8.9466\n",
      "Epoch 1093/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4783 - val_loss: 8.9459\n",
      "Epoch 1094/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.4771 - val_loss: 8.9453\n",
      "Epoch 1095/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4759 - val_loss: 8.9446\n",
      "Epoch 1096/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.4747 - val_loss: 8.9440\n",
      "Epoch 1097/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4735 - val_loss: 8.9434\n",
      "Epoch 1098/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4723 - val_loss: 8.9429\n",
      "Epoch 1099/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4711 - val_loss: 8.9423\n",
      "Epoch 1100/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.4700 - val_loss: 8.9417\n",
      "Epoch 1101/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.4688 - val_loss: 8.9412\n",
      "Epoch 1102/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4676 - val_loss: 8.9403\n",
      "Epoch 1103/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4664 - val_loss: 8.9395\n",
      "Epoch 1104/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.4652 - val_loss: 8.9388\n",
      "Epoch 1105/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.4640 - val_loss: 8.9380\n",
      "Epoch 1106/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4629 - val_loss: 8.9373\n",
      "Epoch 1107/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4617 - val_loss: 8.9366\n",
      "Epoch 1108/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4605 - val_loss: 8.9360\n",
      "Epoch 1109/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.4593 - val_loss: 8.9354\n",
      "Epoch 1110/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.4582 - val_loss: 8.9348\n",
      "Epoch 1111/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.4570 - val_loss: 8.9342\n",
      "Epoch 1112/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.4558 - val_loss: 8.9337\n",
      "Epoch 1113/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.4546 - val_loss: 8.9331\n",
      "Epoch 1114/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.4535 - val_loss: 8.9323\n",
      "Epoch 1115/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.4523 - val_loss: 8.9315\n",
      "Epoch 1116/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4512 - val_loss: 8.9308\n",
      "Epoch 1117/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4500 - val_loss: 8.9301\n",
      "Epoch 1118/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4488 - val_loss: 8.9294\n",
      "Epoch 1119/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4477 - val_loss: 8.9287\n",
      "Epoch 1120/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4465 - val_loss: 8.9281\n",
      "Epoch 1121/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4454 - val_loss: 8.9275\n",
      "Epoch 1122/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4442 - val_loss: 8.9269\n",
      "Epoch 1123/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4430 - val_loss: 8.9264\n",
      "Epoch 1124/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4419 - val_loss: 8.9258\n",
      "Epoch 1125/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4407 - val_loss: 8.9252\n",
      "Epoch 1126/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4396 - val_loss: 8.9247\n",
      "Epoch 1127/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4384 - val_loss: 8.9240\n",
      "Epoch 1128/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4373 - val_loss: 8.9232\n",
      "Epoch 1129/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4362 - val_loss: 8.9225\n",
      "Epoch 1130/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.4350 - val_loss: 8.9219\n",
      "Epoch 1131/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.4339 - val_loss: 8.9212\n",
      "Epoch 1132/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.4328 - val_loss: 8.9206\n",
      "Epoch 1133/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.4316 - val_loss: 8.9200\n",
      "Epoch 1134/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.4305 - val_loss: 8.9194\n",
      "Epoch 1135/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.4294 - val_loss: 8.9189\n",
      "Epoch 1136/10000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 6.4282 - val_loss: 8.9183\n",
      "Epoch 1137/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.4271 - val_loss: 8.9178\n",
      "Epoch 1138/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.4260 - val_loss: 8.9170\n",
      "Epoch 1139/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4248 - val_loss: 8.9162\n",
      "Epoch 1140/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.4237 - val_loss: 8.9155\n",
      "Epoch 1141/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.4226 - val_loss: 8.9148\n",
      "Epoch 1142/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.4215 - val_loss: 8.9142\n",
      "Epoch 1143/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.4204 - val_loss: 8.9136\n",
      "Epoch 1144/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.4192 - val_loss: 8.9130\n",
      "Epoch 1145/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.4181 - val_loss: 8.9124\n",
      "Epoch 1146/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4170 - val_loss: 8.9118\n",
      "Epoch 1147/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4159 - val_loss: 8.9113\n",
      "Epoch 1148/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4148 - val_loss: 8.9105\n",
      "Epoch 1149/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.4137 - val_loss: 8.9098\n",
      "Epoch 1150/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4126 - val_loss: 8.9091\n",
      "Epoch 1151/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4115 - val_loss: 8.9084\n",
      "Epoch 1152/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4104 - val_loss: 8.9078\n",
      "Epoch 1153/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4092 - val_loss: 8.9072\n",
      "Epoch 1154/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4081 - val_loss: 8.9066\n",
      "Epoch 1155/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.4070 - val_loss: 8.9061\n",
      "Epoch 1156/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.4059 - val_loss: 8.9055\n",
      "Epoch 1157/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.4048 - val_loss: 8.9050\n",
      "Epoch 1158/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4037 - val_loss: 8.9045\n",
      "Epoch 1159/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.4026 - val_loss: 8.9040\n",
      "Epoch 1160/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.4015 - val_loss: 8.9033\n",
      "Epoch 1161/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4004 - val_loss: 8.9026\n",
      "Epoch 1162/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.3993 - val_loss: 8.9020\n",
      "Epoch 1163/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3982 - val_loss: 8.9013\n",
      "Epoch 1164/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3972 - val_loss: 8.9007\n",
      "Epoch 1165/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.3961 - val_loss: 8.9001\n",
      "Epoch 1166/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3950 - val_loss: 8.8996\n",
      "Epoch 1167/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3939 - val_loss: 8.8990\n",
      "Epoch 1168/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3928 - val_loss: 8.8985\n",
      "Epoch 1169/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.3917 - val_loss: 8.8979\n",
      "Epoch 1170/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.3906 - val_loss: 8.8972\n",
      "Epoch 1171/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.3895 - val_loss: 8.8965\n",
      "Epoch 1172/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.3885 - val_loss: 8.8959\n",
      "Epoch 1173/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.3874 - val_loss: 8.8952\n",
      "Epoch 1174/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.3863 - val_loss: 8.8946\n",
      "Epoch 1175/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.3852 - val_loss: 8.8940\n",
      "Epoch 1176/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step - loss: 6.3841 - val_loss: 8.8934\n",
      "Epoch 1177/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3830 - val_loss: 8.8929\n",
      "Epoch 1178/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3819 - val_loss: 8.8923\n",
      "Epoch 1179/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.3809 - val_loss: 8.8918\n",
      "Epoch 1180/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.3798 - val_loss: 8.8913\n",
      "Epoch 1181/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.3787 - val_loss: 8.8906\n",
      "Epoch 1182/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.3776 - val_loss: 8.8899\n",
      "Epoch 1183/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.3765 - val_loss: 8.8893\n",
      "Epoch 1184/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.3755 - val_loss: 8.8887\n",
      "Epoch 1185/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3744 - val_loss: 8.8880\n",
      "Epoch 1186/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.3733 - val_loss: 8.8875\n",
      "Epoch 1187/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3722 - val_loss: 8.8869\n",
      "Epoch 1188/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3711 - val_loss: 8.8864\n",
      "Epoch 1189/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3701 - val_loss: 8.8859\n",
      "Epoch 1190/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.3690 - val_loss: 8.8854\n",
      "Epoch 1191/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3679 - val_loss: 8.8850\n",
      "Epoch 1192/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.3669 - val_loss: 8.8843\n",
      "Epoch 1193/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3658 - val_loss: 8.8836\n",
      "Epoch 1194/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.3647 - val_loss: 8.8830\n",
      "Epoch 1195/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.3637 - val_loss: 8.8824\n",
      "Epoch 1196/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3626 - val_loss: 8.8818\n",
      "Epoch 1197/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.3616 - val_loss: 8.8813\n",
      "Epoch 1198/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3605 - val_loss: 8.8808\n",
      "Epoch 1199/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3594 - val_loss: 8.8803\n",
      "Epoch 1200/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3584 - val_loss: 8.8798\n",
      "Epoch 1201/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.3573 - val_loss: 8.8793\n",
      "Epoch 1202/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.3563 - val_loss: 8.8788\n",
      "Epoch 1203/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.3552 - val_loss: 8.8781\n",
      "Epoch 1204/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.3542 - val_loss: 8.8774\n",
      "Epoch 1205/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3531 - val_loss: 8.8768\n",
      "Epoch 1206/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3521 - val_loss: 8.8762\n",
      "Epoch 1207/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3510 - val_loss: 8.8756\n",
      "Epoch 1208/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.3500 - val_loss: 8.8750\n",
      "Epoch 1209/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.3489 - val_loss: 8.8745\n",
      "Epoch 1210/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.3479 - val_loss: 8.8740\n",
      "Epoch 1211/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3468 - val_loss: 8.8735\n",
      "Epoch 1212/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3458 - val_loss: 8.8731\n",
      "Epoch 1213/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.3447 - val_loss: 8.8724\n",
      "Epoch 1214/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.3437 - val_loss: 8.8717\n",
      "Epoch 1215/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.3427 - val_loss: 8.8711\n",
      "Epoch 1216/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.3416 - val_loss: 8.8705\n",
      "Epoch 1217/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.3406 - val_loss: 8.8700\n",
      "Epoch 1218/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.3396 - val_loss: 8.8695\n",
      "Epoch 1219/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.3385 - val_loss: 8.8690\n",
      "Epoch 1220/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.3375 - val_loss: 8.8686\n",
      "Epoch 1221/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.3365 - val_loss: 8.8681\n",
      "Epoch 1222/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.3354 - val_loss: 8.8677\n",
      "Epoch 1223/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.3344 - val_loss: 8.8672\n",
      "Epoch 1224/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.3334 - val_loss: 8.8668\n",
      "Epoch 1225/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.3324 - val_loss: 8.8661\n",
      "Epoch 1226/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.3313 - val_loss: 8.8655\n",
      "Epoch 1227/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.3303 - val_loss: 8.8649\n",
      "Epoch 1228/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3293 - val_loss: 8.8643\n",
      "Epoch 1229/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.3282 - val_loss: 8.8638\n",
      "Epoch 1230/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3272 - val_loss: 8.8633\n",
      "Epoch 1231/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3262 - val_loss: 8.8628\n",
      "Epoch 1232/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.3252 - val_loss: 8.8623\n",
      "Epoch 1233/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.3242 - val_loss: 8.8618\n",
      "Epoch 1234/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.3232 - val_loss: 8.8613\n",
      "Epoch 1235/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.3222 - val_loss: 8.8606\n",
      "Epoch 1236/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3212 - val_loss: 8.8599\n",
      "Epoch 1237/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3202 - val_loss: 8.8593\n",
      "Epoch 1238/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.3191 - val_loss: 8.8587\n",
      "Epoch 1239/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3181 - val_loss: 8.8581\n",
      "Epoch 1240/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3171 - val_loss: 8.8576\n",
      "Epoch 1241/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.3161 - val_loss: 8.8571\n",
      "Epoch 1242/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.3151 - val_loss: 8.8566\n",
      "Epoch 1243/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3141 - val_loss: 8.8562\n",
      "Epoch 1244/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.3131 - val_loss: 8.8557\n",
      "Epoch 1245/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.3121 - val_loss: 8.8553\n",
      "Epoch 1246/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.3111 - val_loss: 8.8548\n",
      "Epoch 1247/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.3101 - val_loss: 8.8542\n",
      "Epoch 1248/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3091 - val_loss: 8.8536\n",
      "Epoch 1249/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3081 - val_loss: 8.8530\n",
      "Epoch 1250/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3071 - val_loss: 8.8524\n",
      "Epoch 1251/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.3061 - val_loss: 8.8519\n",
      "Epoch 1252/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.3051 - val_loss: 8.8513\n",
      "Epoch 1253/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.3041 - val_loss: 8.8508\n",
      "Epoch 1254/10000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.3032 - val_loss: 8.8504\n",
      "Epoch 1255/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step - loss: 6.3022 - val_loss: 8.8499\n",
      "Epoch 1256/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.3012 - val_loss: 8.8494\n",
      "Epoch 1257/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.3002 - val_loss: 8.8490\n",
      "Epoch 1258/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.2992 - val_loss: 8.8483\n",
      "Epoch 1259/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.2983 - val_loss: 8.8477\n",
      "Epoch 1260/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2973 - val_loss: 8.8471\n",
      "Epoch 1261/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.2963 - val_loss: 8.8465\n",
      "Epoch 1262/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2954 - val_loss: 8.8459\n",
      "Epoch 1263/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.2944 - val_loss: 8.8454\n",
      "Epoch 1264/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.2934 - val_loss: 8.8449\n",
      "Epoch 1265/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.2925 - val_loss: 8.8444\n",
      "Epoch 1266/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.2915 - val_loss: 8.8440\n",
      "Epoch 1267/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.2905 - val_loss: 8.8436\n",
      "Epoch 1268/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.2896 - val_loss: 8.8432\n",
      "Epoch 1269/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.2886 - val_loss: 8.8428\n",
      "Epoch 1270/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.2876 - val_loss: 8.8422\n",
      "Epoch 1271/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.2867 - val_loss: 8.8416\n",
      "Epoch 1272/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2857 - val_loss: 8.8411\n",
      "Epoch 1273/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.2848 - val_loss: 8.8406\n",
      "Epoch 1274/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.2838 - val_loss: 8.8401\n",
      "Epoch 1275/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.2828 - val_loss: 8.8397\n",
      "Epoch 1276/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2819 - val_loss: 8.8393\n",
      "Epoch 1277/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.2809 - val_loss: 8.8389\n",
      "Epoch 1278/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.2800 - val_loss: 8.8385\n",
      "Epoch 1279/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.2790 - val_loss: 8.8381\n",
      "Epoch 1280/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.2781 - val_loss: 8.8377\n",
      "Epoch 1281/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.2771 - val_loss: 8.8371\n",
      "Epoch 1282/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.2762 - val_loss: 8.8366\n",
      "Epoch 1283/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2752 - val_loss: 8.8361\n",
      "Epoch 1284/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.2743 - val_loss: 8.8356\n",
      "Epoch 1285/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2734 - val_loss: 8.8352\n",
      "Epoch 1286/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2724 - val_loss: 8.8348\n",
      "Epoch 1287/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.2715 - val_loss: 8.8345\n",
      "Epoch 1288/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.2705 - val_loss: 8.8341\n",
      "Epoch 1289/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.2696 - val_loss: 8.8337\n",
      "Epoch 1290/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2686 - val_loss: 8.8333\n",
      "Epoch 1291/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.2677 - val_loss: 8.8330\n",
      "Epoch 1292/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.2668 - val_loss: 8.8326\n",
      "Epoch 1293/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.2658 - val_loss: 8.8320\n",
      "Epoch 1294/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2649 - val_loss: 8.8315\n",
      "Epoch 1295/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.2640 - val_loss: 8.8310\n",
      "Epoch 1296/10000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 6.2630 - val_loss: 8.8305\n",
      "Epoch 1297/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.2621 - val_loss: 8.8300\n",
      "Epoch 1298/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2611 - val_loss: 8.8296\n",
      "Epoch 1299/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.2602 - val_loss: 8.8292\n",
      "Epoch 1300/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.2592 - val_loss: 8.8288\n",
      "Epoch 1301/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.2583 - val_loss: 8.8284\n",
      "Epoch 1302/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.2574 - val_loss: 8.8280\n",
      "Epoch 1303/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.2564 - val_loss: 8.8277\n",
      "Epoch 1304/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2555 - val_loss: 8.8271\n",
      "Epoch 1305/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.2546 - val_loss: 8.8266\n",
      "Epoch 1306/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2537 - val_loss: 8.8262\n",
      "Epoch 1307/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.2527 - val_loss: 8.8258\n",
      "Epoch 1308/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.2518 - val_loss: 8.8255\n",
      "Epoch 1309/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.2508 - val_loss: 8.8253\n",
      "Epoch 1310/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.2498 - val_loss: 8.8251\n",
      "Epoch 1311/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.2488 - val_loss: 8.8248\n",
      "Epoch 1312/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2478 - val_loss: 8.8245\n",
      "Epoch 1313/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2468 - val_loss: 8.8241\n",
      "Epoch 1314/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.2458 - val_loss: 8.8237\n",
      "Epoch 1315/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.2448 - val_loss: 8.8234\n",
      "Epoch 1316/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2439 - val_loss: 8.8226\n",
      "Epoch 1317/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.2429 - val_loss: 8.8219\n",
      "Epoch 1318/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2420 - val_loss: 8.8211\n",
      "Epoch 1319/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2411 - val_loss: 8.8205\n",
      "Epoch 1320/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.240 - 0s 48ms/step - loss: 6.2402 - val_loss: 8.8200\n",
      "Epoch 1321/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2393 - val_loss: 8.8196\n",
      "Epoch 1322/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.2384 - val_loss: 8.8192\n",
      "Epoch 1323/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.2375 - val_loss: 8.8188\n",
      "Epoch 1324/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.2366 - val_loss: 8.8185\n",
      "Epoch 1325/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.2357 - val_loss: 8.8181\n",
      "Epoch 1326/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.2348 - val_loss: 8.8177\n",
      "Epoch 1327/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.2338 - val_loss: 8.8170\n",
      "Epoch 1328/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2329 - val_loss: 8.8165\n",
      "Epoch 1329/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.2320 - val_loss: 8.8160\n",
      "Epoch 1330/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2311 - val_loss: 8.8156\n",
      "Epoch 1331/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2302 - val_loss: 8.8153\n",
      "Epoch 1332/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.2293 - val_loss: 8.8150\n",
      "Epoch 1333/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.2284 - val_loss: 8.8148\n",
      "Epoch 1334/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step - loss: 6.2275 - val_loss: 8.8145\n",
      "Epoch 1335/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.2266 - val_loss: 8.8143\n",
      "Epoch 1336/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.2257 - val_loss: 8.8141\n",
      "Epoch 1337/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.2248 - val_loss: 8.8140\n",
      "Epoch 1338/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2239 - val_loss: 8.8139\n",
      "Epoch 1339/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.2230 - val_loss: 8.8138\n",
      "Epoch 1340/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.2221 - val_loss: 8.8134\n",
      "Epoch 1341/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.2212 - val_loss: 8.8130\n",
      "Epoch 1342/10000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 6.2203 - val_loss: 8.8126\n",
      "Epoch 1343/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.2194 - val_loss: 8.8122\n",
      "Epoch 1344/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.2185 - val_loss: 8.8118\n",
      "Epoch 1345/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.2176 - val_loss: 8.8115\n",
      "Epoch 1346/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.2168 - val_loss: 8.8112\n",
      "Epoch 1347/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.2159 - val_loss: 8.8108\n",
      "Epoch 1348/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.2150 - val_loss: 8.8105\n",
      "Epoch 1349/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2141 - val_loss: 8.8101\n",
      "Epoch 1350/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2132 - val_loss: 8.8098\n",
      "Epoch 1351/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.2123 - val_loss: 8.8092\n",
      "Epoch 1352/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.2114 - val_loss: 8.8087\n",
      "Epoch 1353/10000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.2106 - val_loss: 8.8082\n",
      "Epoch 1354/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.2097 - val_loss: 8.8077\n",
      "Epoch 1355/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.2088 - val_loss: 8.8073\n",
      "Epoch 1356/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.2079 - val_loss: 8.8069\n",
      "Epoch 1357/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.2071 - val_loss: 8.8066\n",
      "Epoch 1358/10000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.2062 - val_loss: 8.8063\n",
      "Epoch 1359/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.2053 - val_loss: 8.8060\n",
      "Epoch 1360/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2044 - val_loss: 8.8057\n",
      "Epoch 1361/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.2036 - val_loss: 8.8054\n",
      "Epoch 1362/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.2027 - val_loss: 8.8051\n",
      "Epoch 1363/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.2018 - val_loss: 8.8049\n",
      "Epoch 1364/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2010 - val_loss: 8.8044\n",
      "Epoch 1365/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.2001 - val_loss: 8.8039\n",
      "Epoch 1366/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.1992 - val_loss: 8.8035\n",
      "Epoch 1367/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1984 - val_loss: 8.8031\n",
      "Epoch 1368/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.1975 - val_loss: 8.8027\n",
      "Epoch 1369/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.1966 - val_loss: 8.8024\n",
      "Epoch 1370/10000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 6.1958 - val_loss: 8.8021\n",
      "Epoch 1371/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1949 - val_loss: 8.8018\n",
      "Epoch 1372/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1940 - val_loss: 8.8015\n",
      "Epoch 1373/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.1932 - val_loss: 8.8013\n",
      "Epoch 1374/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.1923 - val_loss: 8.8010\n",
      "Epoch 1375/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.1914 - val_loss: 8.8005\n",
      "Epoch 1376/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.1906 - val_loss: 8.8001\n",
      "Epoch 1377/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.1897 - val_loss: 8.7996\n",
      "Epoch 1378/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.1889 - val_loss: 8.7992\n",
      "Epoch 1379/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.1880 - val_loss: 8.7988\n",
      "Epoch 1380/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.1872 - val_loss: 8.7985\n",
      "Epoch 1381/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.1863 - val_loss: 8.7981\n",
      "Epoch 1382/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.1855 - val_loss: 8.7978\n",
      "Epoch 1383/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.1846 - val_loss: 8.7975\n",
      "Epoch 1384/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.1838 - val_loss: 8.7973\n",
      "Epoch 1385/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.1830 - val_loss: 8.7971\n",
      "Epoch 1386/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1821 - val_loss: 8.7968\n",
      "Epoch 1387/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1813 - val_loss: 8.7966\n",
      "Epoch 1388/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.1804 - val_loss: 8.7962\n",
      "Epoch 1389/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1796 - val_loss: 8.7957\n",
      "Epoch 1390/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.1788 - val_loss: 8.7953\n",
      "Epoch 1391/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.1779 - val_loss: 8.7949\n",
      "Epoch 1392/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.1771 - val_loss: 8.7946\n",
      "Epoch 1393/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.1762 - val_loss: 8.7943\n",
      "Epoch 1394/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.1754 - val_loss: 8.7940\n",
      "Epoch 1395/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.1746 - val_loss: 8.7937\n",
      "Epoch 1396/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.1737 - val_loss: 8.7934\n",
      "Epoch 1397/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.1729 - val_loss: 8.7932\n",
      "Epoch 1398/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.1721 - val_loss: 8.7930\n",
      "Epoch 1399/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.1712 - val_loss: 8.7928\n",
      "Epoch 1400/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.1704 - val_loss: 8.7924\n",
      "Epoch 1401/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.1696 - val_loss: 8.7920\n",
      "Epoch 1402/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.1688 - val_loss: 8.7915\n",
      "Epoch 1403/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1679 - val_loss: 8.7912\n",
      "Epoch 1404/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1671 - val_loss: 8.7908\n",
      "Epoch 1405/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.1663 - val_loss: 8.7904\n",
      "Epoch 1406/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.1654 - val_loss: 8.7901\n",
      "Epoch 1407/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.1646 - val_loss: 8.7898\n",
      "Epoch 1408/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.1638 - val_loss: 8.7895\n",
      "Epoch 1409/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.1630 - val_loss: 8.7892\n",
      "Epoch 1410/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.1622 - val_loss: 8.7889\n",
      "Epoch 1411/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.1613 - val_loss: 8.7886\n",
      "Epoch 1412/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.1605 - val_loss: 8.7881\n",
      "Epoch 1413/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 6.1597 - val_loss: 8.7877\n",
      "Epoch 1414/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.1589 - val_loss: 8.7873\n",
      "Epoch 1415/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.1581 - val_loss: 8.7869\n",
      "Epoch 1416/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.1572 - val_loss: 8.7865\n",
      "Epoch 1417/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.1564 - val_loss: 8.7862\n",
      "Epoch 1418/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.1556 - val_loss: 8.7858\n",
      "Epoch 1419/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1548 - val_loss: 8.7855\n",
      "Epoch 1420/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.1540 - val_loss: 8.7852\n",
      "Epoch 1421/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.1532 - val_loss: 8.7849\n",
      "Epoch 1422/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.1524 - val_loss: 8.7846\n",
      "Epoch 1423/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.1515 - val_loss: 8.7843\n",
      "Epoch 1424/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.1507 - val_loss: 8.7841\n",
      "Epoch 1425/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1499 - val_loss: 8.7836\n",
      "Epoch 1426/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1491 - val_loss: 8.7831\n",
      "Epoch 1427/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1483 - val_loss: 8.7827\n",
      "Epoch 1428/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1475 - val_loss: 8.7823\n",
      "Epoch 1429/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1467 - val_loss: 8.7819\n",
      "Epoch 1430/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1459 - val_loss: 8.7815\n",
      "Epoch 1431/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1451 - val_loss: 8.7812\n",
      "Epoch 1432/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.1443 - val_loss: 8.7809\n",
      "Epoch 1433/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.1435 - val_loss: 8.7806\n",
      "Epoch 1434/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1427 - val_loss: 8.7803\n",
      "Epoch 1435/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.1419 - val_loss: 8.7801\n",
      "Epoch 1436/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1411 - val_loss: 8.7798\n",
      "Epoch 1437/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1403 - val_loss: 8.7795\n",
      "Epoch 1438/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.1395 - val_loss: 8.7790\n",
      "Epoch 1439/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1387 - val_loss: 8.7785\n",
      "Epoch 1440/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1379 - val_loss: 8.7781\n",
      "Epoch 1441/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.1371 - val_loss: 8.7777\n",
      "Epoch 1442/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.1363 - val_loss: 8.7773\n",
      "Epoch 1443/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.1355 - val_loss: 8.7770\n",
      "Epoch 1444/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1347 - val_loss: 8.7767\n",
      "Epoch 1445/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.1339 - val_loss: 8.7764\n",
      "Epoch 1446/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.1331 - val_loss: 8.7761\n",
      "Epoch 1447/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.1323 - val_loss: 8.7758\n",
      "Epoch 1448/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.1315 - val_loss: 8.7755\n",
      "Epoch 1449/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.1307 - val_loss: 8.7753\n",
      "Epoch 1450/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.1299 - val_loss: 8.7748\n",
      "Epoch 1451/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.1292 - val_loss: 8.7744\n",
      "Epoch 1452/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.1284 - val_loss: 8.7740\n",
      "Epoch 1453/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.1276 - val_loss: 8.7735\n",
      "Epoch 1454/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.1268 - val_loss: 8.7732\n",
      "Epoch 1455/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.1260 - val_loss: 8.7728\n",
      "Epoch 1456/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.1252 - val_loss: 8.7725\n",
      "Epoch 1457/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.1244 - val_loss: 8.7722\n",
      "Epoch 1458/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.1237 - val_loss: 8.7719\n",
      "Epoch 1459/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1229 - val_loss: 8.7717\n",
      "Epoch 1460/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1221 - val_loss: 8.7714\n",
      "Epoch 1461/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1213 - val_loss: 8.7712\n",
      "Epoch 1462/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1205 - val_loss: 8.7709\n",
      "Epoch 1463/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1197 - val_loss: 8.7706\n",
      "Epoch 1464/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1190 - val_loss: 8.7702\n",
      "Epoch 1465/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.1182 - val_loss: 8.7698\n",
      "Epoch 1466/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.1174 - val_loss: 8.7694\n",
      "Epoch 1467/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.1166 - val_loss: 8.7690\n",
      "Epoch 1468/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1158 - val_loss: 8.7687\n",
      "Epoch 1469/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.1151 - val_loss: 8.7684\n",
      "Epoch 1470/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.1143 - val_loss: 8.7681\n",
      "Epoch 1471/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1135 - val_loss: 8.7678\n",
      "Epoch 1472/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1127 - val_loss: 8.7675\n",
      "Epoch 1473/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1120 - val_loss: 8.7673\n",
      "Epoch 1474/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1112 - val_loss: 8.7670\n",
      "Epoch 1475/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1104 - val_loss: 8.7668\n",
      "Epoch 1476/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1096 - val_loss: 8.7665\n",
      "Epoch 1477/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.1088 - val_loss: 8.7661\n",
      "Epoch 1478/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.1081 - val_loss: 8.7657\n",
      "Epoch 1479/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.1073 - val_loss: 8.7653\n",
      "Epoch 1480/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.1065 - val_loss: 8.7649\n",
      "Epoch 1481/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.1057 - val_loss: 8.7646\n",
      "Epoch 1482/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.1050 - val_loss: 8.7643\n",
      "Epoch 1483/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.1042 - val_loss: 8.7640\n",
      "Epoch 1484/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.1034 - val_loss: 8.7637\n",
      "Epoch 1485/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1027 - val_loss: 8.7635\n",
      "Epoch 1486/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.1019 - val_loss: 8.7632\n",
      "Epoch 1487/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.1011 - val_loss: 8.7630\n",
      "Epoch 1488/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1003 - val_loss: 8.7627\n",
      "Epoch 1489/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.0996 - val_loss: 8.7625\n",
      "Epoch 1490/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.0988 - val_loss: 8.7621\n",
      "Epoch 1491/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0980 - val_loss: 8.7617\n",
      "Epoch 1492/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step - loss: 6.0973 - val_loss: 8.7613\n",
      "Epoch 1493/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.0965 - val_loss: 8.7610\n",
      "Epoch 1494/10000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.0957 - val_loss: 8.7606\n",
      "Epoch 1495/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.0950 - val_loss: 8.7604\n",
      "Epoch 1496/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.0942 - val_loss: 8.7601\n",
      "Epoch 1497/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.0935 - val_loss: 8.7598\n",
      "Epoch 1498/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.0927 - val_loss: 8.7596\n",
      "Epoch 1499/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.0919 - val_loss: 8.7593\n",
      "Epoch 1500/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0912 - val_loss: 8.7590\n",
      "Epoch 1501/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0904 - val_loss: 8.7588\n",
      "Epoch 1502/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0896 - val_loss: 8.7586\n",
      "Epoch 1503/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.0889 - val_loss: 8.7584\n",
      "Epoch 1504/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.0881 - val_loss: 8.7580\n",
      "Epoch 1505/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.0874 - val_loss: 8.7576\n",
      "Epoch 1506/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.0866 - val_loss: 8.7572\n",
      "Epoch 1507/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0859 - val_loss: 8.7568\n",
      "Epoch 1508/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.0851 - val_loss: 8.7565\n",
      "Epoch 1509/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0843 - val_loss: 8.7562\n",
      "Epoch 1510/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0836 - val_loss: 8.7559\n",
      "Epoch 1511/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0828 - val_loss: 8.7556\n",
      "Epoch 1512/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0821 - val_loss: 8.7553\n",
      "Epoch 1513/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.0813 - val_loss: 8.7551\n",
      "Epoch 1514/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0806 - val_loss: 8.7549\n",
      "Epoch 1515/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0798 - val_loss: 8.7546\n",
      "Epoch 1516/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.0791 - val_loss: 8.7542\n",
      "Epoch 1517/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0783 - val_loss: 8.7538\n",
      "Epoch 1518/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0776 - val_loss: 8.7535\n",
      "Epoch 1519/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0768 - val_loss: 8.7532\n",
      "Epoch 1520/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0761 - val_loss: 8.7529\n",
      "Epoch 1521/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0753 - val_loss: 8.7526\n",
      "Epoch 1522/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.0746 - val_loss: 8.7523\n",
      "Epoch 1523/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.0738 - val_loss: 8.7520\n",
      "Epoch 1524/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.0731 - val_loss: 8.7518\n",
      "Epoch 1525/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.0724 - val_loss: 8.7516\n",
      "Epoch 1526/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.0716 - val_loss: 8.7513\n",
      "Epoch 1527/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.0709 - val_loss: 8.7511\n",
      "Epoch 1528/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.0701 - val_loss: 8.7509\n",
      "Epoch 1529/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0694 - val_loss: 8.7506\n",
      "Epoch 1530/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0686 - val_loss: 8.7502\n",
      "Epoch 1531/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.0679 - val_loss: 8.7498\n",
      "Epoch 1532/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0672 - val_loss: 8.7495\n",
      "Epoch 1533/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.0664 - val_loss: 8.7491\n",
      "Epoch 1534/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.0657 - val_loss: 8.7488\n",
      "Epoch 1535/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0649 - val_loss: 8.7484\n",
      "Epoch 1536/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.0642 - val_loss: 8.7482\n",
      "Epoch 1537/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.0635 - val_loss: 8.7479\n",
      "Epoch 1538/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.0627 - val_loss: 8.7476\n",
      "Epoch 1539/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.0620 - val_loss: 8.7474\n",
      "Epoch 1540/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0613 - val_loss: 8.7472\n",
      "Epoch 1541/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0605 - val_loss: 8.7469\n",
      "Epoch 1542/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.0598 - val_loss: 8.7467\n",
      "Epoch 1543/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0591 - val_loss: 8.7465\n",
      "Epoch 1544/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0583 - val_loss: 8.7461\n",
      "Epoch 1545/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0576 - val_loss: 8.7457\n",
      "Epoch 1546/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0569 - val_loss: 8.7454\n",
      "Epoch 1547/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.0561 - val_loss: 8.7451\n",
      "Epoch 1548/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.0554 - val_loss: 8.7447\n",
      "Epoch 1549/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.0547 - val_loss: 8.7444\n",
      "Epoch 1550/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.0540 - val_loss: 8.7442\n",
      "Epoch 1551/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0532 - val_loss: 8.7440\n",
      "Epoch 1552/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0525 - val_loss: 8.7437\n",
      "Epoch 1553/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.0518 - val_loss: 8.7435\n",
      "Epoch 1554/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.0511 - val_loss: 8.7433\n",
      "Epoch 1555/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.0503 - val_loss: 8.7431\n",
      "Epoch 1556/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0496 - val_loss: 8.7428\n",
      "Epoch 1557/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.0489 - val_loss: 8.7426\n",
      "Epoch 1558/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0482 - val_loss: 8.7422\n",
      "Epoch 1559/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0474 - val_loss: 8.7418\n",
      "Epoch 1560/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.0467 - val_loss: 8.7414\n",
      "Epoch 1561/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0460 - val_loss: 8.7412\n",
      "Epoch 1562/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0453 - val_loss: 8.7409\n",
      "Epoch 1563/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.0446 - val_loss: 8.7406\n",
      "Epoch 1564/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0439 - val_loss: 8.7404\n",
      "Epoch 1565/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.0431 - val_loss: 8.7401\n",
      "Epoch 1566/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.0424 - val_loss: 8.7399\n",
      "Epoch 1567/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.0417 - val_loss: 8.7397\n",
      "Epoch 1568/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0410 - val_loss: 8.7395\n",
      "Epoch 1569/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.040 - 0s 35ms/step - loss: 6.0403 - val_loss: 8.7392\n",
      "Epoch 1570/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0396 - val_loss: 8.7390\n",
      "Epoch 1571/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step - loss: 6.0388 - val_loss: 8.7388\n",
      "Epoch 1572/10000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 6.0381 - val_loss: 8.7384\n",
      "Epoch 1573/10000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 6.0374 - val_loss: 8.7381\n",
      "Epoch 1574/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.0367 - val_loss: 8.7377\n",
      "Epoch 1575/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.0360 - val_loss: 8.7374\n",
      "Epoch 1576/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.0353 - val_loss: 8.7371\n",
      "Epoch 1577/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.0346 - val_loss: 8.7368\n",
      "Epoch 1578/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.0339 - val_loss: 8.7366\n",
      "Epoch 1579/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.0332 - val_loss: 8.7364\n",
      "Epoch 1580/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0325 - val_loss: 8.7361\n",
      "Epoch 1581/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.0317 - val_loss: 8.7359\n",
      "Epoch 1582/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.0310 - val_loss: 8.7357\n",
      "Epoch 1583/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.0303 - val_loss: 8.7355\n",
      "Epoch 1584/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.0296 - val_loss: 8.7353\n",
      "Epoch 1585/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.0289 - val_loss: 8.7351\n",
      "Epoch 1586/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0282 - val_loss: 8.7347\n",
      "Epoch 1587/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.0275 - val_loss: 8.7343\n",
      "Epoch 1588/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.0268 - val_loss: 8.7340\n",
      "Epoch 1589/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.0261 - val_loss: 8.7337\n",
      "Epoch 1590/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.0254 - val_loss: 8.7333\n",
      "Epoch 1591/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.0247 - val_loss: 8.7331\n",
      "Epoch 1592/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.0240 - val_loss: 8.7329\n",
      "Epoch 1593/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.0233 - val_loss: 8.7326\n",
      "Epoch 1594/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.0226 - val_loss: 8.7324\n",
      "Epoch 1595/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.0219 - val_loss: 8.7322\n",
      "Epoch 1596/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0212 - val_loss: 8.7320\n",
      "Epoch 1597/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.0205 - val_loss: 8.7318\n",
      "Epoch 1598/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0198 - val_loss: 8.7315\n",
      "Epoch 1599/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0191 - val_loss: 8.7313\n",
      "Epoch 1600/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0184 - val_loss: 8.7309\n",
      "Epoch 1601/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.0177 - val_loss: 8.7306\n",
      "Epoch 1602/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.0170 - val_loss: 8.7303\n",
      "Epoch 1603/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0163 - val_loss: 8.7300\n",
      "Epoch 1604/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0156 - val_loss: 8.7297\n",
      "Epoch 1605/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0149 - val_loss: 8.7295\n",
      "Epoch 1606/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0142 - val_loss: 8.7292\n",
      "Epoch 1607/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0135 - val_loss: 8.7290\n",
      "Epoch 1608/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0128 - val_loss: 8.7288\n",
      "Epoch 1609/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0121 - val_loss: 8.7286\n",
      "Epoch 1610/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.0115 - val_loss: 8.7283\n",
      "Epoch 1611/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.0108 - val_loss: 8.7281\n",
      "Epoch 1612/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.0101 - val_loss: 8.7279\n",
      "Epoch 1613/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0094 - val_loss: 8.7276\n",
      "Epoch 1614/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.0087 - val_loss: 8.7272\n",
      "Epoch 1615/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.0080 - val_loss: 8.7269\n",
      "Epoch 1616/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0073 - val_loss: 8.7266\n",
      "Epoch 1617/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0066 - val_loss: 8.7263\n",
      "Epoch 1618/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.0059 - val_loss: 8.7260\n",
      "Epoch 1619/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.0053 - val_loss: 8.7258\n",
      "Epoch 1620/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.0046 - val_loss: 8.7255\n",
      "Epoch 1621/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.0039 - val_loss: 8.7253\n",
      "Epoch 1622/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.0032 - val_loss: 8.7251\n",
      "Epoch 1623/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.0025 - val_loss: 8.7249\n",
      "Epoch 1624/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.0018 - val_loss: 8.7247\n",
      "Epoch 1625/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.0012 - val_loss: 8.7245\n",
      "Epoch 1626/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0005 - val_loss: 8.7243\n",
      "Epoch 1627/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.9998 - val_loss: 8.7241\n",
      "Epoch 1628/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.9991 - val_loss: 8.7238\n",
      "Epoch 1629/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9984 - val_loss: 8.7234\n",
      "Epoch 1630/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.9977 - val_loss: 8.7231\n",
      "Epoch 1631/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.9971 - val_loss: 8.7228\n",
      "Epoch 1632/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.9964 - val_loss: 8.7225\n",
      "Epoch 1633/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.9957 - val_loss: 8.7222\n",
      "Epoch 1634/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.9950 - val_loss: 8.7220\n",
      "Epoch 1635/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9944 - val_loss: 8.7218\n",
      "Epoch 1636/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9937 - val_loss: 8.7216\n",
      "Epoch 1637/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9930 - val_loss: 8.7213\n",
      "Epoch 1638/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.9923 - val_loss: 8.7211\n",
      "Epoch 1639/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.9917 - val_loss: 8.7209\n",
      "Epoch 1640/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.9910 - val_loss: 8.7208\n",
      "Epoch 1641/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9903 - val_loss: 8.7204\n",
      "Epoch 1642/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9896 - val_loss: 8.7200\n",
      "Epoch 1643/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9890 - val_loss: 8.7197\n",
      "Epoch 1644/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9883 - val_loss: 8.7194\n",
      "Epoch 1645/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9876 - val_loss: 8.7192\n",
      "Epoch 1646/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.9869 - val_loss: 8.7190\n",
      "Epoch 1647/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.9863 - val_loss: 8.7188\n",
      "Epoch 1648/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9856 - val_loss: 8.7186\n",
      "Epoch 1649/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.9849 - val_loss: 8.7184\n",
      "Epoch 1650/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9843 - val_loss: 8.7182\n",
      "Epoch 1651/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9836 - val_loss: 8.7180\n",
      "Epoch 1652/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.9829 - val_loss: 8.7177\n",
      "Epoch 1653/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.9823 - val_loss: 8.7175\n",
      "Epoch 1654/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9816 - val_loss: 8.7173\n",
      "Epoch 1655/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.9809 - val_loss: 8.7169\n",
      "Epoch 1656/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9803 - val_loss: 8.7166\n",
      "Epoch 1657/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9796 - val_loss: 8.7162\n",
      "Epoch 1658/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.9789 - val_loss: 8.7158\n",
      "Epoch 1659/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9783 - val_loss: 8.7155\n",
      "Epoch 1660/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9776 - val_loss: 8.7152\n",
      "Epoch 1661/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.9770 - val_loss: 8.7149\n",
      "Epoch 1662/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9763 - val_loss: 8.7146\n",
      "Epoch 1663/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9756 - val_loss: 8.7143\n",
      "Epoch 1664/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9750 - val_loss: 8.7140\n",
      "Epoch 1665/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.9743 - val_loss: 8.7136\n",
      "Epoch 1666/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9737 - val_loss: 8.7132\n",
      "Epoch 1667/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.9730 - val_loss: 8.7129\n",
      "Epoch 1668/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.9724 - val_loss: 8.7125\n",
      "Epoch 1669/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.9717 - val_loss: 8.7122\n",
      "Epoch 1670/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.9711 - val_loss: 8.7117\n",
      "Epoch 1671/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9704 - val_loss: 8.7113\n",
      "Epoch 1672/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.9698 - val_loss: 8.7110\n",
      "Epoch 1673/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9691 - val_loss: 8.7108\n",
      "Epoch 1674/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9685 - val_loss: 8.7107\n",
      "Epoch 1675/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.9678 - val_loss: 8.7107\n",
      "Epoch 1676/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.9672 - val_loss: 8.7107\n",
      "Epoch 1677/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.9665 - val_loss: 8.7108\n",
      "Epoch 1678/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.9659 - val_loss: 8.7110\n",
      "Epoch 1679/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.9652 - val_loss: 8.7110\n",
      "Epoch 1680/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9646 - val_loss: 8.7110\n",
      "Epoch 1681/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.9639 - val_loss: 8.7109\n",
      "Epoch 1682/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.9633 - val_loss: 8.7107\n",
      "Epoch 1683/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.9627 - val_loss: 8.7104\n",
      "Epoch 1684/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9620 - val_loss: 8.7101\n",
      "Epoch 1685/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.9614 - val_loss: 8.7097\n",
      "Epoch 1686/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9607 - val_loss: 8.7094\n",
      "Epoch 1687/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.9601 - val_loss: 8.7090\n",
      "Epoch 1688/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.9594 - val_loss: 8.7086\n",
      "Epoch 1689/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.9588 - val_loss: 8.7083\n",
      "Epoch 1690/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.9581 - val_loss: 8.7080\n",
      "Epoch 1691/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9575 - val_loss: 8.7076\n",
      "Epoch 1692/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.9569 - val_loss: 8.7073\n",
      "Epoch 1693/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.9562 - val_loss: 8.7070\n",
      "Epoch 1694/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.9556 - val_loss: 8.7067\n",
      "Epoch 1695/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9549 - val_loss: 8.7064\n",
      "Epoch 1696/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9543 - val_loss: 8.7061\n",
      "Epoch 1697/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.9537 - val_loss: 8.7058\n",
      "Epoch 1698/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.9530 - val_loss: 8.7055\n",
      "Epoch 1699/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9524 - val_loss: 8.7052\n",
      "Epoch 1700/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.9518 - val_loss: 8.7049\n",
      "Epoch 1701/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9511 - val_loss: 8.7047\n",
      "Epoch 1702/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9505 - val_loss: 8.7045\n",
      "Epoch 1703/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.9498 - val_loss: 8.7044\n",
      "Epoch 1704/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.9492 - val_loss: 8.7043\n",
      "Epoch 1705/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.9486 - val_loss: 8.7042\n",
      "Epoch 1706/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.9479 - val_loss: 8.7041\n",
      "Epoch 1707/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.9473 - val_loss: 8.7039\n",
      "Epoch 1708/10000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.9467 - val_loss: 8.7035\n",
      "Epoch 1709/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.9460 - val_loss: 8.7032\n",
      "Epoch 1710/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.9454 - val_loss: 8.7028\n",
      "Epoch 1711/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9448 - val_loss: 8.7025\n",
      "Epoch 1712/10000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.9442 - val_loss: 8.7022\n",
      "Epoch 1713/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9435 - val_loss: 8.7019\n",
      "Epoch 1714/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9429 - val_loss: 8.7016\n",
      "Epoch 1715/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.9423 - val_loss: 8.7013\n",
      "Epoch 1716/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.9416 - val_loss: 8.7010\n",
      "Epoch 1717/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9410 - val_loss: 8.7008\n",
      "Epoch 1718/10000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.9404 - val_loss: 8.7005\n",
      "Epoch 1719/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.9397 - val_loss: 8.7003\n",
      "Epoch 1720/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9391 - val_loss: 8.7001\n",
      "Epoch 1721/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.9385 - val_loss: 8.6999\n",
      "Epoch 1722/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.9379 - val_loss: 8.6997\n",
      "Epoch 1723/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9372 - val_loss: 8.6993\n",
      "Epoch 1724/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9366 - val_loss: 8.6989\n",
      "Epoch 1725/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9360 - val_loss: 8.6986\n",
      "Epoch 1726/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.9354 - val_loss: 8.6983\n",
      "Epoch 1727/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.9347 - val_loss: 8.6981\n",
      "Epoch 1728/10000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.9341 - val_loss: 8.6978\n",
      "Epoch 1729/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step - loss: 5.9335 - val_loss: 8.6976\n",
      "Epoch 1730/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.9329 - val_loss: 8.6973\n",
      "Epoch 1731/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9322 - val_loss: 8.6971\n",
      "Epoch 1732/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.9316 - val_loss: 8.6969\n",
      "Epoch 1733/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.9310 - val_loss: 8.6967\n",
      "Epoch 1734/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.9304 - val_loss: 8.6965\n",
      "Epoch 1735/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.9297 - val_loss: 8.6962\n",
      "Epoch 1736/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.9291 - val_loss: 8.6959\n",
      "Epoch 1737/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.9285 - val_loss: 8.6956\n",
      "Epoch 1738/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.9279 - val_loss: 8.6952\n",
      "Epoch 1739/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 5.9273 - val_loss: 8.6949\n",
      "Epoch 1740/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.9266 - val_loss: 8.6946\n",
      "Epoch 1741/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.9260 - val_loss: 8.6943\n",
      "Epoch 1742/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.9254 - val_loss: 8.6941\n",
      "Epoch 1743/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9248 - val_loss: 8.6939\n",
      "Epoch 1744/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9242 - val_loss: 8.6938\n",
      "Epoch 1745/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.9235 - val_loss: 8.6937\n",
      "Epoch 1746/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.9229 - val_loss: 8.6936\n",
      "Epoch 1747/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.9223 - val_loss: 8.6934\n",
      "Epoch 1748/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9217 - val_loss: 8.6931\n",
      "Epoch 1749/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.9211 - val_loss: 8.6927\n",
      "Epoch 1750/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9204 - val_loss: 8.6924\n",
      "Epoch 1751/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.9198 - val_loss: 8.6920\n",
      "Epoch 1752/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.9192 - val_loss: 8.6918\n",
      "Epoch 1753/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.9186 - val_loss: 8.6915\n",
      "Epoch 1754/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.9180 - val_loss: 8.6912\n",
      "Epoch 1755/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9174 - val_loss: 8.6909\n",
      "Epoch 1756/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.9167 - val_loss: 8.6906\n",
      "Epoch 1757/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.9161 - val_loss: 8.6904\n",
      "Epoch 1758/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.9155 - val_loss: 8.6902\n",
      "Epoch 1759/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.9149 - val_loss: 8.6900\n",
      "Epoch 1760/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9143 - val_loss: 8.6898\n",
      "Epoch 1761/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.9137 - val_loss: 8.6895\n",
      "Epoch 1762/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9130 - val_loss: 8.6892\n",
      "Epoch 1763/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.9124 - val_loss: 8.6888\n",
      "Epoch 1764/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9118 - val_loss: 8.6886\n",
      "Epoch 1765/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.9112 - val_loss: 8.6883\n",
      "Epoch 1766/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9106 - val_loss: 8.6881\n",
      "Epoch 1767/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.9100 - val_loss: 8.6878\n",
      "Epoch 1768/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.9094 - val_loss: 8.6876\n",
      "Epoch 1769/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.9088 - val_loss: 8.6873\n",
      "Epoch 1770/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9082 - val_loss: 8.6870\n",
      "Epoch 1771/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.9075 - val_loss: 8.6868\n",
      "Epoch 1772/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9069 - val_loss: 8.6866\n",
      "Epoch 1773/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.9063 - val_loss: 8.6864\n",
      "Epoch 1774/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.9057 - val_loss: 8.6861\n",
      "Epoch 1775/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.9051 - val_loss: 8.6858\n",
      "Epoch 1776/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.9045 - val_loss: 8.6855\n",
      "Epoch 1777/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.9039 - val_loss: 8.6852\n",
      "Epoch 1778/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.9033 - val_loss: 8.6849\n",
      "Epoch 1779/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.9027 - val_loss: 8.6846\n",
      "Epoch 1780/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9021 - val_loss: 8.6843\n",
      "Epoch 1781/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.9015 - val_loss: 8.6841\n",
      "Epoch 1782/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.9009 - val_loss: 8.6839\n",
      "Epoch 1783/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.9003 - val_loss: 8.6837\n",
      "Epoch 1784/10000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.8997 - val_loss: 8.6835\n",
      "Epoch 1785/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8991 - val_loss: 8.6833\n",
      "Epoch 1786/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8984 - val_loss: 8.6831\n",
      "Epoch 1787/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8978 - val_loss: 8.6829\n",
      "Epoch 1788/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8972 - val_loss: 8.6825\n",
      "Epoch 1789/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8966 - val_loss: 8.6822\n",
      "Epoch 1790/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.8960 - val_loss: 8.6819\n",
      "Epoch 1791/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.8954 - val_loss: 8.6817\n",
      "Epoch 1792/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8948 - val_loss: 8.6814\n",
      "Epoch 1793/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8942 - val_loss: 8.6812\n",
      "Epoch 1794/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8936 - val_loss: 8.6809\n",
      "Epoch 1795/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8930 - val_loss: 8.6806\n",
      "Epoch 1796/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8924 - val_loss: 8.6803\n",
      "Epoch 1797/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8918 - val_loss: 8.6801\n",
      "Epoch 1798/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8912 - val_loss: 8.6800\n",
      "Epoch 1799/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8906 - val_loss: 8.6798\n",
      "Epoch 1800/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8900 - val_loss: 8.6796\n",
      "Epoch 1801/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8895 - val_loss: 8.6792\n",
      "Epoch 1802/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.8889 - val_loss: 8.6788\n",
      "Epoch 1803/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8883 - val_loss: 8.6786\n",
      "Epoch 1804/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8877 - val_loss: 8.6783\n",
      "Epoch 1805/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.8871 - val_loss: 8.6781\n",
      "Epoch 1806/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8865 - val_loss: 8.6779\n",
      "Epoch 1807/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8859 - val_loss: 8.6777\n",
      "Epoch 1808/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8853 - val_loss: 8.6774\n",
      "Epoch 1809/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.8847 - val_loss: 8.6772\n",
      "Epoch 1810/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8841 - val_loss: 8.6770\n",
      "Epoch 1811/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8835 - val_loss: 8.6768\n",
      "Epoch 1812/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8829 - val_loss: 8.6766\n",
      "Epoch 1813/10000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.8823 - val_loss: 8.6765\n",
      "Epoch 1814/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.8817 - val_loss: 8.6763\n",
      "Epoch 1815/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8811 - val_loss: 8.6759\n",
      "Epoch 1816/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.8806 - val_loss: 8.6756\n",
      "Epoch 1817/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.8800 - val_loss: 8.6753\n",
      "Epoch 1818/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8794 - val_loss: 8.6751\n",
      "Epoch 1819/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.8788 - val_loss: 8.6749\n",
      "Epoch 1820/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8782 - val_loss: 8.6746\n",
      "Epoch 1821/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8776 - val_loss: 8.6743\n",
      "Epoch 1822/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.8770 - val_loss: 8.6740\n",
      "Epoch 1823/10000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.8764 - val_loss: 8.6738\n",
      "Epoch 1824/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8759 - val_loss: 8.6735\n",
      "Epoch 1825/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.8753 - val_loss: 8.6733\n",
      "Epoch 1826/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.8747 - val_loss: 8.6731\n",
      "Epoch 1827/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.8741 - val_loss: 8.6728\n",
      "Epoch 1828/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8735 - val_loss: 8.6725\n",
      "Epoch 1829/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8729 - val_loss: 8.6722\n",
      "Epoch 1830/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8723 - val_loss: 8.6720\n",
      "Epoch 1831/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8718 - val_loss: 8.6717\n",
      "Epoch 1832/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.8712 - val_loss: 8.6715\n",
      "Epoch 1833/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.8706 - val_loss: 8.6713\n",
      "Epoch 1834/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8700 - val_loss: 8.6711\n",
      "Epoch 1835/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.8694 - val_loss: 8.6709\n",
      "Epoch 1836/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8689 - val_loss: 8.6707\n",
      "Epoch 1837/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8683 - val_loss: 8.6706\n",
      "Epoch 1838/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8677 - val_loss: 8.6704\n",
      "Epoch 1839/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8671 - val_loss: 8.6703\n",
      "Epoch 1840/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8665 - val_loss: 8.6701\n",
      "Epoch 1841/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8660 - val_loss: 8.6699\n",
      "Epoch 1842/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8654 - val_loss: 8.6695\n",
      "Epoch 1843/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.8648 - val_loss: 8.6692\n",
      "Epoch 1844/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.8642 - val_loss: 8.6689\n",
      "Epoch 1845/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8636 - val_loss: 8.6686\n",
      "Epoch 1846/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8631 - val_loss: 8.6683\n",
      "Epoch 1847/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.8625 - val_loss: 8.6681\n",
      "Epoch 1848/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.8619 - val_loss: 8.6678\n",
      "Epoch 1849/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8613 - val_loss: 8.6676\n",
      "Epoch 1850/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8608 - val_loss: 8.6674\n",
      "Epoch 1851/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8602 - val_loss: 8.6672\n",
      "Epoch 1852/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8596 - val_loss: 8.6670\n",
      "Epoch 1853/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8590 - val_loss: 8.6669\n",
      "Epoch 1854/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.8585 - val_loss: 8.6667\n",
      "Epoch 1855/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.8579 - val_loss: 8.6665\n",
      "Epoch 1856/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8573 - val_loss: 8.6662\n",
      "Epoch 1857/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.8568 - val_loss: 8.6659\n",
      "Epoch 1858/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.8562 - val_loss: 8.6656\n",
      "Epoch 1859/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8556 - val_loss: 8.6654\n",
      "Epoch 1860/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8551 - val_loss: 8.6652\n",
      "Epoch 1861/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8545 - val_loss: 8.6650\n",
      "Epoch 1862/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8539 - val_loss: 8.6649\n",
      "Epoch 1863/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.8534 - val_loss: 8.6647\n",
      "Epoch 1864/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.8528 - val_loss: 8.6645\n",
      "Epoch 1865/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8522 - val_loss: 8.6644\n",
      "Epoch 1866/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.8517 - val_loss: 8.6643\n",
      "Epoch 1867/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.8511 - val_loss: 8.6642\n",
      "Epoch 1868/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.8505 - val_loss: 8.6640\n",
      "Epoch 1869/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8500 - val_loss: 8.6639\n",
      "Epoch 1870/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8494 - val_loss: 8.6636\n",
      "Epoch 1871/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8489 - val_loss: 8.6633\n",
      "Epoch 1872/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8483 - val_loss: 8.6631\n",
      "Epoch 1873/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8477 - val_loss: 8.6628\n",
      "Epoch 1874/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8472 - val_loss: 8.6625\n",
      "Epoch 1875/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.8466 - val_loss: 8.6623\n",
      "Epoch 1876/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8461 - val_loss: 8.6621\n",
      "Epoch 1877/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8455 - val_loss: 8.6619\n",
      "Epoch 1878/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8449 - val_loss: 8.6617\n",
      "Epoch 1879/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.8444 - val_loss: 8.6615\n",
      "Epoch 1880/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.8438 - val_loss: 8.6613\n",
      "Epoch 1881/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8433 - val_loss: 8.6610\n",
      "Epoch 1882/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.8427 - val_loss: 8.6608\n",
      "Epoch 1883/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8422 - val_loss: 8.6606\n",
      "Epoch 1884/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8416 - val_loss: 8.6605\n",
      "Epoch 1885/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8411 - val_loss: 8.6603\n",
      "Epoch 1886/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8405 - val_loss: 8.6600\n",
      "Epoch 1887/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8400 - val_loss: 8.6597\n",
      "Epoch 1888/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8394 - val_loss: 8.6595\n",
      "Epoch 1889/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8388 - val_loss: 8.6592\n",
      "Epoch 1890/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8383 - val_loss: 8.6590\n",
      "Epoch 1891/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.8377 - val_loss: 8.6588\n",
      "Epoch 1892/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.8372 - val_loss: 8.6586\n",
      "Epoch 1893/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.8366 - val_loss: 8.6584\n",
      "Epoch 1894/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8361 - val_loss: 8.6582\n",
      "Epoch 1895/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8355 - val_loss: 8.6580\n",
      "Epoch 1896/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8350 - val_loss: 8.6578\n",
      "Epoch 1897/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.8344 - val_loss: 8.6576\n",
      "Epoch 1898/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8339 - val_loss: 8.6574\n",
      "Epoch 1899/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8333 - val_loss: 8.6571\n",
      "Epoch 1900/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.8328 - val_loss: 8.6569\n",
      "Epoch 1901/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.8322 - val_loss: 8.6566\n",
      "Epoch 1902/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8317 - val_loss: 8.6564\n",
      "Epoch 1903/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.8311 - val_loss: 8.6561\n",
      "Epoch 1904/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8306 - val_loss: 8.6559\n",
      "Epoch 1905/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8300 - val_loss: 8.6557\n",
      "Epoch 1906/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8295 - val_loss: 8.6555\n",
      "Epoch 1907/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.8290 - val_loss: 8.6553\n",
      "Epoch 1908/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.8284 - val_loss: 8.6552\n",
      "Epoch 1909/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.8279 - val_loss: 8.6550\n",
      "Epoch 1910/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.8273 - val_loss: 8.6548\n",
      "Epoch 1911/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.8268 - val_loss: 8.6545\n",
      "Epoch 1912/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.8262 - val_loss: 8.6542\n",
      "Epoch 1913/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8257 - val_loss: 8.6540\n",
      "Epoch 1914/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8251 - val_loss: 8.6537\n",
      "Epoch 1915/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8246 - val_loss: 8.6535\n",
      "Epoch 1916/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8240 - val_loss: 8.6532\n",
      "Epoch 1917/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.8235 - val_loss: 8.6529\n",
      "Epoch 1918/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8229 - val_loss: 8.6527\n",
      "Epoch 1919/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8224 - val_loss: 8.6525\n",
      "Epoch 1920/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8219 - val_loss: 8.6523\n",
      "Epoch 1921/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8213 - val_loss: 8.6521\n",
      "Epoch 1922/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.8208 - val_loss: 8.6519\n",
      "Epoch 1923/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8202 - val_loss: 8.6517\n",
      "Epoch 1924/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.8197 - val_loss: 8.6515\n",
      "Epoch 1925/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8191 - val_loss: 8.6513\n",
      "Epoch 1926/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.8186 - val_loss: 8.6512\n",
      "Epoch 1927/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8181 - val_loss: 8.6508\n",
      "Epoch 1928/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8175 - val_loss: 8.6505\n",
      "Epoch 1929/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8170 - val_loss: 8.6502\n",
      "Epoch 1930/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8164 - val_loss: 8.6500\n",
      "Epoch 1931/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8159 - val_loss: 8.6498\n",
      "Epoch 1932/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8153 - val_loss: 8.6496\n",
      "Epoch 1933/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8148 - val_loss: 8.6494\n",
      "Epoch 1934/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.8143 - val_loss: 8.6492\n",
      "Epoch 1935/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.8137 - val_loss: 8.6489\n",
      "Epoch 1936/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.8132 - val_loss: 8.6487\n",
      "Epoch 1937/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8126 - val_loss: 8.6485\n",
      "Epoch 1938/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.8121 - val_loss: 8.6483\n",
      "Epoch 1939/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8116 - val_loss: 8.6481\n",
      "Epoch 1940/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.8110 - val_loss: 8.6480\n",
      "Epoch 1941/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8105 - val_loss: 8.6479\n",
      "Epoch 1942/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.8099 - val_loss: 8.6476\n",
      "Epoch 1943/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.8094 - val_loss: 8.6473\n",
      "Epoch 1944/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.8089 - val_loss: 8.6471\n",
      "Epoch 1945/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.8083 - val_loss: 8.6468\n",
      "Epoch 1946/10000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.8078 - val_loss: 8.6465\n",
      "Epoch 1947/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.8073 - val_loss: 8.6462\n",
      "Epoch 1948/10000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.8067 - val_loss: 8.6460\n",
      "Epoch 1949/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.8062 - val_loss: 8.6458\n",
      "Epoch 1950/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.8056 - val_loss: 8.6457\n",
      "Epoch 1951/10000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.8051 - val_loss: 8.6456\n",
      "Epoch 1952/10000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.8046 - val_loss: 8.6454\n",
      "Epoch 1953/10000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.8040 - val_loss: 8.6452\n",
      "Epoch 1954/10000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.8035 - val_loss: 8.6451\n",
      "Epoch 1955/10000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 5.8030 - val_loss: 8.6447\n",
      "Epoch 1956/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 5.8024 - val_loss: 8.6444\n",
      "Epoch 1957/10000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 5.8019 - val_loss: 8.6442\n",
      "Epoch 1958/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.8014 - val_loss: 8.6439\n",
      "Epoch 1959/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8008 - val_loss: 8.6438\n",
      "Epoch 1960/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.8003 - val_loss: 8.6436\n",
      "Epoch 1961/10000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.7998 - val_loss: 8.6434\n",
      "Epoch 1962/10000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.7992 - val_loss: 8.6432\n",
      "Epoch 1963/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.7987 - val_loss: 8.6430\n",
      "Epoch 1964/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.7982 - val_loss: 8.6428\n",
      "Epoch 1965/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.7976 - val_loss: 8.6427\n",
      "Epoch 1966/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step - loss: 5.7971 - val_loss: 8.6425\n",
      "Epoch 1967/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.7966 - val_loss: 8.6423\n",
      "Epoch 1968/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.7960 - val_loss: 8.6420\n",
      "Epoch 1969/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.7955 - val_loss: 8.6417\n",
      "Epoch 1970/10000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.7950 - val_loss: 8.6414\n",
      "Epoch 1971/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.7944 - val_loss: 8.6411\n",
      "Epoch 1972/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.7939 - val_loss: 8.6409\n",
      "Epoch 1973/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.7934 - val_loss: 8.6406\n",
      "Epoch 1974/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.7929 - val_loss: 8.6405\n",
      "Epoch 1975/10000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.7923 - val_loss: 8.6403\n",
      "Epoch 1976/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7918 - val_loss: 8.6401\n",
      "Epoch 1977/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7913 - val_loss: 8.6400\n",
      "Epoch 1978/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.7907 - val_loss: 8.6398\n",
      "Epoch 1979/10000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.7902 - val_loss: 8.6396\n",
      "Epoch 1980/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.7897 - val_loss: 8.6395\n",
      "Epoch 1981/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.7892 - val_loss: 8.6393\n",
      "Epoch 1982/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.7886 - val_loss: 8.6390\n",
      "Epoch 1983/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7881 - val_loss: 8.6387\n",
      "Epoch 1984/10000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.7876 - val_loss: 8.6385\n",
      "Epoch 1985/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.7871 - val_loss: 8.6383\n",
      "Epoch 1986/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.7865 - val_loss: 8.6380\n",
      "Epoch 1987/10000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.7860 - val_loss: 8.6378\n",
      "Epoch 1988/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.7855 - val_loss: 8.6375\n",
      "Epoch 1989/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.7849 - val_loss: 8.6374\n",
      "Epoch 1990/10000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.7844 - val_loss: 8.6372\n",
      "Epoch 1991/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.7839 - val_loss: 8.6370\n",
      "Epoch 1992/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7834 - val_loss: 8.6368\n",
      "Epoch 1993/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7828 - val_loss: 8.6367\n",
      "Epoch 1994/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7823 - val_loss: 8.6365\n",
      "Epoch 1995/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.7818 - val_loss: 8.6363\n",
      "Epoch 1996/10000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.7813 - val_loss: 8.6360\n",
      "Epoch 1997/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.7807 - val_loss: 8.6359\n",
      "Epoch 1998/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.7802 - val_loss: 8.6357\n",
      "Epoch 1999/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.7797 - val_loss: 8.6355\n",
      "Epoch 2000/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.7791 - val_loss: 8.6354\n",
      "Epoch 2001/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.7786 - val_loss: 8.6352\n",
      "Epoch 2002/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.7781 - val_loss: 8.6351\n",
      "Epoch 2003/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7776 - val_loss: 8.6350\n",
      "Epoch 2004/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7770 - val_loss: 8.6348\n",
      "Epoch 2005/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7765 - val_loss: 8.6346\n",
      "Epoch 2006/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7760 - val_loss: 8.6344\n",
      "Epoch 2007/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7755 - val_loss: 8.6341\n",
      "Epoch 2008/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.7750 - val_loss: 8.6340\n",
      "Epoch 2009/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7744 - val_loss: 8.6338\n",
      "Epoch 2010/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7739 - val_loss: 8.6337\n",
      "Epoch 2011/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7734 - val_loss: 8.6336\n",
      "Epoch 2012/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7729 - val_loss: 8.6335\n",
      "Epoch 2013/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7723 - val_loss: 8.6334\n",
      "Epoch 2014/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.7718 - val_loss: 8.6333\n",
      "Epoch 2015/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.7713 - val_loss: 8.6331\n",
      "Epoch 2016/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.7708 - val_loss: 8.6328\n",
      "Epoch 2017/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7702 - val_loss: 8.6325\n",
      "Epoch 2018/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7697 - val_loss: 8.6323\n",
      "Epoch 2019/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.7692 - val_loss: 8.6322\n",
      "Epoch 2020/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.7687 - val_loss: 8.6321\n",
      "Epoch 2021/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.7682 - val_loss: 8.6320\n",
      "Epoch 2022/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.7676 - val_loss: 8.6318\n",
      "Epoch 2023/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.7671 - val_loss: 8.6317\n",
      "Epoch 2024/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7666 - val_loss: 8.6316\n",
      "Epoch 2025/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7661 - val_loss: 8.6313\n",
      "Epoch 2026/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.7656 - val_loss: 8.6311\n",
      "Epoch 2027/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.7651 - val_loss: 8.6308\n",
      "Epoch 2028/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.7645 - val_loss: 8.6306\n",
      "Epoch 2029/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.7640 - val_loss: 8.6305\n",
      "Epoch 2030/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.7635 - val_loss: 8.6304\n",
      "Epoch 2031/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.7630 - val_loss: 8.6302\n",
      "Epoch 2032/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7625 - val_loss: 8.6301\n",
      "Epoch 2033/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.7619 - val_loss: 8.6299\n",
      "Epoch 2034/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7614 - val_loss: 8.6297\n",
      "Epoch 2035/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7609 - val_loss: 8.6295\n",
      "Epoch 2036/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.7604 - val_loss: 8.6293\n",
      "Epoch 2037/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.7599 - val_loss: 8.6291\n",
      "Epoch 2038/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.7594 - val_loss: 8.6290\n",
      "Epoch 2039/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7589 - val_loss: 8.6288\n",
      "Epoch 2040/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7583 - val_loss: 8.6286\n",
      "Epoch 2041/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7578 - val_loss: 8.6285\n",
      "Epoch 2042/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7573 - val_loss: 8.6283\n",
      "Epoch 2043/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7568 - val_loss: 8.6282\n",
      "Epoch 2044/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7563 - val_loss: 8.6280\n",
      "Epoch 2045/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7558 - val_loss: 8.6278\n",
      "Epoch 2046/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7553 - val_loss: 8.6276\n",
      "Epoch 2047/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7548 - val_loss: 8.6274\n",
      "Epoch 2048/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.7542 - val_loss: 8.6272\n",
      "Epoch 2049/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.7537 - val_loss: 8.6270\n",
      "Epoch 2050/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7532 - val_loss: 8.6268\n",
      "Epoch 2051/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7527 - val_loss: 8.6267\n",
      "Epoch 2052/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7522 - val_loss: 8.6265\n",
      "Epoch 2053/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7517 - val_loss: 8.6264\n",
      "Epoch 2054/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7512 - val_loss: 8.6263\n",
      "Epoch 2055/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.7507 - val_loss: 8.6260\n",
      "Epoch 2056/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7502 - val_loss: 8.6258\n",
      "Epoch 2057/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.7497 - val_loss: 8.6257\n",
      "Epoch 2058/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.7491 - val_loss: 8.6255\n",
      "Epoch 2059/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7486 - val_loss: 8.6253\n",
      "Epoch 2060/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7481 - val_loss: 8.6252\n",
      "Epoch 2061/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7476 - val_loss: 8.6251\n",
      "Epoch 2062/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.7471 - val_loss: 8.6249\n",
      "Epoch 2063/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.7466 - val_loss: 8.6248\n",
      "Epoch 2064/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7461 - val_loss: 8.6246\n",
      "Epoch 2065/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7456 - val_loss: 8.6244\n",
      "Epoch 2066/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.7451 - val_loss: 8.6242\n",
      "Epoch 2067/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 5.7446 - val_loss: 8.6241\n",
      "Epoch 2068/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7441 - val_loss: 8.6239\n",
      "Epoch 2069/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.7436 - val_loss: 8.6238\n",
      "Epoch 2070/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.7431 - val_loss: 8.6236\n",
      "Epoch 2071/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7426 - val_loss: 8.6235\n",
      "Epoch 2072/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.7421 - val_loss: 8.6233\n",
      "Epoch 2073/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7416 - val_loss: 8.6232\n",
      "Epoch 2074/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.7411 - val_loss: 8.6231\n",
      "Epoch 2075/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7406 - val_loss: 8.6229\n",
      "Epoch 2076/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7400 - val_loss: 8.6227\n",
      "Epoch 2077/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7395 - val_loss: 8.6225\n",
      "Epoch 2078/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7390 - val_loss: 8.6223\n",
      "Epoch 2079/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7385 - val_loss: 8.6222\n",
      "Epoch 2080/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.7380 - val_loss: 8.6221\n",
      "Epoch 2081/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7375 - val_loss: 8.6220\n",
      "Epoch 2082/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.7370 - val_loss: 8.6219\n",
      "Epoch 2083/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7365 - val_loss: 8.6218\n",
      "Epoch 2084/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7360 - val_loss: 8.6216\n",
      "Epoch 2085/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.7355 - val_loss: 8.6214\n",
      "Epoch 2086/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.7350 - val_loss: 8.6212\n",
      "Epoch 2087/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7345 - val_loss: 8.6210\n",
      "Epoch 2088/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7340 - val_loss: 8.6208\n",
      "Epoch 2089/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.7335 - val_loss: 8.6207\n",
      "Epoch 2090/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7330 - val_loss: 8.6205\n",
      "Epoch 2091/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.7325 - val_loss: 8.6204\n",
      "Epoch 2092/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.7320 - val_loss: 8.6203\n",
      "Epoch 2093/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7315 - val_loss: 8.6202\n",
      "Epoch 2094/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7310 - val_loss: 8.6200\n",
      "Epoch 2095/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7306 - val_loss: 8.6198\n",
      "Epoch 2096/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7301 - val_loss: 8.6196\n",
      "Epoch 2097/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.7296 - val_loss: 8.6194\n",
      "Epoch 2098/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7291 - val_loss: 8.6192\n",
      "Epoch 2099/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.7286 - val_loss: 8.6190\n",
      "Epoch 2100/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7281 - val_loss: 8.6189\n",
      "Epoch 2101/10000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.7276 - val_loss: 8.6188\n",
      "Epoch 2102/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7271 - val_loss: 8.6186\n",
      "Epoch 2103/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.7266 - val_loss: 8.6185\n",
      "Epoch 2104/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.7261 - val_loss: 8.6184\n",
      "Epoch 2105/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7256 - val_loss: 8.6182\n",
      "Epoch 2106/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.7251 - val_loss: 8.6180\n",
      "Epoch 2107/10000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.7246 - val_loss: 8.6179\n",
      "Epoch 2108/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.7241 - val_loss: 8.6178\n",
      "Epoch 2109/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 5.7236 - val_loss: 8.6176\n",
      "Epoch 2110/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 5.7231 - val_loss: 8.6173\n",
      "Epoch 2111/10000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.7226 - val_loss: 8.6171\n",
      "Epoch 2112/10000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 5.7221 - val_loss: 8.6170\n",
      "Epoch 2113/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.7216 - val_loss: 8.6169\n",
      "Epoch 2114/10000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.7211 - val_loss: 8.6167\n",
      "Epoch 2115/10000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.7206 - val_loss: 8.6165\n",
      "Epoch 2116/10000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.7201 - val_loss: 8.6162\n",
      "Epoch 2117/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.7196 - val_loss: 8.6161\n",
      "Epoch 2118/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7191 - val_loss: 8.6159\n",
      "Epoch 2119/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.7187 - val_loss: 8.6158\n",
      "Epoch 2120/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7182 - val_loss: 8.6157\n",
      "Epoch 2121/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.7177 - val_loss: 8.6156\n",
      "Epoch 2122/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7172 - val_loss: 8.6155\n",
      "Epoch 2123/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.7167 - val_loss: 8.6154\n",
      "Epoch 2124/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 5.7162 - val_loss: 8.6152\n",
      "Epoch 2125/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7157 - val_loss: 8.6151\n",
      "Epoch 2126/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.7152 - val_loss: 8.6150\n",
      "Epoch 2127/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.7147 - val_loss: 8.6148\n",
      "Epoch 2128/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.7142 - val_loss: 8.6147\n",
      "Epoch 2129/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.7138 - val_loss: 8.6145\n",
      "Epoch 2130/10000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.7133 - val_loss: 8.6144\n",
      "Epoch 2131/10000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.7128 - val_loss: 8.6143\n",
      "Epoch 2132/10000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.7123 - val_loss: 8.6142\n",
      "Epoch 2133/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.7118 - val_loss: 8.6140\n",
      "Epoch 2134/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.7113 - val_loss: 8.6138\n",
      "Epoch 2135/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.7108 - val_loss: 8.6136\n",
      "Epoch 2136/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.7103 - val_loss: 8.6135\n",
      "Epoch 2137/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.7099 - val_loss: 8.6134\n",
      "Epoch 2138/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.7094 - val_loss: 8.6133\n",
      "Epoch 2139/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.7089 - val_loss: 8.6132\n",
      "Epoch 2140/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7084 - val_loss: 8.6132\n",
      "Epoch 2141/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.7079 - val_loss: 8.6131\n",
      "Epoch 2142/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.7074 - val_loss: 8.6129\n",
      "Epoch 2143/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7069 - val_loss: 8.6127\n",
      "Epoch 2144/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7065 - val_loss: 8.6126\n",
      "Epoch 2145/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7060 - val_loss: 8.6125\n",
      "Epoch 2146/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.7055 - val_loss: 8.6123\n",
      "Epoch 2147/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.7050 - val_loss: 8.6122\n",
      "Epoch 2148/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7045 - val_loss: 8.6120\n",
      "Epoch 2149/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7040 - val_loss: 8.6119\n",
      "Epoch 2150/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7036 - val_loss: 8.6119\n",
      "Epoch 2151/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7031 - val_loss: 8.6118\n",
      "Epoch 2152/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.7026 - val_loss: 8.6117\n",
      "Epoch 2153/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.7021 - val_loss: 8.6115\n",
      "Epoch 2154/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7016 - val_loss: 8.6114\n",
      "Epoch 2155/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7011 - val_loss: 8.6112\n",
      "Epoch 2156/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7007 - val_loss: 8.6111\n",
      "Epoch 2157/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7002 - val_loss: 8.6110\n",
      "Epoch 2158/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6997 - val_loss: 8.6108\n",
      "Epoch 2159/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6992 - val_loss: 8.6107\n",
      "Epoch 2160/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.6987 - val_loss: 8.6107\n",
      "Epoch 2161/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6983 - val_loss: 8.6105\n",
      "Epoch 2162/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.6978 - val_loss: 8.6103\n",
      "Epoch 2163/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.6973 - val_loss: 8.6101\n",
      "Epoch 2164/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6968 - val_loss: 8.6099\n",
      "Epoch 2165/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.6963 - val_loss: 8.6098\n",
      "Epoch 2166/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.6959 - val_loss: 8.6097\n",
      "Epoch 2167/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6954 - val_loss: 8.6096\n",
      "Epoch 2168/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.6949 - val_loss: 8.6095\n",
      "Epoch 2169/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6944 - val_loss: 8.6094\n",
      "Epoch 2170/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.6939 - val_loss: 8.6092\n",
      "Epoch 2171/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.6935 - val_loss: 8.6091\n",
      "Epoch 2172/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.6930 - val_loss: 8.6089\n",
      "Epoch 2173/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.6925 - val_loss: 8.6088\n",
      "Epoch 2174/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6920 - val_loss: 8.6086\n",
      "Epoch 2175/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.6916 - val_loss: 8.6084\n",
      "Epoch 2176/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.6911 - val_loss: 8.6083\n",
      "Epoch 2177/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.6906 - val_loss: 8.6083\n",
      "Epoch 2178/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.6901 - val_loss: 8.6082\n",
      "Epoch 2179/10000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.6897 - val_loss: 8.6081\n",
      "Epoch 2180/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6892 - val_loss: 8.6079\n",
      "Epoch 2181/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.6887 - val_loss: 8.6077\n",
      "Epoch 2182/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6882 - val_loss: 8.6075\n",
      "Epoch 2183/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6878 - val_loss: 8.6072\n",
      "Epoch 2184/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.6873 - val_loss: 8.6071\n",
      "Epoch 2185/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.6868 - val_loss: 8.6070\n",
      "Epoch 2186/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6863 - val_loss: 8.6069\n",
      "Epoch 2187/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6859 - val_loss: 8.6068\n",
      "Epoch 2188/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6854 - val_loss: 8.6066\n",
      "Epoch 2189/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6849 - val_loss: 8.6065\n",
      "Epoch 2190/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.6844 - val_loss: 8.6063\n",
      "Epoch 2191/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6840 - val_loss: 8.6062\n",
      "Epoch 2192/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.6835 - val_loss: 8.6060\n",
      "Epoch 2193/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.6830 - val_loss: 8.6058\n",
      "Epoch 2194/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.6825 - val_loss: 8.6057\n",
      "Epoch 2195/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6821 - val_loss: 8.6057\n",
      "Epoch 2196/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6816 - val_loss: 8.6056\n",
      "Epoch 2197/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6811 - val_loss: 8.6054\n",
      "Epoch 2198/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6807 - val_loss: 8.6052\n",
      "Epoch 2199/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6802 - val_loss: 8.6049\n",
      "Epoch 2200/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.6797 - val_loss: 8.6048\n",
      "Epoch 2201/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6793 - val_loss: 8.6047\n",
      "Epoch 2202/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.6788 - val_loss: 8.6045\n",
      "Epoch 2203/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6783 - val_loss: 8.6044\n",
      "Epoch 2204/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6778 - val_loss: 8.6042\n",
      "Epoch 2205/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.6774 - val_loss: 8.6042\n",
      "Epoch 2206/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6769 - val_loss: 8.6040\n",
      "Epoch 2207/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.6764 - val_loss: 8.6039\n",
      "Epoch 2208/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.6760 - val_loss: 8.6037\n",
      "Epoch 2209/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.6755 - val_loss: 8.6036\n",
      "Epoch 2210/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6750 - val_loss: 8.6034\n",
      "Epoch 2211/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6746 - val_loss: 8.6033\n",
      "Epoch 2212/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6741 - val_loss: 8.6033\n",
      "Epoch 2213/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.6737 - val_loss: 8.6032\n",
      "Epoch 2214/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.6732 - val_loss: 8.6031\n",
      "Epoch 2215/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.6727 - val_loss: 8.6029\n",
      "Epoch 2216/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.6723 - val_loss: 8.6026\n",
      "Epoch 2217/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.6718 - val_loss: 8.6024\n",
      "Epoch 2218/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.6713 - val_loss: 8.6023\n",
      "Epoch 2219/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6709 - val_loss: 8.6022\n",
      "Epoch 2220/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.6704 - val_loss: 8.6022\n",
      "Epoch 2221/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6699 - val_loss: 8.6020\n",
      "Epoch 2222/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6695 - val_loss: 8.6019\n",
      "Epoch 2223/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6690 - val_loss: 8.6018\n",
      "Epoch 2224/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6685 - val_loss: 8.6016\n",
      "Epoch 2225/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.6681 - val_loss: 8.6013\n",
      "Epoch 2226/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6676 - val_loss: 8.6011\n",
      "Epoch 2227/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6672 - val_loss: 8.6010\n",
      "Epoch 2228/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6667 - val_loss: 8.6010\n",
      "Epoch 2229/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6662 - val_loss: 8.6009\n",
      "Epoch 2230/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6658 - val_loss: 8.6008\n",
      "Epoch 2231/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.6653 - val_loss: 8.6007\n",
      "Epoch 2232/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6649 - val_loss: 8.6005\n",
      "Epoch 2233/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6644 - val_loss: 8.6003\n",
      "Epoch 2234/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6639 - val_loss: 8.6002\n",
      "Epoch 2235/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6635 - val_loss: 8.6001\n",
      "Epoch 2236/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6630 - val_loss: 8.6000\n",
      "Epoch 2237/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6625 - val_loss: 8.5998\n",
      "Epoch 2238/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6621 - val_loss: 8.5997\n",
      "Epoch 2239/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6616 - val_loss: 8.5996\n",
      "Epoch 2240/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6612 - val_loss: 8.5995\n",
      "Epoch 2241/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6607 - val_loss: 8.5993\n",
      "Epoch 2242/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6602 - val_loss: 8.5992\n",
      "Epoch 2243/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6598 - val_loss: 8.5990\n",
      "Epoch 2244/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6593 - val_loss: 8.5989\n",
      "Epoch 2245/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6589 - val_loss: 8.5987\n",
      "Epoch 2246/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6584 - val_loss: 8.5986\n",
      "Epoch 2247/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6580 - val_loss: 8.5984\n",
      "Epoch 2248/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.6575 - val_loss: 8.5983\n",
      "Epoch 2249/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.6570 - val_loss: 8.5981\n",
      "Epoch 2250/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.6566 - val_loss: 8.5979\n",
      "Epoch 2251/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.6561 - val_loss: 8.5977\n",
      "Epoch 2252/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.6557 - val_loss: 8.5975\n",
      "Epoch 2253/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6552 - val_loss: 8.5974\n",
      "Epoch 2254/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6548 - val_loss: 8.5972\n",
      "Epoch 2255/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.6543 - val_loss: 8.5970\n",
      "Epoch 2256/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.6538 - val_loss: 8.5968\n",
      "Epoch 2257/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6534 - val_loss: 8.5967\n",
      "Epoch 2258/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.6529 - val_loss: 8.5966\n",
      "Epoch 2259/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.6525 - val_loss: 8.5965\n",
      "Epoch 2260/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6520 - val_loss: 8.5963\n",
      "Epoch 2261/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.6516 - val_loss: 8.5961\n",
      "Epoch 2262/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6511 - val_loss: 8.5959\n",
      "Epoch 2263/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6507 - val_loss: 8.5957\n",
      "Epoch 2264/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.6502 - val_loss: 8.5955\n",
      "Epoch 2265/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.6497 - val_loss: 8.5953\n",
      "Epoch 2266/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.6493 - val_loss: 8.5952\n",
      "Epoch 2267/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6488 - val_loss: 8.5951\n",
      "Epoch 2268/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6484 - val_loss: 8.5949\n",
      "Epoch 2269/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6479 - val_loss: 8.5948\n",
      "Epoch 2270/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6475 - val_loss: 8.5946\n",
      "Epoch 2271/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6470 - val_loss: 8.5945\n",
      "Epoch 2272/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6466 - val_loss: 8.5943\n",
      "Epoch 2273/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6461 - val_loss: 8.5942\n",
      "Epoch 2274/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.6457 - val_loss: 8.5940\n",
      "Epoch 2275/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6452 - val_loss: 8.5939\n",
      "Epoch 2276/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6448 - val_loss: 8.5938\n",
      "Epoch 2277/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6443 - val_loss: 8.5936\n",
      "Epoch 2278/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6438 - val_loss: 8.5935\n",
      "Epoch 2279/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6434 - val_loss: 8.5934\n",
      "Epoch 2280/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6429 - val_loss: 8.5933\n",
      "Epoch 2281/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6425 - val_loss: 8.5931\n",
      "Epoch 2282/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6420 - val_loss: 8.5930\n",
      "Epoch 2283/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6416 - val_loss: 8.5928\n",
      "Epoch 2284/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6411 - val_loss: 8.5927\n",
      "Epoch 2285/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6407 - val_loss: 8.5925\n",
      "Epoch 2286/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6402 - val_loss: 8.5924\n",
      "Epoch 2287/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.6398 - val_loss: 8.5922\n",
      "Epoch 2288/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6393 - val_loss: 8.5920\n",
      "Epoch 2289/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.6389 - val_loss: 8.5919\n",
      "Epoch 2290/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.6384 - val_loss: 8.5917\n",
      "Epoch 2291/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.6380 - val_loss: 8.5916\n",
      "Epoch 2292/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6375 - val_loss: 8.5915\n",
      "Epoch 2293/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6371 - val_loss: 8.5913\n",
      "Epoch 2294/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.6366 - val_loss: 8.5911\n",
      "Epoch 2295/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.6362 - val_loss: 8.5910\n",
      "Epoch 2296/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.6357 - val_loss: 8.5908\n",
      "Epoch 2297/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6353 - val_loss: 8.5908\n",
      "Epoch 2298/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6348 - val_loss: 8.5906\n",
      "Epoch 2299/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.634 - 0s 47ms/step - loss: 5.6344 - val_loss: 8.5905\n",
      "Epoch 2300/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.6339 - val_loss: 8.5904\n",
      "Epoch 2301/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.6335 - val_loss: 8.5902\n",
      "Epoch 2302/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.6330 - val_loss: 8.5900\n",
      "Epoch 2303/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.6326 - val_loss: 8.5898\n",
      "Epoch 2304/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6322 - val_loss: 8.5896\n",
      "Epoch 2305/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.6317 - val_loss: 8.5895\n",
      "Epoch 2306/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.6312 - val_loss: 8.5894\n",
      "Epoch 2307/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6308 - val_loss: 8.5894\n",
      "Epoch 2308/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6304 - val_loss: 8.5893\n",
      "Epoch 2309/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6299 - val_loss: 8.5891\n",
      "Epoch 2310/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6295 - val_loss: 8.5890\n",
      "Epoch 2311/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6290 - val_loss: 8.5888\n",
      "Epoch 2312/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6286 - val_loss: 8.5885\n",
      "Epoch 2313/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6281 - val_loss: 8.5884\n",
      "Epoch 2314/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6277 - val_loss: 8.5882\n",
      "Epoch 2315/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6272 - val_loss: 8.5881\n",
      "Epoch 2316/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6268 - val_loss: 8.5880\n",
      "Epoch 2317/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6263 - val_loss: 8.5879\n",
      "Epoch 2318/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6259 - val_loss: 8.5878\n",
      "Epoch 2319/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6255 - val_loss: 8.5875\n",
      "Epoch 2320/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6250 - val_loss: 8.5873\n",
      "Epoch 2321/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.6246 - val_loss: 8.5870\n",
      "Epoch 2322/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.6241 - val_loss: 8.5869\n",
      "Epoch 2323/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6237 - val_loss: 8.5868\n",
      "Epoch 2324/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6232 - val_loss: 8.5867\n",
      "Epoch 2325/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6228 - val_loss: 8.5866\n",
      "Epoch 2326/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6223 - val_loss: 8.5865\n",
      "Epoch 2327/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6219 - val_loss: 8.5864\n",
      "Epoch 2328/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6214 - val_loss: 8.5863\n",
      "Epoch 2329/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6210 - val_loss: 8.5862\n",
      "Epoch 2330/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6206 - val_loss: 8.5860\n",
      "Epoch 2331/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6201 - val_loss: 8.5858\n",
      "Epoch 2332/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.6197 - val_loss: 8.5856\n",
      "Epoch 2333/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.6192 - val_loss: 8.5854\n",
      "Epoch 2334/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6188 - val_loss: 8.5853\n",
      "Epoch 2335/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6183 - val_loss: 8.5851\n",
      "Epoch 2336/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.6179 - val_loss: 8.5850\n",
      "Epoch 2337/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.6175 - val_loss: 8.5849\n",
      "Epoch 2338/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.6170 - val_loss: 8.5847\n",
      "Epoch 2339/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.6166 - val_loss: 8.5846\n",
      "Epoch 2340/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6161 - val_loss: 8.5844\n",
      "Epoch 2341/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6157 - val_loss: 8.5842\n",
      "Epoch 2342/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.6153 - val_loss: 8.5840\n",
      "Epoch 2343/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.6148 - val_loss: 8.5839\n",
      "Epoch 2344/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.6144 - val_loss: 8.5838\n",
      "Epoch 2345/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.6139 - val_loss: 8.5837\n",
      "Epoch 2346/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.6135 - val_loss: 8.5835\n",
      "Epoch 2347/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6131 - val_loss: 8.5834\n",
      "Epoch 2348/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.6126 - val_loss: 8.5833\n",
      "Epoch 2349/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6122 - val_loss: 8.5831\n",
      "Epoch 2350/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6117 - val_loss: 8.5830\n",
      "Epoch 2351/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.6113 - val_loss: 8.5828\n",
      "Epoch 2352/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.6109 - val_loss: 8.5827\n",
      "Epoch 2353/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6104 - val_loss: 8.5826\n",
      "Epoch 2354/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6100 - val_loss: 8.5825\n",
      "Epoch 2355/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6095 - val_loss: 8.5824\n",
      "Epoch 2356/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6091 - val_loss: 8.5822\n",
      "Epoch 2357/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6087 - val_loss: 8.5821\n",
      "Epoch 2358/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6082 - val_loss: 8.5819\n",
      "Epoch 2359/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6078 - val_loss: 8.5817\n",
      "Epoch 2360/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6073 - val_loss: 8.5816\n",
      "Epoch 2361/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6069 - val_loss: 8.5815\n",
      "Epoch 2362/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6065 - val_loss: 8.5813\n",
      "Epoch 2363/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6060 - val_loss: 8.5811\n",
      "Epoch 2364/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.6056 - val_loss: 8.5810\n",
      "Epoch 2365/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6052 - val_loss: 8.5808\n",
      "Epoch 2366/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6047 - val_loss: 8.5806\n",
      "Epoch 2367/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6043 - val_loss: 8.5805\n",
      "Epoch 2368/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6038 - val_loss: 8.5805\n",
      "Epoch 2369/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6034 - val_loss: 8.5804\n",
      "Epoch 2370/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6030 - val_loss: 8.5803\n",
      "Epoch 2371/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6025 - val_loss: 8.5802\n",
      "Epoch 2372/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.6021 - val_loss: 8.5800\n",
      "Epoch 2373/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6017 - val_loss: 8.5799\n",
      "Epoch 2374/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6012 - val_loss: 8.5798\n",
      "Epoch 2375/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6008 - val_loss: 8.5797\n",
      "Epoch 2376/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6004 - val_loss: 8.5795\n",
      "Epoch 2377/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.5999 - val_loss: 8.5794\n",
      "Epoch 2378/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.5995 - val_loss: 8.5792\n",
      "Epoch 2379/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5991 - val_loss: 8.5790\n",
      "Epoch 2380/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.5986 - val_loss: 8.5790\n",
      "Epoch 2381/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.5982 - val_loss: 8.5788\n",
      "Epoch 2382/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.5977 - val_loss: 8.5787\n",
      "Epoch 2383/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.5973 - val_loss: 8.5785\n",
      "Epoch 2384/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.5969 - val_loss: 8.5784\n",
      "Epoch 2385/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5964 - val_loss: 8.5782\n",
      "Epoch 2386/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.5960 - val_loss: 8.5781\n",
      "Epoch 2387/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.5956 - val_loss: 8.5781\n",
      "Epoch 2388/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.5951 - val_loss: 8.5780\n",
      "Epoch 2389/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5947 - val_loss: 8.5779\n",
      "Epoch 2390/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5943 - val_loss: 8.5778\n",
      "Epoch 2391/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.5939 - val_loss: 8.5776\n",
      "Epoch 2392/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.5934 - val_loss: 8.5775\n",
      "Epoch 2393/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5930 - val_loss: 8.5773\n",
      "Epoch 2394/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.5926 - val_loss: 8.5771\n",
      "Epoch 2395/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.5921 - val_loss: 8.5769\n",
      "Epoch 2396/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.5917 - val_loss: 8.5767\n",
      "Epoch 2397/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.5913 - val_loss: 8.5766\n",
      "Epoch 2398/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5908 - val_loss: 8.5765\n",
      "Epoch 2399/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5904 - val_loss: 8.5765\n",
      "Epoch 2400/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5900 - val_loss: 8.5764\n",
      "Epoch 2401/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.5895 - val_loss: 8.5763\n",
      "Epoch 2402/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5891 - val_loss: 8.5762\n",
      "Epoch 2403/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5887 - val_loss: 8.5760\n",
      "Epoch 2404/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5882 - val_loss: 8.5759\n",
      "Epoch 2405/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5878 - val_loss: 8.5757\n",
      "Epoch 2406/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5874 - val_loss: 8.5756\n",
      "Epoch 2407/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.5869 - val_loss: 8.5755\n",
      "Epoch 2408/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5865 - val_loss: 8.5754\n",
      "Epoch 2409/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5861 - val_loss: 8.5753\n",
      "Epoch 2410/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5857 - val_loss: 8.5751\n",
      "Epoch 2411/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.5852 - val_loss: 8.5750\n",
      "Epoch 2412/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.5848 - val_loss: 8.5747\n",
      "Epoch 2413/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5844 - val_loss: 8.5744\n",
      "Epoch 2414/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5839 - val_loss: 8.5742\n",
      "Epoch 2415/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.5835 - val_loss: 8.5741\n",
      "Epoch 2416/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.5831 - val_loss: 8.5740\n",
      "Epoch 2417/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.5826 - val_loss: 8.5740\n",
      "Epoch 2418/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5822 - val_loss: 8.5739\n",
      "Epoch 2419/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.5818 - val_loss: 8.5738\n",
      "Epoch 2420/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.5814 - val_loss: 8.5737\n",
      "Epoch 2421/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.5809 - val_loss: 8.5736\n",
      "Epoch 2422/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.5805 - val_loss: 8.5734\n",
      "Epoch 2423/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.5801 - val_loss: 8.5731\n",
      "Epoch 2424/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5796 - val_loss: 8.5729\n",
      "Epoch 2425/10000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.5792 - val_loss: 8.5728\n",
      "Epoch 2426/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.5788 - val_loss: 8.5728\n",
      "Epoch 2427/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5784 - val_loss: 8.5727\n",
      "Epoch 2428/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.5779 - val_loss: 8.5727\n",
      "Epoch 2429/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.5775 - val_loss: 8.5726\n",
      "Epoch 2430/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.5771 - val_loss: 8.5725\n",
      "Epoch 2431/10000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.5767 - val_loss: 8.5723\n",
      "Epoch 2432/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.5762 - val_loss: 8.5721\n",
      "Epoch 2433/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5758 - val_loss: 8.5720\n",
      "Epoch 2434/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5754 - val_loss: 8.5719\n",
      "Epoch 2435/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5749 - val_loss: 8.5718\n",
      "Epoch 2436/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.5745 - val_loss: 8.5717\n",
      "Epoch 2437/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.5741 - val_loss: 8.5715\n",
      "Epoch 2438/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.5737 - val_loss: 8.5713\n",
      "Epoch 2439/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.5732 - val_loss: 8.5711\n",
      "Epoch 2440/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5728 - val_loss: 8.5710\n",
      "Epoch 2441/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 5.5724 - val_loss: 8.5708\n",
      "Epoch 2442/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.5720 - val_loss: 8.5706\n",
      "Epoch 2443/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5715 - val_loss: 8.5705\n",
      "Epoch 2444/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.5711 - val_loss: 8.5703\n",
      "Epoch 2445/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.5707 - val_loss: 8.5702\n",
      "Epoch 2446/10000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.5703 - val_loss: 8.5702\n",
      "Epoch 2447/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.5698 - val_loss: 8.5702\n",
      "Epoch 2448/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.5694 - val_loss: 8.5702\n",
      "Epoch 2449/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.5690 - val_loss: 8.5702\n",
      "Epoch 2450/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.5685 - val_loss: 8.5701\n",
      "Epoch 2451/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.5681 - val_loss: 8.5701\n",
      "Epoch 2452/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.5677 - val_loss: 8.5701\n",
      "Epoch 2453/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.5672 - val_loss: 8.5702\n",
      "Epoch 2454/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5668 - val_loss: 8.5702\n",
      "Epoch 2455/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.5663 - val_loss: 8.5701\n",
      "Epoch 2456/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.5659 - val_loss: 8.5700\n",
      "Epoch 2457/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.5655 - val_loss: 8.5700\n",
      "Epoch 2458/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.5650 - val_loss: 8.5700\n",
      "Epoch 2459/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.5646 - val_loss: 8.5700\n",
      "Epoch 2460/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5641 - val_loss: 8.5700\n",
      "Epoch 2461/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5637 - val_loss: 8.5699\n",
      "Epoch 2462/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.5633 - val_loss: 8.5698\n",
      "Epoch 2463/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.5628 - val_loss: 8.5698\n",
      "Epoch 2464/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.5624 - val_loss: 8.5698\n",
      "Epoch 2465/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.5620 - val_loss: 8.5698\n",
      "Epoch 2466/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.5615 - val_loss: 8.5698\n",
      "Epoch 2467/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5611 - val_loss: 8.5697\n",
      "Epoch 2468/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.5606 - val_loss: 8.5696\n",
      "Epoch 2469/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5602 - val_loss: 8.5696\n",
      "Epoch 2470/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5598 - val_loss: 8.5696\n",
      "Epoch 2471/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5593 - val_loss: 8.5697\n",
      "Epoch 2472/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5589 - val_loss: 8.5698\n",
      "Epoch 2473/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5584 - val_loss: 8.5698\n",
      "Epoch 2474/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5580 - val_loss: 8.5699\n",
      "Epoch 2475/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5576 - val_loss: 8.5700\n",
      "Epoch 2476/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5571 - val_loss: 8.5701\n",
      "Epoch 2477/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5567 - val_loss: 8.5702\n",
      "Epoch 2478/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5563 - val_loss: 8.5702\n",
      "Epoch 2479/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5558 - val_loss: 8.5702\n",
      "Epoch 2480/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5554 - val_loss: 8.5702\n",
      "Epoch 2481/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.5550 - val_loss: 8.5703\n",
      "Epoch 2482/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5545 - val_loss: 8.5704\n",
      "Epoch 2483/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5541 - val_loss: 8.5703\n",
      "Epoch 2484/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5537 - val_loss: 8.5703\n",
      "Epoch 2485/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.5532 - val_loss: 8.5703\n",
      "Epoch 2486/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.5528 - val_loss: 8.5703\n",
      "Epoch 2487/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.5524 - val_loss: 8.5703\n",
      "Epoch 2488/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.5519 - val_loss: 8.5704\n",
      "Epoch 2489/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.5515 - val_loss: 8.5705\n",
      "Epoch 2490/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5511 - val_loss: 8.5705\n",
      "Epoch 2491/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5507 - val_loss: 8.5705\n",
      "Epoch 2492/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5502 - val_loss: 8.5705\n",
      "Epoch 2493/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5498 - val_loss: 8.5705\n",
      "Epoch 2494/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5494 - val_loss: 8.5706\n",
      "Epoch 2495/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.5489 - val_loss: 8.5707\n",
      "Epoch 2496/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5485 - val_loss: 8.5708\n",
      "Epoch 2497/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5481 - val_loss: 8.5708\n",
      "Epoch 2498/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5476 - val_loss: 8.5709\n",
      "Epoch 2499/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.5472 - val_loss: 8.5710\n",
      "Epoch 2500/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.5468 - val_loss: 8.5711\n",
      "Epoch 2501/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.5463 - val_loss: 8.5712\n",
      "Epoch 2502/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5459 - val_loss: 8.5712\n",
      "Epoch 2503/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5455 - val_loss: 8.5712\n",
      "Epoch 2504/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5450 - val_loss: 8.5713\n",
      "Epoch 2505/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5446 - val_loss: 8.5714\n",
      "Epoch 2506/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5442 - val_loss: 8.5716\n",
      "Epoch 2507/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5437 - val_loss: 8.5717\n",
      "Epoch 2508/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5433 - val_loss: 8.5717\n",
      "Epoch 2509/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.5429 - val_loss: 8.5717\n",
      "Epoch 2510/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.5424 - val_loss: 8.5717\n",
      "Epoch 2511/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.5420 - val_loss: 8.5717\n",
      "Epoch 2512/10000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.5416 - val_loss: 8.5718\n",
      "Epoch 2513/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.5412 - val_loss: 8.5719\n",
      "Epoch 2514/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5407 - val_loss: 8.5720\n",
      "Epoch 2515/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5403 - val_loss: 8.5721\n",
      "Epoch 2516/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5399 - val_loss: 8.5722\n",
      "Epoch 2517/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.5394 - val_loss: 8.5723\n",
      "Epoch 2518/10000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.5390 - val_loss: 8.5725\n",
      "Epoch 2519/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 5.5386 - val_loss: 8.5726\n",
      "Epoch 2520/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.5381 - val_loss: 8.5728\n",
      "Epoch 2521/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5377 - val_loss: 8.5729\n",
      "Epoch 2522/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.5373 - val_loss: 8.5730\n",
      "Epoch 2523/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5368 - val_loss: 8.5731\n",
      "Epoch 2524/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5364 - val_loss: 8.5732\n",
      "Epoch 2525/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5360 - val_loss: 8.5733\n",
      "Epoch 2526/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5356 - val_loss: 8.5734\n",
      "Epoch 2527/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5351 - val_loss: 8.5734\n",
      "Epoch 2528/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.5347 - val_loss: 8.5734\n",
      "Epoch 2529/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.5343 - val_loss: 8.5734\n",
      "Epoch 2530/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.5338 - val_loss: 8.5734\n",
      "Epoch 2531/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5334 - val_loss: 8.5734\n",
      "Epoch 2532/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5330 - val_loss: 8.5734\n",
      "Epoch 2533/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5326 - val_loss: 8.5736\n",
      "Epoch 2534/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5321 - val_loss: 8.5737\n",
      "Epoch 2535/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5317 - val_loss: 8.5738\n",
      "Epoch 2536/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5313 - val_loss: 8.5739\n",
      "Epoch 2537/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5309 - val_loss: 8.5741\n",
      "Epoch 2538/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5304 - val_loss: 8.5742\n",
      "Epoch 2539/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5300 - val_loss: 8.5744\n",
      "Epoch 2540/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5296 - val_loss: 8.5745\n",
      "Epoch 2541/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.5292 - val_loss: 8.5746\n",
      "Epoch 2542/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.5287 - val_loss: 8.5746\n",
      "Epoch 2543/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5283 - val_loss: 8.5746\n",
      "Epoch 2544/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5279 - val_loss: 8.5746\n",
      "Epoch 2545/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5275 - val_loss: 8.5747\n",
      "Epoch 2546/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5270 - val_loss: 8.5748\n",
      "Epoch 2547/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5266 - val_loss: 8.5748\n",
      "Epoch 2548/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5262 - val_loss: 8.5748\n",
      "Epoch 2549/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5258 - val_loss: 8.5747\n",
      "Epoch 2550/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5253 - val_loss: 8.5747\n",
      "Epoch 2551/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5249 - val_loss: 8.5747\n",
      "Epoch 2552/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5245 - val_loss: 8.5748\n",
      "Epoch 2553/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5241 - val_loss: 8.5750\n",
      "Epoch 2554/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5236 - val_loss: 8.5751\n",
      "Epoch 2555/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5232 - val_loss: 8.5752\n",
      "Epoch 2556/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5228 - val_loss: 8.5753\n",
      "Epoch 2557/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5224 - val_loss: 8.5753\n",
      "Epoch 2558/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5220 - val_loss: 8.5752\n",
      "Epoch 2559/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5215 - val_loss: 8.5752\n",
      "Epoch 2560/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5211 - val_loss: 8.5752\n",
      "Epoch 2561/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5207 - val_loss: 8.5753\n",
      "Epoch 2562/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5203 - val_loss: 8.5754\n",
      "Epoch 2563/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5198 - val_loss: 8.5755\n",
      "Epoch 2564/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5194 - val_loss: 8.5756\n",
      "Epoch 2565/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5190 - val_loss: 8.5756\n",
      "Epoch 2566/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5186 - val_loss: 8.5756\n",
      "Epoch 2567/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5182 - val_loss: 8.5755\n",
      "Epoch 2568/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5177 - val_loss: 8.5756\n",
      "Epoch 2569/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5173 - val_loss: 8.5756\n",
      "Epoch 2570/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.5169 - val_loss: 8.5757\n",
      "Epoch 2571/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5165 - val_loss: 8.5758\n",
      "Epoch 2572/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5161 - val_loss: 8.5758\n",
      "Epoch 2573/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5156 - val_loss: 8.5759\n",
      "Epoch 2574/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5152 - val_loss: 8.5760\n",
      "Epoch 2575/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5148 - val_loss: 8.5760\n",
      "Epoch 2576/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.5144 - val_loss: 8.5760\n",
      "Epoch 2577/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5140 - val_loss: 8.5759\n",
      "Epoch 2578/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5135 - val_loss: 8.5759\n",
      "Epoch 2579/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5131 - val_loss: 8.5760\n",
      "Epoch 2580/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.5127 - val_loss: 8.5761\n",
      "Epoch 2581/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5123 - val_loss: 8.5762\n",
      "Epoch 2582/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.5119 - val_loss: 8.5763\n",
      "Epoch 2583/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5115 - val_loss: 8.5762\n",
      "Epoch 2584/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5110 - val_loss: 8.5762\n",
      "Epoch 2585/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5106 - val_loss: 8.5762\n",
      "Epoch 2586/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5102 - val_loss: 8.5763\n",
      "Epoch 2587/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5098 - val_loss: 8.5764\n",
      "Epoch 2588/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5094 - val_loss: 8.5765\n",
      "Epoch 2589/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5090 - val_loss: 8.5765\n",
      "Epoch 2590/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5085 - val_loss: 8.5766\n",
      "Epoch 2591/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5081 - val_loss: 8.5765\n",
      "Epoch 2592/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5077 - val_loss: 8.5765\n",
      "Epoch 2593/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5073 - val_loss: 8.5765\n",
      "Epoch 2594/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5069 - val_loss: 8.5766\n",
      "Epoch 2595/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5065 - val_loss: 8.5766\n",
      "Epoch 2596/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5060 - val_loss: 8.5767\n",
      "Epoch 2597/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5056 - val_loss: 8.5767\n",
      "Epoch 2598/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5052 - val_loss: 8.5768\n",
      "Epoch 2599/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5048 - val_loss: 8.5768\n",
      "Epoch 2600/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5044 - val_loss: 8.5768\n",
      "Epoch 2601/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5040 - val_loss: 8.5769\n",
      "Epoch 2602/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5036 - val_loss: 8.5769\n",
      "Epoch 2603/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5031 - val_loss: 8.5770\n",
      "Epoch 2604/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.5027 - val_loss: 8.5771\n",
      "Epoch 2605/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5023 - val_loss: 8.5772\n",
      "Epoch 2606/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5019 - val_loss: 8.5772\n",
      "Epoch 2607/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5015 - val_loss: 8.5773\n",
      "Epoch 2608/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5011 - val_loss: 8.5774\n",
      "Epoch 2609/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5007 - val_loss: 8.5774\n",
      "Epoch 2610/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5002 - val_loss: 8.5774\n",
      "Epoch 2611/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4998 - val_loss: 8.5774\n",
      "Epoch 2612/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4994 - val_loss: 8.5774\n",
      "Epoch 2613/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4990 - val_loss: 8.5774\n",
      "Epoch 2614/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4986 - val_loss: 8.5774\n",
      "Epoch 2615/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4982 - val_loss: 8.5775\n",
      "Epoch 2616/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4978 - val_loss: 8.5776\n",
      "Epoch 2617/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4974 - val_loss: 8.5776\n",
      "Epoch 2618/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4969 - val_loss: 8.5776\n",
      "Epoch 2619/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4965 - val_loss: 8.5776\n",
      "Epoch 2620/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4961 - val_loss: 8.5775\n",
      "Epoch 2621/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4957 - val_loss: 8.5775\n",
      "Epoch 2622/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4953 - val_loss: 8.5775\n",
      "Epoch 2623/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4949 - val_loss: 8.5775\n",
      "Epoch 2624/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4945 - val_loss: 8.5775\n",
      "Epoch 2625/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4941 - val_loss: 8.5775\n",
      "Epoch 2626/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4937 - val_loss: 8.5774\n",
      "Epoch 2627/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4932 - val_loss: 8.5773\n",
      "Epoch 2628/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4928 - val_loss: 8.5773\n",
      "Epoch 2629/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4924 - val_loss: 8.5773\n",
      "Epoch 2630/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.4920 - val_loss: 8.5772\n",
      "Epoch 2631/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.4916 - val_loss: 8.5772\n",
      "Epoch 2632/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4912 - val_loss: 8.5772\n",
      "Epoch 2633/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4908 - val_loss: 8.5772\n",
      "Epoch 2634/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4904 - val_loss: 8.5772\n",
      "Epoch 2635/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.4900 - val_loss: 8.5772\n",
      "Epoch 2636/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4896 - val_loss: 8.5771\n",
      "Epoch 2637/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4892 - val_loss: 8.5770\n",
      "Epoch 2638/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4887 - val_loss: 8.5770\n",
      "Epoch 2639/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4883 - val_loss: 8.5769\n",
      "Epoch 2640/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4879 - val_loss: 8.5770\n",
      "Epoch 2641/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4875 - val_loss: 8.5770\n",
      "Epoch 2642/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4871 - val_loss: 8.5771\n",
      "Epoch 2643/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4867 - val_loss: 8.5771\n",
      "Epoch 2644/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4863 - val_loss: 8.5771\n",
      "Epoch 2645/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4859 - val_loss: 8.5772\n",
      "Epoch 2646/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4855 - val_loss: 8.5772\n",
      "Epoch 2647/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4851 - val_loss: 8.5771\n",
      "Epoch 2648/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4846 - val_loss: 8.5770\n",
      "Epoch 2649/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4842 - val_loss: 8.5771\n",
      "Epoch 2650/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4838 - val_loss: 8.5771\n",
      "Epoch 2651/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4834 - val_loss: 8.5770\n",
      "Epoch 2652/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4830 - val_loss: 8.5770\n",
      "Epoch 2653/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4826 - val_loss: 8.5769\n",
      "Epoch 2654/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4822 - val_loss: 8.5770\n",
      "Epoch 2655/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4818 - val_loss: 8.5769\n",
      "Epoch 2656/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4813 - val_loss: 8.5769\n",
      "Epoch 2657/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4809 - val_loss: 8.5768\n",
      "Epoch 2658/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4805 - val_loss: 8.5767\n",
      "Epoch 2659/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4801 - val_loss: 8.5767\n",
      "Epoch 2660/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4797 - val_loss: 8.5767\n",
      "Epoch 2661/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4793 - val_loss: 8.5766\n",
      "Epoch 2662/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4789 - val_loss: 8.5766\n",
      "Epoch 2663/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4785 - val_loss: 8.5765\n",
      "Epoch 2664/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4781 - val_loss: 8.5765\n",
      "Epoch 2665/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4777 - val_loss: 8.5766\n",
      "Epoch 2666/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4773 - val_loss: 8.5766\n",
      "Epoch 2667/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4768 - val_loss: 8.5765\n",
      "Epoch 2668/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4764 - val_loss: 8.5764\n",
      "Epoch 2669/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4760 - val_loss: 8.5762\n",
      "Epoch 2670/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4756 - val_loss: 8.5761\n",
      "Epoch 2671/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4752 - val_loss: 8.5760\n",
      "Epoch 2672/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4748 - val_loss: 8.5760\n",
      "Epoch 2673/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4744 - val_loss: 8.5761\n",
      "Epoch 2674/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4740 - val_loss: 8.5763\n",
      "Epoch 2675/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4736 - val_loss: 8.5763\n",
      "Epoch 2676/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4732 - val_loss: 8.5763\n",
      "Epoch 2677/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4728 - val_loss: 8.5763\n",
      "Epoch 2678/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4724 - val_loss: 8.5762\n",
      "Epoch 2679/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4720 - val_loss: 8.5761\n",
      "Epoch 2680/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4716 - val_loss: 8.5759\n",
      "Epoch 2681/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4712 - val_loss: 8.5759\n",
      "Epoch 2682/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4708 - val_loss: 8.5760\n",
      "Epoch 2683/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4704 - val_loss: 8.5761\n",
      "Epoch 2684/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.4699 - val_loss: 8.5762\n",
      "Epoch 2685/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4695 - val_loss: 8.5763\n",
      "Epoch 2686/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4691 - val_loss: 8.5763\n",
      "Epoch 2687/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4687 - val_loss: 8.5763\n",
      "Epoch 2688/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4683 - val_loss: 8.5762\n",
      "Epoch 2689/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4679 - val_loss: 8.5761\n",
      "Epoch 2690/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4675 - val_loss: 8.5760\n",
      "Epoch 2691/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4671 - val_loss: 8.5760\n",
      "Epoch 2692/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4667 - val_loss: 8.5760\n",
      "Epoch 2693/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4663 - val_loss: 8.5760\n",
      "Epoch 2694/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4659 - val_loss: 8.5760\n",
      "Epoch 2695/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4655 - val_loss: 8.5760\n",
      "Epoch 2696/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4651 - val_loss: 8.5760\n",
      "Epoch 2697/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.464 - 0s 35ms/step - loss: 5.4647 - val_loss: 8.5760\n",
      "Epoch 2698/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4643 - val_loss: 8.5760\n",
      "Epoch 2699/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4639 - val_loss: 8.5760\n",
      "Epoch 2700/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4635 - val_loss: 8.5760\n",
      "Epoch 2701/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4631 - val_loss: 8.5760\n",
      "Epoch 2702/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4627 - val_loss: 8.5760\n",
      "Epoch 2703/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4623 - val_loss: 8.5760\n",
      "Epoch 2704/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4619 - val_loss: 8.5759\n",
      "Epoch 2705/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4615 - val_loss: 8.5759\n",
      "Epoch 2706/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4611 - val_loss: 8.5759\n",
      "Epoch 2707/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4607 - val_loss: 8.5759\n",
      "Epoch 2708/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4603 - val_loss: 8.5760\n",
      "Epoch 2709/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4599 - val_loss: 8.5761\n",
      "Epoch 2710/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4595 - val_loss: 8.5761\n",
      "Epoch 2711/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4591 - val_loss: 8.5760\n",
      "Epoch 2712/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4587 - val_loss: 8.5759\n",
      "Epoch 2713/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4583 - val_loss: 8.5758\n",
      "Epoch 2714/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4579 - val_loss: 8.5757\n",
      "Epoch 2715/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4575 - val_loss: 8.5757\n",
      "Epoch 2716/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4571 - val_loss: 8.5757\n",
      "Epoch 2717/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4567 - val_loss: 8.5758\n",
      "Epoch 2718/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4563 - val_loss: 8.5759\n",
      "Epoch 2719/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4559 - val_loss: 8.5759\n",
      "Epoch 2720/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4555 - val_loss: 8.5760\n",
      "Epoch 2721/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4551 - val_loss: 8.5760\n",
      "Epoch 2722/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4547 - val_loss: 8.5758\n",
      "Epoch 2723/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4543 - val_loss: 8.5757\n",
      "Epoch 2724/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.4539 - val_loss: 8.5756\n",
      "Epoch 2725/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4535 - val_loss: 8.5755\n",
      "Epoch 2726/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4531 - val_loss: 8.5755\n",
      "Epoch 2727/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4527 - val_loss: 8.5756\n",
      "Epoch 2728/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4523 - val_loss: 8.5756\n",
      "Epoch 2729/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4519 - val_loss: 8.5756\n",
      "Epoch 2730/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4515 - val_loss: 8.5756\n",
      "Epoch 2731/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4511 - val_loss: 8.5756\n",
      "Epoch 2732/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4507 - val_loss: 8.5756\n",
      "Epoch 2733/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4503 - val_loss: 8.5756\n",
      "Epoch 2734/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4499 - val_loss: 8.5756\n",
      "Epoch 2735/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4495 - val_loss: 8.5755\n",
      "Epoch 2736/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4491 - val_loss: 8.5755\n",
      "Epoch 2737/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4487 - val_loss: 8.5755\n",
      "Epoch 2738/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4483 - val_loss: 8.5755\n",
      "Epoch 2739/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4479 - val_loss: 8.5755\n",
      "Epoch 2740/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4475 - val_loss: 8.5755\n",
      "Epoch 2741/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4471 - val_loss: 8.5754\n",
      "Epoch 2742/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4467 - val_loss: 8.5754\n",
      "Epoch 2743/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4463 - val_loss: 8.5754\n",
      "Epoch 2744/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4459 - val_loss: 8.5754\n",
      "Epoch 2745/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4455 - val_loss: 8.5755\n",
      "Epoch 2746/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4451 - val_loss: 8.5755\n",
      "Epoch 2747/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4447 - val_loss: 8.5755\n",
      "Epoch 2748/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4443 - val_loss: 8.5753\n",
      "Epoch 2749/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4440 - val_loss: 8.5753\n",
      "Epoch 2750/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4436 - val_loss: 8.5752\n",
      "Epoch 2751/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4432 - val_loss: 8.5752\n",
      "Epoch 2752/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4428 - val_loss: 8.5753\n",
      "Epoch 2753/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4424 - val_loss: 8.5753\n",
      "Epoch 2754/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4420 - val_loss: 8.5754\n",
      "Epoch 2755/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4416 - val_loss: 8.5754\n",
      "Epoch 2756/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4412 - val_loss: 8.5753\n",
      "Epoch 2757/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4408 - val_loss: 8.5753\n",
      "Epoch 2758/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4404 - val_loss: 8.5752\n",
      "Epoch 2759/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4400 - val_loss: 8.5751\n",
      "Epoch 2760/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4396 - val_loss: 8.5751\n",
      "Epoch 2761/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4392 - val_loss: 8.5751\n",
      "Epoch 2762/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4388 - val_loss: 8.5752\n",
      "Epoch 2763/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4384 - val_loss: 8.5752\n",
      "Epoch 2764/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4380 - val_loss: 8.5752\n",
      "Epoch 2765/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4376 - val_loss: 8.5751\n",
      "Epoch 2766/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4372 - val_loss: 8.5751\n",
      "Epoch 2767/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4368 - val_loss: 8.5751\n",
      "Epoch 2768/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4365 - val_loss: 8.5750\n",
      "Epoch 2769/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4361 - val_loss: 8.5751\n",
      "Epoch 2770/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4357 - val_loss: 8.5750\n",
      "Epoch 2771/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4353 - val_loss: 8.5750\n",
      "Epoch 2772/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4349 - val_loss: 8.5751\n",
      "Epoch 2773/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4345 - val_loss: 8.5752\n",
      "Epoch 2774/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4341 - val_loss: 8.5752\n",
      "Epoch 2775/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4337 - val_loss: 8.5751\n",
      "Epoch 2776/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4333 - val_loss: 8.5750\n",
      "Epoch 2777/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4329 - val_loss: 8.5749\n",
      "Epoch 2778/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4325 - val_loss: 8.5748\n",
      "Epoch 2779/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4321 - val_loss: 8.5747\n",
      "Epoch 2780/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4317 - val_loss: 8.5747\n",
      "Epoch 2781/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4313 - val_loss: 8.5748\n",
      "Epoch 2782/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4309 - val_loss: 8.5748\n",
      "Epoch 2783/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4305 - val_loss: 8.5748\n",
      "Epoch 2784/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4301 - val_loss: 8.5748\n",
      "Epoch 2785/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4297 - val_loss: 8.5748\n",
      "Epoch 2786/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4293 - val_loss: 8.5748\n",
      "Epoch 2787/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4289 - val_loss: 8.5748\n",
      "Epoch 2788/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4285 - val_loss: 8.5748\n",
      "Epoch 2789/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.4281 - val_loss: 8.5749\n",
      "Epoch 2790/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4277 - val_loss: 8.5749\n",
      "Epoch 2791/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4273 - val_loss: 8.5748\n",
      "Epoch 2792/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4269 - val_loss: 8.5747\n",
      "Epoch 2793/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4265 - val_loss: 8.5747\n",
      "Epoch 2794/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4261 - val_loss: 8.5746\n",
      "Epoch 2795/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.4257 - val_loss: 8.5746\n",
      "Epoch 2796/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4253 - val_loss: 8.5746\n",
      "Epoch 2797/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4249 - val_loss: 8.5747\n",
      "Epoch 2798/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4245 - val_loss: 8.5747\n",
      "Epoch 2799/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4241 - val_loss: 8.5747\n",
      "Epoch 2800/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4238 - val_loss: 8.5746\n",
      "Epoch 2801/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4234 - val_loss: 8.5746\n",
      "Epoch 2802/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4230 - val_loss: 8.5746\n",
      "Epoch 2803/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4226 - val_loss: 8.5746\n",
      "Epoch 2804/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4222 - val_loss: 8.5746\n",
      "Epoch 2805/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4218 - val_loss: 8.5746\n",
      "Epoch 2806/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4214 - val_loss: 8.5746\n",
      "Epoch 2807/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4210 - val_loss: 8.5746\n",
      "Epoch 2808/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4206 - val_loss: 8.5746\n",
      "Epoch 2809/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4202 - val_loss: 8.5747\n",
      "Epoch 2810/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4198 - val_loss: 8.5746\n",
      "Epoch 2811/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4194 - val_loss: 8.5746\n",
      "Epoch 2812/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4190 - val_loss: 8.5747\n",
      "Epoch 2813/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4186 - val_loss: 8.5747\n",
      "Epoch 2814/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4182 - val_loss: 8.5747\n",
      "Epoch 2815/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4178 - val_loss: 8.5747\n",
      "Epoch 2816/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4174 - val_loss: 8.5746\n",
      "Epoch 2817/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4170 - val_loss: 8.5745\n",
      "Epoch 2818/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4166 - val_loss: 8.5746\n",
      "Epoch 2819/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4162 - val_loss: 8.5747\n",
      "Epoch 2820/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4159 - val_loss: 8.5748\n",
      "Epoch 2821/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4155 - val_loss: 8.5749\n",
      "Epoch 2822/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4151 - val_loss: 8.5750\n",
      "Epoch 2823/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4147 - val_loss: 8.5750\n",
      "Epoch 2824/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4143 - val_loss: 8.5750\n",
      "Epoch 2825/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4139 - val_loss: 8.5750\n",
      "Epoch 2826/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4135 - val_loss: 8.5751\n",
      "Epoch 2827/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4131 - val_loss: 8.5752\n",
      "Epoch 2828/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4127 - val_loss: 8.5752\n",
      "Epoch 2829/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4123 - val_loss: 8.5752\n",
      "Epoch 2830/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4119 - val_loss: 8.5753\n",
      "Epoch 2831/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4115 - val_loss: 8.5753\n",
      "Epoch 2832/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4111 - val_loss: 8.5753\n",
      "Epoch 2833/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4107 - val_loss: 8.5753\n",
      "Epoch 2834/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4103 - val_loss: 8.5753\n",
      "Epoch 2835/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4099 - val_loss: 8.5753\n",
      "Epoch 2836/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4096 - val_loss: 8.5753\n",
      "Epoch 2837/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4092 - val_loss: 8.5754\n",
      "Epoch 2838/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4088 - val_loss: 8.5755\n",
      "Epoch 2839/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4084 - val_loss: 8.5756\n",
      "Epoch 2840/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4080 - val_loss: 8.5756\n",
      "Epoch 2841/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4076 - val_loss: 8.5756\n",
      "Epoch 2842/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4072 - val_loss: 8.5756\n",
      "Epoch 2843/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4068 - val_loss: 8.5757\n",
      "Epoch 2844/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4064 - val_loss: 8.5757\n",
      "Epoch 2845/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4060 - val_loss: 8.5757\n",
      "Epoch 2846/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4056 - val_loss: 8.5757\n",
      "Epoch 2847/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4052 - val_loss: 8.5757\n",
      "Epoch 2848/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4048 - val_loss: 8.5757\n",
      "Epoch 2849/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4044 - val_loss: 8.5758\n",
      "Epoch 2850/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4041 - val_loss: 8.5759\n",
      "Epoch 2851/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4037 - val_loss: 8.5760\n",
      "Epoch 2852/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4033 - val_loss: 8.5760\n",
      "Epoch 2853/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4029 - val_loss: 8.5760\n",
      "Epoch 2854/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4025 - val_loss: 8.5759\n",
      "Epoch 2855/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4021 - val_loss: 8.5759\n",
      "Epoch 2856/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4017 - val_loss: 8.5759\n",
      "Epoch 2857/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4013 - val_loss: 8.5760\n",
      "Epoch 2858/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4009 - val_loss: 8.5761\n",
      "Epoch 2859/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4005 - val_loss: 8.5762\n",
      "Epoch 2860/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4001 - val_loss: 8.5762\n",
      "Epoch 2861/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3997 - val_loss: 8.5762\n",
      "Epoch 2862/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3994 - val_loss: 8.5762\n",
      "Epoch 2863/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3990 - val_loss: 8.5763\n",
      "Epoch 2864/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3986 - val_loss: 8.5763\n",
      "Epoch 2865/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3982 - val_loss: 8.5764\n",
      "Epoch 2866/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3978 - val_loss: 8.5764\n",
      "Epoch 2867/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3974 - val_loss: 8.5764\n",
      "Epoch 2868/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3970 - val_loss: 8.5765\n",
      "Epoch 2869/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3966 - val_loss: 8.5766\n",
      "Epoch 2870/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3962 - val_loss: 8.5766\n",
      "Epoch 2871/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3958 - val_loss: 8.5766\n",
      "Epoch 2872/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3954 - val_loss: 8.5766\n",
      "Epoch 2873/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3950 - val_loss: 8.5767\n",
      "Epoch 2874/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3947 - val_loss: 8.5767\n",
      "Epoch 2875/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3943 - val_loss: 8.5767\n",
      "Epoch 2876/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3939 - val_loss: 8.5767\n",
      "Epoch 2877/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3935 - val_loss: 8.5767\n",
      "Epoch 2878/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3931 - val_loss: 8.5767\n",
      "Epoch 2879/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3927 - val_loss: 8.5767\n",
      "Epoch 2880/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3923 - val_loss: 8.5767\n",
      "Epoch 2881/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3919 - val_loss: 8.5767\n",
      "Epoch 2882/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3915 - val_loss: 8.5767\n",
      "Epoch 2883/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3911 - val_loss: 8.5767\n",
      "Epoch 2884/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3907 - val_loss: 8.5768\n",
      "Epoch 2885/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3903 - val_loss: 8.5768\n",
      "Epoch 2886/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3899 - val_loss: 8.5767\n",
      "Epoch 2887/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3895 - val_loss: 8.5767\n",
      "Epoch 2888/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3892 - val_loss: 8.5767\n",
      "Epoch 2889/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3888 - val_loss: 8.5767\n",
      "Epoch 2890/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3884 - val_loss: 8.5768\n",
      "Epoch 2891/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3880 - val_loss: 8.5768\n",
      "Epoch 2892/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3876 - val_loss: 8.5768\n",
      "Epoch 2893/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3872 - val_loss: 8.5768\n",
      "Epoch 2894/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3868 - val_loss: 8.5769\n",
      "Epoch 2895/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.3864 - val_loss: 8.5770\n",
      "Epoch 2896/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3860 - val_loss: 8.5770\n",
      "Epoch 2897/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3856 - val_loss: 8.5770\n",
      "Epoch 2898/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3852 - val_loss: 8.5771\n",
      "Epoch 2899/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3849 - val_loss: 8.5771\n",
      "Epoch 2900/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3845 - val_loss: 8.5771\n",
      "Epoch 2901/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3841 - val_loss: 8.5772\n",
      "Epoch 2902/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3837 - val_loss: 8.5772\n",
      "Epoch 2903/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3833 - val_loss: 8.5773\n",
      "Epoch 2904/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3829 - val_loss: 8.5774\n",
      "Epoch 2905/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3825 - val_loss: 8.5775\n",
      "Epoch 2906/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3822 - val_loss: 8.5775\n",
      "Epoch 2907/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3818 - val_loss: 8.5775\n",
      "Epoch 2908/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3814 - val_loss: 8.5776\n",
      "Epoch 2909/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3810 - val_loss: 8.5776\n",
      "Epoch 2910/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3806 - val_loss: 8.5777\n",
      "Epoch 2911/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.3802 - val_loss: 8.5776\n",
      "Epoch 2912/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3798 - val_loss: 8.5777\n",
      "Epoch 2913/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3795 - val_loss: 8.5777\n",
      "Epoch 2914/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3791 - val_loss: 8.5778\n",
      "Epoch 2915/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3787 - val_loss: 8.5778\n",
      "Epoch 2916/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3783 - val_loss: 8.5779\n",
      "Epoch 2917/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3779 - val_loss: 8.5780\n",
      "Epoch 2918/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3775 - val_loss: 8.5781\n",
      "Epoch 2919/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3771 - val_loss: 8.5781\n",
      "Epoch 2920/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3767 - val_loss: 8.5782\n",
      "Epoch 2921/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3764 - val_loss: 8.5782\n",
      "Epoch 2922/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3760 - val_loss: 8.5782\n",
      "Epoch 2923/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3756 - val_loss: 8.5782\n",
      "Epoch 2924/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3752 - val_loss: 8.5782\n",
      "Epoch 2925/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3748 - val_loss: 8.5783\n",
      "Epoch 2926/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3744 - val_loss: 8.5784\n",
      "Epoch 2927/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3740 - val_loss: 8.5785\n",
      "Epoch 2928/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3737 - val_loss: 8.5785\n",
      "Epoch 2929/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3733 - val_loss: 8.5785\n",
      "Epoch 2930/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3729 - val_loss: 8.5786\n",
      "Epoch 2931/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3725 - val_loss: 8.5787\n",
      "Epoch 2932/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3721 - val_loss: 8.5788\n",
      "Epoch 2933/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3717 - val_loss: 8.5788\n",
      "Epoch 2934/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3713 - val_loss: 8.5788\n",
      "Epoch 2935/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3710 - val_loss: 8.5788\n",
      "Epoch 2936/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3706 - val_loss: 8.5789\n",
      "Epoch 2937/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3702 - val_loss: 8.5789\n",
      "Epoch 2938/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3698 - val_loss: 8.5790\n",
      "Epoch 2939/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3694 - val_loss: 8.5790\n",
      "Epoch 2940/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3690 - val_loss: 8.5791\n",
      "Epoch 2941/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3686 - val_loss: 8.5791\n",
      "Epoch 2942/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3683 - val_loss: 8.5791\n",
      "Epoch 2943/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3679 - val_loss: 8.5791\n",
      "Epoch 2944/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3675 - val_loss: 8.5792\n",
      "Epoch 2945/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3671 - val_loss: 8.5792\n",
      "Epoch 2946/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3667 - val_loss: 8.5793\n",
      "Epoch 2947/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3663 - val_loss: 8.5793\n",
      "Epoch 2948/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3660 - val_loss: 8.5793\n",
      "Epoch 2949/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3656 - val_loss: 8.5794\n",
      "Epoch 2950/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.3652 - val_loss: 8.5794\n",
      "Epoch 2951/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3648 - val_loss: 8.5795\n",
      "Epoch 2952/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3644 - val_loss: 8.5796\n",
      "Epoch 2953/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3640 - val_loss: 8.5796\n",
      "Epoch 2954/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3637 - val_loss: 8.5796\n",
      "Epoch 2955/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3633 - val_loss: 8.5796\n",
      "Epoch 2956/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3629 - val_loss: 8.5797\n",
      "Epoch 2957/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3625 - val_loss: 8.5797\n",
      "Epoch 2958/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3621 - val_loss: 8.5798\n",
      "Epoch 2959/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3618 - val_loss: 8.5799\n",
      "Epoch 2960/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3614 - val_loss: 8.5800\n",
      "Epoch 2961/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3610 - val_loss: 8.5801\n",
      "Epoch 2962/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3606 - val_loss: 8.5801\n",
      "Epoch 2963/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3603 - val_loss: 8.5801\n",
      "Epoch 2964/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3599 - val_loss: 8.5801\n",
      "Epoch 2965/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3595 - val_loss: 8.5802\n",
      "Epoch 2966/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3591 - val_loss: 8.5802\n",
      "Epoch 2967/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3587 - val_loss: 8.5803\n",
      "Epoch 2968/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3584 - val_loss: 8.5803\n",
      "Epoch 2969/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3580 - val_loss: 8.5805\n",
      "Epoch 2970/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3576 - val_loss: 8.5805\n",
      "Epoch 2971/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3572 - val_loss: 8.5806\n",
      "Epoch 2972/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3568 - val_loss: 8.5806\n",
      "Epoch 2973/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3565 - val_loss: 8.5806\n",
      "Epoch 2974/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3561 - val_loss: 8.5807\n",
      "Epoch 2975/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3557 - val_loss: 8.5808\n",
      "Epoch 2976/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3553 - val_loss: 8.5809\n",
      "Epoch 2977/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3550 - val_loss: 8.5810\n",
      "Epoch 2978/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3546 - val_loss: 8.5811\n",
      "Epoch 2979/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3542 - val_loss: 8.5811\n",
      "Epoch 2980/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3538 - val_loss: 8.5812\n",
      "Epoch 2981/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3534 - val_loss: 8.5813\n",
      "Epoch 2982/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3531 - val_loss: 8.5815\n",
      "Epoch 2983/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3527 - val_loss: 8.5816\n",
      "Epoch 2984/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3523 - val_loss: 8.5816\n",
      "Epoch 2985/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3519 - val_loss: 8.5817\n",
      "Epoch 2986/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3516 - val_loss: 8.5817\n",
      "Epoch 2987/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3512 - val_loss: 8.5817\n",
      "Epoch 2988/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3508 - val_loss: 8.5817\n",
      "Epoch 2989/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3504 - val_loss: 8.5818\n",
      "Epoch 2990/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3501 - val_loss: 8.5818\n",
      "Epoch 2991/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3497 - val_loss: 8.5819\n",
      "Epoch 2992/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3493 - val_loss: 8.5819\n",
      "Epoch 2993/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3489 - val_loss: 8.5820\n",
      "Epoch 2994/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3486 - val_loss: 8.5821\n",
      "Epoch 2995/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3482 - val_loss: 8.5822\n",
      "Epoch 2996/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3478 - val_loss: 8.5823\n",
      "Epoch 2997/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3474 - val_loss: 8.5824\n",
      "Epoch 2998/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3471 - val_loss: 8.5825\n",
      "Epoch 2999/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3467 - val_loss: 8.5826\n",
      "Epoch 3000/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3463 - val_loss: 8.5827\n",
      "Epoch 3001/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3459 - val_loss: 8.5828\n",
      "Epoch 3002/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.345 - 0s 33ms/step - loss: 5.3456 - val_loss: 8.5828\n",
      "Epoch 3003/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3452 - val_loss: 8.5827\n",
      "Epoch 3004/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3448 - val_loss: 8.5828\n",
      "Epoch 3005/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.3444 - val_loss: 8.5828\n",
      "Epoch 3006/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3441 - val_loss: 8.5829\n",
      "Epoch 3007/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.3437 - val_loss: 8.5830\n",
      "Epoch 3008/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3433 - val_loss: 8.5831\n",
      "Epoch 3009/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3429 - val_loss: 8.5831\n",
      "Epoch 3010/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3426 - val_loss: 8.5832\n",
      "Epoch 3011/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3422 - val_loss: 8.5832\n",
      "Epoch 3012/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3418 - val_loss: 8.5833\n",
      "Epoch 3013/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3414 - val_loss: 8.5834\n",
      "Epoch 3014/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3411 - val_loss: 8.5835\n",
      "Epoch 3015/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3407 - val_loss: 8.5836\n",
      "Epoch 3016/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3403 - val_loss: 8.5837\n",
      "Epoch 3017/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3399 - val_loss: 8.5838\n",
      "Epoch 3018/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3396 - val_loss: 8.5839\n",
      "Epoch 3019/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3392 - val_loss: 8.5839\n",
      "Epoch 3020/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3388 - val_loss: 8.5840\n",
      "Epoch 3021/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3385 - val_loss: 8.5841\n",
      "Epoch 3022/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.3381 - val_loss: 8.5841\n",
      "Epoch 3023/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3377 - val_loss: 8.5842\n",
      "Epoch 3024/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3373 - val_loss: 8.5843\n",
      "Epoch 3025/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3370 - val_loss: 8.5844\n",
      "Epoch 3026/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3366 - val_loss: 8.5845\n",
      "Epoch 3027/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3362 - val_loss: 8.5846\n",
      "Epoch 3028/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3359 - val_loss: 8.5847\n",
      "Epoch 3029/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3355 - val_loss: 8.5848\n",
      "Epoch 3030/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3351 - val_loss: 8.5848\n",
      "Epoch 3031/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3347 - val_loss: 8.5849\n",
      "Epoch 3032/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3344 - val_loss: 8.5850\n",
      "Epoch 3033/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3340 - val_loss: 8.5851\n",
      "Epoch 3034/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3336 - val_loss: 8.5851\n",
      "Epoch 3035/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3333 - val_loss: 8.5852\n",
      "Epoch 3036/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3329 - val_loss: 8.5852\n",
      "Epoch 3037/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3325 - val_loss: 8.5853\n",
      "Epoch 3038/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3322 - val_loss: 8.5854\n",
      "Epoch 3039/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3318 - val_loss: 8.5855\n",
      "Epoch 3040/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3314 - val_loss: 8.5856\n",
      "Epoch 3041/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3310 - val_loss: 8.5857\n",
      "Epoch 3042/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3307 - val_loss: 8.5859\n",
      "Epoch 3043/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.3303 - val_loss: 8.5860\n",
      "Epoch 3044/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3299 - val_loss: 8.5860\n",
      "Epoch 3045/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3296 - val_loss: 8.5861\n",
      "Epoch 3046/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3292 - val_loss: 8.5862\n",
      "Epoch 3047/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3288 - val_loss: 8.5864\n",
      "Epoch 3048/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3285 - val_loss: 8.5865\n",
      "Epoch 3049/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3281 - val_loss: 8.5866\n",
      "Epoch 3050/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3277 - val_loss: 8.5866\n",
      "Epoch 3051/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3274 - val_loss: 8.5867\n",
      "Epoch 3052/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3270 - val_loss: 8.5867\n",
      "Epoch 3053/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3266 - val_loss: 8.5867\n",
      "Epoch 3054/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3262 - val_loss: 8.5868\n",
      "Epoch 3055/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3259 - val_loss: 8.5869\n",
      "Epoch 3056/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.3255 - val_loss: 8.5871\n",
      "Epoch 3057/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3251 - val_loss: 8.5872\n",
      "Epoch 3058/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3248 - val_loss: 8.5872\n",
      "Epoch 3059/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3244 - val_loss: 8.5873\n",
      "Epoch 3060/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3240 - val_loss: 8.5872\n",
      "Epoch 3061/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3237 - val_loss: 8.5873\n",
      "Epoch 3062/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3233 - val_loss: 8.5873\n",
      "Epoch 3063/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.3229 - val_loss: 8.5875\n",
      "Epoch 3064/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.3225 - val_loss: 8.5877\n",
      "Epoch 3065/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.3222 - val_loss: 8.5878\n",
      "Epoch 3066/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3218 - val_loss: 8.5878\n",
      "Epoch 3067/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3214 - val_loss: 8.5878\n",
      "Epoch 3068/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3211 - val_loss: 8.5878\n",
      "Epoch 3069/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3207 - val_loss: 8.5880\n",
      "Epoch 3070/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3203 - val_loss: 8.5881\n",
      "Epoch 3071/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3199 - val_loss: 8.5882\n",
      "Epoch 3072/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3196 - val_loss: 8.5883\n",
      "Epoch 3073/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3192 - val_loss: 8.5884\n",
      "Epoch 3074/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3188 - val_loss: 8.5884\n",
      "Epoch 3075/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3184 - val_loss: 8.5884\n",
      "Epoch 3076/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3181 - val_loss: 8.5886\n",
      "Epoch 3077/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3177 - val_loss: 8.5886\n",
      "Epoch 3078/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3173 - val_loss: 8.5887\n",
      "Epoch 3079/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3170 - val_loss: 8.5888\n",
      "Epoch 3080/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3166 - val_loss: 8.5888\n",
      "Epoch 3081/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3162 - val_loss: 8.5889\n",
      "Epoch 3082/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.3159 - val_loss: 8.5891\n",
      "Epoch 3083/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3155 - val_loss: 8.5892\n",
      "Epoch 3084/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.3151 - val_loss: 8.5893\n",
      "Epoch 3085/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3147 - val_loss: 8.5894\n",
      "Epoch 3086/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3144 - val_loss: 8.5895\n",
      "Epoch 3087/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3140 - val_loss: 8.5896\n",
      "Epoch 3088/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3136 - val_loss: 8.5897\n",
      "Epoch 3089/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3132 - val_loss: 8.5897\n",
      "Epoch 3090/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3129 - val_loss: 8.5898\n",
      "Epoch 3091/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3125 - val_loss: 8.5899\n",
      "Epoch 3092/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3121 - val_loss: 8.5900\n",
      "Epoch 3093/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3118 - val_loss: 8.5900\n",
      "Epoch 3094/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3114 - val_loss: 8.5902\n",
      "Epoch 3095/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.3110 - val_loss: 8.5903\n",
      "Epoch 3096/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3106 - val_loss: 8.5904\n",
      "Epoch 3097/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3103 - val_loss: 8.5904\n",
      "Epoch 3098/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3099 - val_loss: 8.5905\n",
      "Epoch 3099/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3095 - val_loss: 8.5905\n",
      "Epoch 3100/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3092 - val_loss: 8.5906\n",
      "Epoch 3101/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3088 - val_loss: 8.5908\n",
      "Epoch 3102/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.3084 - val_loss: 8.5909\n",
      "Epoch 3103/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3080 - val_loss: 8.5909\n",
      "Epoch 3104/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3077 - val_loss: 8.5910\n",
      "Epoch 3105/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.3073 - val_loss: 8.5911\n",
      "Epoch 3106/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.3069 - val_loss: 8.5911\n",
      "Epoch 3107/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.3066 - val_loss: 8.5912\n",
      "Epoch 3108/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3062 - val_loss: 8.5914\n",
      "Epoch 3109/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.3058 - val_loss: 8.5915\n",
      "Epoch 3110/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3054 - val_loss: 8.5915\n",
      "Epoch 3111/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3051 - val_loss: 8.5916\n",
      "Epoch 3112/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3047 - val_loss: 8.5917\n",
      "Epoch 3113/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3043 - val_loss: 8.5919\n",
      "Epoch 3114/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3040 - val_loss: 8.5919\n",
      "Epoch 3115/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3036 - val_loss: 8.5920\n",
      "Epoch 3116/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.3032 - val_loss: 8.5921\n",
      "Epoch 3117/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3028 - val_loss: 8.5922\n",
      "Epoch 3118/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3025 - val_loss: 8.5923\n",
      "Epoch 3119/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3021 - val_loss: 8.5924\n",
      "Epoch 3120/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3017 - val_loss: 8.5925\n",
      "Epoch 3121/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3014 - val_loss: 8.5926\n",
      "Epoch 3122/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3010 - val_loss: 8.5927\n",
      "Epoch 3123/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3006 - val_loss: 8.5927\n",
      "Epoch 3124/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3003 - val_loss: 8.5928\n",
      "Epoch 3125/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2999 - val_loss: 8.5928\n",
      "Epoch 3126/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2995 - val_loss: 8.5929\n",
      "Epoch 3127/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2991 - val_loss: 8.5929\n",
      "Epoch 3128/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2988 - val_loss: 8.5930\n",
      "Epoch 3129/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2984 - val_loss: 8.5931\n",
      "Epoch 3130/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2980 - val_loss: 8.5933\n",
      "Epoch 3131/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2977 - val_loss: 8.5934\n",
      "Epoch 3132/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.2973 - val_loss: 8.5935\n",
      "Epoch 3133/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2969 - val_loss: 8.5935\n",
      "Epoch 3134/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2966 - val_loss: 8.5937\n",
      "Epoch 3135/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2962 - val_loss: 8.5938\n",
      "Epoch 3136/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2958 - val_loss: 8.5940\n",
      "Epoch 3137/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2955 - val_loss: 8.5941\n",
      "Epoch 3138/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2951 - val_loss: 8.5942\n",
      "Epoch 3139/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2947 - val_loss: 8.5942\n",
      "Epoch 3140/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.2943 - val_loss: 8.5943\n",
      "Epoch 3141/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2940 - val_loss: 8.5943\n",
      "Epoch 3142/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2936 - val_loss: 8.5944\n",
      "Epoch 3143/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2932 - val_loss: 8.5944\n",
      "Epoch 3144/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2929 - val_loss: 8.5944\n",
      "Epoch 3145/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2925 - val_loss: 8.5945\n",
      "Epoch 3146/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2921 - val_loss: 8.5945\n",
      "Epoch 3147/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.2918 - val_loss: 8.5947\n",
      "Epoch 3148/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.2914 - val_loss: 8.5949\n",
      "Epoch 3149/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.2910 - val_loss: 8.5950\n",
      "Epoch 3150/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.2907 - val_loss: 8.5951\n",
      "Epoch 3151/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2903 - val_loss: 8.5952\n",
      "Epoch 3152/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2899 - val_loss: 8.5953\n",
      "Epoch 3153/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2896 - val_loss: 8.5954\n",
      "Epoch 3154/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2892 - val_loss: 8.5955\n",
      "Epoch 3155/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2888 - val_loss: 8.5956\n",
      "Epoch 3156/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2885 - val_loss: 8.5957\n",
      "Epoch 3157/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2881 - val_loss: 8.5958\n",
      "Epoch 3158/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2877 - val_loss: 8.5958\n",
      "Epoch 3159/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2874 - val_loss: 8.5959\n",
      "Epoch 3160/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2870 - val_loss: 8.5960\n",
      "Epoch 3161/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2866 - val_loss: 8.5960\n",
      "Epoch 3162/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2863 - val_loss: 8.5961\n",
      "Epoch 3163/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2859 - val_loss: 8.5961\n",
      "Epoch 3164/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2855 - val_loss: 8.5962\n",
      "Epoch 3165/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.2852 - val_loss: 8.5964\n",
      "Epoch 3166/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.2848 - val_loss: 8.5965\n",
      "Epoch 3167/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2844 - val_loss: 8.5966\n",
      "Epoch 3168/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2841 - val_loss: 8.5968\n",
      "Epoch 3169/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2837 - val_loss: 8.5969\n",
      "Epoch 3170/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2833 - val_loss: 8.5970\n",
      "Epoch 3171/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2830 - val_loss: 8.5970\n",
      "Epoch 3172/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2826 - val_loss: 8.5971\n",
      "Epoch 3173/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2822 - val_loss: 8.5972\n",
      "Epoch 3174/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2819 - val_loss: 8.5973\n",
      "Epoch 3175/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2815 - val_loss: 8.5973\n",
      "Epoch 3176/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2811 - val_loss: 8.5974\n",
      "Epoch 3177/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2808 - val_loss: 8.5974\n",
      "Epoch 3178/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2804 - val_loss: 8.5976\n",
      "Epoch 3179/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2800 - val_loss: 8.5976\n",
      "Epoch 3180/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2797 - val_loss: 8.5977\n",
      "Epoch 3181/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2793 - val_loss: 8.5978\n",
      "Epoch 3182/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2790 - val_loss: 8.5979\n",
      "Epoch 3183/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2786 - val_loss: 8.5980\n",
      "Epoch 3184/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2782 - val_loss: 8.5981\n",
      "Epoch 3185/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2779 - val_loss: 8.5981\n",
      "Epoch 3186/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2775 - val_loss: 8.5982\n",
      "Epoch 3187/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2771 - val_loss: 8.5984\n",
      "Epoch 3188/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2768 - val_loss: 8.5985\n",
      "Epoch 3189/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2764 - val_loss: 8.5986\n",
      "Epoch 3190/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.2760 - val_loss: 8.5987\n",
      "Epoch 3191/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.2757 - val_loss: 8.5988\n",
      "Epoch 3192/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2753 - val_loss: 8.5988\n",
      "Epoch 3193/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2750 - val_loss: 8.5989\n",
      "Epoch 3194/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2746 - val_loss: 8.5990\n",
      "Epoch 3195/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2742 - val_loss: 8.5990\n",
      "Epoch 3196/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2739 - val_loss: 8.5992\n",
      "Epoch 3197/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2735 - val_loss: 8.5994\n",
      "Epoch 3198/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2731 - val_loss: 8.5995\n",
      "Epoch 3199/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2728 - val_loss: 8.5995\n",
      "Epoch 3200/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2724 - val_loss: 8.5996\n",
      "Epoch 3201/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2721 - val_loss: 8.5996\n",
      "Epoch 3202/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2717 - val_loss: 8.5996\n",
      "Epoch 3203/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2713 - val_loss: 8.5997\n",
      "Epoch 3204/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2710 - val_loss: 8.5998\n",
      "Epoch 3205/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.2706 - val_loss: 8.6000\n",
      "Epoch 3206/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.2703 - val_loss: 8.6000\n",
      "Epoch 3207/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2699 - val_loss: 8.6001\n",
      "Epoch 3208/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2695 - val_loss: 8.6002\n",
      "Epoch 3209/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2692 - val_loss: 8.6003\n",
      "Epoch 3210/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2688 - val_loss: 8.6004\n",
      "Epoch 3211/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2684 - val_loss: 8.6006\n",
      "Epoch 3212/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.2681 - val_loss: 8.6007\n",
      "Epoch 3213/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.2677 - val_loss: 8.6008\n",
      "Epoch 3214/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2674 - val_loss: 8.6009\n",
      "Epoch 3215/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2670 - val_loss: 8.6009\n",
      "Epoch 3216/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2666 - val_loss: 8.6010\n",
      "Epoch 3217/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2663 - val_loss: 8.6011\n",
      "Epoch 3218/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2659 - val_loss: 8.6012\n",
      "Epoch 3219/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2656 - val_loss: 8.6014\n",
      "Epoch 3220/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2652 - val_loss: 8.6014\n",
      "Epoch 3221/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2648 - val_loss: 8.6015\n",
      "Epoch 3222/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2645 - val_loss: 8.6015\n",
      "Epoch 3223/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2641 - val_loss: 8.6016\n",
      "Epoch 3224/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2638 - val_loss: 8.6017\n",
      "Epoch 3225/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2634 - val_loss: 8.6018\n",
      "Epoch 3226/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.2630 - val_loss: 8.6021\n",
      "Epoch 3227/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2627 - val_loss: 8.6023\n",
      "Epoch 3228/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2623 - val_loss: 8.6024\n",
      "Epoch 3229/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2620 - val_loss: 8.6025\n",
      "Epoch 3230/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2616 - val_loss: 8.6026\n",
      "Epoch 3231/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2613 - val_loss: 8.6026\n",
      "Epoch 3232/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2609 - val_loss: 8.6027\n",
      "Epoch 3233/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2605 - val_loss: 8.6027\n",
      "Epoch 3234/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2602 - val_loss: 8.6028\n",
      "Epoch 3235/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2598 - val_loss: 8.6029\n",
      "Epoch 3236/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2595 - val_loss: 8.6031\n",
      "Epoch 3237/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2591 - val_loss: 8.6032\n",
      "Epoch 3238/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.2587 - val_loss: 8.6033\n",
      "Epoch 3239/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2584 - val_loss: 8.6034\n",
      "Epoch 3240/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.2580 - val_loss: 8.6035\n",
      "Epoch 3241/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2577 - val_loss: 8.6037\n",
      "Epoch 3242/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2573 - val_loss: 8.6038\n",
      "Epoch 3243/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2569 - val_loss: 8.6039\n",
      "Epoch 3244/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2566 - val_loss: 8.6041\n",
      "Epoch 3245/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2562 - val_loss: 8.6043\n",
      "Epoch 3246/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2559 - val_loss: 8.6044\n",
      "Epoch 3247/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2555 - val_loss: 8.6045\n",
      "Epoch 3248/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2551 - val_loss: 8.6046\n",
      "Epoch 3249/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2548 - val_loss: 8.6047\n",
      "Epoch 3250/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2544 - val_loss: 8.6048\n",
      "Epoch 3251/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2541 - val_loss: 8.6049\n",
      "Epoch 3252/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2537 - val_loss: 8.6050\n",
      "Epoch 3253/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2533 - val_loss: 8.6051\n",
      "Epoch 3254/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2530 - val_loss: 8.6053\n",
      "Epoch 3255/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2526 - val_loss: 8.6054\n",
      "Epoch 3256/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2523 - val_loss: 8.6055\n",
      "Epoch 3257/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2519 - val_loss: 8.6056\n",
      "Epoch 3258/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2516 - val_loss: 8.6057\n",
      "Epoch 3259/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2512 - val_loss: 8.6059\n",
      "Epoch 3260/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2508 - val_loss: 8.6061\n",
      "Epoch 3261/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2505 - val_loss: 8.6063\n",
      "Epoch 3262/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2501 - val_loss: 8.6065\n",
      "Epoch 3263/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2497 - val_loss: 8.6067\n",
      "Epoch 3264/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2494 - val_loss: 8.6069\n",
      "Epoch 3265/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2490 - val_loss: 8.6071\n",
      "Epoch 3266/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2486 - val_loss: 8.6073\n",
      "Epoch 3267/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2483 - val_loss: 8.6074\n",
      "Epoch 3268/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2479 - val_loss: 8.6076\n",
      "Epoch 3269/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2475 - val_loss: 8.6077\n",
      "Epoch 3270/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2472 - val_loss: 8.6079\n",
      "Epoch 3271/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2468 - val_loss: 8.6080\n",
      "Epoch 3272/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2464 - val_loss: 8.6081\n",
      "Epoch 3273/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2461 - val_loss: 8.6082\n",
      "Epoch 3274/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2457 - val_loss: 8.6084\n",
      "Epoch 3275/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2453 - val_loss: 8.6086\n",
      "Epoch 3276/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2449 - val_loss: 8.6088\n",
      "Epoch 3277/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2446 - val_loss: 8.6090\n",
      "Epoch 3278/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2442 - val_loss: 8.6092\n",
      "Epoch 3279/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2438 - val_loss: 8.6094\n",
      "Epoch 3280/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2435 - val_loss: 8.6096\n",
      "Epoch 3281/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2431 - val_loss: 8.6098\n",
      "Epoch 3282/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2427 - val_loss: 8.6100\n",
      "Epoch 3283/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2424 - val_loss: 8.6101\n",
      "Epoch 3284/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2420 - val_loss: 8.6103\n",
      "Epoch 3285/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2416 - val_loss: 8.6105\n",
      "Epoch 3286/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.2412 - val_loss: 8.6108\n",
      "Epoch 3287/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.2409 - val_loss: 8.6109\n",
      "Epoch 3288/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.2405 - val_loss: 8.6111\n",
      "Epoch 3289/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2401 - val_loss: 8.6112\n",
      "Epoch 3290/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2398 - val_loss: 8.6114\n",
      "Epoch 3291/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2394 - val_loss: 8.6116\n",
      "Epoch 3292/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2390 - val_loss: 8.6119\n",
      "Epoch 3293/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2387 - val_loss: 8.6121\n",
      "Epoch 3294/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2383 - val_loss: 8.6123\n",
      "Epoch 3295/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2379 - val_loss: 8.6124\n",
      "Epoch 3296/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2375 - val_loss: 8.6125\n",
      "Epoch 3297/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2372 - val_loss: 8.6127\n",
      "Epoch 3298/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2368 - val_loss: 8.6129\n",
      "Epoch 3299/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2364 - val_loss: 8.6132\n",
      "Epoch 3300/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2361 - val_loss: 8.6134\n",
      "Epoch 3301/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2357 - val_loss: 8.6136\n",
      "Epoch 3302/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2353 - val_loss: 8.6138\n",
      "Epoch 3303/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2350 - val_loss: 8.6140\n",
      "Epoch 3304/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2346 - val_loss: 8.6141\n",
      "Epoch 3305/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2342 - val_loss: 8.6142\n",
      "Epoch 3306/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2339 - val_loss: 8.6144\n",
      "Epoch 3307/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2335 - val_loss: 8.6146\n",
      "Epoch 3308/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2331 - val_loss: 8.6149\n",
      "Epoch 3309/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2328 - val_loss: 8.6151\n",
      "Epoch 3310/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2324 - val_loss: 8.6154\n",
      "Epoch 3311/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2320 - val_loss: 8.6156\n",
      "Epoch 3312/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.2316 - val_loss: 8.6157\n",
      "Epoch 3313/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.2313 - val_loss: 8.6159\n",
      "Epoch 3314/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2309 - val_loss: 8.6160\n",
      "Epoch 3315/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2305 - val_loss: 8.6162\n",
      "Epoch 3316/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2302 - val_loss: 8.6164\n",
      "Epoch 3317/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2298 - val_loss: 8.6166\n",
      "Epoch 3318/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2294 - val_loss: 8.6168\n",
      "Epoch 3319/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2291 - val_loss: 8.6169\n",
      "Epoch 3320/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2287 - val_loss: 8.6169\n",
      "Epoch 3321/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.2283 - val_loss: 8.6170\n",
      "Epoch 3322/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2280 - val_loss: 8.6172\n",
      "Epoch 3323/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2276 - val_loss: 8.6174\n",
      "Epoch 3324/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2272 - val_loss: 8.6177\n",
      "Epoch 3325/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2269 - val_loss: 8.6179\n",
      "Epoch 3326/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2265 - val_loss: 8.6181\n",
      "Epoch 3327/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2261 - val_loss: 8.6183\n",
      "Epoch 3328/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2258 - val_loss: 8.6185\n",
      "Epoch 3329/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2254 - val_loss: 8.6187\n",
      "Epoch 3330/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2250 - val_loss: 8.6189\n",
      "Epoch 3331/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2247 - val_loss: 8.6190\n",
      "Epoch 3332/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2243 - val_loss: 8.6191\n",
      "Epoch 3333/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2240 - val_loss: 8.6193\n",
      "Epoch 3334/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2236 - val_loss: 8.6195\n",
      "Epoch 3335/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2232 - val_loss: 8.6197\n",
      "Epoch 3336/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2229 - val_loss: 8.6198\n",
      "Epoch 3337/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2225 - val_loss: 8.6199\n",
      "Epoch 3338/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2221 - val_loss: 8.6200\n",
      "Epoch 3339/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2218 - val_loss: 8.6202\n",
      "Epoch 3340/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.2214 - val_loss: 8.6203\n",
      "Epoch 3341/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2211 - val_loss: 8.6204\n",
      "Epoch 3342/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2207 - val_loss: 8.6206\n",
      "Epoch 3343/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2203 - val_loss: 8.6207\n",
      "Epoch 3344/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2200 - val_loss: 8.6209\n",
      "Epoch 3345/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2196 - val_loss: 8.6211\n",
      "Epoch 3346/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2192 - val_loss: 8.6213\n",
      "Epoch 3347/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2189 - val_loss: 8.6214\n",
      "Epoch 3348/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2185 - val_loss: 8.6216\n",
      "Epoch 3349/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2182 - val_loss: 8.6217\n",
      "Epoch 3350/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2178 - val_loss: 8.6220\n",
      "Epoch 3351/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2174 - val_loss: 8.6223\n",
      "Epoch 3352/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2171 - val_loss: 8.6225\n",
      "Epoch 3353/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2167 - val_loss: 8.6226\n",
      "Epoch 3354/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2163 - val_loss: 8.6228\n",
      "Epoch 3355/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2160 - val_loss: 8.6228\n",
      "Epoch 3356/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2156 - val_loss: 8.6228\n",
      "Epoch 3357/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2153 - val_loss: 8.6229\n",
      "Epoch 3358/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2149 - val_loss: 8.6231\n",
      "Epoch 3359/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2145 - val_loss: 8.6234\n",
      "Epoch 3360/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2142 - val_loss: 8.6236\n",
      "Epoch 3361/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2138 - val_loss: 8.6238\n",
      "Epoch 3362/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2134 - val_loss: 8.6240\n",
      "Epoch 3363/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2131 - val_loss: 8.6241\n",
      "Epoch 3364/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2127 - val_loss: 8.6242\n",
      "Epoch 3365/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2124 - val_loss: 8.6243\n",
      "Epoch 3366/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.2120 - val_loss: 8.6244\n",
      "Epoch 3367/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2116 - val_loss: 8.6246\n",
      "Epoch 3368/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2113 - val_loss: 8.6248\n",
      "Epoch 3369/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2109 - val_loss: 8.6249\n",
      "Epoch 3370/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2106 - val_loss: 8.6251\n",
      "Epoch 3371/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2102 - val_loss: 8.6253\n",
      "Epoch 3372/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2098 - val_loss: 8.6255\n",
      "Epoch 3373/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.2095 - val_loss: 8.6257\n",
      "Epoch 3374/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.2091 - val_loss: 8.6259\n",
      "Epoch 3375/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2088 - val_loss: 8.6261\n",
      "Epoch 3376/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2084 - val_loss: 8.6263\n",
      "Epoch 3377/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2080 - val_loss: 8.6265\n",
      "Epoch 3378/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2077 - val_loss: 8.6266\n",
      "Epoch 3379/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2073 - val_loss: 8.6267\n",
      "Epoch 3380/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2070 - val_loss: 8.6269\n",
      "Epoch 3381/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2066 - val_loss: 8.6271\n",
      "Epoch 3382/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2062 - val_loss: 8.6272\n",
      "Epoch 3383/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.2059 - val_loss: 8.6273\n",
      "Epoch 3384/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2055 - val_loss: 8.6275\n",
      "Epoch 3385/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2052 - val_loss: 8.6276\n",
      "Epoch 3386/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2048 - val_loss: 8.6277\n",
      "Epoch 3387/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2044 - val_loss: 8.6278\n",
      "Epoch 3388/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2041 - val_loss: 8.6279\n",
      "Epoch 3389/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2037 - val_loss: 8.6281\n",
      "Epoch 3390/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2034 - val_loss: 8.6283\n",
      "Epoch 3391/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2030 - val_loss: 8.6285\n",
      "Epoch 3392/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2027 - val_loss: 8.6287\n",
      "Epoch 3393/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2023 - val_loss: 8.6288\n",
      "Epoch 3394/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2020 - val_loss: 8.6290\n",
      "Epoch 3395/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2016 - val_loss: 8.6292\n",
      "Epoch 3396/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2012 - val_loss: 8.6294\n",
      "Epoch 3397/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2009 - val_loss: 8.6296\n",
      "Epoch 3398/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2005 - val_loss: 8.6298\n",
      "Epoch 3399/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2002 - val_loss: 8.6300\n",
      "Epoch 3400/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1998 - val_loss: 8.6302\n",
      "Epoch 3401/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1994 - val_loss: 8.6305\n",
      "Epoch 3402/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1991 - val_loss: 8.6308\n",
      "Epoch 3403/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1987 - val_loss: 8.6310\n",
      "Epoch 3404/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1983 - val_loss: 8.6312\n",
      "Epoch 3405/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1980 - val_loss: 8.6314\n",
      "Epoch 3406/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1976 - val_loss: 8.6316\n",
      "Epoch 3407/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1972 - val_loss: 8.6319\n",
      "Epoch 3408/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1968 - val_loss: 8.6321\n",
      "Epoch 3409/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1965 - val_loss: 8.6324\n",
      "Epoch 3410/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1961 - val_loss: 8.6326\n",
      "Epoch 3411/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1957 - val_loss: 8.6328\n",
      "Epoch 3412/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1954 - val_loss: 8.6331\n",
      "Epoch 3413/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1950 - val_loss: 8.6333\n",
      "Epoch 3414/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1946 - val_loss: 8.6335\n",
      "Epoch 3415/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1943 - val_loss: 8.6338\n",
      "Epoch 3416/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1939 - val_loss: 8.6340\n",
      "Epoch 3417/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1935 - val_loss: 8.6343\n",
      "Epoch 3418/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1932 - val_loss: 8.6345\n",
      "Epoch 3419/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1928 - val_loss: 8.6348\n",
      "Epoch 3420/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1924 - val_loss: 8.6351\n",
      "Epoch 3421/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1920 - val_loss: 8.6353\n",
      "Epoch 3422/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1917 - val_loss: 8.6355\n",
      "Epoch 3423/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1913 - val_loss: 8.6357\n",
      "Epoch 3424/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1909 - val_loss: 8.6359\n",
      "Epoch 3425/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.1906 - val_loss: 8.6362\n",
      "Epoch 3426/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1902 - val_loss: 8.6364\n",
      "Epoch 3427/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.1898 - val_loss: 8.6367\n",
      "Epoch 3428/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1895 - val_loss: 8.6369\n",
      "Epoch 3429/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1891 - val_loss: 8.6372\n",
      "Epoch 3430/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1887 - val_loss: 8.6373\n",
      "Epoch 3431/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1884 - val_loss: 8.6376\n",
      "Epoch 3432/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1880 - val_loss: 8.6380\n",
      "Epoch 3433/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1876 - val_loss: 8.6383\n",
      "Epoch 3434/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1873 - val_loss: 8.6385\n",
      "Epoch 3435/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1869 - val_loss: 8.6387\n",
      "Epoch 3436/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1865 - val_loss: 8.6389\n",
      "Epoch 3437/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.1862 - val_loss: 8.6391\n",
      "Epoch 3438/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.1858 - val_loss: 8.6393\n",
      "Epoch 3439/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.1854 - val_loss: 8.6395\n",
      "Epoch 3440/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.1851 - val_loss: 8.6397\n",
      "Epoch 3441/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1847 - val_loss: 8.6399\n",
      "Epoch 3442/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1843 - val_loss: 8.6401\n",
      "Epoch 3443/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1840 - val_loss: 8.6404\n",
      "Epoch 3444/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1836 - val_loss: 8.6408\n",
      "Epoch 3445/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1832 - val_loss: 8.6411\n",
      "Epoch 3446/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1829 - val_loss: 8.6413\n",
      "Epoch 3447/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1825 - val_loss: 8.6415\n",
      "Epoch 3448/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.1821 - val_loss: 8.6417\n",
      "Epoch 3449/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.1818 - val_loss: 8.6418\n",
      "Epoch 3450/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.1814 - val_loss: 8.6420\n",
      "Epoch 3451/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1810 - val_loss: 8.6423\n",
      "Epoch 3452/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1807 - val_loss: 8.6426\n",
      "Epoch 3453/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1803 - val_loss: 8.6429\n",
      "Epoch 3454/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1800 - val_loss: 8.6433\n",
      "Epoch 3455/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1796 - val_loss: 8.6435\n",
      "Epoch 3456/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1792 - val_loss: 8.6438\n",
      "Epoch 3457/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1789 - val_loss: 8.6440\n",
      "Epoch 3458/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1785 - val_loss: 8.6443\n",
      "Epoch 3459/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1781 - val_loss: 8.6445\n",
      "Epoch 3460/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1778 - val_loss: 8.6448\n",
      "Epoch 3461/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1774 - val_loss: 8.6450\n",
      "Epoch 3462/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1771 - val_loss: 8.6452\n",
      "Epoch 3463/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1767 - val_loss: 8.6454\n",
      "Epoch 3464/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1763 - val_loss: 8.6456\n",
      "Epoch 3465/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1760 - val_loss: 8.6457\n",
      "Epoch 3466/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1756 - val_loss: 8.6460\n",
      "Epoch 3467/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1752 - val_loss: 8.6463\n",
      "Epoch 3468/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1749 - val_loss: 8.6466\n",
      "Epoch 3469/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1745 - val_loss: 8.6468\n",
      "Epoch 3470/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1742 - val_loss: 8.6470\n",
      "Epoch 3471/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1738 - val_loss: 8.6472\n",
      "Epoch 3472/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1734 - val_loss: 8.6475\n",
      "Epoch 3473/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1731 - val_loss: 8.6478\n",
      "Epoch 3474/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1727 - val_loss: 8.6481\n",
      "Epoch 3475/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1724 - val_loss: 8.6483\n",
      "Epoch 3476/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1720 - val_loss: 8.6485\n",
      "Epoch 3477/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1716 - val_loss: 8.6487\n",
      "Epoch 3478/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1713 - val_loss: 8.6490\n",
      "Epoch 3479/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1709 - val_loss: 8.6493\n",
      "Epoch 3480/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1706 - val_loss: 8.6496\n",
      "Epoch 3481/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.1702 - val_loss: 8.6498\n",
      "Epoch 3482/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1698 - val_loss: 8.6501\n",
      "Epoch 3483/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1695 - val_loss: 8.6505\n",
      "Epoch 3484/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1691 - val_loss: 8.6508\n",
      "Epoch 3485/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1688 - val_loss: 8.6511\n",
      "Epoch 3486/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.1684 - val_loss: 8.6514\n",
      "Epoch 3487/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.1680 - val_loss: 8.6517\n",
      "Epoch 3488/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.1677 - val_loss: 8.6520\n",
      "Epoch 3489/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.1673 - val_loss: 8.6524\n",
      "Epoch 3490/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1670 - val_loss: 8.6526\n",
      "Epoch 3491/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1666 - val_loss: 8.6529\n",
      "Epoch 3492/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1663 - val_loss: 8.6532\n",
      "Epoch 3493/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1659 - val_loss: 8.6535\n",
      "Epoch 3494/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1655 - val_loss: 8.6538\n",
      "Epoch 3495/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1652 - val_loss: 8.6541\n",
      "Epoch 3496/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1648 - val_loss: 8.6544\n",
      "Epoch 3497/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.1645 - val_loss: 8.6547\n",
      "Epoch 3498/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1641 - val_loss: 8.6550\n",
      "Epoch 3499/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1638 - val_loss: 8.6553\n",
      "Epoch 3500/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1634 - val_loss: 8.6556\n",
      "Epoch 3501/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1630 - val_loss: 8.6559\n",
      "Epoch 3502/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1627 - val_loss: 8.6562\n",
      "Epoch 3503/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1623 - val_loss: 8.6565\n",
      "Epoch 3504/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1620 - val_loss: 8.6568\n",
      "Epoch 3505/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1616 - val_loss: 8.6570\n",
      "Epoch 3506/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1613 - val_loss: 8.6573\n",
      "Epoch 3507/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1609 - val_loss: 8.6576\n",
      "Epoch 3508/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1606 - val_loss: 8.6579\n",
      "Epoch 3509/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1602 - val_loss: 8.6582\n",
      "Epoch 3510/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1598 - val_loss: 8.6585\n",
      "Epoch 3511/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1595 - val_loss: 8.6587\n",
      "Epoch 3512/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.1591 - val_loss: 8.6590\n",
      "Epoch 3513/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.1588 - val_loss: 8.6593\n",
      "Epoch 3514/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.1584 - val_loss: 8.6596\n",
      "Epoch 3515/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1581 - val_loss: 8.6600\n",
      "Epoch 3516/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1577 - val_loss: 8.6604\n",
      "Epoch 3517/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1574 - val_loss: 8.6607\n",
      "Epoch 3518/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1570 - val_loss: 8.6610\n",
      "Epoch 3519/10000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.1567 - val_loss: 8.6613\n",
      "Epoch 3520/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.1563 - val_loss: 8.6616\n",
      "Epoch 3521/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.1559 - val_loss: 8.6618\n",
      "Epoch 3522/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.1556 - val_loss: 8.6621\n",
      "Epoch 3523/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.1552 - val_loss: 8.6624\n",
      "Epoch 3524/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1549 - val_loss: 8.6627\n",
      "Epoch 3525/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.1545 - val_loss: 8.6629\n",
      "Epoch 3526/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.1542 - val_loss: 8.6632\n",
      "Epoch 3527/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.1538 - val_loss: 8.6635\n",
      "Epoch 3528/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.1535 - val_loss: 8.6639\n",
      "Epoch 3529/10000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.1531 - val_loss: 8.6642\n",
      "Epoch 3530/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1528 - val_loss: 8.6645\n",
      "Epoch 3531/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.1524 - val_loss: 8.6648\n",
      "Epoch 3532/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1521 - val_loss: 8.6651\n",
      "Epoch 3533/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1517 - val_loss: 8.6653\n",
      "Epoch 3534/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1514 - val_loss: 8.6656\n",
      "Epoch 3535/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1510 - val_loss: 8.6659\n",
      "Epoch 3536/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.1507 - val_loss: 8.6663\n",
      "Epoch 3537/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1503 - val_loss: 8.6666\n",
      "Epoch 3538/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1499 - val_loss: 8.6668\n",
      "Epoch 3539/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1496 - val_loss: 8.6671\n",
      "Epoch 3540/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1492 - val_loss: 8.6674\n",
      "Epoch 3541/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1489 - val_loss: 8.6676\n",
      "Epoch 3542/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1485 - val_loss: 8.6680\n",
      "Epoch 3543/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1482 - val_loss: 8.6683\n",
      "Epoch 3544/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1478 - val_loss: 8.6685\n",
      "Epoch 3545/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1475 - val_loss: 8.6688\n",
      "Epoch 3546/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1471 - val_loss: 8.6691\n",
      "Epoch 3547/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1468 - val_loss: 8.6694\n",
      "Epoch 3548/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1464 - val_loss: 8.6697\n",
      "Epoch 3549/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1461 - val_loss: 8.6700\n",
      "Epoch 3550/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.1457 - val_loss: 8.6703\n",
      "Epoch 3551/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.1454 - val_loss: 8.6706\n",
      "Epoch 3552/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1450 - val_loss: 8.6708\n",
      "Epoch 3553/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1447 - val_loss: 8.6710\n",
      "Epoch 3554/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1443 - val_loss: 8.6713\n",
      "Epoch 3555/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1440 - val_loss: 8.6715\n",
      "Epoch 3556/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1436 - val_loss: 8.6717\n",
      "Epoch 3557/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1433 - val_loss: 8.6720\n",
      "Epoch 3558/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1429 - val_loss: 8.6723\n",
      "Epoch 3559/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1426 - val_loss: 8.6726\n",
      "Epoch 3560/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1422 - val_loss: 8.6728\n",
      "Epoch 3561/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1419 - val_loss: 8.6731\n",
      "Epoch 3562/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1416 - val_loss: 8.6734\n",
      "Epoch 3563/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1412 - val_loss: 8.6737\n",
      "Epoch 3564/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1409 - val_loss: 8.6739\n",
      "Epoch 3565/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1405 - val_loss: 8.6742\n",
      "Epoch 3566/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1402 - val_loss: 8.6745\n",
      "Epoch 3567/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1398 - val_loss: 8.6747\n",
      "Epoch 3568/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1395 - val_loss: 8.6749\n",
      "Epoch 3569/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1391 - val_loss: 8.6751\n",
      "Epoch 3570/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1388 - val_loss: 8.6753\n",
      "Epoch 3571/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1384 - val_loss: 8.6757\n",
      "Epoch 3572/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1381 - val_loss: 8.6760\n",
      "Epoch 3573/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1377 - val_loss: 8.6763\n",
      "Epoch 3574/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1374 - val_loss: 8.6765\n",
      "Epoch 3575/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.1370 - val_loss: 8.6767\n",
      "Epoch 3576/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.1367 - val_loss: 8.6770\n",
      "Epoch 3577/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.1363 - val_loss: 8.6774\n",
      "Epoch 3578/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.1360 - val_loss: 8.6776\n",
      "Epoch 3579/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1356 - val_loss: 8.6779\n",
      "Epoch 3580/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.1353 - val_loss: 8.6782\n",
      "Epoch 3581/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1350 - val_loss: 8.6785\n",
      "Epoch 3582/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1346 - val_loss: 8.6788\n",
      "Epoch 3583/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1343 - val_loss: 8.6790\n",
      "Epoch 3584/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1339 - val_loss: 8.6793\n",
      "Epoch 3585/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1336 - val_loss: 8.6796\n",
      "Epoch 3586/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1332 - val_loss: 8.6798\n",
      "Epoch 3587/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1329 - val_loss: 8.6800\n",
      "Epoch 3588/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1325 - val_loss: 8.6802\n",
      "Epoch 3589/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1322 - val_loss: 8.6805\n",
      "Epoch 3590/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1318 - val_loss: 8.6808\n",
      "Epoch 3591/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1315 - val_loss: 8.6811\n",
      "Epoch 3592/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1311 - val_loss: 8.6814\n",
      "Epoch 3593/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1308 - val_loss: 8.6818\n",
      "Epoch 3594/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1304 - val_loss: 8.6821\n",
      "Epoch 3595/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1301 - val_loss: 8.6824\n",
      "Epoch 3596/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1298 - val_loss: 8.6826\n",
      "Epoch 3597/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1294 - val_loss: 8.6829\n",
      "Epoch 3598/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1291 - val_loss: 8.6831\n",
      "Epoch 3599/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1287 - val_loss: 8.6834\n",
      "Epoch 3600/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1284 - val_loss: 8.6836\n",
      "Epoch 3601/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1280 - val_loss: 8.6839\n",
      "Epoch 3602/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1277 - val_loss: 8.6842\n",
      "Epoch 3603/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1273 - val_loss: 8.6845\n",
      "Epoch 3604/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.1270 - val_loss: 8.6848\n",
      "Epoch 3605/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.1267 - val_loss: 8.6851\n",
      "Epoch 3606/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1263 - val_loss: 8.6854\n",
      "Epoch 3607/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1260 - val_loss: 8.6857\n",
      "Epoch 3608/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1256 - val_loss: 8.6859\n",
      "Epoch 3609/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1253 - val_loss: 8.6861\n",
      "Epoch 3610/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1249 - val_loss: 8.6864\n",
      "Epoch 3611/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1246 - val_loss: 8.6867\n",
      "Epoch 3612/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1242 - val_loss: 8.6870\n",
      "Epoch 3613/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.1239 - val_loss: 8.6873\n",
      "Epoch 3614/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1235 - val_loss: 8.6876\n",
      "Epoch 3615/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1232 - val_loss: 8.6879\n",
      "Epoch 3616/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1229 - val_loss: 8.6881\n",
      "Epoch 3617/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1225 - val_loss: 8.6885\n",
      "Epoch 3618/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1222 - val_loss: 8.6888\n",
      "Epoch 3619/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1218 - val_loss: 8.6892\n",
      "Epoch 3620/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1215 - val_loss: 8.6895\n",
      "Epoch 3621/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1211 - val_loss: 8.6897\n",
      "Epoch 3622/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1208 - val_loss: 8.6901\n",
      "Epoch 3623/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1204 - val_loss: 8.6904\n",
      "Epoch 3624/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1201 - val_loss: 8.6907\n",
      "Epoch 3625/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1198 - val_loss: 8.6910\n",
      "Epoch 3626/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1194 - val_loss: 8.6912\n",
      "Epoch 3627/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1191 - val_loss: 8.6915\n",
      "Epoch 3628/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1187 - val_loss: 8.6918\n",
      "Epoch 3629/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1184 - val_loss: 8.6921\n",
      "Epoch 3630/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1180 - val_loss: 8.6923\n",
      "Epoch 3631/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1177 - val_loss: 8.6926\n",
      "Epoch 3632/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1174 - val_loss: 8.6929\n",
      "Epoch 3633/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1170 - val_loss: 8.6932\n",
      "Epoch 3634/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1167 - val_loss: 8.6935\n",
      "Epoch 3635/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1163 - val_loss: 8.6938\n",
      "Epoch 3636/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1160 - val_loss: 8.6942\n",
      "Epoch 3637/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1156 - val_loss: 8.6945\n",
      "Epoch 3638/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1153 - val_loss: 8.6948\n",
      "Epoch 3639/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1150 - val_loss: 8.6951\n",
      "Epoch 3640/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1146 - val_loss: 8.6954\n",
      "Epoch 3641/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1143 - val_loss: 8.6956\n",
      "Epoch 3642/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1139 - val_loss: 8.6958\n",
      "Epoch 3643/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1136 - val_loss: 8.6961\n",
      "Epoch 3644/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1132 - val_loss: 8.6963\n",
      "Epoch 3645/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1129 - val_loss: 8.6966\n",
      "Epoch 3646/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1126 - val_loss: 8.6969\n",
      "Epoch 3647/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1122 - val_loss: 8.6972\n",
      "Epoch 3648/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1119 - val_loss: 8.6976\n",
      "Epoch 3649/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1115 - val_loss: 8.6979\n",
      "Epoch 3650/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1112 - val_loss: 8.6982\n",
      "Epoch 3651/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1108 - val_loss: 8.6984\n",
      "Epoch 3652/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1105 - val_loss: 8.6987\n",
      "Epoch 3653/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1102 - val_loss: 8.6989\n",
      "Epoch 3654/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1098 - val_loss: 8.6993\n",
      "Epoch 3655/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1095 - val_loss: 8.6996\n",
      "Epoch 3656/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1091 - val_loss: 8.6999\n",
      "Epoch 3657/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1088 - val_loss: 8.7002\n",
      "Epoch 3658/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1085 - val_loss: 8.7004\n",
      "Epoch 3659/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1081 - val_loss: 8.7007\n",
      "Epoch 3660/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1078 - val_loss: 8.7009\n",
      "Epoch 3661/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1074 - val_loss: 8.7012\n",
      "Epoch 3662/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1071 - val_loss: 8.7014\n",
      "Epoch 3663/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1068 - val_loss: 8.7017\n",
      "Epoch 3664/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1064 - val_loss: 8.7020\n",
      "Epoch 3665/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1061 - val_loss: 8.7024\n",
      "Epoch 3666/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1057 - val_loss: 8.7027\n",
      "Epoch 3667/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1054 - val_loss: 8.7030\n",
      "Epoch 3668/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1051 - val_loss: 8.7033\n",
      "Epoch 3669/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1047 - val_loss: 8.7036\n",
      "Epoch 3670/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1044 - val_loss: 8.7039\n",
      "Epoch 3671/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1040 - val_loss: 8.7041\n",
      "Epoch 3672/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1037 - val_loss: 8.7043\n",
      "Epoch 3673/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.1034 - val_loss: 8.7045\n",
      "Epoch 3674/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.1030 - val_loss: 8.7048\n",
      "Epoch 3675/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.1027 - val_loss: 8.7051\n",
      "Epoch 3676/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1023 - val_loss: 8.7054\n",
      "Epoch 3677/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1020 - val_loss: 8.7057\n",
      "Epoch 3678/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1017 - val_loss: 8.7060\n",
      "Epoch 3679/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1013 - val_loss: 8.7063\n",
      "Epoch 3680/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1010 - val_loss: 8.7066\n",
      "Epoch 3681/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1006 - val_loss: 8.7069\n",
      "Epoch 3682/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1003 - val_loss: 8.7072\n",
      "Epoch 3683/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1000 - val_loss: 8.7074\n",
      "Epoch 3684/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0996 - val_loss: 8.7077\n",
      "Epoch 3685/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0993 - val_loss: 8.7079\n",
      "Epoch 3686/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0989 - val_loss: 8.7082\n",
      "Epoch 3687/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0986 - val_loss: 8.7084\n",
      "Epoch 3688/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0983 - val_loss: 8.7087\n",
      "Epoch 3689/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0979 - val_loss: 8.7090\n",
      "Epoch 3690/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0976 - val_loss: 8.7092\n",
      "Epoch 3691/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0973 - val_loss: 8.7094\n",
      "Epoch 3692/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0969 - val_loss: 8.7097\n",
      "Epoch 3693/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0966 - val_loss: 8.7099\n",
      "Epoch 3694/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0962 - val_loss: 8.7101\n",
      "Epoch 3695/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0959 - val_loss: 8.7104\n",
      "Epoch 3696/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0956 - val_loss: 8.7107\n",
      "Epoch 3697/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.0952 - val_loss: 8.7110\n",
      "Epoch 3698/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.0949 - val_loss: 8.7114\n",
      "Epoch 3699/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0946 - val_loss: 8.7116\n",
      "Epoch 3700/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0942 - val_loss: 8.7119\n",
      "Epoch 3701/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0939 - val_loss: 8.7122\n",
      "Epoch 3702/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0935 - val_loss: 8.7125\n",
      "Epoch 3703/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0932 - val_loss: 8.7127\n",
      "Epoch 3704/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0929 - val_loss: 8.7130\n",
      "Epoch 3705/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0925 - val_loss: 8.7133\n",
      "Epoch 3706/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0922 - val_loss: 8.7136\n",
      "Epoch 3707/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0919 - val_loss: 8.7138\n",
      "Epoch 3708/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0915 - val_loss: 8.7140\n",
      "Epoch 3709/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0912 - val_loss: 8.7142\n",
      "Epoch 3710/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0909 - val_loss: 8.7144\n",
      "Epoch 3711/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0905 - val_loss: 8.7147\n",
      "Epoch 3712/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0902 - val_loss: 8.7150\n",
      "Epoch 3713/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0898 - val_loss: 8.7154\n",
      "Epoch 3714/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0895 - val_loss: 8.7157\n",
      "Epoch 3715/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0892 - val_loss: 8.7160\n",
      "Epoch 3716/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0888 - val_loss: 8.7162\n",
      "Epoch 3717/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0885 - val_loss: 8.7164\n",
      "Epoch 3718/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0882 - val_loss: 8.7167\n",
      "Epoch 3719/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0878 - val_loss: 8.7171\n",
      "Epoch 3720/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0875 - val_loss: 8.7175\n",
      "Epoch 3721/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0871 - val_loss: 8.7178\n",
      "Epoch 3722/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0868 - val_loss: 8.7180\n",
      "Epoch 3723/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.0865 - val_loss: 8.7182\n",
      "Epoch 3724/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0861 - val_loss: 8.7184\n",
      "Epoch 3725/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.0858 - val_loss: 8.7186\n",
      "Epoch 3726/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0855 - val_loss: 8.7189\n",
      "Epoch 3727/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0851 - val_loss: 8.7192\n",
      "Epoch 3728/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0848 - val_loss: 8.7194\n",
      "Epoch 3729/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0845 - val_loss: 8.7196\n",
      "Epoch 3730/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0841 - val_loss: 8.7198\n",
      "Epoch 3731/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0838 - val_loss: 8.7201\n",
      "Epoch 3732/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0834 - val_loss: 8.7204\n",
      "Epoch 3733/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0831 - val_loss: 8.7208\n",
      "Epoch 3734/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0828 - val_loss: 8.7211\n",
      "Epoch 3735/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0824 - val_loss: 8.7214\n",
      "Epoch 3736/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0821 - val_loss: 8.7216\n",
      "Epoch 3737/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0818 - val_loss: 8.7218\n",
      "Epoch 3738/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0814 - val_loss: 8.7221\n",
      "Epoch 3739/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.0811 - val_loss: 8.7223\n",
      "Epoch 3740/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0808 - val_loss: 8.7226\n",
      "Epoch 3741/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0804 - val_loss: 8.7229\n",
      "Epoch 3742/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0801 - val_loss: 8.7231\n",
      "Epoch 3743/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0797 - val_loss: 8.7234\n",
      "Epoch 3744/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0794 - val_loss: 8.7237\n",
      "Epoch 3745/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0791 - val_loss: 8.7239\n",
      "Epoch 3746/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0787 - val_loss: 8.7242\n",
      "Epoch 3747/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0784 - val_loss: 8.7246\n",
      "Epoch 3748/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0781 - val_loss: 8.7249\n",
      "Epoch 3749/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0777 - val_loss: 8.7252\n",
      "Epoch 3750/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0774 - val_loss: 8.7255\n",
      "Epoch 3751/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0771 - val_loss: 8.7257\n",
      "Epoch 3752/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0767 - val_loss: 8.7260\n",
      "Epoch 3753/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0764 - val_loss: 8.7263\n",
      "Epoch 3754/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0761 - val_loss: 8.7266\n",
      "Epoch 3755/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0757 - val_loss: 8.7269\n",
      "Epoch 3756/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0754 - val_loss: 8.7272\n",
      "Epoch 3757/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0750 - val_loss: 8.7275\n",
      "Epoch 3758/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0747 - val_loss: 8.7278\n",
      "Epoch 3759/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0744 - val_loss: 8.7281\n",
      "Epoch 3760/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0740 - val_loss: 8.7284\n",
      "Epoch 3761/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0737 - val_loss: 8.7286\n",
      "Epoch 3762/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.0734 - val_loss: 8.7288\n",
      "Epoch 3763/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.0730 - val_loss: 8.7291\n",
      "Epoch 3764/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.0727 - val_loss: 8.7293\n",
      "Epoch 3765/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0724 - val_loss: 8.7296\n",
      "Epoch 3766/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0720 - val_loss: 8.7299\n",
      "Epoch 3767/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0717 - val_loss: 8.7302\n",
      "Epoch 3768/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0714 - val_loss: 8.7305\n",
      "Epoch 3769/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0710 - val_loss: 8.7308\n",
      "Epoch 3770/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0707 - val_loss: 8.7310\n",
      "Epoch 3771/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0704 - val_loss: 8.7313\n",
      "Epoch 3772/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0700 - val_loss: 8.7316\n",
      "Epoch 3773/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0697 - val_loss: 8.7320\n",
      "Epoch 3774/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0694 - val_loss: 8.7323\n",
      "Epoch 3775/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0690 - val_loss: 8.7326\n",
      "Epoch 3776/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0687 - val_loss: 8.7328\n",
      "Epoch 3777/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0684 - val_loss: 8.7331\n",
      "Epoch 3778/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0680 - val_loss: 8.7334\n",
      "Epoch 3779/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0677 - val_loss: 8.7336\n",
      "Epoch 3780/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0674 - val_loss: 8.7339\n",
      "Epoch 3781/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0670 - val_loss: 8.7341\n",
      "Epoch 3782/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0667 - val_loss: 8.7344\n",
      "Epoch 3783/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0663 - val_loss: 8.7347\n",
      "Epoch 3784/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0660 - val_loss: 8.7350\n",
      "Epoch 3785/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0657 - val_loss: 8.7354\n",
      "Epoch 3786/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0653 - val_loss: 8.7357\n",
      "Epoch 3787/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0650 - val_loss: 8.7361\n",
      "Epoch 3788/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.0647 - val_loss: 8.7364\n",
      "Epoch 3789/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.0643 - val_loss: 8.7366\n",
      "Epoch 3790/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0640 - val_loss: 8.7369\n",
      "Epoch 3791/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0637 - val_loss: 8.7373\n",
      "Epoch 3792/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0633 - val_loss: 8.7376\n",
      "Epoch 3793/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0630 - val_loss: 8.7378\n",
      "Epoch 3794/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0627 - val_loss: 8.7381\n",
      "Epoch 3795/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0623 - val_loss: 8.7383\n",
      "Epoch 3796/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0620 - val_loss: 8.7386\n",
      "Epoch 3797/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0617 - val_loss: 8.7389\n",
      "Epoch 3798/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0613 - val_loss: 8.7393\n",
      "Epoch 3799/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.0610 - val_loss: 8.7396\n",
      "Epoch 3800/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0607 - val_loss: 8.7399\n",
      "Epoch 3801/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.0603 - val_loss: 8.7401\n",
      "Epoch 3802/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0600 - val_loss: 8.7404\n",
      "Epoch 3803/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0597 - val_loss: 8.7407\n",
      "Epoch 3804/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0593 - val_loss: 8.7411\n",
      "Epoch 3805/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0590 - val_loss: 8.7414\n",
      "Epoch 3806/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0587 - val_loss: 8.7417\n",
      "Epoch 3807/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0583 - val_loss: 8.7420\n",
      "Epoch 3808/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0580 - val_loss: 8.7422\n",
      "Epoch 3809/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0577 - val_loss: 8.7424\n",
      "Epoch 3810/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0573 - val_loss: 8.7426\n",
      "Epoch 3811/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0570 - val_loss: 8.7428\n",
      "Epoch 3812/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0567 - val_loss: 8.7431\n",
      "Epoch 3813/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.0563 - val_loss: 8.7434\n",
      "Epoch 3814/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0560 - val_loss: 8.7437\n",
      "Epoch 3815/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0557 - val_loss: 8.7440\n",
      "Epoch 3816/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.0553 - val_loss: 8.7442\n",
      "Epoch 3817/10000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.0550 - val_loss: 8.7445\n",
      "Epoch 3818/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.0547 - val_loss: 8.7449\n",
      "Epoch 3819/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.0543 - val_loss: 8.7452\n",
      "Epoch 3820/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0540 - val_loss: 8.7456\n",
      "Epoch 3821/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0537 - val_loss: 8.7460\n",
      "Epoch 3822/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0534 - val_loss: 8.7462\n",
      "Epoch 3823/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0530 - val_loss: 8.7465\n",
      "Epoch 3824/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0527 - val_loss: 8.7467\n",
      "Epoch 3825/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0524 - val_loss: 8.7470\n",
      "Epoch 3826/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.0520 - val_loss: 8.7473\n",
      "Epoch 3827/10000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.0517 - val_loss: 8.7476\n",
      "Epoch 3828/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.0514 - val_loss: 8.7479\n",
      "Epoch 3829/10000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.0510 - val_loss: 8.7482\n",
      "Epoch 3830/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0507 - val_loss: 8.7484\n",
      "Epoch 3831/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.0504 - val_loss: 8.7487\n",
      "Epoch 3832/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.0500 - val_loss: 8.7490\n",
      "Epoch 3833/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.0497 - val_loss: 8.7493\n",
      "Epoch 3834/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.0494 - val_loss: 8.7496\n",
      "Epoch 3835/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.0490 - val_loss: 8.7499\n",
      "Epoch 3836/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.0487 - val_loss: 8.7502\n",
      "Epoch 3837/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.0484 - val_loss: 8.7504\n",
      "Epoch 3838/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.0480 - val_loss: 8.7507\n",
      "Epoch 3839/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.0477 - val_loss: 8.7510\n",
      "Epoch 3840/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.0474 - val_loss: 8.7513\n",
      "Epoch 3841/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0470 - val_loss: 8.7516\n",
      "Epoch 3842/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.0467 - val_loss: 8.7519\n",
      "Epoch 3843/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0464 - val_loss: 8.7522\n",
      "Epoch 3844/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.0461 - val_loss: 8.7525\n",
      "Epoch 3845/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.0457 - val_loss: 8.7528\n",
      "Epoch 3846/10000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 5.0454 - val_loss: 8.7531\n",
      "Epoch 3847/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.0451 - val_loss: 8.7534\n",
      "Epoch 3848/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.0447 - val_loss: 8.7537\n",
      "Epoch 3849/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.0444 - val_loss: 8.7539\n",
      "Epoch 3850/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.0441 - val_loss: 8.7542\n",
      "Epoch 3851/10000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.0437 - val_loss: 8.7546\n",
      "Epoch 3852/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.0434 - val_loss: 8.7549\n",
      "Epoch 3853/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.0431 - val_loss: 8.7551\n",
      "Epoch 3854/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.0427 - val_loss: 8.7553\n",
      "Epoch 3855/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.0424 - val_loss: 8.7556\n",
      "Epoch 3856/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.0421 - val_loss: 8.7558\n",
      "Epoch 3857/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.0418 - val_loss: 8.7560\n",
      "Epoch 3858/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.0414 - val_loss: 8.7564\n",
      "Epoch 3859/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0411 - val_loss: 8.7567\n",
      "Epoch 3860/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.0408 - val_loss: 8.7570\n",
      "Epoch 3861/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0404 - val_loss: 8.7573\n",
      "Epoch 3862/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0401 - val_loss: 8.7576\n",
      "Epoch 3863/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.0398 - val_loss: 8.7579\n",
      "Epoch 3864/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.0395 - val_loss: 8.7583\n",
      "Epoch 3865/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0391 - val_loss: 8.7586\n",
      "Epoch 3866/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.0388 - val_loss: 8.7590\n",
      "Epoch 3867/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.0385 - val_loss: 8.7592\n",
      "Epoch 3868/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0381 - val_loss: 8.7595\n",
      "Epoch 3869/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.0378 - val_loss: 8.7598\n",
      "Epoch 3870/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.0375 - val_loss: 8.7601\n",
      "Epoch 3871/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.0372 - val_loss: 8.7603\n",
      "Epoch 3872/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0368 - val_loss: 8.7606\n",
      "Epoch 3873/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0365 - val_loss: 8.7608\n",
      "Epoch 3874/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0362 - val_loss: 8.7611\n",
      "Epoch 3875/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0358 - val_loss: 8.7614\n",
      "Epoch 3876/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.0355 - val_loss: 8.7617\n",
      "Epoch 3877/10000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.0352 - val_loss: 8.7621\n",
      "Epoch 3878/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.0349 - val_loss: 8.7625\n",
      "Epoch 3879/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.0345 - val_loss: 8.7628\n",
      "Epoch 3880/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.0342 - val_loss: 8.7631\n",
      "Epoch 3881/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0339 - val_loss: 8.7634\n",
      "Epoch 3882/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0335 - val_loss: 8.7637\n",
      "Epoch 3883/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0332 - val_loss: 8.7640\n",
      "Epoch 3884/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0329 - val_loss: 8.7643\n",
      "Epoch 3885/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0326 - val_loss: 8.7646\n",
      "Epoch 3886/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0322 - val_loss: 8.7649\n",
      "Epoch 3887/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0319 - val_loss: 8.7652\n",
      "Epoch 3888/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0316 - val_loss: 8.7655\n",
      "Epoch 3889/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0313 - val_loss: 8.7657\n",
      "Epoch 3890/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.0309 - val_loss: 8.7661\n",
      "Epoch 3891/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0306 - val_loss: 8.7664\n",
      "Epoch 3892/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0303 - val_loss: 8.7668\n",
      "Epoch 3893/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.0299 - val_loss: 8.7671\n",
      "Epoch 3894/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0296 - val_loss: 8.7674\n",
      "Epoch 3895/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0293 - val_loss: 8.7677\n",
      "Epoch 3896/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0290 - val_loss: 8.7680\n",
      "Epoch 3897/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0286 - val_loss: 8.7683\n",
      "Epoch 3898/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0283 - val_loss: 8.7686\n",
      "Epoch 3899/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0280 - val_loss: 8.7690\n",
      "Epoch 3900/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0277 - val_loss: 8.7692\n",
      "Epoch 3901/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.0273 - val_loss: 8.7695\n",
      "Epoch 3902/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0270 - val_loss: 8.7698\n",
      "Epoch 3903/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0267 - val_loss: 8.7701\n",
      "Epoch 3904/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0264 - val_loss: 8.7704\n",
      "Epoch 3905/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.0260 - val_loss: 8.7706\n",
      "Epoch 3906/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0257 - val_loss: 8.7709\n",
      "Epoch 3907/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0254 - val_loss: 8.7712\n",
      "Epoch 3908/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0251 - val_loss: 8.7714\n",
      "Epoch 3909/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0247 - val_loss: 8.7717\n",
      "Epoch 3910/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.024 - 0s 33ms/step - loss: 5.0244 - val_loss: 8.7720\n",
      "Epoch 3911/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0241 - val_loss: 8.7723\n",
      "Epoch 3912/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0237 - val_loss: 8.7726\n",
      "Epoch 3913/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0234 - val_loss: 8.7728\n",
      "Epoch 3914/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0231 - val_loss: 8.7732\n",
      "Epoch 3915/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0228 - val_loss: 8.7735\n",
      "Epoch 3916/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0224 - val_loss: 8.7738\n",
      "Epoch 3917/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0221 - val_loss: 8.7741\n",
      "Epoch 3918/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0218 - val_loss: 8.7744\n",
      "Epoch 3919/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0215 - val_loss: 8.7746\n",
      "Epoch 3920/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0211 - val_loss: 8.7749\n",
      "Epoch 3921/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0208 - val_loss: 8.7752\n",
      "Epoch 3922/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0205 - val_loss: 8.7754\n",
      "Epoch 3923/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0201 - val_loss: 8.7756\n",
      "Epoch 3924/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0198 - val_loss: 8.7759\n",
      "Epoch 3925/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0195 - val_loss: 8.7761\n",
      "Epoch 3926/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0192 - val_loss: 8.7764\n",
      "Epoch 3927/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0188 - val_loss: 8.7767\n",
      "Epoch 3928/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0185 - val_loss: 8.7770\n",
      "Epoch 3929/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0182 - val_loss: 8.7773\n",
      "Epoch 3930/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0179 - val_loss: 8.7776\n",
      "Epoch 3931/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0175 - val_loss: 8.7779\n",
      "Epoch 3932/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0172 - val_loss: 8.7782\n",
      "Epoch 3933/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0169 - val_loss: 8.7785\n",
      "Epoch 3934/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0166 - val_loss: 8.7788\n",
      "Epoch 3935/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0162 - val_loss: 8.7790\n",
      "Epoch 3936/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0159 - val_loss: 8.7793\n",
      "Epoch 3937/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0156 - val_loss: 8.7796\n",
      "Epoch 3938/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0153 - val_loss: 8.7798\n",
      "Epoch 3939/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0149 - val_loss: 8.7800\n",
      "Epoch 3940/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0146 - val_loss: 8.7802\n",
      "Epoch 3941/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0143 - val_loss: 8.7804\n",
      "Epoch 3942/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0139 - val_loss: 8.7807\n",
      "Epoch 3943/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0136 - val_loss: 8.7809\n",
      "Epoch 3944/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0133 - val_loss: 8.7812\n",
      "Epoch 3945/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.0130 - val_loss: 8.7814\n",
      "Epoch 3946/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0126 - val_loss: 8.7816\n",
      "Epoch 3947/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0123 - val_loss: 8.7818\n",
      "Epoch 3948/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0120 - val_loss: 8.7820\n",
      "Epoch 3949/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0117 - val_loss: 8.7823\n",
      "Epoch 3950/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0113 - val_loss: 8.7826\n",
      "Epoch 3951/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0110 - val_loss: 8.7829\n",
      "Epoch 3952/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0107 - val_loss: 8.7831\n",
      "Epoch 3953/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0104 - val_loss: 8.7833\n",
      "Epoch 3954/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0100 - val_loss: 8.7835\n",
      "Epoch 3955/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0097 - val_loss: 8.7838\n",
      "Epoch 3956/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0094 - val_loss: 8.7840\n",
      "Epoch 3957/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0091 - val_loss: 8.7844\n",
      "Epoch 3958/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0087 - val_loss: 8.7846\n",
      "Epoch 3959/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0084 - val_loss: 8.7849\n",
      "Epoch 3960/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0081 - val_loss: 8.7851\n",
      "Epoch 3961/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0078 - val_loss: 8.7853\n",
      "Epoch 3962/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0074 - val_loss: 8.7855\n",
      "Epoch 3963/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0071 - val_loss: 8.7856\n",
      "Epoch 3964/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0068 - val_loss: 8.7858\n",
      "Epoch 3965/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0065 - val_loss: 8.7860\n",
      "Epoch 3966/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0061 - val_loss: 8.7863\n",
      "Epoch 3967/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0058 - val_loss: 8.7865\n",
      "Epoch 3968/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.0055 - val_loss: 8.7867\n",
      "Epoch 3969/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0052 - val_loss: 8.7870\n",
      "Epoch 3970/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.0048 - val_loss: 8.7872\n",
      "Epoch 3971/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.0045 - val_loss: 8.7874\n",
      "Epoch 3972/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.0042 - val_loss: 8.7876\n",
      "Epoch 3973/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0039 - val_loss: 8.7878\n",
      "Epoch 3974/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0035 - val_loss: 8.7880\n",
      "Epoch 3975/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0032 - val_loss: 8.7883\n",
      "Epoch 3976/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.0029 - val_loss: 8.7885\n",
      "Epoch 3977/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.0026 - val_loss: 8.7887\n",
      "Epoch 3978/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0023 - val_loss: 8.7889\n",
      "Epoch 3979/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0019 - val_loss: 8.7892\n",
      "Epoch 3980/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0016 - val_loss: 8.7894\n",
      "Epoch 3981/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0013 - val_loss: 8.7897\n",
      "Epoch 3982/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0010 - val_loss: 8.7899\n",
      "Epoch 3983/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0006 - val_loss: 8.7900\n",
      "Epoch 3984/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0003 - val_loss: 8.7902\n",
      "Epoch 3985/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0000 - val_loss: 8.7905\n",
      "Epoch 3986/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9997 - val_loss: 8.7907\n",
      "Epoch 3987/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9993 - val_loss: 8.7909\n",
      "Epoch 3988/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9990 - val_loss: 8.7911\n",
      "Epoch 3989/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9987 - val_loss: 8.7913\n",
      "Epoch 3990/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9984 - val_loss: 8.7915\n",
      "Epoch 3991/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.9980 - val_loss: 8.7917\n",
      "Epoch 3992/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.9977 - val_loss: 8.7919\n",
      "Epoch 3993/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.9974 - val_loss: 8.7921\n",
      "Epoch 3994/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9971 - val_loss: 8.7924\n",
      "Epoch 3995/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9968 - val_loss: 8.7927\n",
      "Epoch 3996/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9964 - val_loss: 8.7930\n",
      "Epoch 3997/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9961 - val_loss: 8.7932\n",
      "Epoch 3998/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9958 - val_loss: 8.7936\n",
      "Epoch 3999/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9955 - val_loss: 8.7938\n",
      "Epoch 4000/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9951 - val_loss: 8.7940\n",
      "Epoch 4001/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9948 - val_loss: 8.7942\n",
      "Epoch 4002/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9945 - val_loss: 8.7945\n",
      "Epoch 4003/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.9942 - val_loss: 8.7948\n",
      "Epoch 4004/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9939 - val_loss: 8.7950\n",
      "Epoch 4005/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9935 - val_loss: 8.7951\n",
      "Epoch 4006/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9932 - val_loss: 8.7953\n",
      "Epoch 4007/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9929 - val_loss: 8.7954\n",
      "Epoch 4008/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9926 - val_loss: 8.7956\n",
      "Epoch 4009/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9923 - val_loss: 8.7958\n",
      "Epoch 4010/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9919 - val_loss: 8.7961\n",
      "Epoch 4011/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9916 - val_loss: 8.7963\n",
      "Epoch 4012/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9913 - val_loss: 8.7966\n",
      "Epoch 4013/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.9910 - val_loss: 8.7969\n",
      "Epoch 4014/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9906 - val_loss: 8.7972\n",
      "Epoch 4015/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9903 - val_loss: 8.7975\n",
      "Epoch 4016/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9900 - val_loss: 8.7977\n",
      "Epoch 4017/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9897 - val_loss: 8.7978\n",
      "Epoch 4018/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9894 - val_loss: 8.7980\n",
      "Epoch 4019/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9890 - val_loss: 8.7982\n",
      "Epoch 4020/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9887 - val_loss: 8.7984\n",
      "Epoch 4021/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9884 - val_loss: 8.7986\n",
      "Epoch 4022/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9881 - val_loss: 8.7989\n",
      "Epoch 4023/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.9878 - val_loss: 8.7992\n",
      "Epoch 4024/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9874 - val_loss: 8.7995\n",
      "Epoch 4025/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9871 - val_loss: 8.7998\n",
      "Epoch 4026/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9868 - val_loss: 8.8000\n",
      "Epoch 4027/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9865 - val_loss: 8.8003\n",
      "Epoch 4028/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9862 - val_loss: 8.8004\n",
      "Epoch 4029/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9858 - val_loss: 8.8006\n",
      "Epoch 4030/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9855 - val_loss: 8.8007\n",
      "Epoch 4031/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9852 - val_loss: 8.8009\n",
      "Epoch 4032/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9849 - val_loss: 8.8011\n",
      "Epoch 4033/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9846 - val_loss: 8.8013\n",
      "Epoch 4034/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9842 - val_loss: 8.8016\n",
      "Epoch 4035/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9839 - val_loss: 8.8018\n",
      "Epoch 4036/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.9836 - val_loss: 8.8021\n",
      "Epoch 4037/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.9833 - val_loss: 8.8023\n",
      "Epoch 4038/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.9830 - val_loss: 8.8026\n",
      "Epoch 4039/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9826 - val_loss: 8.8029\n",
      "Epoch 4040/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9823 - val_loss: 8.8031\n",
      "Epoch 4041/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.9820 - val_loss: 8.8034\n",
      "Epoch 4042/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9817 - val_loss: 8.8036\n",
      "Epoch 4043/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9814 - val_loss: 8.8038\n",
      "Epoch 4044/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9810 - val_loss: 8.8040\n",
      "Epoch 4045/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9807 - val_loss: 8.8042\n",
      "Epoch 4046/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9804 - val_loss: 8.8044\n",
      "Epoch 4047/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9801 - val_loss: 8.8046\n",
      "Epoch 4048/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9798 - val_loss: 8.8048\n",
      "Epoch 4049/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9795 - val_loss: 8.8049\n",
      "Epoch 4050/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9791 - val_loss: 8.8051\n",
      "Epoch 4051/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9788 - val_loss: 8.8054\n",
      "Epoch 4052/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9785 - val_loss: 8.8057\n",
      "Epoch 4053/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9782 - val_loss: 8.8060\n",
      "Epoch 4054/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9779 - val_loss: 8.8062\n",
      "Epoch 4055/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.9775 - val_loss: 8.8064\n",
      "Epoch 4056/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9772 - val_loss: 8.8066\n",
      "Epoch 4057/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9769 - val_loss: 8.8068\n",
      "Epoch 4058/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9766 - val_loss: 8.8070\n",
      "Epoch 4059/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9763 - val_loss: 8.8073\n",
      "Epoch 4060/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9759 - val_loss: 8.8075\n",
      "Epoch 4061/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9756 - val_loss: 8.8078\n",
      "Epoch 4062/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9753 - val_loss: 8.8079\n",
      "Epoch 4063/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9750 - val_loss: 8.8082\n",
      "Epoch 4064/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9747 - val_loss: 8.8084\n",
      "Epoch 4065/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9743 - val_loss: 8.8087\n",
      "Epoch 4066/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9740 - val_loss: 8.8089\n",
      "Epoch 4067/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9737 - val_loss: 8.8091\n",
      "Epoch 4068/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9734 - val_loss: 8.8093\n",
      "Epoch 4069/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9731 - val_loss: 8.8095\n",
      "Epoch 4070/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9728 - val_loss: 8.8097\n",
      "Epoch 4071/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.9724 - val_loss: 8.8100\n",
      "Epoch 4072/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9721 - val_loss: 8.8103\n",
      "Epoch 4073/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9718 - val_loss: 8.8105\n",
      "Epoch 4074/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9715 - val_loss: 8.8106\n",
      "Epoch 4075/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9712 - val_loss: 8.8108\n",
      "Epoch 4076/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9708 - val_loss: 8.8109\n",
      "Epoch 4077/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9705 - val_loss: 8.8111\n",
      "Epoch 4078/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9702 - val_loss: 8.8113\n",
      "Epoch 4079/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9699 - val_loss: 8.8115\n",
      "Epoch 4080/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9696 - val_loss: 8.8118\n",
      "Epoch 4081/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9693 - val_loss: 8.8121\n",
      "Epoch 4082/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9689 - val_loss: 8.8124\n",
      "Epoch 4083/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9686 - val_loss: 8.8126\n",
      "Epoch 4084/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9683 - val_loss: 8.8128\n",
      "Epoch 4085/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9680 - val_loss: 8.8130\n",
      "Epoch 4086/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.9677 - val_loss: 8.8132\n",
      "Epoch 4087/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9674 - val_loss: 8.8134\n",
      "Epoch 4088/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.9670 - val_loss: 8.8136\n",
      "Epoch 4089/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.9667 - val_loss: 8.8139\n",
      "Epoch 4090/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9664 - val_loss: 8.8141\n",
      "Epoch 4091/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9661 - val_loss: 8.8142\n",
      "Epoch 4092/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9658 - val_loss: 8.8144\n",
      "Epoch 4093/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9654 - val_loss: 8.8146\n",
      "Epoch 4094/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9651 - val_loss: 8.8148\n",
      "Epoch 4095/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9648 - val_loss: 8.8150\n",
      "Epoch 4096/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9645 - val_loss: 8.8153\n",
      "Epoch 4097/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9642 - val_loss: 8.8155\n",
      "Epoch 4098/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9639 - val_loss: 8.8157\n",
      "Epoch 4099/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9635 - val_loss: 8.8159\n",
      "Epoch 4100/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9632 - val_loss: 8.8161\n",
      "Epoch 4101/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9629 - val_loss: 8.8163\n",
      "Epoch 4102/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9626 - val_loss: 8.8165\n",
      "Epoch 4103/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9623 - val_loss: 8.8168\n",
      "Epoch 4104/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9620 - val_loss: 8.8171\n",
      "Epoch 4105/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9616 - val_loss: 8.8172\n",
      "Epoch 4106/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9613 - val_loss: 8.8174\n",
      "Epoch 4107/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9610 - val_loss: 8.8175\n",
      "Epoch 4108/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9607 - val_loss: 8.8177\n",
      "Epoch 4109/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9604 - val_loss: 8.8180\n",
      "Epoch 4110/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9601 - val_loss: 8.8183\n",
      "Epoch 4111/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9598 - val_loss: 8.8186\n",
      "Epoch 4112/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9594 - val_loss: 8.8188\n",
      "Epoch 4113/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9591 - val_loss: 8.8189\n",
      "Epoch 4114/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9588 - val_loss: 8.8191\n",
      "Epoch 4115/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9585 - val_loss: 8.8193\n",
      "Epoch 4116/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9582 - val_loss: 8.8196\n",
      "Epoch 4117/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9579 - val_loss: 8.8198\n",
      "Epoch 4118/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9575 - val_loss: 8.8200\n",
      "Epoch 4119/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9572 - val_loss: 8.8202\n",
      "Epoch 4120/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9569 - val_loss: 8.8204\n",
      "Epoch 4121/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9566 - val_loss: 8.8206\n",
      "Epoch 4122/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9563 - val_loss: 8.8209\n",
      "Epoch 4123/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9560 - val_loss: 8.8211\n",
      "Epoch 4124/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9556 - val_loss: 8.8214\n",
      "Epoch 4125/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9553 - val_loss: 8.8216\n",
      "Epoch 4126/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9550 - val_loss: 8.8218\n",
      "Epoch 4127/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9547 - val_loss: 8.8221\n",
      "Epoch 4128/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9544 - val_loss: 8.8223\n",
      "Epoch 4129/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9541 - val_loss: 8.8225\n",
      "Epoch 4130/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.9537 - val_loss: 8.8227\n",
      "Epoch 4131/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9534 - val_loss: 8.8228\n",
      "Epoch 4132/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9531 - val_loss: 8.8231\n",
      "Epoch 4133/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9528 - val_loss: 8.8233\n",
      "Epoch 4134/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9525 - val_loss: 8.8236\n",
      "Epoch 4135/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9522 - val_loss: 8.8237\n",
      "Epoch 4136/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.9519 - val_loss: 8.8239\n",
      "Epoch 4137/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.9515 - val_loss: 8.8241\n",
      "Epoch 4138/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.9512 - val_loss: 8.8244\n",
      "Epoch 4139/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9509 - val_loss: 8.8247\n",
      "Epoch 4140/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9506 - val_loss: 8.8249\n",
      "Epoch 4141/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9503 - val_loss: 8.8251\n",
      "Epoch 4142/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9500 - val_loss: 8.8253\n",
      "Epoch 4143/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9496 - val_loss: 8.8255\n",
      "Epoch 4144/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9493 - val_loss: 8.8257\n",
      "Epoch 4145/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9490 - val_loss: 8.8260\n",
      "Epoch 4146/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9487 - val_loss: 8.8262\n",
      "Epoch 4147/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9484 - val_loss: 8.8264\n",
      "Epoch 4148/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9481 - val_loss: 8.8267\n",
      "Epoch 4149/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9478 - val_loss: 8.8269\n",
      "Epoch 4150/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9474 - val_loss: 8.8271\n",
      "Epoch 4151/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9471 - val_loss: 8.8273\n",
      "Epoch 4152/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9468 - val_loss: 8.8276\n",
      "Epoch 4153/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9465 - val_loss: 8.8278\n",
      "Epoch 4154/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9462 - val_loss: 8.8280\n",
      "Epoch 4155/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9459 - val_loss: 8.8282\n",
      "Epoch 4156/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9456 - val_loss: 8.8284\n",
      "Epoch 4157/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9452 - val_loss: 8.8286\n",
      "Epoch 4158/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9449 - val_loss: 8.8289\n",
      "Epoch 4159/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.9446 - val_loss: 8.8291\n",
      "Epoch 4160/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9443 - val_loss: 8.8293\n",
      "Epoch 4161/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9440 - val_loss: 8.8295\n",
      "Epoch 4162/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9437 - val_loss: 8.8298\n",
      "Epoch 4163/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9433 - val_loss: 8.8301\n",
      "Epoch 4164/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9430 - val_loss: 8.8303\n",
      "Epoch 4165/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9427 - val_loss: 8.8304\n",
      "Epoch 4166/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9424 - val_loss: 8.8306\n",
      "Epoch 4167/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.9421 - val_loss: 8.8308\n",
      "Epoch 4168/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.9418 - val_loss: 8.8310\n",
      "Epoch 4169/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.9415 - val_loss: 8.8313\n",
      "Epoch 4170/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9411 - val_loss: 8.8315\n",
      "Epoch 4171/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9408 - val_loss: 8.8317\n",
      "Epoch 4172/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9405 - val_loss: 8.8319\n",
      "Epoch 4173/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9402 - val_loss: 8.8321\n",
      "Epoch 4174/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9399 - val_loss: 8.8324\n",
      "Epoch 4175/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9396 - val_loss: 8.8327\n",
      "Epoch 4176/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9393 - val_loss: 8.8329\n",
      "Epoch 4177/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9389 - val_loss: 8.8332\n",
      "Epoch 4178/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9386 - val_loss: 8.8334\n",
      "Epoch 4179/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9383 - val_loss: 8.8336\n",
      "Epoch 4180/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9380 - val_loss: 8.8338\n",
      "Epoch 4181/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9377 - val_loss: 8.8340\n",
      "Epoch 4182/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9374 - val_loss: 8.8342\n",
      "Epoch 4183/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9371 - val_loss: 8.8344\n",
      "Epoch 4184/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9367 - val_loss: 8.8346\n",
      "Epoch 4185/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9364 - val_loss: 8.8349\n",
      "Epoch 4186/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.9361 - val_loss: 8.8351\n",
      "Epoch 4187/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9358 - val_loss: 8.8353\n",
      "Epoch 4188/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9355 - val_loss: 8.8356\n",
      "Epoch 4189/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9352 - val_loss: 8.8358\n",
      "Epoch 4190/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9349 - val_loss: 8.8360\n",
      "Epoch 4191/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9345 - val_loss: 8.8363\n",
      "Epoch 4192/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9342 - val_loss: 8.8365\n",
      "Epoch 4193/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9339 - val_loss: 8.8367\n",
      "Epoch 4194/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.9336 - val_loss: 8.8369\n",
      "Epoch 4195/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9333 - val_loss: 8.8371\n",
      "Epoch 4196/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9330 - val_loss: 8.8374\n",
      "Epoch 4197/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9327 - val_loss: 8.8376\n",
      "Epoch 4198/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.9324 - val_loss: 8.8378\n",
      "Epoch 4199/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9320 - val_loss: 8.8380\n",
      "Epoch 4200/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9317 - val_loss: 8.8382\n",
      "Epoch 4201/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9314 - val_loss: 8.8383\n",
      "Epoch 4202/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9311 - val_loss: 8.8386\n",
      "Epoch 4203/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9308 - val_loss: 8.8388\n",
      "Epoch 4204/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9305 - val_loss: 8.8391\n",
      "Epoch 4205/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9302 - val_loss: 8.8394\n",
      "Epoch 4206/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9298 - val_loss: 8.8397\n",
      "Epoch 4207/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9295 - val_loss: 8.8399\n",
      "Epoch 4208/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9292 - val_loss: 8.8401\n",
      "Epoch 4209/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9289 - val_loss: 8.8402\n",
      "Epoch 4210/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9286 - val_loss: 8.8404\n",
      "Epoch 4211/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9283 - val_loss: 8.8407\n",
      "Epoch 4212/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9280 - val_loss: 8.8410\n",
      "Epoch 4213/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.9277 - val_loss: 8.8413\n",
      "Epoch 4214/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9273 - val_loss: 8.8415\n",
      "Epoch 4215/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9270 - val_loss: 8.8416\n",
      "Epoch 4216/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.9267 - val_loss: 8.8418\n",
      "Epoch 4217/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9264 - val_loss: 8.8420\n",
      "Epoch 4218/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9261 - val_loss: 8.8423\n",
      "Epoch 4219/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9258 - val_loss: 8.8425\n",
      "Epoch 4220/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9255 - val_loss: 8.8426\n",
      "Epoch 4221/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.9252 - val_loss: 8.8429\n",
      "Epoch 4222/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9248 - val_loss: 8.8432\n",
      "Epoch 4223/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9245 - val_loss: 8.8434\n",
      "Epoch 4224/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9242 - val_loss: 8.8436\n",
      "Epoch 4225/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9239 - val_loss: 8.8438\n",
      "Epoch 4226/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9236 - val_loss: 8.8441\n",
      "Epoch 4227/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9233 - val_loss: 8.8443\n",
      "Epoch 4228/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9230 - val_loss: 8.8446\n",
      "Epoch 4229/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9227 - val_loss: 8.8448\n",
      "Epoch 4230/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9223 - val_loss: 8.8450\n",
      "Epoch 4231/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9220 - val_loss: 8.8452\n",
      "Epoch 4232/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9217 - val_loss: 8.8454\n",
      "Epoch 4233/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9214 - val_loss: 8.8456\n",
      "Epoch 4234/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9211 - val_loss: 8.8458\n",
      "Epoch 4235/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9208 - val_loss: 8.8461\n",
      "Epoch 4236/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9205 - val_loss: 8.8465\n",
      "Epoch 4237/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.9202 - val_loss: 8.8467\n",
      "Epoch 4238/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9199 - val_loss: 8.8469\n",
      "Epoch 4239/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9195 - val_loss: 8.8471\n",
      "Epoch 4240/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9192 - val_loss: 8.8472\n",
      "Epoch 4241/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9189 - val_loss: 8.8474\n",
      "Epoch 4242/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9186 - val_loss: 8.8476\n",
      "Epoch 4243/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9183 - val_loss: 8.8479\n",
      "Epoch 4244/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9180 - val_loss: 8.8481\n",
      "Epoch 4245/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9177 - val_loss: 8.8483\n",
      "Epoch 4246/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9174 - val_loss: 8.8485\n",
      "Epoch 4247/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9170 - val_loss: 8.8487\n",
      "Epoch 4248/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9167 - val_loss: 8.8490\n",
      "Epoch 4249/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9164 - val_loss: 8.8493\n",
      "Epoch 4250/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9161 - val_loss: 8.8496\n",
      "Epoch 4251/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9158 - val_loss: 8.8498\n",
      "Epoch 4252/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9155 - val_loss: 8.8500\n",
      "Epoch 4253/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9152 - val_loss: 8.8502\n",
      "Epoch 4254/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9149 - val_loss: 8.8504\n",
      "Epoch 4255/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9146 - val_loss: 8.8506\n",
      "Epoch 4256/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9143 - val_loss: 8.8508\n",
      "Epoch 4257/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 4.9139 - val_loss: 8.8510\n",
      "Epoch 4258/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9136 - val_loss: 8.8512\n",
      "Epoch 4259/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9133 - val_loss: 8.8514\n",
      "Epoch 4260/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9130 - val_loss: 8.8517\n",
      "Epoch 4261/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9127 - val_loss: 8.8520\n",
      "Epoch 4262/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9124 - val_loss: 8.8523\n",
      "Epoch 4263/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9121 - val_loss: 8.8525\n",
      "Epoch 4264/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9118 - val_loss: 8.8527\n",
      "Epoch 4265/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9115 - val_loss: 8.8529\n",
      "Epoch 4266/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9111 - val_loss: 8.8531\n",
      "Epoch 4267/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9108 - val_loss: 8.8534\n",
      "Epoch 4268/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9105 - val_loss: 8.8537\n",
      "Epoch 4269/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9102 - val_loss: 8.8539\n",
      "Epoch 4270/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9099 - val_loss: 8.8541\n",
      "Epoch 4271/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9096 - val_loss: 8.8542\n",
      "Epoch 4272/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9093 - val_loss: 8.8544\n",
      "Epoch 4273/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9090 - val_loss: 8.8545\n",
      "Epoch 4274/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.9087 - val_loss: 8.8547\n",
      "Epoch 4275/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9084 - val_loss: 8.8549\n",
      "Epoch 4276/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9080 - val_loss: 8.8552\n",
      "Epoch 4277/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9077 - val_loss: 8.8555\n",
      "Epoch 4278/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9074 - val_loss: 8.8558\n",
      "Epoch 4279/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9071 - val_loss: 8.8560\n",
      "Epoch 4280/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9068 - val_loss: 8.8562\n",
      "Epoch 4281/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9065 - val_loss: 8.8565\n",
      "Epoch 4282/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9062 - val_loss: 8.8568\n",
      "Epoch 4283/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9059 - val_loss: 8.8570\n",
      "Epoch 4284/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9056 - val_loss: 8.8571\n",
      "Epoch 4285/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9052 - val_loss: 8.8573\n",
      "Epoch 4286/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9049 - val_loss: 8.8575\n",
      "Epoch 4287/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9046 - val_loss: 8.8577\n",
      "Epoch 4288/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9043 - val_loss: 8.8579\n",
      "Epoch 4289/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9040 - val_loss: 8.8581\n",
      "Epoch 4290/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.9037 - val_loss: 8.8583\n",
      "Epoch 4291/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.9034 - val_loss: 8.8585\n",
      "Epoch 4292/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9031 - val_loss: 8.8586\n",
      "Epoch 4293/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9028 - val_loss: 8.8589\n",
      "Epoch 4294/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9025 - val_loss: 8.8592\n",
      "Epoch 4295/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9021 - val_loss: 8.8595\n",
      "Epoch 4296/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.9018 - val_loss: 8.8596\n",
      "Epoch 4297/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9015 - val_loss: 8.8598\n",
      "Epoch 4298/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9012 - val_loss: 8.8601\n",
      "Epoch 4299/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9009 - val_loss: 8.8603\n",
      "Epoch 4300/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9006 - val_loss: 8.8605\n",
      "Epoch 4301/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9003 - val_loss: 8.8608\n",
      "Epoch 4302/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9000 - val_loss: 8.8610\n",
      "Epoch 4303/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8997 - val_loss: 8.8611\n",
      "Epoch 4304/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8994 - val_loss: 8.8613\n",
      "Epoch 4305/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8990 - val_loss: 8.8615\n",
      "Epoch 4306/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8987 - val_loss: 8.8617\n",
      "Epoch 4307/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8984 - val_loss: 8.8619\n",
      "Epoch 4308/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8981 - val_loss: 8.8622\n",
      "Epoch 4309/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8978 - val_loss: 8.8624\n",
      "Epoch 4310/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8975 - val_loss: 8.8626\n",
      "Epoch 4311/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8972 - val_loss: 8.8628\n",
      "Epoch 4312/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8969 - val_loss: 8.8630\n",
      "Epoch 4313/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8966 - val_loss: 8.8633\n",
      "Epoch 4314/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8963 - val_loss: 8.8635\n",
      "Epoch 4315/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8959 - val_loss: 8.8638\n",
      "Epoch 4316/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8956 - val_loss: 8.8640\n",
      "Epoch 4317/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8953 - val_loss: 8.8642\n",
      "Epoch 4318/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8950 - val_loss: 8.8644\n",
      "Epoch 4319/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8947 - val_loss: 8.8646\n",
      "Epoch 4320/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8944 - val_loss: 8.8649\n",
      "Epoch 4321/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8941 - val_loss: 8.8651\n",
      "Epoch 4322/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8938 - val_loss: 8.8653\n",
      "Epoch 4323/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8935 - val_loss: 8.8655\n",
      "Epoch 4324/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8932 - val_loss: 8.8657\n",
      "Epoch 4325/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8928 - val_loss: 8.8659\n",
      "Epoch 4326/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8925 - val_loss: 8.8661\n",
      "Epoch 4327/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8922 - val_loss: 8.8664\n",
      "Epoch 4328/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8919 - val_loss: 8.8666\n",
      "Epoch 4329/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8916 - val_loss: 8.8669\n",
      "Epoch 4330/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8913 - val_loss: 8.8671\n",
      "Epoch 4331/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8910 - val_loss: 8.8673\n",
      "Epoch 4332/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8907 - val_loss: 8.8675\n",
      "Epoch 4333/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8904 - val_loss: 8.8677\n",
      "Epoch 4334/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8901 - val_loss: 8.8679\n",
      "Epoch 4335/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8898 - val_loss: 8.8682\n",
      "Epoch 4336/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8894 - val_loss: 8.8685\n",
      "Epoch 4337/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8891 - val_loss: 8.8687\n",
      "Epoch 4338/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8888 - val_loss: 8.8690\n",
      "Epoch 4339/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8885 - val_loss: 8.8692\n",
      "Epoch 4340/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8882 - val_loss: 8.8695\n",
      "Epoch 4341/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8879 - val_loss: 8.8696\n",
      "Epoch 4342/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8876 - val_loss: 8.8698\n",
      "Epoch 4343/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8873 - val_loss: 8.8700\n",
      "Epoch 4344/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8870 - val_loss: 8.8702\n",
      "Epoch 4345/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8867 - val_loss: 8.8704\n",
      "Epoch 4346/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8864 - val_loss: 8.8706\n",
      "Epoch 4347/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8861 - val_loss: 8.8708\n",
      "Epoch 4348/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8857 - val_loss: 8.8710\n",
      "Epoch 4349/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8854 - val_loss: 8.8712\n",
      "Epoch 4350/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8851 - val_loss: 8.8715\n",
      "Epoch 4351/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8848 - val_loss: 8.8718\n",
      "Epoch 4352/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8845 - val_loss: 8.8720\n",
      "Epoch 4353/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8842 - val_loss: 8.8722\n",
      "Epoch 4354/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8839 - val_loss: 8.8724\n",
      "Epoch 4355/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8836 - val_loss: 8.8726\n",
      "Epoch 4356/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8833 - val_loss: 8.8728\n",
      "Epoch 4357/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8830 - val_loss: 8.8731\n",
      "Epoch 4358/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8827 - val_loss: 8.8734\n",
      "Epoch 4359/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8824 - val_loss: 8.8736\n",
      "Epoch 4360/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8821 - val_loss: 8.8738\n",
      "Epoch 4361/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8817 - val_loss: 8.8739\n",
      "Epoch 4362/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8814 - val_loss: 8.8741\n",
      "Epoch 4363/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8811 - val_loss: 8.8743\n",
      "Epoch 4364/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8808 - val_loss: 8.8745\n",
      "Epoch 4365/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8805 - val_loss: 8.8747\n",
      "Epoch 4366/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8802 - val_loss: 8.8749\n",
      "Epoch 4367/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8799 - val_loss: 8.8752\n",
      "Epoch 4368/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8796 - val_loss: 8.8755\n",
      "Epoch 4369/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8793 - val_loss: 8.8757\n",
      "Epoch 4370/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8790 - val_loss: 8.8760\n",
      "Epoch 4371/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8787 - val_loss: 8.8763\n",
      "Epoch 4372/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8784 - val_loss: 8.8767\n",
      "Epoch 4373/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8781 - val_loss: 8.8770\n",
      "Epoch 4374/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8777 - val_loss: 8.8773\n",
      "Epoch 4375/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8774 - val_loss: 8.8774\n",
      "Epoch 4376/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8771 - val_loss: 8.8775\n",
      "Epoch 4377/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8768 - val_loss: 8.8776\n",
      "Epoch 4378/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8765 - val_loss: 8.8778\n",
      "Epoch 4379/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8762 - val_loss: 8.8781\n",
      "Epoch 4380/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8759 - val_loss: 8.8783\n",
      "Epoch 4381/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8756 - val_loss: 8.8786\n",
      "Epoch 4382/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8753 - val_loss: 8.8788\n",
      "Epoch 4383/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8750 - val_loss: 8.8790\n",
      "Epoch 4384/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8747 - val_loss: 8.8793\n",
      "Epoch 4385/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8743 - val_loss: 8.8796\n",
      "Epoch 4386/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8740 - val_loss: 8.8799\n",
      "Epoch 4387/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8737 - val_loss: 8.8802\n",
      "Epoch 4388/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8734 - val_loss: 8.8804\n",
      "Epoch 4389/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8731 - val_loss: 8.8807\n",
      "Epoch 4390/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8728 - val_loss: 8.8809\n",
      "Epoch 4391/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8725 - val_loss: 8.8811\n",
      "Epoch 4392/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8722 - val_loss: 8.8814\n",
      "Epoch 4393/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8719 - val_loss: 8.8817\n",
      "Epoch 4394/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8716 - val_loss: 8.8819\n",
      "Epoch 4395/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.8712 - val_loss: 8.8822\n",
      "Epoch 4396/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.8709 - val_loss: 8.8824\n",
      "Epoch 4397/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.8706 - val_loss: 8.8826\n",
      "Epoch 4398/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8703 - val_loss: 8.8829\n",
      "Epoch 4399/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8700 - val_loss: 8.8831\n",
      "Epoch 4400/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8697 - val_loss: 8.8833\n",
      "Epoch 4401/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8694 - val_loss: 8.8836\n",
      "Epoch 4402/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8691 - val_loss: 8.8839\n",
      "Epoch 4403/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.8688 - val_loss: 8.8842\n",
      "Epoch 4404/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8685 - val_loss: 8.8845\n",
      "Epoch 4405/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8681 - val_loss: 8.8847\n",
      "Epoch 4406/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8678 - val_loss: 8.8850\n",
      "Epoch 4407/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8675 - val_loss: 8.8852\n",
      "Epoch 4408/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8672 - val_loss: 8.8855\n",
      "Epoch 4409/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8669 - val_loss: 8.8857\n",
      "Epoch 4410/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8666 - val_loss: 8.8860\n",
      "Epoch 4411/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8663 - val_loss: 8.8862\n",
      "Epoch 4412/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8660 - val_loss: 8.8864\n",
      "Epoch 4413/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8657 - val_loss: 8.8867\n",
      "Epoch 4414/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8654 - val_loss: 8.8870\n",
      "Epoch 4415/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8651 - val_loss: 8.8872\n",
      "Epoch 4416/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8647 - val_loss: 8.8875\n",
      "Epoch 4417/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8644 - val_loss: 8.8877\n",
      "Epoch 4418/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8641 - val_loss: 8.8879\n",
      "Epoch 4419/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8638 - val_loss: 8.8882\n",
      "Epoch 4420/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8635 - val_loss: 8.8885\n",
      "Epoch 4421/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8632 - val_loss: 8.8889\n",
      "Epoch 4422/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8629 - val_loss: 8.8892\n",
      "Epoch 4423/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8626 - val_loss: 8.8894\n",
      "Epoch 4424/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8623 - val_loss: 8.8896\n",
      "Epoch 4425/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8620 - val_loss: 8.8898\n",
      "Epoch 4426/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8616 - val_loss: 8.8901\n",
      "Epoch 4427/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8613 - val_loss: 8.8903\n",
      "Epoch 4428/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8610 - val_loss: 8.8906\n",
      "Epoch 4429/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8607 - val_loss: 8.8908\n",
      "Epoch 4430/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8604 - val_loss: 8.8911\n",
      "Epoch 4431/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8601 - val_loss: 8.8913\n",
      "Epoch 4432/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8598 - val_loss: 8.8916\n",
      "Epoch 4433/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8595 - val_loss: 8.8918\n",
      "Epoch 4434/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8592 - val_loss: 8.8922\n",
      "Epoch 4435/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8589 - val_loss: 8.8925\n",
      "Epoch 4436/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8585 - val_loss: 8.8928\n",
      "Epoch 4437/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8582 - val_loss: 8.8931\n",
      "Epoch 4438/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8579 - val_loss: 8.8933\n",
      "Epoch 4439/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8576 - val_loss: 8.8935\n",
      "Epoch 4440/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8573 - val_loss: 8.8938\n",
      "Epoch 4441/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8570 - val_loss: 8.8940\n",
      "Epoch 4442/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8567 - val_loss: 8.8942\n",
      "Epoch 4443/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8564 - val_loss: 8.8944\n",
      "Epoch 4444/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8561 - val_loss: 8.8946\n",
      "Epoch 4445/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8558 - val_loss: 8.8949\n",
      "Epoch 4446/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8554 - val_loss: 8.8951\n",
      "Epoch 4447/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8551 - val_loss: 8.8954\n",
      "Epoch 4448/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8548 - val_loss: 8.8958\n",
      "Epoch 4449/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8545 - val_loss: 8.8960\n",
      "Epoch 4450/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8542 - val_loss: 8.8963\n",
      "Epoch 4451/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8539 - val_loss: 8.8965\n",
      "Epoch 4452/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.8536 - val_loss: 8.8968\n",
      "Epoch 4453/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8533 - val_loss: 8.8971\n",
      "Epoch 4454/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8530 - val_loss: 8.8973\n",
      "Epoch 4455/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8527 - val_loss: 8.8975\n",
      "Epoch 4456/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8524 - val_loss: 8.8977\n",
      "Epoch 4457/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8520 - val_loss: 8.8979\n",
      "Epoch 4458/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8517 - val_loss: 8.8981\n",
      "Epoch 4459/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8514 - val_loss: 8.8984\n",
      "Epoch 4460/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8511 - val_loss: 8.8987\n",
      "Epoch 4461/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8508 - val_loss: 8.8989\n",
      "Epoch 4462/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8505 - val_loss: 8.8991\n",
      "Epoch 4463/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8502 - val_loss: 8.8993\n",
      "Epoch 4464/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8499 - val_loss: 8.8996\n",
      "Epoch 4465/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8496 - val_loss: 8.9000\n",
      "Epoch 4466/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8493 - val_loss: 8.9004\n",
      "Epoch 4467/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8489 - val_loss: 8.9007\n",
      "Epoch 4468/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8486 - val_loss: 8.9009\n",
      "Epoch 4469/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8483 - val_loss: 8.9011\n",
      "Epoch 4470/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8480 - val_loss: 8.9012\n",
      "Epoch 4471/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8477 - val_loss: 8.9015\n",
      "Epoch 4472/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8474 - val_loss: 8.9018\n",
      "Epoch 4473/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8471 - val_loss: 8.9022\n",
      "Epoch 4474/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8468 - val_loss: 8.9025\n",
      "Epoch 4475/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8465 - val_loss: 8.9027\n",
      "Epoch 4476/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8462 - val_loss: 8.9028\n",
      "Epoch 4477/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8459 - val_loss: 8.9031\n",
      "Epoch 4478/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8456 - val_loss: 8.9034\n",
      "Epoch 4479/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8452 - val_loss: 8.9037\n",
      "Epoch 4480/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8449 - val_loss: 8.9041\n",
      "Epoch 4481/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8446 - val_loss: 8.9043\n",
      "Epoch 4482/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8443 - val_loss: 8.9045\n",
      "Epoch 4483/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8440 - val_loss: 8.9048\n",
      "Epoch 4484/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8437 - val_loss: 8.9050\n",
      "Epoch 4485/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8434 - val_loss: 8.9052\n",
      "Epoch 4486/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8431 - val_loss: 8.9055\n",
      "Epoch 4487/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8428 - val_loss: 8.9057\n",
      "Epoch 4488/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8425 - val_loss: 8.9059\n",
      "Epoch 4489/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8422 - val_loss: 8.9061\n",
      "Epoch 4490/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8418 - val_loss: 8.9063\n",
      "Epoch 4491/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8415 - val_loss: 8.9066\n",
      "Epoch 4492/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8412 - val_loss: 8.9069\n",
      "Epoch 4493/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8409 - val_loss: 8.9072\n",
      "Epoch 4494/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8406 - val_loss: 8.9075\n",
      "Epoch 4495/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8403 - val_loss: 8.9077\n",
      "Epoch 4496/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8400 - val_loss: 8.9080\n",
      "Epoch 4497/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8397 - val_loss: 8.9083\n",
      "Epoch 4498/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8394 - val_loss: 8.9086\n",
      "Epoch 4499/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8391 - val_loss: 8.9089\n",
      "Epoch 4500/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8388 - val_loss: 8.9091\n",
      "Epoch 4501/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8384 - val_loss: 8.9093\n",
      "Epoch 4502/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8381 - val_loss: 8.9095\n",
      "Epoch 4503/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.8378 - val_loss: 8.9097\n",
      "Epoch 4504/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8375 - val_loss: 8.9101\n",
      "Epoch 4505/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8372 - val_loss: 8.9103\n",
      "Epoch 4506/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8369 - val_loss: 8.9105\n",
      "Epoch 4507/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8366 - val_loss: 8.9107\n",
      "Epoch 4508/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8363 - val_loss: 8.9110\n",
      "Epoch 4509/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8360 - val_loss: 8.9113\n",
      "Epoch 4510/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8357 - val_loss: 8.9116\n",
      "Epoch 4511/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8354 - val_loss: 8.9119\n",
      "Epoch 4512/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8351 - val_loss: 8.9122\n",
      "Epoch 4513/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8347 - val_loss: 8.9124\n",
      "Epoch 4514/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8344 - val_loss: 8.9126\n",
      "Epoch 4515/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8341 - val_loss: 8.9129\n",
      "Epoch 4516/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8338 - val_loss: 8.9132\n",
      "Epoch 4517/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8335 - val_loss: 8.9134\n",
      "Epoch 4518/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8332 - val_loss: 8.9136\n",
      "Epoch 4519/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8329 - val_loss: 8.9138\n",
      "Epoch 4520/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8326 - val_loss: 8.9141\n",
      "Epoch 4521/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8323 - val_loss: 8.9143\n",
      "Epoch 4522/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8320 - val_loss: 8.9146\n",
      "Epoch 4523/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8317 - val_loss: 8.9149\n",
      "Epoch 4524/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8314 - val_loss: 8.9152\n",
      "Epoch 4525/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8311 - val_loss: 8.9155\n",
      "Epoch 4526/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.8307 - val_loss: 8.9158\n",
      "Epoch 4527/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8304 - val_loss: 8.9160\n",
      "Epoch 4528/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8301 - val_loss: 8.9163\n",
      "Epoch 4529/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8298 - val_loss: 8.9166\n",
      "Epoch 4530/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8295 - val_loss: 8.9170\n",
      "Epoch 4531/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8292 - val_loss: 8.9172\n",
      "Epoch 4532/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8289 - val_loss: 8.9174\n",
      "Epoch 4533/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8286 - val_loss: 8.9176\n",
      "Epoch 4534/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8283 - val_loss: 8.9178\n",
      "Epoch 4535/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8280 - val_loss: 8.9180\n",
      "Epoch 4536/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.8277 - val_loss: 8.9182\n",
      "Epoch 4537/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8274 - val_loss: 8.9185\n",
      "Epoch 4538/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8271 - val_loss: 8.9188\n",
      "Epoch 4539/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8268 - val_loss: 8.9192\n",
      "Epoch 4540/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8264 - val_loss: 8.9196\n",
      "Epoch 4541/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8261 - val_loss: 8.9200\n",
      "Epoch 4542/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8258 - val_loss: 8.9203\n",
      "Epoch 4543/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8255 - val_loss: 8.9206\n",
      "Epoch 4544/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8252 - val_loss: 8.9209\n",
      "Epoch 4545/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8249 - val_loss: 8.9212\n",
      "Epoch 4546/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8246 - val_loss: 8.9214\n",
      "Epoch 4547/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8243 - val_loss: 8.9216\n",
      "Epoch 4548/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8240 - val_loss: 8.9219\n",
      "Epoch 4549/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8237 - val_loss: 8.9222\n",
      "Epoch 4550/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8234 - val_loss: 8.9225\n",
      "Epoch 4551/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8231 - val_loss: 8.9228\n",
      "Epoch 4552/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8228 - val_loss: 8.9230\n",
      "Epoch 4553/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8225 - val_loss: 8.9232\n",
      "Epoch 4554/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8222 - val_loss: 8.9235\n",
      "Epoch 4555/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8218 - val_loss: 8.9237\n",
      "Epoch 4556/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8215 - val_loss: 8.9240\n",
      "Epoch 4557/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.8212 - val_loss: 8.9243\n",
      "Epoch 4558/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.8209 - val_loss: 8.9246\n",
      "Epoch 4559/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8206 - val_loss: 8.9249\n",
      "Epoch 4560/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8203 - val_loss: 8.9252\n",
      "Epoch 4561/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8200 - val_loss: 8.9256\n",
      "Epoch 4562/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8197 - val_loss: 8.9259\n",
      "Epoch 4563/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8194 - val_loss: 8.9262\n",
      "Epoch 4564/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8191 - val_loss: 8.9265\n",
      "Epoch 4565/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8188 - val_loss: 8.9268\n",
      "Epoch 4566/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8185 - val_loss: 8.9270\n",
      "Epoch 4567/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8182 - val_loss: 8.9273\n",
      "Epoch 4568/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8179 - val_loss: 8.9276\n",
      "Epoch 4569/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8175 - val_loss: 8.9279\n",
      "Epoch 4570/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8172 - val_loss: 8.9282\n",
      "Epoch 4571/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8169 - val_loss: 8.9284\n",
      "Epoch 4572/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8166 - val_loss: 8.9287\n",
      "Epoch 4573/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8163 - val_loss: 8.9290\n",
      "Epoch 4574/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8160 - val_loss: 8.9293\n",
      "Epoch 4575/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8157 - val_loss: 8.9296\n",
      "Epoch 4576/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8154 - val_loss: 8.9299\n",
      "Epoch 4577/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8151 - val_loss: 8.9302\n",
      "Epoch 4578/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8148 - val_loss: 8.9304\n",
      "Epoch 4579/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8145 - val_loss: 8.9307\n",
      "Epoch 4580/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8142 - val_loss: 8.9310\n",
      "Epoch 4581/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8139 - val_loss: 8.9313\n",
      "Epoch 4582/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8136 - val_loss: 8.9315\n",
      "Epoch 4583/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8133 - val_loss: 8.9318\n",
      "Epoch 4584/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8130 - val_loss: 8.9321\n",
      "Epoch 4585/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8127 - val_loss: 8.9324\n",
      "Epoch 4586/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8124 - val_loss: 8.9327\n",
      "Epoch 4587/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8120 - val_loss: 8.9331\n",
      "Epoch 4588/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8117 - val_loss: 8.9334\n",
      "Epoch 4589/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8114 - val_loss: 8.9336\n",
      "Epoch 4590/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8111 - val_loss: 8.9339\n",
      "Epoch 4591/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8108 - val_loss: 8.9343\n",
      "Epoch 4592/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8105 - val_loss: 8.9345\n",
      "Epoch 4593/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8102 - val_loss: 8.9348\n",
      "Epoch 4594/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8099 - val_loss: 8.9351\n",
      "Epoch 4595/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8096 - val_loss: 8.9354\n",
      "Epoch 4596/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8093 - val_loss: 8.9357\n",
      "Epoch 4597/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8090 - val_loss: 8.9360\n",
      "Epoch 4598/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8087 - val_loss: 8.9364\n",
      "Epoch 4599/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8084 - val_loss: 8.9367\n",
      "Epoch 4600/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8081 - val_loss: 8.9371\n",
      "Epoch 4601/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8078 - val_loss: 8.9374\n",
      "Epoch 4602/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8075 - val_loss: 8.9377\n",
      "Epoch 4603/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8072 - val_loss: 8.9381\n",
      "Epoch 4604/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8069 - val_loss: 8.9384\n",
      "Epoch 4605/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8066 - val_loss: 8.9386\n",
      "Epoch 4606/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8062 - val_loss: 8.9388\n",
      "Epoch 4607/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8059 - val_loss: 8.9390\n",
      "Epoch 4608/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8056 - val_loss: 8.9393\n",
      "Epoch 4609/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.8053 - val_loss: 8.9397\n",
      "Epoch 4610/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.8050 - val_loss: 8.9401\n",
      "Epoch 4611/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8047 - val_loss: 8.9405\n",
      "Epoch 4612/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8044 - val_loss: 8.9409\n",
      "Epoch 4613/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8041 - val_loss: 8.9412\n",
      "Epoch 4614/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8038 - val_loss: 8.9416\n",
      "Epoch 4615/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8035 - val_loss: 8.9419\n",
      "Epoch 4616/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8032 - val_loss: 8.9422\n",
      "Epoch 4617/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8029 - val_loss: 8.9425\n",
      "Epoch 4618/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8026 - val_loss: 8.9427\n",
      "Epoch 4619/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8023 - val_loss: 8.9429\n",
      "Epoch 4620/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8020 - val_loss: 8.9432\n",
      "Epoch 4621/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8017 - val_loss: 8.9435\n",
      "Epoch 4622/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8014 - val_loss: 8.9439\n",
      "Epoch 4623/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8011 - val_loss: 8.9443\n",
      "Epoch 4624/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8007 - val_loss: 8.9446\n",
      "Epoch 4625/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8004 - val_loss: 8.9450\n",
      "Epoch 4626/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8001 - val_loss: 8.9453\n",
      "Epoch 4627/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7998 - val_loss: 8.9456\n",
      "Epoch 4628/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7995 - val_loss: 8.9458\n",
      "Epoch 4629/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7992 - val_loss: 8.9461\n",
      "Epoch 4630/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7989 - val_loss: 8.9463\n",
      "Epoch 4631/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7986 - val_loss: 8.9464\n",
      "Epoch 4632/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7983 - val_loss: 8.9467\n",
      "Epoch 4633/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7980 - val_loss: 8.9470\n",
      "Epoch 4634/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7977 - val_loss: 8.9474\n",
      "Epoch 4635/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7974 - val_loss: 8.9477\n",
      "Epoch 4636/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7971 - val_loss: 8.9480\n",
      "Epoch 4637/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7968 - val_loss: 8.9483\n",
      "Epoch 4638/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7965 - val_loss: 8.9487\n",
      "Epoch 4639/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7962 - val_loss: 8.9491\n",
      "Epoch 4640/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7959 - val_loss: 8.9495\n",
      "Epoch 4641/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7956 - val_loss: 8.9498\n",
      "Epoch 4642/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7953 - val_loss: 8.9499\n",
      "Epoch 4643/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7950 - val_loss: 8.9501\n",
      "Epoch 4644/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7947 - val_loss: 8.9503\n",
      "Epoch 4645/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7943 - val_loss: 8.9507\n",
      "Epoch 4646/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7940 - val_loss: 8.9510\n",
      "Epoch 4647/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7937 - val_loss: 8.9513\n",
      "Epoch 4648/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7934 - val_loss: 8.9515\n",
      "Epoch 4649/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7931 - val_loss: 8.9518\n",
      "Epoch 4650/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7928 - val_loss: 8.9521\n",
      "Epoch 4651/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7925 - val_loss: 8.9524\n",
      "Epoch 4652/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7922 - val_loss: 8.9527\n",
      "Epoch 4653/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7919 - val_loss: 8.9531\n",
      "Epoch 4654/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7916 - val_loss: 8.9534\n",
      "Epoch 4655/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7913 - val_loss: 8.9536\n",
      "Epoch 4656/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7910 - val_loss: 8.9539\n",
      "Epoch 4657/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7907 - val_loss: 8.9543\n",
      "Epoch 4658/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7904 - val_loss: 8.9546\n",
      "Epoch 4659/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7901 - val_loss: 8.9549\n",
      "Epoch 4660/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7898 - val_loss: 8.9551\n",
      "Epoch 4661/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7895 - val_loss: 8.9554\n",
      "Epoch 4662/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7892 - val_loss: 8.9556\n",
      "Epoch 4663/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7889 - val_loss: 8.9559\n",
      "Epoch 4664/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7886 - val_loss: 8.9562\n",
      "Epoch 4665/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7883 - val_loss: 8.9565\n",
      "Epoch 4666/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7880 - val_loss: 8.9568\n",
      "Epoch 4667/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7877 - val_loss: 8.9571\n",
      "Epoch 4668/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7874 - val_loss: 8.9574\n",
      "Epoch 4669/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7870 - val_loss: 8.9577\n",
      "Epoch 4670/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7867 - val_loss: 8.9580\n",
      "Epoch 4671/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7864 - val_loss: 8.9583\n",
      "Epoch 4672/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7861 - val_loss: 8.9585\n",
      "Epoch 4673/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7858 - val_loss: 8.9589\n",
      "Epoch 4674/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7855 - val_loss: 8.9592\n",
      "Epoch 4675/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7852 - val_loss: 8.9594\n",
      "Epoch 4676/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7849 - val_loss: 8.9597\n",
      "Epoch 4677/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7846 - val_loss: 8.9599\n",
      "Epoch 4678/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7843 - val_loss: 8.9602\n",
      "Epoch 4679/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.7840 - val_loss: 8.9606\n",
      "Epoch 4680/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.7837 - val_loss: 8.9609\n",
      "Epoch 4681/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7834 - val_loss: 8.9612\n",
      "Epoch 4682/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7831 - val_loss: 8.9615\n",
      "Epoch 4683/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7828 - val_loss: 8.9619\n",
      "Epoch 4684/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7825 - val_loss: 8.9622\n",
      "Epoch 4685/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7822 - val_loss: 8.9625\n",
      "Epoch 4686/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7819 - val_loss: 8.9627\n",
      "Epoch 4687/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7816 - val_loss: 8.9629\n",
      "Epoch 4688/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7813 - val_loss: 8.9631\n",
      "Epoch 4689/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7810 - val_loss: 8.9634\n",
      "Epoch 4690/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7807 - val_loss: 8.9637\n",
      "Epoch 4691/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7804 - val_loss: 8.9640\n",
      "Epoch 4692/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7801 - val_loss: 8.9644\n",
      "Epoch 4693/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7798 - val_loss: 8.9647\n",
      "Epoch 4694/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7795 - val_loss: 8.9650\n",
      "Epoch 4695/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7792 - val_loss: 8.9654\n",
      "Epoch 4696/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7789 - val_loss: 8.9658\n",
      "Epoch 4697/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7785 - val_loss: 8.9661\n",
      "Epoch 4698/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7782 - val_loss: 8.9663\n",
      "Epoch 4699/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7779 - val_loss: 8.9665\n",
      "Epoch 4700/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7776 - val_loss: 8.9667\n",
      "Epoch 4701/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7773 - val_loss: 8.9670\n",
      "Epoch 4702/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7770 - val_loss: 8.9674\n",
      "Epoch 4703/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.7767 - val_loss: 8.9677\n",
      "Epoch 4704/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7764 - val_loss: 8.9680\n",
      "Epoch 4705/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.7761 - val_loss: 8.9683\n",
      "Epoch 4706/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7758 - val_loss: 8.9687\n",
      "Epoch 4707/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7755 - val_loss: 8.9691\n",
      "Epoch 4708/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7752 - val_loss: 8.9694\n",
      "Epoch 4709/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7749 - val_loss: 8.9698\n",
      "Epoch 4710/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7746 - val_loss: 8.9700\n",
      "Epoch 4711/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7743 - val_loss: 8.9703\n",
      "Epoch 4712/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7740 - val_loss: 8.9705\n",
      "Epoch 4713/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7737 - val_loss: 8.9707\n",
      "Epoch 4714/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7734 - val_loss: 8.9710\n",
      "Epoch 4715/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7731 - val_loss: 8.9713\n",
      "Epoch 4716/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7728 - val_loss: 8.9717\n",
      "Epoch 4717/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7725 - val_loss: 8.9720\n",
      "Epoch 4718/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7722 - val_loss: 8.9724\n",
      "Epoch 4719/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7719 - val_loss: 8.9727\n",
      "Epoch 4720/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.7716 - val_loss: 8.9731\n",
      "Epoch 4721/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7713 - val_loss: 8.9735\n",
      "Epoch 4722/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7710 - val_loss: 8.9738\n",
      "Epoch 4723/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7707 - val_loss: 8.9740\n",
      "Epoch 4724/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7704 - val_loss: 8.9742\n",
      "Epoch 4725/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7701 - val_loss: 8.9744\n",
      "Epoch 4726/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7698 - val_loss: 8.9747\n",
      "Epoch 4727/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7695 - val_loss: 8.9751\n",
      "Epoch 4728/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7692 - val_loss: 8.9754\n",
      "Epoch 4729/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7689 - val_loss: 8.9757\n",
      "Epoch 4730/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7686 - val_loss: 8.9760\n",
      "Epoch 4731/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7682 - val_loss: 8.9764\n",
      "Epoch 4732/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7679 - val_loss: 8.9767\n",
      "Epoch 4733/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7676 - val_loss: 8.9769\n",
      "Epoch 4734/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7673 - val_loss: 8.9772\n",
      "Epoch 4735/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7670 - val_loss: 8.9775\n",
      "Epoch 4736/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7667 - val_loss: 8.9778\n",
      "Epoch 4737/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7664 - val_loss: 8.9781\n",
      "Epoch 4738/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7661 - val_loss: 8.9784\n",
      "Epoch 4739/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7658 - val_loss: 8.9787\n",
      "Epoch 4740/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7655 - val_loss: 8.9791\n",
      "Epoch 4741/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7652 - val_loss: 8.9794\n",
      "Epoch 4742/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7649 - val_loss: 8.9797\n",
      "Epoch 4743/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7646 - val_loss: 8.9800\n",
      "Epoch 4744/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7643 - val_loss: 8.9803\n",
      "Epoch 4745/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7640 - val_loss: 8.9806\n",
      "Epoch 4746/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7637 - val_loss: 8.9809\n",
      "Epoch 4747/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7634 - val_loss: 8.9811\n",
      "Epoch 4748/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7631 - val_loss: 8.9814\n",
      "Epoch 4749/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7628 - val_loss: 8.9817\n",
      "Epoch 4750/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7625 - val_loss: 8.9820\n",
      "Epoch 4751/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7622 - val_loss: 8.9823\n",
      "Epoch 4752/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.7619 - val_loss: 8.9826\n",
      "Epoch 4753/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7616 - val_loss: 8.9829\n",
      "Epoch 4754/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7613 - val_loss: 8.9833\n",
      "Epoch 4755/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7610 - val_loss: 8.9835\n",
      "Epoch 4756/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7607 - val_loss: 8.9838\n",
      "Epoch 4757/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7604 - val_loss: 8.9840\n",
      "Epoch 4758/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7601 - val_loss: 8.9842\n",
      "Epoch 4759/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7598 - val_loss: 8.9845\n",
      "Epoch 4760/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7595 - val_loss: 8.9848\n",
      "Epoch 4761/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7592 - val_loss: 8.9852\n",
      "Epoch 4762/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7589 - val_loss: 8.9855\n",
      "Epoch 4763/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7586 - val_loss: 8.9858\n",
      "Epoch 4764/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7583 - val_loss: 8.9861\n",
      "Epoch 4765/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7580 - val_loss: 8.9865\n",
      "Epoch 4766/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.7577 - val_loss: 8.9870\n",
      "Epoch 4767/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7574 - val_loss: 8.9873\n",
      "Epoch 4768/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7571 - val_loss: 8.9876\n",
      "Epoch 4769/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7568 - val_loss: 8.9878\n",
      "Epoch 4770/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7565 - val_loss: 8.9881\n",
      "Epoch 4771/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7562 - val_loss: 8.9883\n",
      "Epoch 4772/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.7559 - val_loss: 8.9886\n",
      "Epoch 4773/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7555 - val_loss: 8.9889\n",
      "Epoch 4774/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.7552 - val_loss: 8.9891\n",
      "Epoch 4775/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7549 - val_loss: 8.9894\n",
      "Epoch 4776/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7546 - val_loss: 8.9897\n",
      "Epoch 4777/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.7543 - val_loss: 8.9900\n",
      "Epoch 4778/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7540 - val_loss: 8.9904\n",
      "Epoch 4779/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.7537 - val_loss: 8.9908\n",
      "Epoch 4780/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.7534 - val_loss: 8.9911\n",
      "Epoch 4781/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7531 - val_loss: 8.9914\n",
      "Epoch 4782/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7528 - val_loss: 8.9917\n",
      "Epoch 4783/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7525 - val_loss: 8.9921\n",
      "Epoch 4784/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7522 - val_loss: 8.9923\n",
      "Epoch 4785/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7519 - val_loss: 8.9926\n",
      "Epoch 4786/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7516 - val_loss: 8.9929\n",
      "Epoch 4787/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7513 - val_loss: 8.9931\n",
      "Epoch 4788/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7510 - val_loss: 8.9934\n",
      "Epoch 4789/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7507 - val_loss: 8.9938\n",
      "Epoch 4790/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7504 - val_loss: 8.9940\n",
      "Epoch 4791/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7501 - val_loss: 8.9943\n",
      "Epoch 4792/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7498 - val_loss: 8.9946\n",
      "Epoch 4793/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7495 - val_loss: 8.9950\n",
      "Epoch 4794/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7492 - val_loss: 8.9953\n",
      "Epoch 4795/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7489 - val_loss: 8.9957\n",
      "Epoch 4796/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7486 - val_loss: 8.9960\n",
      "Epoch 4797/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7483 - val_loss: 8.9964\n",
      "Epoch 4798/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7480 - val_loss: 8.9967\n",
      "Epoch 4799/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7477 - val_loss: 8.9969\n",
      "Epoch 4800/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7474 - val_loss: 8.9973\n",
      "Epoch 4801/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7471 - val_loss: 8.9975\n",
      "Epoch 4802/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7468 - val_loss: 8.9977\n",
      "Epoch 4803/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7465 - val_loss: 8.9980\n",
      "Epoch 4804/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7462 - val_loss: 8.9983\n",
      "Epoch 4805/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7459 - val_loss: 8.9986\n",
      "Epoch 4806/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7456 - val_loss: 8.9989\n",
      "Epoch 4807/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7453 - val_loss: 8.9993\n",
      "Epoch 4808/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7450 - val_loss: 8.9996\n",
      "Epoch 4809/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7447 - val_loss: 9.0000\n",
      "Epoch 4810/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7444 - val_loss: 9.0003\n",
      "Epoch 4811/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.7441 - val_loss: 9.0006\n",
      "Epoch 4812/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7438 - val_loss: 9.0009\n",
      "Epoch 4813/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.7435 - val_loss: 9.0010\n",
      "Epoch 4814/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.7432 - val_loss: 9.0012\n",
      "Epoch 4815/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.7429 - val_loss: 9.0014\n",
      "Epoch 4816/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7426 - val_loss: 9.0016\n",
      "Epoch 4817/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7423 - val_loss: 9.0019\n",
      "Epoch 4818/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7420 - val_loss: 9.0022\n",
      "Epoch 4819/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7417 - val_loss: 9.0026\n",
      "Epoch 4820/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7414 - val_loss: 9.0029\n",
      "Epoch 4821/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7411 - val_loss: 9.0033\n",
      "Epoch 4822/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.7408 - val_loss: 9.0036\n",
      "Epoch 4823/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7405 - val_loss: 9.0038\n",
      "Epoch 4824/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7402 - val_loss: 9.0040\n",
      "Epoch 4825/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7399 - val_loss: 9.0042\n",
      "Epoch 4826/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7396 - val_loss: 9.0044\n",
      "Epoch 4827/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7393 - val_loss: 9.0046\n",
      "Epoch 4828/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7390 - val_loss: 9.0047\n",
      "Epoch 4829/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7387 - val_loss: 9.0049\n",
      "Epoch 4830/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7384 - val_loss: 9.0052\n",
      "Epoch 4831/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7381 - val_loss: 9.0056\n",
      "Epoch 4832/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7378 - val_loss: 9.0059\n",
      "Epoch 4833/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7375 - val_loss: 9.0062\n",
      "Epoch 4834/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.7372 - val_loss: 9.0064\n",
      "Epoch 4835/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7369 - val_loss: 9.0067\n",
      "Epoch 4836/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7366 - val_loss: 9.0070\n",
      "Epoch 4837/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7363 - val_loss: 9.0073\n",
      "Epoch 4838/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7360 - val_loss: 9.0076\n",
      "Epoch 4839/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7357 - val_loss: 9.0078\n",
      "Epoch 4840/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7354 - val_loss: 9.0080\n",
      "Epoch 4841/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7351 - val_loss: 9.0082\n",
      "Epoch 4842/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7348 - val_loss: 9.0084\n",
      "Epoch 4843/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7345 - val_loss: 9.0087\n",
      "Epoch 4844/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7342 - val_loss: 9.0090\n",
      "Epoch 4845/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7339 - val_loss: 9.0093\n",
      "Epoch 4846/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7336 - val_loss: 9.0095\n",
      "Epoch 4847/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7333 - val_loss: 9.0098\n",
      "Epoch 4848/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7330 - val_loss: 9.0100\n",
      "Epoch 4849/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7327 - val_loss: 9.0103\n",
      "Epoch 4850/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7324 - val_loss: 9.0105\n",
      "Epoch 4851/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7321 - val_loss: 9.0108\n",
      "Epoch 4852/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7318 - val_loss: 9.0110\n",
      "Epoch 4853/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7315 - val_loss: 9.0113\n",
      "Epoch 4854/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7312 - val_loss: 9.0116\n",
      "Epoch 4855/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7309 - val_loss: 9.0119\n",
      "Epoch 4856/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7306 - val_loss: 9.0122\n",
      "Epoch 4857/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7303 - val_loss: 9.0125\n",
      "Epoch 4858/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7300 - val_loss: 9.0128\n",
      "Epoch 4859/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7297 - val_loss: 9.0130\n",
      "Epoch 4860/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7294 - val_loss: 9.0131\n",
      "Epoch 4861/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7291 - val_loss: 9.0133\n",
      "Epoch 4862/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7288 - val_loss: 9.0135\n",
      "Epoch 4863/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.7285 - val_loss: 9.0138\n",
      "Epoch 4864/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7282 - val_loss: 9.0140\n",
      "Epoch 4865/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7279 - val_loss: 9.0142\n",
      "Epoch 4866/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7276 - val_loss: 9.0144\n",
      "Epoch 4867/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7273 - val_loss: 9.0147\n",
      "Epoch 4868/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7270 - val_loss: 9.0151\n",
      "Epoch 4869/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7267 - val_loss: 9.0154\n",
      "Epoch 4870/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7263 - val_loss: 9.0157\n",
      "Epoch 4871/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7261 - val_loss: 9.0159\n",
      "Epoch 4872/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7257 - val_loss: 9.0161\n",
      "Epoch 4873/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7255 - val_loss: 9.0164\n",
      "Epoch 4874/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7252 - val_loss: 9.0167\n",
      "Epoch 4875/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7249 - val_loss: 9.0169\n",
      "Epoch 4876/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7246 - val_loss: 9.0172\n",
      "Epoch 4877/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7243 - val_loss: 9.0174\n",
      "Epoch 4878/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7240 - val_loss: 9.0176\n",
      "Epoch 4879/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7237 - val_loss: 9.0178\n",
      "Epoch 4880/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7233 - val_loss: 9.0179\n",
      "Epoch 4881/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7230 - val_loss: 9.0181\n",
      "Epoch 4882/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7227 - val_loss: 9.0184\n",
      "Epoch 4883/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7225 - val_loss: 9.0187\n",
      "Epoch 4884/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7221 - val_loss: 9.0190\n",
      "Epoch 4885/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7219 - val_loss: 9.0193\n",
      "Epoch 4886/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7216 - val_loss: 9.0196\n",
      "Epoch 4887/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7213 - val_loss: 9.0199\n",
      "Epoch 4888/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7210 - val_loss: 9.0202\n",
      "Epoch 4889/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7207 - val_loss: 9.0205\n",
      "Epoch 4890/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7204 - val_loss: 9.0206\n",
      "Epoch 4891/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7201 - val_loss: 9.0208\n",
      "Epoch 4892/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7198 - val_loss: 9.0210\n",
      "Epoch 4893/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7195 - val_loss: 9.0212\n",
      "Epoch 4894/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7192 - val_loss: 9.0214\n",
      "Epoch 4895/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7189 - val_loss: 9.0217\n",
      "Epoch 4896/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7186 - val_loss: 9.0219\n",
      "Epoch 4897/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7183 - val_loss: 9.0222\n",
      "Epoch 4898/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7180 - val_loss: 9.0225\n",
      "Epoch 4899/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7177 - val_loss: 9.0228\n",
      "Epoch 4900/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7174 - val_loss: 9.0230\n",
      "Epoch 4901/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7171 - val_loss: 9.0232\n",
      "Epoch 4902/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7168 - val_loss: 9.0234\n",
      "Epoch 4903/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7165 - val_loss: 9.0236\n",
      "Epoch 4904/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7162 - val_loss: 9.0239\n",
      "Epoch 4905/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7159 - val_loss: 9.0241\n",
      "Epoch 4906/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7156 - val_loss: 9.0243\n",
      "Epoch 4907/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7153 - val_loss: 9.0245\n",
      "Epoch 4908/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7150 - val_loss: 9.0247\n",
      "Epoch 4909/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7147 - val_loss: 9.0250\n",
      "Epoch 4910/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7144 - val_loss: 9.0252\n",
      "Epoch 4911/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7141 - val_loss: 9.0254\n",
      "Epoch 4912/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7138 - val_loss: 9.0256\n",
      "Epoch 4913/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7135 - val_loss: 9.0259\n",
      "Epoch 4914/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.7132 - val_loss: 9.0262\n",
      "Epoch 4915/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.7129 - val_loss: 9.0265\n",
      "Epoch 4916/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.7126 - val_loss: 9.0268\n",
      "Epoch 4917/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7123 - val_loss: 9.0270\n",
      "Epoch 4918/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7120 - val_loss: 9.0272\n",
      "Epoch 4919/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7117 - val_loss: 9.0274\n",
      "Epoch 4920/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7114 - val_loss: 9.0276\n",
      "Epoch 4921/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.7111 - val_loss: 9.0279\n",
      "Epoch 4922/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7108 - val_loss: 9.0281\n",
      "Epoch 4923/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7105 - val_loss: 9.0283\n",
      "Epoch 4924/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7102 - val_loss: 9.0285\n",
      "Epoch 4925/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7099 - val_loss: 9.0287\n",
      "Epoch 4926/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7096 - val_loss: 9.0288\n",
      "Epoch 4927/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.7093 - val_loss: 9.0290\n",
      "Epoch 4928/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7090 - val_loss: 9.0293\n",
      "Epoch 4929/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7087 - val_loss: 9.0297\n",
      "Epoch 4930/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7084 - val_loss: 9.0301\n",
      "Epoch 4931/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7081 - val_loss: 9.0304\n",
      "Epoch 4932/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7078 - val_loss: 9.0307\n",
      "Epoch 4933/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7075 - val_loss: 9.0309\n",
      "Epoch 4934/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7072 - val_loss: 9.0311\n",
      "Epoch 4935/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7069 - val_loss: 9.0313\n",
      "Epoch 4936/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7066 - val_loss: 9.0315\n",
      "Epoch 4937/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7063 - val_loss: 9.0317\n",
      "Epoch 4938/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7060 - val_loss: 9.0320\n",
      "Epoch 4939/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7057 - val_loss: 9.0322\n",
      "Epoch 4940/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7054 - val_loss: 9.0325\n",
      "Epoch 4941/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.7051 - val_loss: 9.0327\n",
      "Epoch 4942/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7048 - val_loss: 9.0329\n",
      "Epoch 4943/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7045 - val_loss: 9.0332\n",
      "Epoch 4944/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7042 - val_loss: 9.0334\n",
      "Epoch 4945/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7039 - val_loss: 9.0337\n",
      "Epoch 4946/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7036 - val_loss: 9.0340\n",
      "Epoch 4947/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7033 - val_loss: 9.0343\n",
      "Epoch 4948/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7030 - val_loss: 9.0345\n",
      "Epoch 4949/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7027 - val_loss: 9.0347\n",
      "Epoch 4950/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7024 - val_loss: 9.0350\n",
      "Epoch 4951/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7021 - val_loss: 9.0352\n",
      "Epoch 4952/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7018 - val_loss: 9.0354\n",
      "Epoch 4953/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7015 - val_loss: 9.0356\n",
      "Epoch 4954/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7012 - val_loss: 9.0359\n",
      "Epoch 4955/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7009 - val_loss: 9.0362\n",
      "Epoch 4956/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7006 - val_loss: 9.0364\n",
      "Epoch 4957/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7003 - val_loss: 9.0367\n",
      "Epoch 4958/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7000 - val_loss: 9.0371\n",
      "Epoch 4959/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6997 - val_loss: 9.0373\n",
      "Epoch 4960/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6994 - val_loss: 9.0376\n",
      "Epoch 4961/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6991 - val_loss: 9.0378\n",
      "Epoch 4962/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6988 - val_loss: 9.0381\n",
      "Epoch 4963/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6985 - val_loss: 9.0383\n",
      "Epoch 4964/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.6982 - val_loss: 9.0385\n",
      "Epoch 4965/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.6979 - val_loss: 9.0388\n",
      "Epoch 4966/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6976 - val_loss: 9.0390\n",
      "Epoch 4967/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6973 - val_loss: 9.0393\n",
      "Epoch 4968/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6970 - val_loss: 9.0396\n",
      "Epoch 4969/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6967 - val_loss: 9.0399\n",
      "Epoch 4970/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6964 - val_loss: 9.0402\n",
      "Epoch 4971/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6961 - val_loss: 9.0405\n",
      "Epoch 4972/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6958 - val_loss: 9.0407\n",
      "Epoch 4973/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6955 - val_loss: 9.0409\n",
      "Epoch 4974/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6952 - val_loss: 9.0411\n",
      "Epoch 4975/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6949 - val_loss: 9.0413\n",
      "Epoch 4976/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6946 - val_loss: 9.0415\n",
      "Epoch 4977/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6943 - val_loss: 9.0418\n",
      "Epoch 4978/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6940 - val_loss: 9.0421\n",
      "Epoch 4979/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6937 - val_loss: 9.0424\n",
      "Epoch 4980/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.6934 - val_loss: 9.0427\n",
      "Epoch 4981/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6931 - val_loss: 9.0430\n",
      "Epoch 4982/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6928 - val_loss: 9.0434\n",
      "Epoch 4983/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6925 - val_loss: 9.0437\n",
      "Epoch 4984/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6922 - val_loss: 9.0439\n",
      "Epoch 4985/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6919 - val_loss: 9.0441\n",
      "Epoch 4986/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6916 - val_loss: 9.0444\n",
      "Epoch 4987/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6913 - val_loss: 9.0446\n",
      "Epoch 4988/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6910 - val_loss: 9.0448\n",
      "Epoch 4989/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6907 - val_loss: 9.0450\n",
      "Epoch 4990/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6904 - val_loss: 9.0453\n",
      "Epoch 4991/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6901 - val_loss: 9.0455\n",
      "Epoch 4992/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6898 - val_loss: 9.0458\n",
      "Epoch 4993/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6895 - val_loss: 9.0461\n",
      "Epoch 4994/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6892 - val_loss: 9.0463\n",
      "Epoch 4995/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6889 - val_loss: 9.0466\n",
      "Epoch 4996/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6886 - val_loss: 9.0469\n",
      "Epoch 4997/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6883 - val_loss: 9.0472\n",
      "Epoch 4998/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6880 - val_loss: 9.0475\n",
      "Epoch 4999/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6877 - val_loss: 9.0478\n",
      "Epoch 5000/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6874 - val_loss: 9.0480\n",
      "Epoch 5001/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6871 - val_loss: 9.0482\n",
      "Epoch 5002/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6868 - val_loss: 9.0485\n",
      "Epoch 5003/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6865 - val_loss: 9.0488\n",
      "Epoch 5004/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6862 - val_loss: 9.0492\n",
      "Epoch 5005/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6859 - val_loss: 9.0495\n",
      "Epoch 5006/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6856 - val_loss: 9.0497\n",
      "Epoch 5007/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6853 - val_loss: 9.0500\n",
      "Epoch 5008/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6850 - val_loss: 9.0502\n",
      "Epoch 5009/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.684 - 0s 33ms/step - loss: 4.6847 - val_loss: 9.0504\n",
      "Epoch 5010/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6844 - val_loss: 9.0506\n",
      "Epoch 5011/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6841 - val_loss: 9.0508\n",
      "Epoch 5012/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6838 - val_loss: 9.0510\n",
      "Epoch 5013/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6835 - val_loss: 9.0513\n",
      "Epoch 5014/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6832 - val_loss: 9.0516\n",
      "Epoch 5015/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6829 - val_loss: 9.0520\n",
      "Epoch 5016/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6826 - val_loss: 9.0523\n",
      "Epoch 5017/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6823 - val_loss: 9.0526\n",
      "Epoch 5018/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.6820 - val_loss: 9.0528\n",
      "Epoch 5019/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6817 - val_loss: 9.0531\n",
      "Epoch 5020/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6814 - val_loss: 9.0534\n",
      "Epoch 5021/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6811 - val_loss: 9.0537\n",
      "Epoch 5022/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6808 - val_loss: 9.0540\n",
      "Epoch 5023/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6805 - val_loss: 9.0542\n",
      "Epoch 5024/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6802 - val_loss: 9.0544\n",
      "Epoch 5025/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6799 - val_loss: 9.0547\n",
      "Epoch 5026/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6796 - val_loss: 9.0550\n",
      "Epoch 5027/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6793 - val_loss: 9.0554\n",
      "Epoch 5028/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6790 - val_loss: 9.0556\n",
      "Epoch 5029/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6787 - val_loss: 9.0558\n",
      "Epoch 5030/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6784 - val_loss: 9.0560\n",
      "Epoch 5031/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6781 - val_loss: 9.0563\n",
      "Epoch 5032/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6778 - val_loss: 9.0567\n",
      "Epoch 5033/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6775 - val_loss: 9.0569\n",
      "Epoch 5034/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6772 - val_loss: 9.0572\n",
      "Epoch 5035/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6769 - val_loss: 9.0574\n",
      "Epoch 5036/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6766 - val_loss: 9.0577\n",
      "Epoch 5037/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6763 - val_loss: 9.0580\n",
      "Epoch 5038/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.6760 - val_loss: 9.0583\n",
      "Epoch 5039/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.6757 - val_loss: 9.0584\n",
      "Epoch 5040/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.6754 - val_loss: 9.0586\n",
      "Epoch 5041/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.6751 - val_loss: 9.0588\n",
      "Epoch 5042/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6748 - val_loss: 9.0591\n",
      "Epoch 5043/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6745 - val_loss: 9.0595\n",
      "Epoch 5044/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6742 - val_loss: 9.0599\n",
      "Epoch 5045/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6739 - val_loss: 9.0602\n",
      "Epoch 5046/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6736 - val_loss: 9.0605\n",
      "Epoch 5047/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6733 - val_loss: 9.0608\n",
      "Epoch 5048/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6730 - val_loss: 9.0610\n",
      "Epoch 5049/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6727 - val_loss: 9.0611\n",
      "Epoch 5050/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6724 - val_loss: 9.0613\n",
      "Epoch 5051/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6721 - val_loss: 9.0616\n",
      "Epoch 5052/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6718 - val_loss: 9.0619\n",
      "Epoch 5053/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6715 - val_loss: 9.0622\n",
      "Epoch 5054/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6712 - val_loss: 9.0625\n",
      "Epoch 5055/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6709 - val_loss: 9.0628\n",
      "Epoch 5056/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6706 - val_loss: 9.0631\n",
      "Epoch 5057/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6703 - val_loss: 9.0633\n",
      "Epoch 5058/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6700 - val_loss: 9.0636\n",
      "Epoch 5059/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.6697 - val_loss: 9.0638\n",
      "Epoch 5060/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.6694 - val_loss: 9.0641\n",
      "Epoch 5061/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6691 - val_loss: 9.0644\n",
      "Epoch 5062/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.6688 - val_loss: 9.0647\n",
      "Epoch 5063/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.6685 - val_loss: 9.0649\n",
      "Epoch 5064/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6682 - val_loss: 9.0651\n",
      "Epoch 5065/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.6679 - val_loss: 9.0654\n",
      "Epoch 5066/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6676 - val_loss: 9.0657\n",
      "Epoch 5067/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.6673 - val_loss: 9.0660\n",
      "Epoch 5068/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.6670 - val_loss: 9.0663\n",
      "Epoch 5069/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.6667 - val_loss: 9.0665\n",
      "Epoch 5070/10000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6664 - val_loss: 9.0667\n",
      "Epoch 5071/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.6661 - val_loss: 9.0669\n",
      "Epoch 5072/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.6658 - val_loss: 9.0671\n",
      "Epoch 5073/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6655 - val_loss: 9.0674\n",
      "Epoch 5074/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6652 - val_loss: 9.0676\n",
      "Epoch 5075/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6649 - val_loss: 9.0679\n",
      "Epoch 5076/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6646 - val_loss: 9.0683\n",
      "Epoch 5077/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6644 - val_loss: 9.0686\n",
      "Epoch 5078/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6641 - val_loss: 9.0690\n",
      "Epoch 5079/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6638 - val_loss: 9.0692\n",
      "Epoch 5080/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.6635 - val_loss: 9.0695\n",
      "Epoch 5081/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6632 - val_loss: 9.0698\n",
      "Epoch 5082/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6629 - val_loss: 9.0700\n",
      "Epoch 5083/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6626 - val_loss: 9.0702\n",
      "Epoch 5084/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6623 - val_loss: 9.0704\n",
      "Epoch 5085/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6620 - val_loss: 9.0707\n",
      "Epoch 5086/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6617 - val_loss: 9.0710\n",
      "Epoch 5087/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6614 - val_loss: 9.0713\n",
      "Epoch 5088/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6611 - val_loss: 9.0716\n",
      "Epoch 5089/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6608 - val_loss: 9.0718\n",
      "Epoch 5090/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6605 - val_loss: 9.0721\n",
      "Epoch 5091/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6602 - val_loss: 9.0724\n",
      "Epoch 5092/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6599 - val_loss: 9.0727\n",
      "Epoch 5093/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6596 - val_loss: 9.0729\n",
      "Epoch 5094/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6593 - val_loss: 9.0731\n",
      "Epoch 5095/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6590 - val_loss: 9.0733\n",
      "Epoch 5096/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6587 - val_loss: 9.0736\n",
      "Epoch 5097/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6584 - val_loss: 9.0739\n",
      "Epoch 5098/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6581 - val_loss: 9.0742\n",
      "Epoch 5099/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6578 - val_loss: 9.0744\n",
      "Epoch 5100/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6575 - val_loss: 9.0748\n",
      "Epoch 5101/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6572 - val_loss: 9.0751\n",
      "Epoch 5102/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6569 - val_loss: 9.0754\n",
      "Epoch 5103/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.656 - 0s 37ms/step - loss: 4.6566 - val_loss: 9.0756\n",
      "Epoch 5104/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6563 - val_loss: 9.0759\n",
      "Epoch 5105/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6560 - val_loss: 9.0761\n",
      "Epoch 5106/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6557 - val_loss: 9.0764\n",
      "Epoch 5107/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6554 - val_loss: 9.0766\n",
      "Epoch 5108/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6551 - val_loss: 9.0769\n",
      "Epoch 5109/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6548 - val_loss: 9.0772\n",
      "Epoch 5110/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6545 - val_loss: 9.0775\n",
      "Epoch 5111/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6542 - val_loss: 9.0778\n",
      "Epoch 5112/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6539 - val_loss: 9.0781\n",
      "Epoch 5113/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6536 - val_loss: 9.0783\n",
      "Epoch 5114/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.6533 - val_loss: 9.0785\n",
      "Epoch 5115/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6530 - val_loss: 9.0787\n",
      "Epoch 5116/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6527 - val_loss: 9.0790\n",
      "Epoch 5117/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6524 - val_loss: 9.0793\n",
      "Epoch 5118/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6521 - val_loss: 9.0795\n",
      "Epoch 5119/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6518 - val_loss: 9.0798\n",
      "Epoch 5120/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.6515 - val_loss: 9.0800\n",
      "Epoch 5121/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6512 - val_loss: 9.0803\n",
      "Epoch 5122/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6509 - val_loss: 9.0805\n",
      "Epoch 5123/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6506 - val_loss: 9.0807\n",
      "Epoch 5124/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6503 - val_loss: 9.0810\n",
      "Epoch 5125/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6500 - val_loss: 9.0812\n",
      "Epoch 5126/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6497 - val_loss: 9.0815\n",
      "Epoch 5127/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6494 - val_loss: 9.0817\n",
      "Epoch 5128/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6491 - val_loss: 9.0819\n",
      "Epoch 5129/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6488 - val_loss: 9.0820\n",
      "Epoch 5130/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6485 - val_loss: 9.0822\n",
      "Epoch 5131/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6482 - val_loss: 9.0824\n",
      "Epoch 5132/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6479 - val_loss: 9.0826\n",
      "Epoch 5133/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6476 - val_loss: 9.0829\n",
      "Epoch 5134/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6473 - val_loss: 9.0831\n",
      "Epoch 5135/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6470 - val_loss: 9.0834\n",
      "Epoch 5136/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6467 - val_loss: 9.0836\n",
      "Epoch 5137/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6464 - val_loss: 9.0838\n",
      "Epoch 5138/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6461 - val_loss: 9.0839\n",
      "Epoch 5139/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6458 - val_loss: 9.0841\n",
      "Epoch 5140/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6455 - val_loss: 9.0843\n",
      "Epoch 5141/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6452 - val_loss: 9.0846\n",
      "Epoch 5142/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6449 - val_loss: 9.0848\n",
      "Epoch 5143/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6446 - val_loss: 9.0849\n",
      "Epoch 5144/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6443 - val_loss: 9.0851\n",
      "Epoch 5145/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6439 - val_loss: 9.0854\n",
      "Epoch 5146/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6436 - val_loss: 9.0856\n",
      "Epoch 5147/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6433 - val_loss: 9.0859\n",
      "Epoch 5148/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6430 - val_loss: 9.0861\n",
      "Epoch 5149/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6427 - val_loss: 9.0863\n",
      "Epoch 5150/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6424 - val_loss: 9.0865\n",
      "Epoch 5151/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6421 - val_loss: 9.0867\n",
      "Epoch 5152/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6418 - val_loss: 9.0869\n",
      "Epoch 5153/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.6415 - val_loss: 9.0871\n",
      "Epoch 5154/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6412 - val_loss: 9.0873\n",
      "Epoch 5155/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6409 - val_loss: 9.0875\n",
      "Epoch 5156/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6406 - val_loss: 9.0877\n",
      "Epoch 5157/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6403 - val_loss: 9.0879\n",
      "Epoch 5158/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6400 - val_loss: 9.0881\n",
      "Epoch 5159/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6397 - val_loss: 9.0883\n",
      "Epoch 5160/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6394 - val_loss: 9.0886\n",
      "Epoch 5161/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6391 - val_loss: 9.0889\n",
      "Epoch 5162/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6388 - val_loss: 9.0891\n",
      "Epoch 5163/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6385 - val_loss: 9.0894\n",
      "Epoch 5164/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6382 - val_loss: 9.0896\n",
      "Epoch 5165/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6379 - val_loss: 9.0898\n",
      "Epoch 5166/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6376 - val_loss: 9.0900\n",
      "Epoch 5167/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6373 - val_loss: 9.0902\n",
      "Epoch 5168/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6370 - val_loss: 9.0904\n",
      "Epoch 5169/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6367 - val_loss: 9.0906\n",
      "Epoch 5170/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6364 - val_loss: 9.0908\n",
      "Epoch 5171/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6361 - val_loss: 9.0911\n",
      "Epoch 5172/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6358 - val_loss: 9.0914\n",
      "Epoch 5173/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6355 - val_loss: 9.0915\n",
      "Epoch 5174/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6352 - val_loss: 9.0917\n",
      "Epoch 5175/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6349 - val_loss: 9.0920\n",
      "Epoch 5176/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6346 - val_loss: 9.0922\n",
      "Epoch 5177/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6343 - val_loss: 9.0925\n",
      "Epoch 5178/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6340 - val_loss: 9.0927\n",
      "Epoch 5179/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.6337 - val_loss: 9.0929\n",
      "Epoch 5180/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6334 - val_loss: 9.0931\n",
      "Epoch 5181/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6331 - val_loss: 9.0933\n",
      "Epoch 5182/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6328 - val_loss: 9.0935\n",
      "Epoch 5183/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6325 - val_loss: 9.0936\n",
      "Epoch 5184/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6322 - val_loss: 9.0938\n",
      "Epoch 5185/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6319 - val_loss: 9.0940\n",
      "Epoch 5186/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6316 - val_loss: 9.0943\n",
      "Epoch 5187/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6313 - val_loss: 9.0946\n",
      "Epoch 5188/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6310 - val_loss: 9.0949\n",
      "Epoch 5189/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6307 - val_loss: 9.0951\n",
      "Epoch 5190/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6304 - val_loss: 9.0953\n",
      "Epoch 5191/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6301 - val_loss: 9.0955\n",
      "Epoch 5192/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6298 - val_loss: 9.0958\n",
      "Epoch 5193/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6295 - val_loss: 9.0960\n",
      "Epoch 5194/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6292 - val_loss: 9.0961\n",
      "Epoch 5195/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6289 - val_loss: 9.0964\n",
      "Epoch 5196/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6286 - val_loss: 9.0965\n",
      "Epoch 5197/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6283 - val_loss: 9.0968\n",
      "Epoch 5198/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6280 - val_loss: 9.0971\n",
      "Epoch 5199/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6277 - val_loss: 9.0974\n",
      "Epoch 5200/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6274 - val_loss: 9.0976\n",
      "Epoch 5201/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6271 - val_loss: 9.0979\n",
      "Epoch 5202/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6268 - val_loss: 9.0982\n",
      "Epoch 5203/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6265 - val_loss: 9.0984\n",
      "Epoch 5204/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6262 - val_loss: 9.0985\n",
      "Epoch 5205/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6259 - val_loss: 9.0986\n",
      "Epoch 5206/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6256 - val_loss: 9.0989\n",
      "Epoch 5207/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6253 - val_loss: 9.0990\n",
      "Epoch 5208/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6250 - val_loss: 9.0992\n",
      "Epoch 5209/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6247 - val_loss: 9.0994\n",
      "Epoch 5210/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6244 - val_loss: 9.0997\n",
      "Epoch 5211/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6241 - val_loss: 9.1000\n",
      "Epoch 5212/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6238 - val_loss: 9.1002\n",
      "Epoch 5213/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6235 - val_loss: 9.1005\n",
      "Epoch 5214/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6232 - val_loss: 9.1006\n",
      "Epoch 5215/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6229 - val_loss: 9.1008\n",
      "Epoch 5216/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6226 - val_loss: 9.1010\n",
      "Epoch 5217/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6223 - val_loss: 9.1012\n",
      "Epoch 5218/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.6220 - val_loss: 9.1015\n",
      "Epoch 5219/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6217 - val_loss: 9.1018\n",
      "Epoch 5220/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6214 - val_loss: 9.1020\n",
      "Epoch 5221/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6211 - val_loss: 9.1022\n",
      "Epoch 5222/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6208 - val_loss: 9.1023\n",
      "Epoch 5223/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6205 - val_loss: 9.1026\n",
      "Epoch 5224/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6202 - val_loss: 9.1028\n",
      "Epoch 5225/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6199 - val_loss: 9.1031\n",
      "Epoch 5226/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6196 - val_loss: 9.1034\n",
      "Epoch 5227/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6193 - val_loss: 9.1036\n",
      "Epoch 5228/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6190 - val_loss: 9.1037\n",
      "Epoch 5229/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6187 - val_loss: 9.1039\n",
      "Epoch 5230/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6184 - val_loss: 9.1041\n",
      "Epoch 5231/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6181 - val_loss: 9.1044\n",
      "Epoch 5232/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6178 - val_loss: 9.1047\n",
      "Epoch 5233/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6175 - val_loss: 9.1049\n",
      "Epoch 5234/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6172 - val_loss: 9.1051\n",
      "Epoch 5235/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6169 - val_loss: 9.1053\n",
      "Epoch 5236/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6166 - val_loss: 9.1055\n",
      "Epoch 5237/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6163 - val_loss: 9.1057\n",
      "Epoch 5238/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6160 - val_loss: 9.1059\n",
      "Epoch 5239/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6157 - val_loss: 9.1062\n",
      "Epoch 5240/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6154 - val_loss: 9.1064\n",
      "Epoch 5241/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6151 - val_loss: 9.1067\n",
      "Epoch 5242/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6148 - val_loss: 9.1069\n",
      "Epoch 5243/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6145 - val_loss: 9.1071\n",
      "Epoch 5244/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6142 - val_loss: 9.1073\n",
      "Epoch 5245/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6139 - val_loss: 9.1076\n",
      "Epoch 5246/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6136 - val_loss: 9.1078\n",
      "Epoch 5247/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6133 - val_loss: 9.1081\n",
      "Epoch 5248/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6130 - val_loss: 9.1083\n",
      "Epoch 5249/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6127 - val_loss: 9.1085\n",
      "Epoch 5250/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6124 - val_loss: 9.1087\n",
      "Epoch 5251/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6121 - val_loss: 9.1088\n",
      "Epoch 5252/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6118 - val_loss: 9.1090\n",
      "Epoch 5253/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6115 - val_loss: 9.1093\n",
      "Epoch 5254/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6112 - val_loss: 9.1096\n",
      "Epoch 5255/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6109 - val_loss: 9.1099\n",
      "Epoch 5256/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6106 - val_loss: 9.1102\n",
      "Epoch 5257/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6103 - val_loss: 9.1105\n",
      "Epoch 5258/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6100 - val_loss: 9.1107\n",
      "Epoch 5259/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6097 - val_loss: 9.1108\n",
      "Epoch 5260/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6094 - val_loss: 9.1111\n",
      "Epoch 5261/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6091 - val_loss: 9.1113\n",
      "Epoch 5262/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6088 - val_loss: 9.1115\n",
      "Epoch 5263/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6085 - val_loss: 9.1117\n",
      "Epoch 5264/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6082 - val_loss: 9.1119\n",
      "Epoch 5265/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6079 - val_loss: 9.1122\n",
      "Epoch 5266/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6076 - val_loss: 9.1125\n",
      "Epoch 5267/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6073 - val_loss: 9.1128\n",
      "Epoch 5268/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6070 - val_loss: 9.1130\n",
      "Epoch 5269/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6067 - val_loss: 9.1132\n",
      "Epoch 5270/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6064 - val_loss: 9.1134\n",
      "Epoch 5271/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6061 - val_loss: 9.1137\n",
      "Epoch 5272/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6058 - val_loss: 9.1140\n",
      "Epoch 5273/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6055 - val_loss: 9.1142\n",
      "Epoch 5274/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6052 - val_loss: 9.1144\n",
      "Epoch 5275/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6049 - val_loss: 9.1146\n",
      "Epoch 5276/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6046 - val_loss: 9.1148\n",
      "Epoch 5277/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6043 - val_loss: 9.1150\n",
      "Epoch 5278/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6040 - val_loss: 9.1151\n",
      "Epoch 5279/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6037 - val_loss: 9.1153\n",
      "Epoch 5280/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6034 - val_loss: 9.1156\n",
      "Epoch 5281/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6031 - val_loss: 9.1160\n",
      "Epoch 5282/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6028 - val_loss: 9.1163\n",
      "Epoch 5283/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6025 - val_loss: 9.1166\n",
      "Epoch 5284/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6022 - val_loss: 9.1168\n",
      "Epoch 5285/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6019 - val_loss: 9.1170\n",
      "Epoch 5286/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6016 - val_loss: 9.1172\n",
      "Epoch 5287/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6013 - val_loss: 9.1174\n",
      "Epoch 5288/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6010 - val_loss: 9.1177\n",
      "Epoch 5289/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6007 - val_loss: 9.1180\n",
      "Epoch 5290/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6004 - val_loss: 9.1182\n",
      "Epoch 5291/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6001 - val_loss: 9.1183\n",
      "Epoch 5292/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5998 - val_loss: 9.1186\n",
      "Epoch 5293/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5995 - val_loss: 9.1188\n",
      "Epoch 5294/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.5992 - val_loss: 9.1191\n",
      "Epoch 5295/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5989 - val_loss: 9.1193\n",
      "Epoch 5296/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5986 - val_loss: 9.1195\n",
      "Epoch 5297/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5983 - val_loss: 9.1198\n",
      "Epoch 5298/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5980 - val_loss: 9.1200\n",
      "Epoch 5299/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5977 - val_loss: 9.1203\n",
      "Epoch 5300/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5974 - val_loss: 9.1205\n",
      "Epoch 5301/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5971 - val_loss: 9.1207\n",
      "Epoch 5302/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5968 - val_loss: 9.1209\n",
      "Epoch 5303/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5965 - val_loss: 9.1211\n",
      "Epoch 5304/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5962 - val_loss: 9.1214\n",
      "Epoch 5305/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5959 - val_loss: 9.1217\n",
      "Epoch 5306/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.5956 - val_loss: 9.1220\n",
      "Epoch 5307/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5953 - val_loss: 9.1223\n",
      "Epoch 5308/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5950 - val_loss: 9.1226\n",
      "Epoch 5309/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5947 - val_loss: 9.1227\n",
      "Epoch 5310/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5944 - val_loss: 9.1229\n",
      "Epoch 5311/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5941 - val_loss: 9.1231\n",
      "Epoch 5312/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5938 - val_loss: 9.1233\n",
      "Epoch 5313/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5935 - val_loss: 9.1235\n",
      "Epoch 5314/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5932 - val_loss: 9.1238\n",
      "Epoch 5315/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5929 - val_loss: 9.1241\n",
      "Epoch 5316/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5926 - val_loss: 9.1244\n",
      "Epoch 5317/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5923 - val_loss: 9.1247\n",
      "Epoch 5318/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5920 - val_loss: 9.1249\n",
      "Epoch 5319/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5917 - val_loss: 9.1250\n",
      "Epoch 5320/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5914 - val_loss: 9.1251\n",
      "Epoch 5321/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5911 - val_loss: 9.1253\n",
      "Epoch 5322/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5908 - val_loss: 9.1256\n",
      "Epoch 5323/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5905 - val_loss: 9.1259\n",
      "Epoch 5324/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5902 - val_loss: 9.1262\n",
      "Epoch 5325/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5899 - val_loss: 9.1265\n",
      "Epoch 5326/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5896 - val_loss: 9.1267\n",
      "Epoch 5327/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5893 - val_loss: 9.1269\n",
      "Epoch 5328/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5890 - val_loss: 9.1271\n",
      "Epoch 5329/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5887 - val_loss: 9.1273\n",
      "Epoch 5330/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5884 - val_loss: 9.1276\n",
      "Epoch 5331/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5881 - val_loss: 9.1280\n",
      "Epoch 5332/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5878 - val_loss: 9.1283\n",
      "Epoch 5333/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5875 - val_loss: 9.1287\n",
      "Epoch 5334/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5872 - val_loss: 9.1289\n",
      "Epoch 5335/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5869 - val_loss: 9.1291\n",
      "Epoch 5336/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5866 - val_loss: 9.1293\n",
      "Epoch 5337/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5863 - val_loss: 9.1296\n",
      "Epoch 5338/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5860 - val_loss: 9.1298\n",
      "Epoch 5339/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5857 - val_loss: 9.1300\n",
      "Epoch 5340/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5854 - val_loss: 9.1303\n",
      "Epoch 5341/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5851 - val_loss: 9.1306\n",
      "Epoch 5342/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5848 - val_loss: 9.1309\n",
      "Epoch 5343/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5845 - val_loss: 9.1312\n",
      "Epoch 5344/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5842 - val_loss: 9.1314\n",
      "Epoch 5345/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5839 - val_loss: 9.1317\n",
      "Epoch 5346/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5836 - val_loss: 9.1319\n",
      "Epoch 5347/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5833 - val_loss: 9.1321\n",
      "Epoch 5348/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5830 - val_loss: 9.1323\n",
      "Epoch 5349/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5827 - val_loss: 9.1325\n",
      "Epoch 5350/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5824 - val_loss: 9.1328\n",
      "Epoch 5351/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5821 - val_loss: 9.1330\n",
      "Epoch 5352/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5818 - val_loss: 9.1333\n",
      "Epoch 5353/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5815 - val_loss: 9.1336\n",
      "Epoch 5354/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.5812 - val_loss: 9.1339\n",
      "Epoch 5355/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5809 - val_loss: 9.1342\n",
      "Epoch 5356/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5806 - val_loss: 9.1345\n",
      "Epoch 5357/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5803 - val_loss: 9.1348\n",
      "Epoch 5358/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5800 - val_loss: 9.1351\n",
      "Epoch 5359/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5797 - val_loss: 9.1354\n",
      "Epoch 5360/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5794 - val_loss: 9.1357\n",
      "Epoch 5361/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5791 - val_loss: 9.1360\n",
      "Epoch 5362/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5788 - val_loss: 9.1363\n",
      "Epoch 5363/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5785 - val_loss: 9.1366\n",
      "Epoch 5364/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5782 - val_loss: 9.1369\n",
      "Epoch 5365/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5779 - val_loss: 9.1373\n",
      "Epoch 5366/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5776 - val_loss: 9.1377\n",
      "Epoch 5367/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5773 - val_loss: 9.1382\n",
      "Epoch 5368/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5770 - val_loss: 9.1386\n",
      "Epoch 5369/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5767 - val_loss: 9.1391\n",
      "Epoch 5370/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5764 - val_loss: 9.1395\n",
      "Epoch 5371/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5761 - val_loss: 9.1401\n",
      "Epoch 5372/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5757 - val_loss: 9.1406\n",
      "Epoch 5373/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5754 - val_loss: 9.1411\n",
      "Epoch 5374/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5751 - val_loss: 9.1415\n",
      "Epoch 5375/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5748 - val_loss: 9.1420\n",
      "Epoch 5376/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5745 - val_loss: 9.1426\n",
      "Epoch 5377/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5742 - val_loss: 9.1431\n",
      "Epoch 5378/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5739 - val_loss: 9.1436\n",
      "Epoch 5379/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5736 - val_loss: 9.1441\n",
      "Epoch 5380/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5733 - val_loss: 9.1445\n",
      "Epoch 5381/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5730 - val_loss: 9.1449\n",
      "Epoch 5382/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.5727 - val_loss: 9.1454\n",
      "Epoch 5383/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.5724 - val_loss: 9.1459\n",
      "Epoch 5384/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5721 - val_loss: 9.1463\n",
      "Epoch 5385/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5718 - val_loss: 9.1468\n",
      "Epoch 5386/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5715 - val_loss: 9.1472\n",
      "Epoch 5387/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5711 - val_loss: 9.1476\n",
      "Epoch 5388/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5708 - val_loss: 9.1481\n",
      "Epoch 5389/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5705 - val_loss: 9.1485\n",
      "Epoch 5390/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5702 - val_loss: 9.1489\n",
      "Epoch 5391/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5699 - val_loss: 9.1492\n",
      "Epoch 5392/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5696 - val_loss: 9.1496\n",
      "Epoch 5393/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5693 - val_loss: 9.1499\n",
      "Epoch 5394/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5690 - val_loss: 9.1503\n",
      "Epoch 5395/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5687 - val_loss: 9.1507\n",
      "Epoch 5396/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5684 - val_loss: 9.1512\n",
      "Epoch 5397/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5681 - val_loss: 9.1516\n",
      "Epoch 5398/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5678 - val_loss: 9.1520\n",
      "Epoch 5399/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5675 - val_loss: 9.1524\n",
      "Epoch 5400/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5672 - val_loss: 9.1527\n",
      "Epoch 5401/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5669 - val_loss: 9.1529\n",
      "Epoch 5402/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5666 - val_loss: 9.1532\n",
      "Epoch 5403/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5663 - val_loss: 9.1535\n",
      "Epoch 5404/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5660 - val_loss: 9.1538\n",
      "Epoch 5405/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5657 - val_loss: 9.1542\n",
      "Epoch 5406/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5654 - val_loss: 9.1547\n",
      "Epoch 5407/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5651 - val_loss: 9.1552\n",
      "Epoch 5408/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5648 - val_loss: 9.1556\n",
      "Epoch 5409/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5645 - val_loss: 9.1559\n",
      "Epoch 5410/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5642 - val_loss: 9.1561\n",
      "Epoch 5411/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5639 - val_loss: 9.1564\n",
      "Epoch 5412/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5636 - val_loss: 9.1567\n",
      "Epoch 5413/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.5633 - val_loss: 9.1570\n",
      "Epoch 5414/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5630 - val_loss: 9.1573\n",
      "Epoch 5415/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5627 - val_loss: 9.1576\n",
      "Epoch 5416/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5624 - val_loss: 9.1578\n",
      "Epoch 5417/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5620 - val_loss: 9.1582\n",
      "Epoch 5418/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5617 - val_loss: 9.1585\n",
      "Epoch 5419/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5614 - val_loss: 9.1589\n",
      "Epoch 5420/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5611 - val_loss: 9.1593\n",
      "Epoch 5421/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5608 - val_loss: 9.1597\n",
      "Epoch 5422/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5605 - val_loss: 9.1600\n",
      "Epoch 5423/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5602 - val_loss: 9.1604\n",
      "Epoch 5424/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5599 - val_loss: 9.1606\n",
      "Epoch 5425/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5596 - val_loss: 9.1609\n",
      "Epoch 5426/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5593 - val_loss: 9.1612\n",
      "Epoch 5427/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5590 - val_loss: 9.1614\n",
      "Epoch 5428/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5587 - val_loss: 9.1617\n",
      "Epoch 5429/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.5584 - val_loss: 9.1620\n",
      "Epoch 5430/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5581 - val_loss: 9.1623\n",
      "Epoch 5431/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5578 - val_loss: 9.1626\n",
      "Epoch 5432/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5575 - val_loss: 9.1629\n",
      "Epoch 5433/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5572 - val_loss: 9.1633\n",
      "Epoch 5434/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5569 - val_loss: 9.1636\n",
      "Epoch 5435/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5566 - val_loss: 9.1640\n",
      "Epoch 5436/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5563 - val_loss: 9.1643\n",
      "Epoch 5437/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5560 - val_loss: 9.1646\n",
      "Epoch 5438/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5557 - val_loss: 9.1649\n",
      "Epoch 5439/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5554 - val_loss: 9.1651\n",
      "Epoch 5440/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5551 - val_loss: 9.1654\n",
      "Epoch 5441/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5548 - val_loss: 9.1657\n",
      "Epoch 5442/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5545 - val_loss: 9.1660\n",
      "Epoch 5443/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5542 - val_loss: 9.1663\n",
      "Epoch 5444/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5539 - val_loss: 9.1666\n",
      "Epoch 5445/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5536 - val_loss: 9.1670\n",
      "Epoch 5446/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5533 - val_loss: 9.1673\n",
      "Epoch 5447/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5530 - val_loss: 9.1676\n",
      "Epoch 5448/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5527 - val_loss: 9.1680\n",
      "Epoch 5449/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5524 - val_loss: 9.1682\n",
      "Epoch 5450/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5521 - val_loss: 9.1685\n",
      "Epoch 5451/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5518 - val_loss: 9.1687\n",
      "Epoch 5452/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5515 - val_loss: 9.1689\n",
      "Epoch 5453/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5512 - val_loss: 9.1692\n",
      "Epoch 5454/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5509 - val_loss: 9.1694\n",
      "Epoch 5455/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5506 - val_loss: 9.1696\n",
      "Epoch 5456/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5503 - val_loss: 9.1700\n",
      "Epoch 5457/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5500 - val_loss: 9.1703\n",
      "Epoch 5458/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5497 - val_loss: 9.1707\n",
      "Epoch 5459/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5494 - val_loss: 9.1710\n",
      "Epoch 5460/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5491 - val_loss: 9.1713\n",
      "Epoch 5461/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5488 - val_loss: 9.1716\n",
      "Epoch 5462/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5485 - val_loss: 9.1719\n",
      "Epoch 5463/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5482 - val_loss: 9.1722\n",
      "Epoch 5464/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5479 - val_loss: 9.1724\n",
      "Epoch 5465/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5476 - val_loss: 9.1726\n",
      "Epoch 5466/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5473 - val_loss: 9.1728\n",
      "Epoch 5467/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5470 - val_loss: 9.1732\n",
      "Epoch 5468/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5467 - val_loss: 9.1736\n",
      "Epoch 5469/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5464 - val_loss: 9.1739\n",
      "Epoch 5470/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5461 - val_loss: 9.1741\n",
      "Epoch 5471/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5458 - val_loss: 9.1744\n",
      "Epoch 5472/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5455 - val_loss: 9.1747\n",
      "Epoch 5473/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5452 - val_loss: 9.1750\n",
      "Epoch 5474/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5449 - val_loss: 9.1753\n",
      "Epoch 5475/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5446 - val_loss: 9.1755\n",
      "Epoch 5476/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5443 - val_loss: 9.1757\n",
      "Epoch 5477/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5440 - val_loss: 9.1759\n",
      "Epoch 5478/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5437 - val_loss: 9.1763\n",
      "Epoch 5479/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5434 - val_loss: 9.1766\n",
      "Epoch 5480/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5431 - val_loss: 9.1769\n",
      "Epoch 5481/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5428 - val_loss: 9.1772\n",
      "Epoch 5482/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5425 - val_loss: 9.1775\n",
      "Epoch 5483/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5422 - val_loss: 9.1778\n",
      "Epoch 5484/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5419 - val_loss: 9.1781\n",
      "Epoch 5485/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5416 - val_loss: 9.1783\n",
      "Epoch 5486/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5413 - val_loss: 9.1785\n",
      "Epoch 5487/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5410 - val_loss: 9.1787\n",
      "Epoch 5488/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5407 - val_loss: 9.1791\n",
      "Epoch 5489/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5404 - val_loss: 9.1795\n",
      "Epoch 5490/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5401 - val_loss: 9.1798\n",
      "Epoch 5491/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5398 - val_loss: 9.1801\n",
      "Epoch 5492/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5395 - val_loss: 9.1803\n",
      "Epoch 5493/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5392 - val_loss: 9.1806\n",
      "Epoch 5494/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5389 - val_loss: 9.1808\n",
      "Epoch 5495/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5386 - val_loss: 9.1811\n",
      "Epoch 5496/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5383 - val_loss: 9.1813\n",
      "Epoch 5497/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5380 - val_loss: 9.1815\n",
      "Epoch 5498/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5377 - val_loss: 9.1818\n",
      "Epoch 5499/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5374 - val_loss: 9.1821\n",
      "Epoch 5500/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5371 - val_loss: 9.1824\n",
      "Epoch 5501/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5368 - val_loss: 9.1828\n",
      "Epoch 5502/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5365 - val_loss: 9.1832\n",
      "Epoch 5503/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5362 - val_loss: 9.1834\n",
      "Epoch 5504/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5359 - val_loss: 9.1836\n",
      "Epoch 5505/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5356 - val_loss: 9.1838\n",
      "Epoch 5506/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5353 - val_loss: 9.1840\n",
      "Epoch 5507/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5350 - val_loss: 9.1842\n",
      "Epoch 5508/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5347 - val_loss: 9.1845\n",
      "Epoch 5509/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5344 - val_loss: 9.1848\n",
      "Epoch 5510/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5341 - val_loss: 9.1851\n",
      "Epoch 5511/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5338 - val_loss: 9.1854\n",
      "Epoch 5512/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5335 - val_loss: 9.1857\n",
      "Epoch 5513/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5332 - val_loss: 9.1859\n",
      "Epoch 5514/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5329 - val_loss: 9.1862\n",
      "Epoch 5515/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5326 - val_loss: 9.1865\n",
      "Epoch 5516/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5323 - val_loss: 9.1868\n",
      "Epoch 5517/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5320 - val_loss: 9.1870\n",
      "Epoch 5518/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5317 - val_loss: 9.1872\n",
      "Epoch 5519/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5314 - val_loss: 9.1874\n",
      "Epoch 5520/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5311 - val_loss: 9.1876\n",
      "Epoch 5521/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5308 - val_loss: 9.1878\n",
      "Epoch 5522/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5305 - val_loss: 9.1881\n",
      "Epoch 5523/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5302 - val_loss: 9.1884\n",
      "Epoch 5524/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5299 - val_loss: 9.1887\n",
      "Epoch 5525/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5296 - val_loss: 9.1890\n",
      "Epoch 5526/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5293 - val_loss: 9.1894\n",
      "Epoch 5527/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5290 - val_loss: 9.1897\n",
      "Epoch 5528/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5287 - val_loss: 9.1899\n",
      "Epoch 5529/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5284 - val_loss: 9.1902\n",
      "Epoch 5530/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5281 - val_loss: 9.1904\n",
      "Epoch 5531/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5278 - val_loss: 9.1906\n",
      "Epoch 5532/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5275 - val_loss: 9.1908\n",
      "Epoch 5533/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5272 - val_loss: 9.1910\n",
      "Epoch 5534/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5269 - val_loss: 9.1913\n",
      "Epoch 5535/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5266 - val_loss: 9.1916\n",
      "Epoch 5536/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5263 - val_loss: 9.1919\n",
      "Epoch 5537/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5260 - val_loss: 9.1921\n",
      "Epoch 5538/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5257 - val_loss: 9.1924\n",
      "Epoch 5539/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5254 - val_loss: 9.1927\n",
      "Epoch 5540/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5251 - val_loss: 9.1929\n",
      "Epoch 5541/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5248 - val_loss: 9.1931\n",
      "Epoch 5542/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5245 - val_loss: 9.1934\n",
      "Epoch 5543/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5242 - val_loss: 9.1936\n",
      "Epoch 5544/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5239 - val_loss: 9.1939\n",
      "Epoch 5545/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5236 - val_loss: 9.1941\n",
      "Epoch 5546/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5233 - val_loss: 9.1944\n",
      "Epoch 5547/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5230 - val_loss: 9.1946\n",
      "Epoch 5548/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5227 - val_loss: 9.1948\n",
      "Epoch 5549/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5224 - val_loss: 9.1951\n",
      "Epoch 5550/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5221 - val_loss: 9.1954\n",
      "Epoch 5551/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5218 - val_loss: 9.1956\n",
      "Epoch 5552/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5215 - val_loss: 9.1958\n",
      "Epoch 5553/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5212 - val_loss: 9.1961\n",
      "Epoch 5554/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5209 - val_loss: 9.1964\n",
      "Epoch 5555/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5206 - val_loss: 9.1966\n",
      "Epoch 5556/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5203 - val_loss: 9.1968\n",
      "Epoch 5557/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5200 - val_loss: 9.1970\n",
      "Epoch 5558/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5197 - val_loss: 9.1973\n",
      "Epoch 5559/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5194 - val_loss: 9.1976\n",
      "Epoch 5560/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5191 - val_loss: 9.1979\n",
      "Epoch 5561/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5188 - val_loss: 9.1981\n",
      "Epoch 5562/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5185 - val_loss: 9.1983\n",
      "Epoch 5563/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5182 - val_loss: 9.1984\n",
      "Epoch 5564/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5179 - val_loss: 9.1986\n",
      "Epoch 5565/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5176 - val_loss: 9.1989\n",
      "Epoch 5566/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5173 - val_loss: 9.1992\n",
      "Epoch 5567/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5170 - val_loss: 9.1995\n",
      "Epoch 5568/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5167 - val_loss: 9.1998\n",
      "Epoch 5569/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5164 - val_loss: 9.2001\n",
      "Epoch 5570/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5161 - val_loss: 9.2003\n",
      "Epoch 5571/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5158 - val_loss: 9.2005\n",
      "Epoch 5572/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5155 - val_loss: 9.2007\n",
      "Epoch 5573/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5152 - val_loss: 9.2009\n",
      "Epoch 5574/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5149 - val_loss: 9.2012\n",
      "Epoch 5575/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5146 - val_loss: 9.2016\n",
      "Epoch 5576/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5143 - val_loss: 9.2020\n",
      "Epoch 5577/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5140 - val_loss: 9.2023\n",
      "Epoch 5578/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5137 - val_loss: 9.2026\n",
      "Epoch 5579/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5134 - val_loss: 9.2028\n",
      "Epoch 5580/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5131 - val_loss: 9.2031\n",
      "Epoch 5581/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5128 - val_loss: 9.2035\n",
      "Epoch 5582/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5125 - val_loss: 9.2039\n",
      "Epoch 5583/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5122 - val_loss: 9.2044\n",
      "Epoch 5584/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5119 - val_loss: 9.2048\n",
      "Epoch 5585/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5116 - val_loss: 9.2052\n",
      "Epoch 5586/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5113 - val_loss: 9.2055\n",
      "Epoch 5587/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5110 - val_loss: 9.2058\n",
      "Epoch 5588/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5107 - val_loss: 9.2062\n",
      "Epoch 5589/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5104 - val_loss: 9.2066\n",
      "Epoch 5590/10000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.5101 - val_loss: 9.2069\n",
      "Epoch 5591/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.5098 - val_loss: 9.2072\n",
      "Epoch 5592/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5095 - val_loss: 9.2075\n",
      "Epoch 5593/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5092 - val_loss: 9.2079\n",
      "Epoch 5594/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5089 - val_loss: 9.2084\n",
      "Epoch 5595/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5086 - val_loss: 9.2088\n",
      "Epoch 5596/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5083 - val_loss: 9.2092\n",
      "Epoch 5597/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5080 - val_loss: 9.2095\n",
      "Epoch 5598/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5077 - val_loss: 9.2099\n",
      "Epoch 5599/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5074 - val_loss: 9.2102\n",
      "Epoch 5600/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5071 - val_loss: 9.2106\n",
      "Epoch 5601/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5068 - val_loss: 9.2110\n",
      "Epoch 5602/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5065 - val_loss: 9.2114\n",
      "Epoch 5603/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5062 - val_loss: 9.2117\n",
      "Epoch 5604/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5059 - val_loss: 9.2121\n",
      "Epoch 5605/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5056 - val_loss: 9.2125\n",
      "Epoch 5606/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5053 - val_loss: 9.2129\n",
      "Epoch 5607/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5050 - val_loss: 9.2134\n",
      "Epoch 5608/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5047 - val_loss: 9.2138\n",
      "Epoch 5609/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5044 - val_loss: 9.2142\n",
      "Epoch 5610/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5041 - val_loss: 9.2146\n",
      "Epoch 5611/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5038 - val_loss: 9.2149\n",
      "Epoch 5612/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5035 - val_loss: 9.2152\n",
      "Epoch 5613/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5032 - val_loss: 9.2155\n",
      "Epoch 5614/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5029 - val_loss: 9.2159\n",
      "Epoch 5615/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5026 - val_loss: 9.2162\n",
      "Epoch 5616/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5023 - val_loss: 9.2166\n",
      "Epoch 5617/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5020 - val_loss: 9.2170\n",
      "Epoch 5618/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5017 - val_loss: 9.2174\n",
      "Epoch 5619/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5014 - val_loss: 9.2177\n",
      "Epoch 5620/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5011 - val_loss: 9.2181\n",
      "Epoch 5621/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5008 - val_loss: 9.2185\n",
      "Epoch 5622/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5005 - val_loss: 9.2189\n",
      "Epoch 5623/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5002 - val_loss: 9.2192\n",
      "Epoch 5624/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4999 - val_loss: 9.2195\n",
      "Epoch 5625/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4996 - val_loss: 9.2199\n",
      "Epoch 5626/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4993 - val_loss: 9.2203\n",
      "Epoch 5627/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4990 - val_loss: 9.2207\n",
      "Epoch 5628/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4987 - val_loss: 9.2210\n",
      "Epoch 5629/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4984 - val_loss: 9.2214\n",
      "Epoch 5630/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4981 - val_loss: 9.2217\n",
      "Epoch 5631/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4978 - val_loss: 9.2221\n",
      "Epoch 5632/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4975 - val_loss: 9.2226\n",
      "Epoch 5633/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4972 - val_loss: 9.2230\n",
      "Epoch 5634/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.4969 - val_loss: 9.2233\n",
      "Epoch 5635/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4966 - val_loss: 9.2236\n",
      "Epoch 5636/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4963 - val_loss: 9.2240\n",
      "Epoch 5637/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4960 - val_loss: 9.2243\n",
      "Epoch 5638/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4957 - val_loss: 9.2247\n",
      "Epoch 5639/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4954 - val_loss: 9.2249\n",
      "Epoch 5640/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4951 - val_loss: 9.2252\n",
      "Epoch 5641/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4948 - val_loss: 9.2256\n",
      "Epoch 5642/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4945 - val_loss: 9.2260\n",
      "Epoch 5643/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4942 - val_loss: 9.2264\n",
      "Epoch 5644/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4939 - val_loss: 9.2268\n",
      "Epoch 5645/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4936 - val_loss: 9.2272\n",
      "Epoch 5646/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4933 - val_loss: 9.2276\n",
      "Epoch 5647/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.4930 - val_loss: 9.2280\n",
      "Epoch 5648/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4927 - val_loss: 9.2284\n",
      "Epoch 5649/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4924 - val_loss: 9.2288\n",
      "Epoch 5650/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4921 - val_loss: 9.2292\n",
      "Epoch 5651/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.4918 - val_loss: 9.2295\n",
      "Epoch 5652/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4915 - val_loss: 9.2300\n",
      "Epoch 5653/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4912 - val_loss: 9.2304\n",
      "Epoch 5654/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.4909 - val_loss: 9.2308\n",
      "Epoch 5655/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4906 - val_loss: 9.2311\n",
      "Epoch 5656/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4903 - val_loss: 9.2314\n",
      "Epoch 5657/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4900 - val_loss: 9.2317\n",
      "Epoch 5658/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4897 - val_loss: 9.2321\n",
      "Epoch 5659/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4894 - val_loss: 9.2324\n",
      "Epoch 5660/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4891 - val_loss: 9.2327\n",
      "Epoch 5661/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4888 - val_loss: 9.2330\n",
      "Epoch 5662/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4885 - val_loss: 9.2334\n",
      "Epoch 5663/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4882 - val_loss: 9.2337\n",
      "Epoch 5664/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4879 - val_loss: 9.2341\n",
      "Epoch 5665/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4876 - val_loss: 9.2345\n",
      "Epoch 5666/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4873 - val_loss: 9.2349\n",
      "Epoch 5667/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4870 - val_loss: 9.2353\n",
      "Epoch 5668/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4867 - val_loss: 9.2357\n",
      "Epoch 5669/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4864 - val_loss: 9.2361\n",
      "Epoch 5670/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4861 - val_loss: 9.2364\n",
      "Epoch 5671/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4858 - val_loss: 9.2368\n",
      "Epoch 5672/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4855 - val_loss: 9.2371\n",
      "Epoch 5673/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4852 - val_loss: 9.2374\n",
      "Epoch 5674/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4849 - val_loss: 9.2377\n",
      "Epoch 5675/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4846 - val_loss: 9.2381\n",
      "Epoch 5676/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4843 - val_loss: 9.2384\n",
      "Epoch 5677/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4840 - val_loss: 9.2387\n",
      "Epoch 5678/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4837 - val_loss: 9.2391\n",
      "Epoch 5679/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4834 - val_loss: 9.2396\n",
      "Epoch 5680/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4831 - val_loss: 9.2401\n",
      "Epoch 5681/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4829 - val_loss: 9.2405\n",
      "Epoch 5682/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4826 - val_loss: 9.2408\n",
      "Epoch 5683/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4823 - val_loss: 9.2411\n",
      "Epoch 5684/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4820 - val_loss: 9.2414\n",
      "Epoch 5685/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4817 - val_loss: 9.2418\n",
      "Epoch 5686/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4814 - val_loss: 9.2421\n",
      "Epoch 5687/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4811 - val_loss: 9.2425\n",
      "Epoch 5688/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4808 - val_loss: 9.2429\n",
      "Epoch 5689/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4805 - val_loss: 9.2432\n",
      "Epoch 5690/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4802 - val_loss: 9.2435\n",
      "Epoch 5691/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4799 - val_loss: 9.2439\n",
      "Epoch 5692/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4796 - val_loss: 9.2443\n",
      "Epoch 5693/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4793 - val_loss: 9.2448\n",
      "Epoch 5694/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4790 - val_loss: 9.2451\n",
      "Epoch 5695/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4787 - val_loss: 9.2455\n",
      "Epoch 5696/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4784 - val_loss: 9.2459\n",
      "Epoch 5697/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4781 - val_loss: 9.2463\n",
      "Epoch 5698/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4778 - val_loss: 9.2466\n",
      "Epoch 5699/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4775 - val_loss: 9.2469\n",
      "Epoch 5700/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4772 - val_loss: 9.2473\n",
      "Epoch 5701/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4769 - val_loss: 9.2476\n",
      "Epoch 5702/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4766 - val_loss: 9.2481\n",
      "Epoch 5703/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4763 - val_loss: 9.2485\n",
      "Epoch 5704/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4760 - val_loss: 9.2489\n",
      "Epoch 5705/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4757 - val_loss: 9.2493\n",
      "Epoch 5706/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4754 - val_loss: 9.2496\n",
      "Epoch 5707/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4751 - val_loss: 9.2500\n",
      "Epoch 5708/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4748 - val_loss: 9.2503\n",
      "Epoch 5709/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.4745 - val_loss: 9.2506\n",
      "Epoch 5710/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.4742 - val_loss: 9.2509\n",
      "Epoch 5711/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4739 - val_loss: 9.2513\n",
      "Epoch 5712/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4736 - val_loss: 9.2517\n",
      "Epoch 5713/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4733 - val_loss: 9.2521\n",
      "Epoch 5714/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4730 - val_loss: 9.2525\n",
      "Epoch 5715/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4727 - val_loss: 9.2528\n",
      "Epoch 5716/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4724 - val_loss: 9.2531\n",
      "Epoch 5717/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4721 - val_loss: 9.2534\n",
      "Epoch 5718/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4718 - val_loss: 9.2538\n",
      "Epoch 5719/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4715 - val_loss: 9.2542\n",
      "Epoch 5720/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4712 - val_loss: 9.2546\n",
      "Epoch 5721/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4709 - val_loss: 9.2550\n",
      "Epoch 5722/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4706 - val_loss: 9.2553\n",
      "Epoch 5723/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4703 - val_loss: 9.2557\n",
      "Epoch 5724/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4700 - val_loss: 9.2561\n",
      "Epoch 5725/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4697 - val_loss: 9.2565\n",
      "Epoch 5726/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4694 - val_loss: 9.2569\n",
      "Epoch 5727/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4691 - val_loss: 9.2573\n",
      "Epoch 5728/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4688 - val_loss: 9.2577\n",
      "Epoch 5729/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4685 - val_loss: 9.2581\n",
      "Epoch 5730/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4682 - val_loss: 9.2583\n",
      "Epoch 5731/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4679 - val_loss: 9.2586\n",
      "Epoch 5732/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4676 - val_loss: 9.2589\n",
      "Epoch 5733/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4673 - val_loss: 9.2594\n",
      "Epoch 5734/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4670 - val_loss: 9.2598\n",
      "Epoch 5735/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4667 - val_loss: 9.2603\n",
      "Epoch 5736/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4664 - val_loss: 9.2607\n",
      "Epoch 5737/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4661 - val_loss: 9.2611\n",
      "Epoch 5738/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4658 - val_loss: 9.2616\n",
      "Epoch 5739/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4655 - val_loss: 9.2621\n",
      "Epoch 5740/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4652 - val_loss: 9.2626\n",
      "Epoch 5741/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4649 - val_loss: 9.2631\n",
      "Epoch 5742/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4646 - val_loss: 9.2635\n",
      "Epoch 5743/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4643 - val_loss: 9.2640\n",
      "Epoch 5744/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4640 - val_loss: 9.2645\n",
      "Epoch 5745/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4637 - val_loss: 9.2648\n",
      "Epoch 5746/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4634 - val_loss: 9.2652\n",
      "Epoch 5747/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4631 - val_loss: 9.2655\n",
      "Epoch 5748/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4628 - val_loss: 9.2659\n",
      "Epoch 5749/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4625 - val_loss: 9.2664\n",
      "Epoch 5750/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4622 - val_loss: 9.2670\n",
      "Epoch 5751/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4619 - val_loss: 9.2675\n",
      "Epoch 5752/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4616 - val_loss: 9.2680\n",
      "Epoch 5753/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4613 - val_loss: 9.2685\n",
      "Epoch 5754/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4610 - val_loss: 9.2690\n",
      "Epoch 5755/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4607 - val_loss: 9.2694\n",
      "Epoch 5756/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4604 - val_loss: 9.2696\n",
      "Epoch 5757/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4601 - val_loss: 9.2699\n",
      "Epoch 5758/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4598 - val_loss: 9.2702\n",
      "Epoch 5759/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4595 - val_loss: 9.2707\n",
      "Epoch 5760/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4592 - val_loss: 9.2713\n",
      "Epoch 5761/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4589 - val_loss: 9.2718\n",
      "Epoch 5762/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4586 - val_loss: 9.2723\n",
      "Epoch 5763/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4583 - val_loss: 9.2728\n",
      "Epoch 5764/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4580 - val_loss: 9.2732\n",
      "Epoch 5765/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4577 - val_loss: 9.2736\n",
      "Epoch 5766/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4574 - val_loss: 9.2738\n",
      "Epoch 5767/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.4571 - val_loss: 9.2740\n",
      "Epoch 5768/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4568 - val_loss: 9.2742\n",
      "Epoch 5769/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4565 - val_loss: 9.2746\n",
      "Epoch 5770/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4562 - val_loss: 9.2750\n",
      "Epoch 5771/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4559 - val_loss: 9.2755\n",
      "Epoch 5772/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4556 - val_loss: 9.2759\n",
      "Epoch 5773/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4553 - val_loss: 9.2763\n",
      "Epoch 5774/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4550 - val_loss: 9.2767\n",
      "Epoch 5775/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4547 - val_loss: 9.2771\n",
      "Epoch 5776/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4544 - val_loss: 9.2775\n",
      "Epoch 5777/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4541 - val_loss: 9.2778\n",
      "Epoch 5778/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4538 - val_loss: 9.2781\n",
      "Epoch 5779/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4535 - val_loss: 9.2784\n",
      "Epoch 5780/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4532 - val_loss: 9.2788\n",
      "Epoch 5781/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4529 - val_loss: 9.2792\n",
      "Epoch 5782/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4526 - val_loss: 9.2796\n",
      "Epoch 5783/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4523 - val_loss: 9.2799\n",
      "Epoch 5784/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4520 - val_loss: 9.2803\n",
      "Epoch 5785/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4517 - val_loss: 9.2807\n",
      "Epoch 5786/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4514 - val_loss: 9.2810\n",
      "Epoch 5787/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4511 - val_loss: 9.2813\n",
      "Epoch 5788/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4508 - val_loss: 9.2815\n",
      "Epoch 5789/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4505 - val_loss: 9.2818\n",
      "Epoch 5790/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4502 - val_loss: 9.2822\n",
      "Epoch 5791/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4499 - val_loss: 9.2826\n",
      "Epoch 5792/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4496 - val_loss: 9.2828\n",
      "Epoch 5793/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4493 - val_loss: 9.2832\n",
      "Epoch 5794/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4490 - val_loss: 9.2835\n",
      "Epoch 5795/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4487 - val_loss: 9.2840\n",
      "Epoch 5796/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4484 - val_loss: 9.2843\n",
      "Epoch 5797/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4481 - val_loss: 9.2845\n",
      "Epoch 5798/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4478 - val_loss: 9.2848\n",
      "Epoch 5799/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4475 - val_loss: 9.2851\n",
      "Epoch 5800/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4472 - val_loss: 9.2855\n",
      "Epoch 5801/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4469 - val_loss: 9.2859\n",
      "Epoch 5802/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4466 - val_loss: 9.2862\n",
      "Epoch 5803/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4463 - val_loss: 9.2865\n",
      "Epoch 5804/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4460 - val_loss: 9.2868\n",
      "Epoch 5805/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4457 - val_loss: 9.2872\n",
      "Epoch 5806/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4454 - val_loss: 9.2875\n",
      "Epoch 5807/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4451 - val_loss: 9.2878\n",
      "Epoch 5808/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4448 - val_loss: 9.2881\n",
      "Epoch 5809/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4445 - val_loss: 9.2884\n",
      "Epoch 5810/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4442 - val_loss: 9.2887\n",
      "Epoch 5811/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4439 - val_loss: 9.2891\n",
      "Epoch 5812/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4436 - val_loss: 9.2894\n",
      "Epoch 5813/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4433 - val_loss: 9.2897\n",
      "Epoch 5814/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4430 - val_loss: 9.2900\n",
      "Epoch 5815/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4427 - val_loss: 9.2903\n",
      "Epoch 5816/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4424 - val_loss: 9.2906\n",
      "Epoch 5817/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4421 - val_loss: 9.2909\n",
      "Epoch 5818/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4418 - val_loss: 9.2913\n",
      "Epoch 5819/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4415 - val_loss: 9.2917\n",
      "Epoch 5820/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4412 - val_loss: 9.2920\n",
      "Epoch 5821/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4409 - val_loss: 9.2923\n",
      "Epoch 5822/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4406 - val_loss: 9.2925\n",
      "Epoch 5823/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4403 - val_loss: 9.2928\n",
      "Epoch 5824/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4400 - val_loss: 9.2931\n",
      "Epoch 5825/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4397 - val_loss: 9.2934\n",
      "Epoch 5826/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4394 - val_loss: 9.2937\n",
      "Epoch 5827/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.4391 - val_loss: 9.2940\n",
      "Epoch 5828/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4388 - val_loss: 9.2943\n",
      "Epoch 5829/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4385 - val_loss: 9.2947\n",
      "Epoch 5830/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4382 - val_loss: 9.2951\n",
      "Epoch 5831/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4379 - val_loss: 9.2954\n",
      "Epoch 5832/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4376 - val_loss: 9.2957\n",
      "Epoch 5833/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4373 - val_loss: 9.2960\n",
      "Epoch 5834/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4370 - val_loss: 9.2962\n",
      "Epoch 5835/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4367 - val_loss: 9.2965\n",
      "Epoch 5836/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4364 - val_loss: 9.2968\n",
      "Epoch 5837/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4361 - val_loss: 9.2971\n",
      "Epoch 5838/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4358 - val_loss: 9.2974\n",
      "Epoch 5839/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4355 - val_loss: 9.2978\n",
      "Epoch 5840/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4352 - val_loss: 9.2981\n",
      "Epoch 5841/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4349 - val_loss: 9.2985\n",
      "Epoch 5842/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.4346 - val_loss: 9.2988\n",
      "Epoch 5843/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4343 - val_loss: 9.2990\n",
      "Epoch 5844/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4340 - val_loss: 9.2993\n",
      "Epoch 5845/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4337 - val_loss: 9.2995\n",
      "Epoch 5846/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4334 - val_loss: 9.2997\n",
      "Epoch 5847/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4331 - val_loss: 9.3000\n",
      "Epoch 5848/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4328 - val_loss: 9.3003\n",
      "Epoch 5849/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4325 - val_loss: 9.3007\n",
      "Epoch 5850/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4322 - val_loss: 9.3011\n",
      "Epoch 5851/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4319 - val_loss: 9.3014\n",
      "Epoch 5852/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4316 - val_loss: 9.3017\n",
      "Epoch 5853/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4313 - val_loss: 9.3020\n",
      "Epoch 5854/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4310 - val_loss: 9.3021\n",
      "Epoch 5855/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4307 - val_loss: 9.3024\n",
      "Epoch 5856/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4304 - val_loss: 9.3026\n",
      "Epoch 5857/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4301 - val_loss: 9.3029\n",
      "Epoch 5858/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4298 - val_loss: 9.3032\n",
      "Epoch 5859/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4295 - val_loss: 9.3035\n",
      "Epoch 5860/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4292 - val_loss: 9.3039\n",
      "Epoch 5861/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4289 - val_loss: 9.3041\n",
      "Epoch 5862/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4286 - val_loss: 9.3044\n",
      "Epoch 5863/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4283 - val_loss: 9.3046\n",
      "Epoch 5864/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4280 - val_loss: 9.3048\n",
      "Epoch 5865/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4277 - val_loss: 9.3051\n",
      "Epoch 5866/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4274 - val_loss: 9.3053\n",
      "Epoch 5867/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4271 - val_loss: 9.3056\n",
      "Epoch 5868/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4268 - val_loss: 9.3060\n",
      "Epoch 5869/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4265 - val_loss: 9.3063\n",
      "Epoch 5870/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4262 - val_loss: 9.3067\n",
      "Epoch 5871/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4259 - val_loss: 9.3071\n",
      "Epoch 5872/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4256 - val_loss: 9.3073\n",
      "Epoch 5873/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4253 - val_loss: 9.3075\n",
      "Epoch 5874/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4250 - val_loss: 9.3077\n",
      "Epoch 5875/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4247 - val_loss: 9.3078\n",
      "Epoch 5876/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4244 - val_loss: 9.3080\n",
      "Epoch 5877/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4241 - val_loss: 9.3083\n",
      "Epoch 5878/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4238 - val_loss: 9.3086\n",
      "Epoch 5879/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4235 - val_loss: 9.3090\n",
      "Epoch 5880/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4232 - val_loss: 9.3094\n",
      "Epoch 5881/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4229 - val_loss: 9.3096\n",
      "Epoch 5882/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4226 - val_loss: 9.3099\n",
      "Epoch 5883/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4223 - val_loss: 9.3101\n",
      "Epoch 5884/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.4220 - val_loss: 9.3104\n",
      "Epoch 5885/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4217 - val_loss: 9.3107\n",
      "Epoch 5886/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4214 - val_loss: 9.3109\n",
      "Epoch 5887/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4211 - val_loss: 9.3111\n",
      "Epoch 5888/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4208 - val_loss: 9.3114\n",
      "Epoch 5889/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4205 - val_loss: 9.3118\n",
      "Epoch 5890/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4202 - val_loss: 9.3121\n",
      "Epoch 5891/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4199 - val_loss: 9.3124\n",
      "Epoch 5892/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.4196 - val_loss: 9.3126\n",
      "Epoch 5893/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4193 - val_loss: 9.3128\n",
      "Epoch 5894/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4190 - val_loss: 9.3130\n",
      "Epoch 5895/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4187 - val_loss: 9.3133\n",
      "Epoch 5896/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4184 - val_loss: 9.3136\n",
      "Epoch 5897/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4181 - val_loss: 9.3139\n",
      "Epoch 5898/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4178 - val_loss: 9.3141\n",
      "Epoch 5899/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4175 - val_loss: 9.3144\n",
      "Epoch 5900/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4172 - val_loss: 9.3147\n",
      "Epoch 5901/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4169 - val_loss: 9.3150\n",
      "Epoch 5902/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4166 - val_loss: 9.3152\n",
      "Epoch 5903/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4163 - val_loss: 9.3155\n",
      "Epoch 5904/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4160 - val_loss: 9.3158\n",
      "Epoch 5905/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.4157 - val_loss: 9.3161\n",
      "Epoch 5906/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4154 - val_loss: 9.3164\n",
      "Epoch 5907/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4151 - val_loss: 9.3166\n",
      "Epoch 5908/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4148 - val_loss: 9.3169\n",
      "Epoch 5909/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.4145 - val_loss: 9.3172\n",
      "Epoch 5910/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4142 - val_loss: 9.3174\n",
      "Epoch 5911/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4139 - val_loss: 9.3177\n",
      "Epoch 5912/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4136 - val_loss: 9.3179\n",
      "Epoch 5913/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4133 - val_loss: 9.3181\n",
      "Epoch 5914/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4130 - val_loss: 9.3184\n",
      "Epoch 5915/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4127 - val_loss: 9.3187\n",
      "Epoch 5916/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4125 - val_loss: 9.3190\n",
      "Epoch 5917/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4122 - val_loss: 9.3192\n",
      "Epoch 5918/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4119 - val_loss: 9.3195\n",
      "Epoch 5919/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4116 - val_loss: 9.3198\n",
      "Epoch 5920/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4113 - val_loss: 9.3201\n",
      "Epoch 5921/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4110 - val_loss: 9.3202\n",
      "Epoch 5922/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4107 - val_loss: 9.3205\n",
      "Epoch 5923/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4104 - val_loss: 9.3208\n",
      "Epoch 5924/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4101 - val_loss: 9.3211\n",
      "Epoch 5925/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4098 - val_loss: 9.3215\n",
      "Epoch 5926/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4095 - val_loss: 9.3218\n",
      "Epoch 5927/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4092 - val_loss: 9.3221\n",
      "Epoch 5928/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4089 - val_loss: 9.3222\n",
      "Epoch 5929/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4086 - val_loss: 9.3224\n",
      "Epoch 5930/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4083 - val_loss: 9.3226\n",
      "Epoch 5931/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.4080 - val_loss: 9.3229\n",
      "Epoch 5932/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4077 - val_loss: 9.3232\n",
      "Epoch 5933/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4074 - val_loss: 9.3235\n",
      "Epoch 5934/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4071 - val_loss: 9.3237\n",
      "Epoch 5935/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.4068 - val_loss: 9.3240\n",
      "Epoch 5936/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4065 - val_loss: 9.3243\n",
      "Epoch 5937/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.4062 - val_loss: 9.3246\n",
      "Epoch 5938/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.4059 - val_loss: 9.3249\n",
      "Epoch 5939/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4056 - val_loss: 9.3251\n",
      "Epoch 5940/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4053 - val_loss: 9.3254\n",
      "Epoch 5941/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4050 - val_loss: 9.3257\n",
      "Epoch 5942/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4047 - val_loss: 9.3260\n",
      "Epoch 5943/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4044 - val_loss: 9.3262\n",
      "Epoch 5944/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4041 - val_loss: 9.3265\n",
      "Epoch 5945/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4038 - val_loss: 9.3268\n",
      "Epoch 5946/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4035 - val_loss: 9.3271\n",
      "Epoch 5947/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.4032 - val_loss: 9.3273\n",
      "Epoch 5948/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4029 - val_loss: 9.3275\n",
      "Epoch 5949/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4026 - val_loss: 9.3277\n",
      "Epoch 5950/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4023 - val_loss: 9.3279\n",
      "Epoch 5951/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4020 - val_loss: 9.3282\n",
      "Epoch 5952/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4017 - val_loss: 9.3284\n",
      "Epoch 5953/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.4014 - val_loss: 9.3287\n",
      "Epoch 5954/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4011 - val_loss: 9.3291\n",
      "Epoch 5955/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4008 - val_loss: 9.3294\n",
      "Epoch 5956/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4005 - val_loss: 9.3296\n",
      "Epoch 5957/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4002 - val_loss: 9.3298\n",
      "Epoch 5958/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3999 - val_loss: 9.3300\n",
      "Epoch 5959/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3996 - val_loss: 9.3303\n",
      "Epoch 5960/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3993 - val_loss: 9.3305\n",
      "Epoch 5961/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3990 - val_loss: 9.3308\n",
      "Epoch 5962/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3987 - val_loss: 9.3311\n",
      "Epoch 5963/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3984 - val_loss: 9.3315\n",
      "Epoch 5964/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3981 - val_loss: 9.3318\n",
      "Epoch 5965/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3978 - val_loss: 9.3321\n",
      "Epoch 5966/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3975 - val_loss: 9.3323\n",
      "Epoch 5967/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3972 - val_loss: 9.3324\n",
      "Epoch 5968/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3969 - val_loss: 9.3326\n",
      "Epoch 5969/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3966 - val_loss: 9.3328\n",
      "Epoch 5970/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3963 - val_loss: 9.3331\n",
      "Epoch 5971/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3960 - val_loss: 9.3335\n",
      "Epoch 5972/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3957 - val_loss: 9.3339\n",
      "Epoch 5973/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3954 - val_loss: 9.3342\n",
      "Epoch 5974/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3951 - val_loss: 9.3345\n",
      "Epoch 5975/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3948 - val_loss: 9.3347\n",
      "Epoch 5976/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3945 - val_loss: 9.3349\n",
      "Epoch 5977/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3942 - val_loss: 9.3351\n",
      "Epoch 5978/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3939 - val_loss: 9.3353\n",
      "Epoch 5979/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3936 - val_loss: 9.3356\n",
      "Epoch 5980/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3933 - val_loss: 9.3358\n",
      "Epoch 5981/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3930 - val_loss: 9.3361\n",
      "Epoch 5982/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3927 - val_loss: 9.3364\n",
      "Epoch 5983/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3924 - val_loss: 9.3367\n",
      "Epoch 5984/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3921 - val_loss: 9.3371\n",
      "Epoch 5985/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3918 - val_loss: 9.3373\n",
      "Epoch 5986/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.391 - 0s 31ms/step - loss: 4.3915 - val_loss: 9.3376\n",
      "Epoch 5987/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3912 - val_loss: 9.3378\n",
      "Epoch 5988/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3909 - val_loss: 9.3380\n",
      "Epoch 5989/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3906 - val_loss: 9.3381\n",
      "Epoch 5990/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3903 - val_loss: 9.3383\n",
      "Epoch 5991/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3900 - val_loss: 9.3386\n",
      "Epoch 5992/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3897 - val_loss: 9.3390\n",
      "Epoch 5993/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3894 - val_loss: 9.3393\n",
      "Epoch 5994/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3891 - val_loss: 9.3395\n",
      "Epoch 5995/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3888 - val_loss: 9.3398\n",
      "Epoch 5996/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3885 - val_loss: 9.3401\n",
      "Epoch 5997/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3882 - val_loss: 9.3404\n",
      "Epoch 5998/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3879 - val_loss: 9.3406\n",
      "Epoch 5999/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3876 - val_loss: 9.3407\n",
      "Epoch 6000/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3873 - val_loss: 9.3409\n",
      "Epoch 6001/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3870 - val_loss: 9.3412\n",
      "Epoch 6002/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3867 - val_loss: 9.3415\n",
      "Epoch 6003/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3864 - val_loss: 9.3418\n",
      "Epoch 6004/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3861 - val_loss: 9.3420\n",
      "Epoch 6005/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3858 - val_loss: 9.3423\n",
      "Epoch 6006/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3855 - val_loss: 9.3426\n",
      "Epoch 6007/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3852 - val_loss: 9.3429\n",
      "Epoch 6008/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3849 - val_loss: 9.3432\n",
      "Epoch 6009/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3846 - val_loss: 9.3434\n",
      "Epoch 6010/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3843 - val_loss: 9.3435\n",
      "Epoch 6011/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3840 - val_loss: 9.3437\n",
      "Epoch 6012/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3837 - val_loss: 9.3439\n",
      "Epoch 6013/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3834 - val_loss: 9.3443\n",
      "Epoch 6014/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3831 - val_loss: 9.3446\n",
      "Epoch 6015/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3828 - val_loss: 9.3450\n",
      "Epoch 6016/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3825 - val_loss: 9.3453\n",
      "Epoch 6017/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3822 - val_loss: 9.3456\n",
      "Epoch 6018/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3819 - val_loss: 9.3458\n",
      "Epoch 6019/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3816 - val_loss: 9.3459\n",
      "Epoch 6020/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3813 - val_loss: 9.3461\n",
      "Epoch 6021/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3810 - val_loss: 9.3463\n",
      "Epoch 6022/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3807 - val_loss: 9.3466\n",
      "Epoch 6023/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3804 - val_loss: 9.3469\n",
      "Epoch 6024/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3801 - val_loss: 9.3472\n",
      "Epoch 6025/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3798 - val_loss: 9.3475\n",
      "Epoch 6026/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3795 - val_loss: 9.3478\n",
      "Epoch 6027/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3792 - val_loss: 9.3481\n",
      "Epoch 6028/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3789 - val_loss: 9.3484\n",
      "Epoch 6029/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3786 - val_loss: 9.3487\n",
      "Epoch 6030/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3783 - val_loss: 9.3488\n",
      "Epoch 6031/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3780 - val_loss: 9.3490\n",
      "Epoch 6032/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3777 - val_loss: 9.3492\n",
      "Epoch 6033/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3774 - val_loss: 9.3495\n",
      "Epoch 6034/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3771 - val_loss: 9.3499\n",
      "Epoch 6035/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3768 - val_loss: 9.3502\n",
      "Epoch 6036/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3765 - val_loss: 9.3505\n",
      "Epoch 6037/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3762 - val_loss: 9.3508\n",
      "Epoch 6038/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3759 - val_loss: 9.3510\n",
      "Epoch 6039/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3756 - val_loss: 9.3513\n",
      "Epoch 6040/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3753 - val_loss: 9.3515\n",
      "Epoch 6041/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3750 - val_loss: 9.3519\n",
      "Epoch 6042/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3747 - val_loss: 9.3523\n",
      "Epoch 6043/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3744 - val_loss: 9.3527\n",
      "Epoch 6044/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3741 - val_loss: 9.3530\n",
      "Epoch 6045/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3738 - val_loss: 9.3534\n",
      "Epoch 6046/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3735 - val_loss: 9.3538\n",
      "Epoch 6047/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3732 - val_loss: 9.3543\n",
      "Epoch 6048/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3729 - val_loss: 9.3547\n",
      "Epoch 6049/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3726 - val_loss: 9.3550\n",
      "Epoch 6050/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3723 - val_loss: 9.3554\n",
      "Epoch 6051/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3720 - val_loss: 9.3558\n",
      "Epoch 6052/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3717 - val_loss: 9.3564\n",
      "Epoch 6053/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3714 - val_loss: 9.3568\n",
      "Epoch 6054/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3711 - val_loss: 9.3572\n",
      "Epoch 6055/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3708 - val_loss: 9.3577\n",
      "Epoch 6056/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3705 - val_loss: 9.3582\n",
      "Epoch 6057/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3702 - val_loss: 9.3586\n",
      "Epoch 6058/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3699 - val_loss: 9.3589\n",
      "Epoch 6059/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3696 - val_loss: 9.3591\n",
      "Epoch 6060/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3693 - val_loss: 9.3593\n",
      "Epoch 6061/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3690 - val_loss: 9.3596\n",
      "Epoch 6062/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3687 - val_loss: 9.3600\n",
      "Epoch 6063/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3684 - val_loss: 9.3603\n",
      "Epoch 6064/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3681 - val_loss: 9.3606\n",
      "Epoch 6065/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3678 - val_loss: 9.3608\n",
      "Epoch 6066/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3675 - val_loss: 9.3610\n",
      "Epoch 6067/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3672 - val_loss: 9.3613\n",
      "Epoch 6068/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3669 - val_loss: 9.3615\n",
      "Epoch 6069/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.3666 - val_loss: 9.3617\n",
      "Epoch 6070/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3663 - val_loss: 9.3620\n",
      "Epoch 6071/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3660 - val_loss: 9.3622\n",
      "Epoch 6072/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3657 - val_loss: 9.3625\n",
      "Epoch 6073/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3654 - val_loss: 9.3627\n",
      "Epoch 6074/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3651 - val_loss: 9.3629\n",
      "Epoch 6075/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3648 - val_loss: 9.3631\n",
      "Epoch 6076/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3645 - val_loss: 9.3632\n",
      "Epoch 6077/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3642 - val_loss: 9.3633\n",
      "Epoch 6078/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3639 - val_loss: 9.3635\n",
      "Epoch 6079/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3636 - val_loss: 9.3637\n",
      "Epoch 6080/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3633 - val_loss: 9.3638\n",
      "Epoch 6081/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3630 - val_loss: 9.3640\n",
      "Epoch 6082/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3627 - val_loss: 9.3643\n",
      "Epoch 6083/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3624 - val_loss: 9.3645\n",
      "Epoch 6084/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3621 - val_loss: 9.3648\n",
      "Epoch 6085/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3618 - val_loss: 9.3649\n",
      "Epoch 6086/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3615 - val_loss: 9.3651\n",
      "Epoch 6087/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3611 - val_loss: 9.3652\n",
      "Epoch 6088/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3608 - val_loss: 9.3653\n",
      "Epoch 6089/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.360 - 0s 30ms/step - loss: 4.3605 - val_loss: 9.3655\n",
      "Epoch 6090/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3602 - val_loss: 9.3657\n",
      "Epoch 6091/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.3599 - val_loss: 9.3658\n",
      "Epoch 6092/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3596 - val_loss: 9.3660\n",
      "Epoch 6093/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3593 - val_loss: 9.3662\n",
      "Epoch 6094/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3590 - val_loss: 9.3664\n",
      "Epoch 6095/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3587 - val_loss: 9.3665\n",
      "Epoch 6096/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3584 - val_loss: 9.3667\n",
      "Epoch 6097/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3581 - val_loss: 9.3669\n",
      "Epoch 6098/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3578 - val_loss: 9.3670\n",
      "Epoch 6099/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3575 - val_loss: 9.3672\n",
      "Epoch 6100/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3572 - val_loss: 9.3674\n",
      "Epoch 6101/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3569 - val_loss: 9.3675\n",
      "Epoch 6102/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3566 - val_loss: 9.3678\n",
      "Epoch 6103/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3563 - val_loss: 9.3681\n",
      "Epoch 6104/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3560 - val_loss: 9.3683\n",
      "Epoch 6105/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3557 - val_loss: 9.3686\n",
      "Epoch 6106/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3554 - val_loss: 9.3688\n",
      "Epoch 6107/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3551 - val_loss: 9.3691\n",
      "Epoch 6108/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3548 - val_loss: 9.3692\n",
      "Epoch 6109/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3545 - val_loss: 9.3693\n",
      "Epoch 6110/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3542 - val_loss: 9.3694\n",
      "Epoch 6111/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3539 - val_loss: 9.3696\n",
      "Epoch 6112/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3536 - val_loss: 9.3698\n",
      "Epoch 6113/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3533 - val_loss: 9.3700\n",
      "Epoch 6114/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3530 - val_loss: 9.3703\n",
      "Epoch 6115/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3527 - val_loss: 9.3707\n",
      "Epoch 6116/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3524 - val_loss: 9.3709\n",
      "Epoch 6117/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3521 - val_loss: 9.3712\n",
      "Epoch 6118/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3518 - val_loss: 9.3714\n",
      "Epoch 6119/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3515 - val_loss: 9.3715\n",
      "Epoch 6120/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3512 - val_loss: 9.3717\n",
      "Epoch 6121/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3509 - val_loss: 9.3719\n",
      "Epoch 6122/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3506 - val_loss: 9.3721\n",
      "Epoch 6123/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3503 - val_loss: 9.3724\n",
      "Epoch 6124/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3500 - val_loss: 9.3727\n",
      "Epoch 6125/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3497 - val_loss: 9.3730\n",
      "Epoch 6126/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3494 - val_loss: 9.3732\n",
      "Epoch 6127/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3491 - val_loss: 9.3735\n",
      "Epoch 6128/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3488 - val_loss: 9.3737\n",
      "Epoch 6129/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3485 - val_loss: 9.3738\n",
      "Epoch 6130/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3482 - val_loss: 9.3740\n",
      "Epoch 6131/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3479 - val_loss: 9.3743\n",
      "Epoch 6132/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3476 - val_loss: 9.3746\n",
      "Epoch 6133/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3473 - val_loss: 9.3748\n",
      "Epoch 6134/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3470 - val_loss: 9.3750\n",
      "Epoch 6135/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3467 - val_loss: 9.3753\n",
      "Epoch 6136/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3464 - val_loss: 9.3755\n",
      "Epoch 6137/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3461 - val_loss: 9.3757\n",
      "Epoch 6138/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3458 - val_loss: 9.3759\n",
      "Epoch 6139/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3455 - val_loss: 9.3761\n",
      "Epoch 6140/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3452 - val_loss: 9.3763\n",
      "Epoch 6141/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3449 - val_loss: 9.3765\n",
      "Epoch 6142/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3446 - val_loss: 9.3767\n",
      "Epoch 6143/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3443 - val_loss: 9.3770\n",
      "Epoch 6144/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3440 - val_loss: 9.3773\n",
      "Epoch 6145/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3437 - val_loss: 9.3775\n",
      "Epoch 6146/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3434 - val_loss: 9.3778\n",
      "Epoch 6147/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3431 - val_loss: 9.3780\n",
      "Epoch 6148/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3428 - val_loss: 9.3782\n",
      "Epoch 6149/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3425 - val_loss: 9.3784\n",
      "Epoch 6150/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3422 - val_loss: 9.3786\n",
      "Epoch 6151/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3419 - val_loss: 9.3789\n",
      "Epoch 6152/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3416 - val_loss: 9.3791\n",
      "Epoch 6153/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3413 - val_loss: 9.3793\n",
      "Epoch 6154/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3410 - val_loss: 9.3794\n",
      "Epoch 6155/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3407 - val_loss: 9.3795\n",
      "Epoch 6156/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3404 - val_loss: 9.3796\n",
      "Epoch 6157/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3401 - val_loss: 9.3798\n",
      "Epoch 6158/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3398 - val_loss: 9.3802\n",
      "Epoch 6159/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3395 - val_loss: 9.3806\n",
      "Epoch 6160/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3392 - val_loss: 9.3809\n",
      "Epoch 6161/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3389 - val_loss: 9.3810\n",
      "Epoch 6162/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3386 - val_loss: 9.3810\n",
      "Epoch 6163/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3383 - val_loss: 9.3811\n",
      "Epoch 6164/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3380 - val_loss: 9.3813\n",
      "Epoch 6165/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3376 - val_loss: 9.3816\n",
      "Epoch 6166/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3373 - val_loss: 9.3819\n",
      "Epoch 6167/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3370 - val_loss: 9.3823\n",
      "Epoch 6168/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3367 - val_loss: 9.3825\n",
      "Epoch 6169/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3364 - val_loss: 9.3826\n",
      "Epoch 6170/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3361 - val_loss: 9.3828\n",
      "Epoch 6171/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3358 - val_loss: 9.3830\n",
      "Epoch 6172/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3355 - val_loss: 9.3833\n",
      "Epoch 6173/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3352 - val_loss: 9.3836\n",
      "Epoch 6174/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3349 - val_loss: 9.3838\n",
      "Epoch 6175/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3346 - val_loss: 9.3839\n",
      "Epoch 6176/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3343 - val_loss: 9.3842\n",
      "Epoch 6177/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3340 - val_loss: 9.3846\n",
      "Epoch 6178/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.3337 - val_loss: 9.3849\n",
      "Epoch 6179/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3334 - val_loss: 9.3851\n",
      "Epoch 6180/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3331 - val_loss: 9.3853\n",
      "Epoch 6181/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3328 - val_loss: 9.3856\n",
      "Epoch 6182/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3325 - val_loss: 9.3858\n",
      "Epoch 6183/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3322 - val_loss: 9.3860\n",
      "Epoch 6184/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3319 - val_loss: 9.3861\n",
      "Epoch 6185/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3316 - val_loss: 9.3862\n",
      "Epoch 6186/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3313 - val_loss: 9.3864\n",
      "Epoch 6187/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3310 - val_loss: 9.3868\n",
      "Epoch 6188/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3307 - val_loss: 9.3871\n",
      "Epoch 6189/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3304 - val_loss: 9.3874\n",
      "Epoch 6190/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3301 - val_loss: 9.3876\n",
      "Epoch 6191/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3298 - val_loss: 9.3879\n",
      "Epoch 6192/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.3295 - val_loss: 9.3881\n",
      "Epoch 6193/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.3292 - val_loss: 9.3882\n",
      "Epoch 6194/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3289 - val_loss: 9.3883\n",
      "Epoch 6195/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3286 - val_loss: 9.3886\n",
      "Epoch 6196/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3283 - val_loss: 9.3889\n",
      "Epoch 6197/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3280 - val_loss: 9.3892\n",
      "Epoch 6198/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3277 - val_loss: 9.3894\n",
      "Epoch 6199/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3274 - val_loss: 9.3897\n",
      "Epoch 6200/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3271 - val_loss: 9.3900\n",
      "Epoch 6201/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3268 - val_loss: 9.3903\n",
      "Epoch 6202/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3265 - val_loss: 9.3906\n",
      "Epoch 6203/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3262 - val_loss: 9.3908\n",
      "Epoch 6204/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3259 - val_loss: 9.3909\n",
      "Epoch 6205/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3256 - val_loss: 9.3912\n",
      "Epoch 6206/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3253 - val_loss: 9.3915\n",
      "Epoch 6207/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3250 - val_loss: 9.3917\n",
      "Epoch 6208/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3247 - val_loss: 9.3920\n",
      "Epoch 6209/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3244 - val_loss: 9.3924\n",
      "Epoch 6210/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3241 - val_loss: 9.3927\n",
      "Epoch 6211/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3238 - val_loss: 9.3930\n",
      "Epoch 6212/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3235 - val_loss: 9.3933\n",
      "Epoch 6213/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3232 - val_loss: 9.3934\n",
      "Epoch 6214/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3229 - val_loss: 9.3936\n",
      "Epoch 6215/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3226 - val_loss: 9.3939\n",
      "Epoch 6216/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3223 - val_loss: 9.3942\n",
      "Epoch 6217/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3220 - val_loss: 9.3944\n",
      "Epoch 6218/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3217 - val_loss: 9.3947\n",
      "Epoch 6219/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3214 - val_loss: 9.3950\n",
      "Epoch 6220/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3211 - val_loss: 9.3954\n",
      "Epoch 6221/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3208 - val_loss: 9.3956\n",
      "Epoch 6222/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3205 - val_loss: 9.3958\n",
      "Epoch 6223/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3202 - val_loss: 9.3961\n",
      "Epoch 6224/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3199 - val_loss: 9.3964\n",
      "Epoch 6225/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3196 - val_loss: 9.3966\n",
      "Epoch 6226/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3193 - val_loss: 9.3968\n",
      "Epoch 6227/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3190 - val_loss: 9.3971\n",
      "Epoch 6228/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3187 - val_loss: 9.3975\n",
      "Epoch 6229/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3184 - val_loss: 9.3979\n",
      "Epoch 6230/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3181 - val_loss: 9.3981\n",
      "Epoch 6231/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3178 - val_loss: 9.3982\n",
      "Epoch 6232/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3175 - val_loss: 9.3984\n",
      "Epoch 6233/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3172 - val_loss: 9.3988\n",
      "Epoch 6234/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3169 - val_loss: 9.3991\n",
      "Epoch 6235/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3166 - val_loss: 9.3994\n",
      "Epoch 6236/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3163 - val_loss: 9.3996\n",
      "Epoch 6237/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3160 - val_loss: 9.3999\n",
      "Epoch 6238/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3157 - val_loss: 9.4002\n",
      "Epoch 6239/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3154 - val_loss: 9.4004\n",
      "Epoch 6240/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3151 - val_loss: 9.4006\n",
      "Epoch 6241/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3148 - val_loss: 9.4009\n",
      "Epoch 6242/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3145 - val_loss: 9.4013\n",
      "Epoch 6243/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3142 - val_loss: 9.4016\n",
      "Epoch 6244/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.3139 - val_loss: 9.4019\n",
      "Epoch 6245/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3136 - val_loss: 9.4021\n",
      "Epoch 6246/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3133 - val_loss: 9.4022\n",
      "Epoch 6247/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3130 - val_loss: 9.4025\n",
      "Epoch 6248/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3127 - val_loss: 9.4028\n",
      "Epoch 6249/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3124 - val_loss: 9.4031\n",
      "Epoch 6250/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3120 - val_loss: 9.4034\n",
      "Epoch 6251/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.3117 - val_loss: 9.4037\n",
      "Epoch 6252/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.3114 - val_loss: 9.4040\n",
      "Epoch 6253/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.3111 - val_loss: 9.4043\n",
      "Epoch 6254/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3108 - val_loss: 9.4045\n",
      "Epoch 6255/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3105 - val_loss: 9.4047\n",
      "Epoch 6256/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3102 - val_loss: 9.4049\n",
      "Epoch 6257/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3099 - val_loss: 9.4052\n",
      "Epoch 6258/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3096 - val_loss: 9.4055\n",
      "Epoch 6259/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3093 - val_loss: 9.4058\n",
      "Epoch 6260/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3090 - val_loss: 9.4062\n",
      "Epoch 6261/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3087 - val_loss: 9.4065\n",
      "Epoch 6262/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3084 - val_loss: 9.4067\n",
      "Epoch 6263/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3081 - val_loss: 9.4069\n",
      "Epoch 6264/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3078 - val_loss: 9.4072\n",
      "Epoch 6265/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3075 - val_loss: 9.4075\n",
      "Epoch 6266/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3072 - val_loss: 9.4079\n",
      "Epoch 6267/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3069 - val_loss: 9.4083\n",
      "Epoch 6268/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3066 - val_loss: 9.4085\n",
      "Epoch 6269/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3063 - val_loss: 9.4088\n",
      "Epoch 6270/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3060 - val_loss: 9.4091\n",
      "Epoch 6271/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3057 - val_loss: 9.4093\n",
      "Epoch 6272/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3054 - val_loss: 9.4095\n",
      "Epoch 6273/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3051 - val_loss: 9.4097\n",
      "Epoch 6274/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3048 - val_loss: 9.4100\n",
      "Epoch 6275/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.3045 - val_loss: 9.4104\n",
      "Epoch 6276/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3042 - val_loss: 9.4107\n",
      "Epoch 6277/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3039 - val_loss: 9.4110\n",
      "Epoch 6278/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3036 - val_loss: 9.4113\n",
      "Epoch 6279/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3033 - val_loss: 9.4116\n",
      "Epoch 6280/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3030 - val_loss: 9.4119\n",
      "Epoch 6281/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3027 - val_loss: 9.4122\n",
      "Epoch 6282/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3024 - val_loss: 9.4125\n",
      "Epoch 6283/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3021 - val_loss: 9.4129\n",
      "Epoch 6284/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3018 - val_loss: 9.4132\n",
      "Epoch 6285/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3015 - val_loss: 9.4135\n",
      "Epoch 6286/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3012 - val_loss: 9.4138\n",
      "Epoch 6287/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3009 - val_loss: 9.4139\n",
      "Epoch 6288/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3006 - val_loss: 9.4141\n",
      "Epoch 6289/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3003 - val_loss: 9.4144\n",
      "Epoch 6290/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3000 - val_loss: 9.4147\n",
      "Epoch 6291/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2997 - val_loss: 9.4150\n",
      "Epoch 6292/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2994 - val_loss: 9.4154\n",
      "Epoch 6293/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2991 - val_loss: 9.4158\n",
      "Epoch 6294/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2988 - val_loss: 9.4161\n",
      "Epoch 6295/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2985 - val_loss: 9.4163\n",
      "Epoch 6296/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2982 - val_loss: 9.4165\n",
      "Epoch 6297/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2979 - val_loss: 9.4168\n",
      "Epoch 6298/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2976 - val_loss: 9.4172\n",
      "Epoch 6299/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2973 - val_loss: 9.4175\n",
      "Epoch 6300/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2970 - val_loss: 9.4177\n",
      "Epoch 6301/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2967 - val_loss: 9.4180\n",
      "Epoch 6302/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2964 - val_loss: 9.4182\n",
      "Epoch 6303/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2961 - val_loss: 9.4185\n",
      "Epoch 6304/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2958 - val_loss: 9.4188\n",
      "Epoch 6305/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2955 - val_loss: 9.4191\n",
      "Epoch 6306/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2952 - val_loss: 9.4194\n",
      "Epoch 6307/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2949 - val_loss: 9.4198\n",
      "Epoch 6308/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2946 - val_loss: 9.4201\n",
      "Epoch 6309/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2943 - val_loss: 9.4204\n",
      "Epoch 6310/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2940 - val_loss: 9.4206\n",
      "Epoch 6311/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2937 - val_loss: 9.4209\n",
      "Epoch 6312/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2934 - val_loss: 9.4212\n",
      "Epoch 6313/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2931 - val_loss: 9.4216\n",
      "Epoch 6314/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2928 - val_loss: 9.4220\n",
      "Epoch 6315/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2925 - val_loss: 9.4223\n",
      "Epoch 6316/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2922 - val_loss: 9.4225\n",
      "Epoch 6317/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2919 - val_loss: 9.4227\n",
      "Epoch 6318/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2916 - val_loss: 9.4228\n",
      "Epoch 6319/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2913 - val_loss: 9.4230\n",
      "Epoch 6320/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2910 - val_loss: 9.4233\n",
      "Epoch 6321/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2907 - val_loss: 9.4237\n",
      "Epoch 6322/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2904 - val_loss: 9.4241\n",
      "Epoch 6323/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2901 - val_loss: 9.4245\n",
      "Epoch 6324/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2898 - val_loss: 9.4248\n",
      "Epoch 6325/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2895 - val_loss: 9.4251\n",
      "Epoch 6326/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2892 - val_loss: 9.4253\n",
      "Epoch 6327/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2889 - val_loss: 9.4255\n",
      "Epoch 6328/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2886 - val_loss: 9.4257\n",
      "Epoch 6329/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2883 - val_loss: 9.4260\n",
      "Epoch 6330/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2880 - val_loss: 9.4263\n",
      "Epoch 6331/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2877 - val_loss: 9.4265\n",
      "Epoch 6332/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2874 - val_loss: 9.4269\n",
      "Epoch 6333/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2870 - val_loss: 9.4273\n",
      "Epoch 6334/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2867 - val_loss: 9.4276\n",
      "Epoch 6335/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2864 - val_loss: 9.4279\n",
      "Epoch 6336/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2861 - val_loss: 9.4281\n",
      "Epoch 6337/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2858 - val_loss: 9.4283\n",
      "Epoch 6338/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2855 - val_loss: 9.4286\n",
      "Epoch 6339/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2852 - val_loss: 9.4288\n",
      "Epoch 6340/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2849 - val_loss: 9.4291\n",
      "Epoch 6341/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2846 - val_loss: 9.4294\n",
      "Epoch 6342/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2843 - val_loss: 9.4297\n",
      "Epoch 6343/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2840 - val_loss: 9.4301\n",
      "Epoch 6344/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2837 - val_loss: 9.4304\n",
      "Epoch 6345/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2834 - val_loss: 9.4306\n",
      "Epoch 6346/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2831 - val_loss: 9.4309\n",
      "Epoch 6347/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2828 - val_loss: 9.4312\n",
      "Epoch 6348/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2825 - val_loss: 9.4315\n",
      "Epoch 6349/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2822 - val_loss: 9.4317\n",
      "Epoch 6350/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2819 - val_loss: 9.4319\n",
      "Epoch 6351/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2816 - val_loss: 9.4323\n",
      "Epoch 6352/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2813 - val_loss: 9.4328\n",
      "Epoch 6353/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2810 - val_loss: 9.4330\n",
      "Epoch 6354/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2807 - val_loss: 9.4332\n",
      "Epoch 6355/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2804 - val_loss: 9.4335\n",
      "Epoch 6356/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2801 - val_loss: 9.4338\n",
      "Epoch 6357/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2798 - val_loss: 9.4340\n",
      "Epoch 6358/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2795 - val_loss: 9.4342\n",
      "Epoch 6359/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2792 - val_loss: 9.4345\n",
      "Epoch 6360/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2789 - val_loss: 9.4349\n",
      "Epoch 6361/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2786 - val_loss: 9.4352\n",
      "Epoch 6362/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2783 - val_loss: 9.4355\n",
      "Epoch 6363/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2780 - val_loss: 9.4357\n",
      "Epoch 6364/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2777 - val_loss: 9.4360\n",
      "Epoch 6365/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2774 - val_loss: 9.4364\n",
      "Epoch 6366/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2771 - val_loss: 9.4366\n",
      "Epoch 6367/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2768 - val_loss: 9.4368\n",
      "Epoch 6368/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2765 - val_loss: 9.4370\n",
      "Epoch 6369/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2762 - val_loss: 9.4373\n",
      "Epoch 6370/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2759 - val_loss: 9.4376\n",
      "Epoch 6371/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2756 - val_loss: 9.4379\n",
      "Epoch 6372/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2753 - val_loss: 9.4382\n",
      "Epoch 6373/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2750 - val_loss: 9.4385\n",
      "Epoch 6374/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2747 - val_loss: 9.4388\n",
      "Epoch 6375/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2744 - val_loss: 9.4389\n",
      "Epoch 6376/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2741 - val_loss: 9.4391\n",
      "Epoch 6377/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2738 - val_loss: 9.4394\n",
      "Epoch 6378/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2735 - val_loss: 9.4396\n",
      "Epoch 6379/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2732 - val_loss: 9.4400\n",
      "Epoch 6380/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2729 - val_loss: 9.4404\n",
      "Epoch 6381/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2726 - val_loss: 9.4407\n",
      "Epoch 6382/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2723 - val_loss: 9.4409\n",
      "Epoch 6383/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2720 - val_loss: 9.4411\n",
      "Epoch 6384/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2717 - val_loss: 9.4414\n",
      "Epoch 6385/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2714 - val_loss: 9.4416\n",
      "Epoch 6386/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2711 - val_loss: 9.4419\n",
      "Epoch 6387/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2708 - val_loss: 9.4423\n",
      "Epoch 6388/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2705 - val_loss: 9.4427\n",
      "Epoch 6389/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2702 - val_loss: 9.4429\n",
      "Epoch 6390/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2699 - val_loss: 9.4431\n",
      "Epoch 6391/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2696 - val_loss: 9.4432\n",
      "Epoch 6392/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2693 - val_loss: 9.4434\n",
      "Epoch 6393/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2690 - val_loss: 9.4437\n",
      "Epoch 6394/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2687 - val_loss: 9.4440\n",
      "Epoch 6395/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2684 - val_loss: 9.4444\n",
      "Epoch 6396/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.2681 - val_loss: 9.4447\n",
      "Epoch 6397/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2678 - val_loss: 9.4450\n",
      "Epoch 6398/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2675 - val_loss: 9.4452\n",
      "Epoch 6399/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2672 - val_loss: 9.4454\n",
      "Epoch 6400/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2669 - val_loss: 9.4455\n",
      "Epoch 6401/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2666 - val_loss: 9.4457\n",
      "Epoch 6402/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2663 - val_loss: 9.4461\n",
      "Epoch 6403/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2660 - val_loss: 9.4464\n",
      "Epoch 6404/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2656 - val_loss: 9.4468\n",
      "Epoch 6405/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2653 - val_loss: 9.4471\n",
      "Epoch 6406/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2650 - val_loss: 9.4474\n",
      "Epoch 6407/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2647 - val_loss: 9.4477\n",
      "Epoch 6408/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2644 - val_loss: 9.4479\n",
      "Epoch 6409/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2641 - val_loss: 9.4481\n",
      "Epoch 6410/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2638 - val_loss: 9.4484\n",
      "Epoch 6411/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.2635 - val_loss: 9.4487\n",
      "Epoch 6412/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2632 - val_loss: 9.4490\n",
      "Epoch 6413/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2629 - val_loss: 9.4493\n",
      "Epoch 6414/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.2626 - val_loss: 9.4495\n",
      "Epoch 6415/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.2623 - val_loss: 9.4498\n",
      "Epoch 6416/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2620 - val_loss: 9.4501\n",
      "Epoch 6417/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2617 - val_loss: 9.4504\n",
      "Epoch 6418/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2614 - val_loss: 9.4508\n",
      "Epoch 6419/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2611 - val_loss: 9.4511\n",
      "Epoch 6420/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2608 - val_loss: 9.4514\n",
      "Epoch 6421/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2605 - val_loss: 9.4516\n",
      "Epoch 6422/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2602 - val_loss: 9.4517\n",
      "Epoch 6423/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2599 - val_loss: 9.4520\n",
      "Epoch 6424/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2596 - val_loss: 9.4522\n",
      "Epoch 6425/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2593 - val_loss: 9.4525\n",
      "Epoch 6426/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2590 - val_loss: 9.4529\n",
      "Epoch 6427/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2587 - val_loss: 9.4533\n",
      "Epoch 6428/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.2584 - val_loss: 9.4537\n",
      "Epoch 6429/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.2581 - val_loss: 9.4539\n",
      "Epoch 6430/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2578 - val_loss: 9.4542\n",
      "Epoch 6431/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2575 - val_loss: 9.4544\n",
      "Epoch 6432/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2572 - val_loss: 9.4546\n",
      "Epoch 6433/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2569 - val_loss: 9.4549\n",
      "Epoch 6434/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2566 - val_loss: 9.4552\n",
      "Epoch 6435/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2563 - val_loss: 9.4554\n",
      "Epoch 6436/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2560 - val_loss: 9.4557\n",
      "Epoch 6437/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2557 - val_loss: 9.4559\n",
      "Epoch 6438/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2554 - val_loss: 9.4561\n",
      "Epoch 6439/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2551 - val_loss: 9.4563\n",
      "Epoch 6440/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2548 - val_loss: 9.4565\n",
      "Epoch 6441/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2545 - val_loss: 9.4568\n",
      "Epoch 6442/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2542 - val_loss: 9.4571\n",
      "Epoch 6443/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2539 - val_loss: 9.4575\n",
      "Epoch 6444/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2536 - val_loss: 9.4578\n",
      "Epoch 6445/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2533 - val_loss: 9.4581\n",
      "Epoch 6446/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2530 - val_loss: 9.4584\n",
      "Epoch 6447/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2527 - val_loss: 9.4586\n",
      "Epoch 6448/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2524 - val_loss: 9.4587\n",
      "Epoch 6449/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2521 - val_loss: 9.4590\n",
      "Epoch 6450/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2518 - val_loss: 9.4592\n",
      "Epoch 6451/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2515 - val_loss: 9.4595\n",
      "Epoch 6452/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2512 - val_loss: 9.4598\n",
      "Epoch 6453/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2509 - val_loss: 9.4601\n",
      "Epoch 6454/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2506 - val_loss: 9.4604\n",
      "Epoch 6455/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2503 - val_loss: 9.4607\n",
      "Epoch 6456/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2500 - val_loss: 9.4610\n",
      "Epoch 6457/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2497 - val_loss: 9.4612\n",
      "Epoch 6458/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2494 - val_loss: 9.4613\n",
      "Epoch 6459/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2491 - val_loss: 9.4615\n",
      "Epoch 6460/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2488 - val_loss: 9.4617\n",
      "Epoch 6461/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2485 - val_loss: 9.4620\n",
      "Epoch 6462/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2482 - val_loss: 9.4624\n",
      "Epoch 6463/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2479 - val_loss: 9.4629\n",
      "Epoch 6464/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2476 - val_loss: 9.4633\n",
      "Epoch 6465/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2473 - val_loss: 9.4635\n",
      "Epoch 6466/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2470 - val_loss: 9.4637\n",
      "Epoch 6467/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2467 - val_loss: 9.4639\n",
      "Epoch 6468/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2463 - val_loss: 9.4641\n",
      "Epoch 6469/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2460 - val_loss: 9.4645\n",
      "Epoch 6470/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2457 - val_loss: 9.4649\n",
      "Epoch 6471/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2454 - val_loss: 9.4654\n",
      "Epoch 6472/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2451 - val_loss: 9.4658\n",
      "Epoch 6473/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2448 - val_loss: 9.4661\n",
      "Epoch 6474/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2445 - val_loss: 9.4663\n",
      "Epoch 6475/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2442 - val_loss: 9.4665\n",
      "Epoch 6476/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2439 - val_loss: 9.4666\n",
      "Epoch 6477/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2436 - val_loss: 9.4669\n",
      "Epoch 6478/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2433 - val_loss: 9.4672\n",
      "Epoch 6479/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2430 - val_loss: 9.4676\n",
      "Epoch 6480/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2427 - val_loss: 9.4680\n",
      "Epoch 6481/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2424 - val_loss: 9.4685\n",
      "Epoch 6482/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2421 - val_loss: 9.4689\n",
      "Epoch 6483/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2418 - val_loss: 9.4691\n",
      "Epoch 6484/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2415 - val_loss: 9.4693\n",
      "Epoch 6485/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2412 - val_loss: 9.4695\n",
      "Epoch 6486/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2409 - val_loss: 9.4698\n",
      "Epoch 6487/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2406 - val_loss: 9.4701\n",
      "Epoch 6488/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2403 - val_loss: 9.4703\n",
      "Epoch 6489/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.2400 - val_loss: 9.4706\n",
      "Epoch 6490/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2397 - val_loss: 9.4710\n",
      "Epoch 6491/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2394 - val_loss: 9.4713\n",
      "Epoch 6492/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2391 - val_loss: 9.4715\n",
      "Epoch 6493/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2388 - val_loss: 9.4717\n",
      "Epoch 6494/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2385 - val_loss: 9.4721\n",
      "Epoch 6495/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2382 - val_loss: 9.4724\n",
      "Epoch 6496/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2379 - val_loss: 9.4727\n",
      "Epoch 6497/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2376 - val_loss: 9.4730\n",
      "Epoch 6498/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2373 - val_loss: 9.4733\n",
      "Epoch 6499/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2370 - val_loss: 9.4736\n",
      "Epoch 6500/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2367 - val_loss: 9.4738\n",
      "Epoch 6501/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2364 - val_loss: 9.4741\n",
      "Epoch 6502/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2361 - val_loss: 9.4744\n",
      "Epoch 6503/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2358 - val_loss: 9.4748\n",
      "Epoch 6504/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2355 - val_loss: 9.4751\n",
      "Epoch 6505/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2352 - val_loss: 9.4755\n",
      "Epoch 6506/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2349 - val_loss: 9.4758\n",
      "Epoch 6507/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2346 - val_loss: 9.4761\n",
      "Epoch 6508/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2343 - val_loss: 9.4763\n",
      "Epoch 6509/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2340 - val_loss: 9.4765\n",
      "Epoch 6510/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2337 - val_loss: 9.4768\n",
      "Epoch 6511/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2334 - val_loss: 9.4771\n",
      "Epoch 6512/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2331 - val_loss: 9.4774\n",
      "Epoch 6513/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2328 - val_loss: 9.4777\n",
      "Epoch 6514/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2325 - val_loss: 9.4781\n",
      "Epoch 6515/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2322 - val_loss: 9.4785\n",
      "Epoch 6516/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2319 - val_loss: 9.4788\n",
      "Epoch 6517/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2316 - val_loss: 9.4791\n",
      "Epoch 6518/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2313 - val_loss: 9.4793\n",
      "Epoch 6519/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2310 - val_loss: 9.4795\n",
      "Epoch 6520/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2306 - val_loss: 9.4798\n",
      "Epoch 6521/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2303 - val_loss: 9.4801\n",
      "Epoch 6522/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2300 - val_loss: 9.4806\n",
      "Epoch 6523/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2297 - val_loss: 9.4810\n",
      "Epoch 6524/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2294 - val_loss: 9.4813\n",
      "Epoch 6525/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2291 - val_loss: 9.4815\n",
      "Epoch 6526/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2288 - val_loss: 9.4816\n",
      "Epoch 6527/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2285 - val_loss: 9.4819\n",
      "Epoch 6528/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2282 - val_loss: 9.4822\n",
      "Epoch 6529/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2279 - val_loss: 9.4826\n",
      "Epoch 6530/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2276 - val_loss: 9.4831\n",
      "Epoch 6531/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2273 - val_loss: 9.4836\n",
      "Epoch 6532/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2270 - val_loss: 9.4838\n",
      "Epoch 6533/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2267 - val_loss: 9.4839\n",
      "Epoch 6534/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2264 - val_loss: 9.4840\n",
      "Epoch 6535/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2261 - val_loss: 9.4842\n",
      "Epoch 6536/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2258 - val_loss: 9.4845\n",
      "Epoch 6537/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2255 - val_loss: 9.4849\n",
      "Epoch 6538/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2252 - val_loss: 9.4854\n",
      "Epoch 6539/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2249 - val_loss: 9.4858\n",
      "Epoch 6540/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2246 - val_loss: 9.4861\n",
      "Epoch 6541/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2243 - val_loss: 9.4864\n",
      "Epoch 6542/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2240 - val_loss: 9.4867\n",
      "Epoch 6543/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2237 - val_loss: 9.4869\n",
      "Epoch 6544/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2234 - val_loss: 9.4871\n",
      "Epoch 6545/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2231 - val_loss: 9.4875\n",
      "Epoch 6546/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2228 - val_loss: 9.4878\n",
      "Epoch 6547/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2225 - val_loss: 9.4882\n",
      "Epoch 6548/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2222 - val_loss: 9.4885\n",
      "Epoch 6549/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2219 - val_loss: 9.4888\n",
      "Epoch 6550/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2216 - val_loss: 9.4891\n",
      "Epoch 6551/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2213 - val_loss: 9.4894\n",
      "Epoch 6552/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2210 - val_loss: 9.4897\n",
      "Epoch 6553/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2207 - val_loss: 9.4901\n",
      "Epoch 6554/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2204 - val_loss: 9.4905\n",
      "Epoch 6555/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2201 - val_loss: 9.4908\n",
      "Epoch 6556/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2198 - val_loss: 9.4911\n",
      "Epoch 6557/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2195 - val_loss: 9.4914\n",
      "Epoch 6558/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2192 - val_loss: 9.4916\n",
      "Epoch 6559/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2188 - val_loss: 9.4919\n",
      "Epoch 6560/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2185 - val_loss: 9.4923\n",
      "Epoch 6561/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2182 - val_loss: 9.4926\n",
      "Epoch 6562/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2179 - val_loss: 9.4930\n",
      "Epoch 6563/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2176 - val_loss: 9.4933\n",
      "Epoch 6564/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2173 - val_loss: 9.4936\n",
      "Epoch 6565/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2170 - val_loss: 9.4939\n",
      "Epoch 6566/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2167 - val_loss: 9.4942\n",
      "Epoch 6567/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2164 - val_loss: 9.4946\n",
      "Epoch 6568/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2161 - val_loss: 9.4949\n",
      "Epoch 6569/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2158 - val_loss: 9.4952\n",
      "Epoch 6570/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2155 - val_loss: 9.4955\n",
      "Epoch 6571/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2152 - val_loss: 9.4959\n",
      "Epoch 6572/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2149 - val_loss: 9.4961\n",
      "Epoch 6573/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2146 - val_loss: 9.4963\n",
      "Epoch 6574/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2143 - val_loss: 9.4966\n",
      "Epoch 6575/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2140 - val_loss: 9.4970\n",
      "Epoch 6576/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2137 - val_loss: 9.4974\n",
      "Epoch 6577/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2134 - val_loss: 9.4978\n",
      "Epoch 6578/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2131 - val_loss: 9.4982\n",
      "Epoch 6579/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2128 - val_loss: 9.4983\n",
      "Epoch 6580/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2125 - val_loss: 9.4984\n",
      "Epoch 6581/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2122 - val_loss: 9.4986\n",
      "Epoch 6582/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2119 - val_loss: 9.4988\n",
      "Epoch 6583/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2116 - val_loss: 9.4991\n",
      "Epoch 6584/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2113 - val_loss: 9.4994\n",
      "Epoch 6585/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2110 - val_loss: 9.4998\n",
      "Epoch 6586/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2107 - val_loss: 9.5002\n",
      "Epoch 6587/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2104 - val_loss: 9.5004\n",
      "Epoch 6588/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2101 - val_loss: 9.5005\n",
      "Epoch 6589/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2098 - val_loss: 9.5006\n",
      "Epoch 6590/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2094 - val_loss: 9.5007\n",
      "Epoch 6591/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2091 - val_loss: 9.5009\n",
      "Epoch 6592/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2088 - val_loss: 9.5012\n",
      "Epoch 6593/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2085 - val_loss: 9.5016\n",
      "Epoch 6594/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2082 - val_loss: 9.5021\n",
      "Epoch 6595/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2079 - val_loss: 9.5025\n",
      "Epoch 6596/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2076 - val_loss: 9.5028\n",
      "Epoch 6597/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2073 - val_loss: 9.5029\n",
      "Epoch 6598/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2070 - val_loss: 9.5030\n",
      "Epoch 6599/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2067 - val_loss: 9.5032\n",
      "Epoch 6600/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2064 - val_loss: 9.5034\n",
      "Epoch 6601/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2061 - val_loss: 9.5036\n",
      "Epoch 6602/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2058 - val_loss: 9.5040\n",
      "Epoch 6603/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2055 - val_loss: 9.5044\n",
      "Epoch 6604/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2052 - val_loss: 9.5046\n",
      "Epoch 6605/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2049 - val_loss: 9.5048\n",
      "Epoch 6606/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2046 - val_loss: 9.5049\n",
      "Epoch 6607/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2043 - val_loss: 9.5052\n",
      "Epoch 6608/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2040 - val_loss: 9.5054\n",
      "Epoch 6609/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2037 - val_loss: 9.5057\n",
      "Epoch 6610/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2034 - val_loss: 9.5060\n",
      "Epoch 6611/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2031 - val_loss: 9.5063\n",
      "Epoch 6612/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2028 - val_loss: 9.5066\n",
      "Epoch 6613/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.2025 - val_loss: 9.5069\n",
      "Epoch 6614/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2022 - val_loss: 9.5072\n",
      "Epoch 6615/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2019 - val_loss: 9.5075\n",
      "Epoch 6616/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2015 - val_loss: 9.5078\n",
      "Epoch 6617/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2012 - val_loss: 9.5080\n",
      "Epoch 6618/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2009 - val_loss: 9.5082\n",
      "Epoch 6619/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2006 - val_loss: 9.5085\n",
      "Epoch 6620/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2003 - val_loss: 9.5087\n",
      "Epoch 6621/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2000 - val_loss: 9.5090\n",
      "Epoch 6622/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1997 - val_loss: 9.5093\n",
      "Epoch 6623/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1994 - val_loss: 9.5096\n",
      "Epoch 6624/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1991 - val_loss: 9.5098\n",
      "Epoch 6625/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1988 - val_loss: 9.5101\n",
      "Epoch 6626/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1985 - val_loss: 9.5104\n",
      "Epoch 6627/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1982 - val_loss: 9.5107\n",
      "Epoch 6628/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1979 - val_loss: 9.5110\n",
      "Epoch 6629/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1976 - val_loss: 9.5113\n",
      "Epoch 6630/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1973 - val_loss: 9.5116\n",
      "Epoch 6631/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1970 - val_loss: 9.5119\n",
      "Epoch 6632/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1967 - val_loss: 9.5121\n",
      "Epoch 6633/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1964 - val_loss: 9.5123\n",
      "Epoch 6634/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1961 - val_loss: 9.5125\n",
      "Epoch 6635/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1958 - val_loss: 9.5128\n",
      "Epoch 6636/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1955 - val_loss: 9.5131\n",
      "Epoch 6637/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1952 - val_loss: 9.5135\n",
      "Epoch 6638/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1949 - val_loss: 9.5138\n",
      "Epoch 6639/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1945 - val_loss: 9.5142\n",
      "Epoch 6640/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1942 - val_loss: 9.5144\n",
      "Epoch 6641/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1939 - val_loss: 9.5146\n",
      "Epoch 6642/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1936 - val_loss: 9.5149\n",
      "Epoch 6643/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1933 - val_loss: 9.5154\n",
      "Epoch 6644/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1930 - val_loss: 9.5157\n",
      "Epoch 6645/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1927 - val_loss: 9.5160\n",
      "Epoch 6646/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1924 - val_loss: 9.5163\n",
      "Epoch 6647/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1921 - val_loss: 9.5165\n",
      "Epoch 6648/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1918 - val_loss: 9.5166\n",
      "Epoch 6649/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1915 - val_loss: 9.5168\n",
      "Epoch 6650/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1912 - val_loss: 9.5171\n",
      "Epoch 6651/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1909 - val_loss: 9.5176\n",
      "Epoch 6652/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1906 - val_loss: 9.5180\n",
      "Epoch 6653/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1903 - val_loss: 9.5184\n",
      "Epoch 6654/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1900 - val_loss: 9.5186\n",
      "Epoch 6655/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1897 - val_loss: 9.5186\n",
      "Epoch 6656/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1894 - val_loss: 9.5186\n",
      "Epoch 6657/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1891 - val_loss: 9.5188\n",
      "Epoch 6658/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1888 - val_loss: 9.5192\n",
      "Epoch 6659/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1885 - val_loss: 9.5197\n",
      "Epoch 6660/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1882 - val_loss: 9.5202\n",
      "Epoch 6661/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1878 - val_loss: 9.5207\n",
      "Epoch 6662/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1875 - val_loss: 9.5211\n",
      "Epoch 6663/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1872 - val_loss: 9.5213\n",
      "Epoch 6664/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1869 - val_loss: 9.5215\n",
      "Epoch 6665/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1866 - val_loss: 9.5217\n",
      "Epoch 6666/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1863 - val_loss: 9.5219\n",
      "Epoch 6667/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.186 - 0s 30ms/step - loss: 4.1860 - val_loss: 9.5222\n",
      "Epoch 6668/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1857 - val_loss: 9.5225\n",
      "Epoch 6669/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1854 - val_loss: 9.5229\n",
      "Epoch 6670/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1851 - val_loss: 9.5233\n",
      "Epoch 6671/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1848 - val_loss: 9.5236\n",
      "Epoch 6672/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1845 - val_loss: 9.5240\n",
      "Epoch 6673/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1842 - val_loss: 9.5242\n",
      "Epoch 6674/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1839 - val_loss: 9.5243\n",
      "Epoch 6675/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1836 - val_loss: 9.5244\n",
      "Epoch 6676/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1833 - val_loss: 9.5246\n",
      "Epoch 6677/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1830 - val_loss: 9.5249\n",
      "Epoch 6678/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1827 - val_loss: 9.5254\n",
      "Epoch 6679/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1824 - val_loss: 9.5258\n",
      "Epoch 6680/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1821 - val_loss: 9.5263\n",
      "Epoch 6681/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1817 - val_loss: 9.5267\n",
      "Epoch 6682/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1814 - val_loss: 9.5269\n",
      "Epoch 6683/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1811 - val_loss: 9.5270\n",
      "Epoch 6684/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1808 - val_loss: 9.5272\n",
      "Epoch 6685/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1805 - val_loss: 9.5274\n",
      "Epoch 6686/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1802 - val_loss: 9.5276\n",
      "Epoch 6687/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1799 - val_loss: 9.5279\n",
      "Epoch 6688/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1796 - val_loss: 9.5284\n",
      "Epoch 6689/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1793 - val_loss: 9.5287\n",
      "Epoch 6690/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1790 - val_loss: 9.5289\n",
      "Epoch 6691/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1787 - val_loss: 9.5293\n",
      "Epoch 6692/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1784 - val_loss: 9.5297\n",
      "Epoch 6693/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1781 - val_loss: 9.5300\n",
      "Epoch 6694/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1778 - val_loss: 9.5302\n",
      "Epoch 6695/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1775 - val_loss: 9.5305\n",
      "Epoch 6696/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1772 - val_loss: 9.5307\n",
      "Epoch 6697/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1769 - val_loss: 9.5310\n",
      "Epoch 6698/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1766 - val_loss: 9.5313\n",
      "Epoch 6699/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1763 - val_loss: 9.5317\n",
      "Epoch 6700/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1760 - val_loss: 9.5320\n",
      "Epoch 6701/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1756 - val_loss: 9.5322\n",
      "Epoch 6702/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1753 - val_loss: 9.5325\n",
      "Epoch 6703/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1750 - val_loss: 9.5327\n",
      "Epoch 6704/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1747 - val_loss: 9.5331\n",
      "Epoch 6705/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1744 - val_loss: 9.5335\n",
      "Epoch 6706/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1741 - val_loss: 9.5338\n",
      "Epoch 6707/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1738 - val_loss: 9.5342\n",
      "Epoch 6708/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1735 - val_loss: 9.5346\n",
      "Epoch 6709/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1732 - val_loss: 9.5349\n",
      "Epoch 6710/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1729 - val_loss: 9.5351\n",
      "Epoch 6711/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1726 - val_loss: 9.5353\n",
      "Epoch 6712/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1723 - val_loss: 9.5355\n",
      "Epoch 6713/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1720 - val_loss: 9.5357\n",
      "Epoch 6714/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1717 - val_loss: 9.5360\n",
      "Epoch 6715/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1714 - val_loss: 9.5363\n",
      "Epoch 6716/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1711 - val_loss: 9.5368\n",
      "Epoch 6717/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1708 - val_loss: 9.5371\n",
      "Epoch 6718/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1705 - val_loss: 9.5375\n",
      "Epoch 6719/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1702 - val_loss: 9.5378\n",
      "Epoch 6720/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1699 - val_loss: 9.5381\n",
      "Epoch 6721/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1695 - val_loss: 9.5384\n",
      "Epoch 6722/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1692 - val_loss: 9.5388\n",
      "Epoch 6723/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1689 - val_loss: 9.5391\n",
      "Epoch 6724/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1686 - val_loss: 9.5394\n",
      "Epoch 6725/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1683 - val_loss: 9.5396\n",
      "Epoch 6726/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.168 - 0s 31ms/step - loss: 4.1680 - val_loss: 9.5398\n",
      "Epoch 6727/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1677 - val_loss: 9.5400\n",
      "Epoch 6728/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1674 - val_loss: 9.5403\n",
      "Epoch 6729/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1671 - val_loss: 9.5408\n",
      "Epoch 6730/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1668 - val_loss: 9.5412\n",
      "Epoch 6731/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1665 - val_loss: 9.5415\n",
      "Epoch 6732/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1662 - val_loss: 9.5419\n",
      "Epoch 6733/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1659 - val_loss: 9.5422\n",
      "Epoch 6734/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1656 - val_loss: 9.5425\n",
      "Epoch 6735/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1653 - val_loss: 9.5429\n",
      "Epoch 6736/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1650 - val_loss: 9.5434\n",
      "Epoch 6737/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1647 - val_loss: 9.5437\n",
      "Epoch 6738/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.1644 - val_loss: 9.5439\n",
      "Epoch 6739/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1641 - val_loss: 9.5441\n",
      "Epoch 6740/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1637 - val_loss: 9.5442\n",
      "Epoch 6741/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1634 - val_loss: 9.5446\n",
      "Epoch 6742/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1631 - val_loss: 9.5450\n",
      "Epoch 6743/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1628 - val_loss: 9.5455\n",
      "Epoch 6744/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1625 - val_loss: 9.5459\n",
      "Epoch 6745/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1622 - val_loss: 9.5462\n",
      "Epoch 6746/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1619 - val_loss: 9.5463\n",
      "Epoch 6747/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1616 - val_loss: 9.5465\n",
      "Epoch 6748/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1613 - val_loss: 9.5468\n",
      "Epoch 6749/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1610 - val_loss: 9.5471\n",
      "Epoch 6750/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1607 - val_loss: 9.5475\n",
      "Epoch 6751/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1604 - val_loss: 9.5480\n",
      "Epoch 6752/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1601 - val_loss: 9.5485\n",
      "Epoch 6753/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1598 - val_loss: 9.5488\n",
      "Epoch 6754/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1595 - val_loss: 9.5490\n",
      "Epoch 6755/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1592 - val_loss: 9.5492\n",
      "Epoch 6756/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1589 - val_loss: 9.5494\n",
      "Epoch 6757/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1586 - val_loss: 9.5498\n",
      "Epoch 6758/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1582 - val_loss: 9.5502\n",
      "Epoch 6759/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1579 - val_loss: 9.5506\n",
      "Epoch 6760/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1576 - val_loss: 9.5511\n",
      "Epoch 6761/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1573 - val_loss: 9.5514\n",
      "Epoch 6762/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1570 - val_loss: 9.5517\n",
      "Epoch 6763/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1567 - val_loss: 9.5519\n",
      "Epoch 6764/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1564 - val_loss: 9.5523\n",
      "Epoch 6765/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1561 - val_loss: 9.5525\n",
      "Epoch 6766/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1558 - val_loss: 9.5527\n",
      "Epoch 6767/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1555 - val_loss: 9.5529\n",
      "Epoch 6768/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1552 - val_loss: 9.5532\n",
      "Epoch 6769/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1549 - val_loss: 9.5536\n",
      "Epoch 6770/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1546 - val_loss: 9.5541\n",
      "Epoch 6771/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1543 - val_loss: 9.5545\n",
      "Epoch 6772/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1540 - val_loss: 9.5550\n",
      "Epoch 6773/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1537 - val_loss: 9.5554\n",
      "Epoch 6774/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1534 - val_loss: 9.5557\n",
      "Epoch 6775/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1530 - val_loss: 9.5559\n",
      "Epoch 6776/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1527 - val_loss: 9.5562\n",
      "Epoch 6777/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1524 - val_loss: 9.5565\n",
      "Epoch 6778/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1521 - val_loss: 9.5570\n",
      "Epoch 6779/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1518 - val_loss: 9.5575\n",
      "Epoch 6780/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1515 - val_loss: 9.5582\n",
      "Epoch 6781/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1512 - val_loss: 9.5587\n",
      "Epoch 6782/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1509 - val_loss: 9.5592\n",
      "Epoch 6783/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1506 - val_loss: 9.5596\n",
      "Epoch 6784/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1503 - val_loss: 9.5600\n",
      "Epoch 6785/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1500 - val_loss: 9.5603\n",
      "Epoch 6786/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1497 - val_loss: 9.5608\n",
      "Epoch 6787/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1494 - val_loss: 9.5614\n",
      "Epoch 6788/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1491 - val_loss: 9.5620\n",
      "Epoch 6789/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1488 - val_loss: 9.5626\n",
      "Epoch 6790/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1485 - val_loss: 9.5631\n",
      "Epoch 6791/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1481 - val_loss: 9.5636\n",
      "Epoch 6792/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1478 - val_loss: 9.5639\n",
      "Epoch 6793/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1475 - val_loss: 9.5643\n",
      "Epoch 6794/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1472 - val_loss: 9.5648\n",
      "Epoch 6795/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1469 - val_loss: 9.5654\n",
      "Epoch 6796/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1466 - val_loss: 9.5660\n",
      "Epoch 6797/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1463 - val_loss: 9.5665\n",
      "Epoch 6798/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1460 - val_loss: 9.5669\n",
      "Epoch 6799/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1457 - val_loss: 9.5674\n",
      "Epoch 6800/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1454 - val_loss: 9.5678\n",
      "Epoch 6801/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1451 - val_loss: 9.5682\n",
      "Epoch 6802/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1448 - val_loss: 9.5687\n",
      "Epoch 6803/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1445 - val_loss: 9.5692\n",
      "Epoch 6804/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1442 - val_loss: 9.5696\n",
      "Epoch 6805/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1439 - val_loss: 9.5701\n",
      "Epoch 6806/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1436 - val_loss: 9.5705\n",
      "Epoch 6807/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1433 - val_loss: 9.5710\n",
      "Epoch 6808/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1429 - val_loss: 9.5715\n",
      "Epoch 6809/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1426 - val_loss: 9.5720\n",
      "Epoch 6810/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1423 - val_loss: 9.5724\n",
      "Epoch 6811/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1420 - val_loss: 9.5728\n",
      "Epoch 6812/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1417 - val_loss: 9.5733\n",
      "Epoch 6813/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1414 - val_loss: 9.5737\n",
      "Epoch 6814/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1411 - val_loss: 9.5742\n",
      "Epoch 6815/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1408 - val_loss: 9.5747\n",
      "Epoch 6816/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1405 - val_loss: 9.5751\n",
      "Epoch 6817/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1402 - val_loss: 9.5755\n",
      "Epoch 6818/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1399 - val_loss: 9.5759\n",
      "Epoch 6819/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1396 - val_loss: 9.5762\n",
      "Epoch 6820/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1393 - val_loss: 9.5767\n",
      "Epoch 6821/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1390 - val_loss: 9.5772\n",
      "Epoch 6822/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1387 - val_loss: 9.5776\n",
      "Epoch 6823/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1384 - val_loss: 9.5781\n",
      "Epoch 6824/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1380 - val_loss: 9.5785\n",
      "Epoch 6825/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1377 - val_loss: 9.5789\n",
      "Epoch 6826/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1374 - val_loss: 9.5793\n",
      "Epoch 6827/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1371 - val_loss: 9.5798\n",
      "Epoch 6828/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1368 - val_loss: 9.5802\n",
      "Epoch 6829/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1365 - val_loss: 9.5806\n",
      "Epoch 6830/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1362 - val_loss: 9.5811\n",
      "Epoch 6831/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1359 - val_loss: 9.5816\n",
      "Epoch 6832/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1356 - val_loss: 9.5819\n",
      "Epoch 6833/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1353 - val_loss: 9.5823\n",
      "Epoch 6834/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1350 - val_loss: 9.5827\n",
      "Epoch 6835/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1347 - val_loss: 9.5831\n",
      "Epoch 6836/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1344 - val_loss: 9.5835\n",
      "Epoch 6837/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1341 - val_loss: 9.5840\n",
      "Epoch 6838/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1338 - val_loss: 9.5844\n",
      "Epoch 6839/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1335 - val_loss: 9.5849\n",
      "Epoch 6840/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1331 - val_loss: 9.5853\n",
      "Epoch 6841/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1328 - val_loss: 9.5857\n",
      "Epoch 6842/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1325 - val_loss: 9.5861\n",
      "Epoch 6843/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1322 - val_loss: 9.5866\n",
      "Epoch 6844/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1319 - val_loss: 9.5870\n",
      "Epoch 6845/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1316 - val_loss: 9.5873\n",
      "Epoch 6846/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1313 - val_loss: 9.5878\n",
      "Epoch 6847/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1310 - val_loss: 9.5884\n",
      "Epoch 6848/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1307 - val_loss: 9.5888\n",
      "Epoch 6849/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1304 - val_loss: 9.5892\n",
      "Epoch 6850/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1301 - val_loss: 9.5895\n",
      "Epoch 6851/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1298 - val_loss: 9.5899\n",
      "Epoch 6852/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1295 - val_loss: 9.5903\n",
      "Epoch 6853/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1292 - val_loss: 9.5907\n",
      "Epoch 6854/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1289 - val_loss: 9.5911\n",
      "Epoch 6855/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1286 - val_loss: 9.5915\n",
      "Epoch 6856/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1283 - val_loss: 9.5919\n",
      "Epoch 6857/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1279 - val_loss: 9.5924\n",
      "Epoch 6858/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1276 - val_loss: 9.5929\n",
      "Epoch 6859/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1273 - val_loss: 9.5935\n",
      "Epoch 6860/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1270 - val_loss: 9.5939\n",
      "Epoch 6861/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1267 - val_loss: 9.5942\n",
      "Epoch 6862/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1264 - val_loss: 9.5944\n",
      "Epoch 6863/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1261 - val_loss: 9.5947\n",
      "Epoch 6864/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1258 - val_loss: 9.5950\n",
      "Epoch 6865/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1255 - val_loss: 9.5955\n",
      "Epoch 6866/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1252 - val_loss: 9.5961\n",
      "Epoch 6867/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1249 - val_loss: 9.5967\n",
      "Epoch 6868/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1246 - val_loss: 9.5973\n",
      "Epoch 6869/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1243 - val_loss: 9.5975\n",
      "Epoch 6870/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1240 - val_loss: 9.5977\n",
      "Epoch 6871/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1237 - val_loss: 9.5980\n",
      "Epoch 6872/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1234 - val_loss: 9.5983\n",
      "Epoch 6873/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1230 - val_loss: 9.5988\n",
      "Epoch 6874/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1227 - val_loss: 9.5994\n",
      "Epoch 6875/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1224 - val_loss: 9.5999\n",
      "Epoch 6876/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1221 - val_loss: 9.6003\n",
      "Epoch 6877/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1218 - val_loss: 9.6007\n",
      "Epoch 6878/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1215 - val_loss: 9.6009\n",
      "Epoch 6879/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1212 - val_loss: 9.6012\n",
      "Epoch 6880/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1209 - val_loss: 9.6016\n",
      "Epoch 6881/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1206 - val_loss: 9.6021\n",
      "Epoch 6882/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1203 - val_loss: 9.6027\n",
      "Epoch 6883/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1200 - val_loss: 9.6032\n",
      "Epoch 6884/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1197 - val_loss: 9.6037\n",
      "Epoch 6885/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1194 - val_loss: 9.6041\n",
      "Epoch 6886/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1191 - val_loss: 9.6043\n",
      "Epoch 6887/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1188 - val_loss: 9.6046\n",
      "Epoch 6888/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1185 - val_loss: 9.6049\n",
      "Epoch 6889/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1181 - val_loss: 9.6053\n",
      "Epoch 6890/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1178 - val_loss: 9.6059\n",
      "Epoch 6891/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1175 - val_loss: 9.6064\n",
      "Epoch 6892/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1172 - val_loss: 9.6069\n",
      "Epoch 6893/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1169 - val_loss: 9.6073\n",
      "Epoch 6894/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1166 - val_loss: 9.6077\n",
      "Epoch 6895/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1163 - val_loss: 9.6080\n",
      "Epoch 6896/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1160 - val_loss: 9.6083\n",
      "Epoch 6897/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1157 - val_loss: 9.6086\n",
      "Epoch 6898/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1154 - val_loss: 9.6090\n",
      "Epoch 6899/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1151 - val_loss: 9.6096\n",
      "Epoch 6900/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1148 - val_loss: 9.6101\n",
      "Epoch 6901/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1145 - val_loss: 9.6105\n",
      "Epoch 6902/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1142 - val_loss: 9.6109\n",
      "Epoch 6903/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1139 - val_loss: 9.6112\n",
      "Epoch 6904/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.1136 - val_loss: 9.6115\n",
      "Epoch 6905/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1132 - val_loss: 9.6118\n",
      "Epoch 6906/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1129 - val_loss: 9.6123\n",
      "Epoch 6907/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1126 - val_loss: 9.6129\n",
      "Epoch 6908/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1123 - val_loss: 9.6133\n",
      "Epoch 6909/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1120 - val_loss: 9.6136\n",
      "Epoch 6910/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1117 - val_loss: 9.6139\n",
      "Epoch 6911/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1114 - val_loss: 9.6141\n",
      "Epoch 6912/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1111 - val_loss: 9.6145\n",
      "Epoch 6913/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1108 - val_loss: 9.6150\n",
      "Epoch 6914/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1105 - val_loss: 9.6156\n",
      "Epoch 6915/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1102 - val_loss: 9.6161\n",
      "Epoch 6916/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1099 - val_loss: 9.6165\n",
      "Epoch 6917/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1096 - val_loss: 9.6169\n",
      "Epoch 6918/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1093 - val_loss: 9.6172\n",
      "Epoch 6919/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1090 - val_loss: 9.6176\n",
      "Epoch 6920/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1087 - val_loss: 9.6180\n",
      "Epoch 6921/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1083 - val_loss: 9.6184\n",
      "Epoch 6922/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1080 - val_loss: 9.6188\n",
      "Epoch 6923/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1077 - val_loss: 9.6191\n",
      "Epoch 6924/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1074 - val_loss: 9.6194\n",
      "Epoch 6925/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1071 - val_loss: 9.6197\n",
      "Epoch 6926/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1068 - val_loss: 9.6201\n",
      "Epoch 6927/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1065 - val_loss: 9.6205\n",
      "Epoch 6928/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1062 - val_loss: 9.6210\n",
      "Epoch 6929/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1059 - val_loss: 9.6214\n",
      "Epoch 6930/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1056 - val_loss: 9.6217\n",
      "Epoch 6931/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1053 - val_loss: 9.6220\n",
      "Epoch 6932/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1050 - val_loss: 9.6223\n",
      "Epoch 6933/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1047 - val_loss: 9.6226\n",
      "Epoch 6934/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1044 - val_loss: 9.6230\n",
      "Epoch 6935/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1040 - val_loss: 9.6235\n",
      "Epoch 6936/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1037 - val_loss: 9.6239\n",
      "Epoch 6937/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1034 - val_loss: 9.6242\n",
      "Epoch 6938/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1031 - val_loss: 9.6245\n",
      "Epoch 6939/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1028 - val_loss: 9.6249\n",
      "Epoch 6940/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1025 - val_loss: 9.6252\n",
      "Epoch 6941/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1022 - val_loss: 9.6255\n",
      "Epoch 6942/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1019 - val_loss: 9.6259\n",
      "Epoch 6943/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1016 - val_loss: 9.6263\n",
      "Epoch 6944/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1013 - val_loss: 9.6266\n",
      "Epoch 6945/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1010 - val_loss: 9.6270\n",
      "Epoch 6946/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1007 - val_loss: 9.6272\n",
      "Epoch 6947/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1004 - val_loss: 9.6276\n",
      "Epoch 6948/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1001 - val_loss: 9.6280\n",
      "Epoch 6949/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0998 - val_loss: 9.6283\n",
      "Epoch 6950/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0994 - val_loss: 9.6287\n",
      "Epoch 6951/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0991 - val_loss: 9.6291\n",
      "Epoch 6952/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0988 - val_loss: 9.6295\n",
      "Epoch 6953/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0985 - val_loss: 9.6298\n",
      "Epoch 6954/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0982 - val_loss: 9.6300\n",
      "Epoch 6955/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0979 - val_loss: 9.6303\n",
      "Epoch 6956/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0976 - val_loss: 9.6308\n",
      "Epoch 6957/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0973 - val_loss: 9.6311\n",
      "Epoch 6958/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0970 - val_loss: 9.6315\n",
      "Epoch 6959/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0967 - val_loss: 9.6320\n",
      "Epoch 6960/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0964 - val_loss: 9.6324\n",
      "Epoch 6961/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0961 - val_loss: 9.6326\n",
      "Epoch 6962/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0958 - val_loss: 9.6328\n",
      "Epoch 6963/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0955 - val_loss: 9.6333\n",
      "Epoch 6964/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0951 - val_loss: 9.6337\n",
      "Epoch 6965/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0948 - val_loss: 9.6339\n",
      "Epoch 6966/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0945 - val_loss: 9.6340\n",
      "Epoch 6967/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0942 - val_loss: 9.6342\n",
      "Epoch 6968/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0939 - val_loss: 9.6344\n",
      "Epoch 6969/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0936 - val_loss: 9.6346\n",
      "Epoch 6970/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0933 - val_loss: 9.6350\n",
      "Epoch 6971/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0930 - val_loss: 9.6353\n",
      "Epoch 6972/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0927 - val_loss: 9.6357\n",
      "Epoch 6973/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0924 - val_loss: 9.6359\n",
      "Epoch 6974/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0921 - val_loss: 9.6360\n",
      "Epoch 6975/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0918 - val_loss: 9.6363\n",
      "Epoch 6976/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0915 - val_loss: 9.6366\n",
      "Epoch 6977/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0912 - val_loss: 9.6368\n",
      "Epoch 6978/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0908 - val_loss: 9.6370\n",
      "Epoch 6979/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0905 - val_loss: 9.6371\n",
      "Epoch 6980/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0902 - val_loss: 9.6372\n",
      "Epoch 6981/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0899 - val_loss: 9.6374\n",
      "Epoch 6982/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0896 - val_loss: 9.6377\n",
      "Epoch 6983/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0893 - val_loss: 9.6380\n",
      "Epoch 6984/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.0890 - val_loss: 9.6383\n",
      "Epoch 6985/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.0887 - val_loss: 9.6386\n",
      "Epoch 6986/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0884 - val_loss: 9.6388\n",
      "Epoch 6987/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0881 - val_loss: 9.6389\n",
      "Epoch 6988/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.0878 - val_loss: 9.6391\n",
      "Epoch 6989/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0875 - val_loss: 9.6393\n",
      "Epoch 6990/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0872 - val_loss: 9.6396\n",
      "Epoch 6991/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0869 - val_loss: 9.6399\n",
      "Epoch 6992/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0866 - val_loss: 9.6402\n",
      "Epoch 6993/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0862 - val_loss: 9.6404\n",
      "Epoch 6994/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0859 - val_loss: 9.6405\n",
      "Epoch 6995/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0856 - val_loss: 9.6407\n",
      "Epoch 6996/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0853 - val_loss: 9.6409\n",
      "Epoch 6997/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0850 - val_loss: 9.6411\n",
      "Epoch 6998/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0847 - val_loss: 9.6413\n",
      "Epoch 6999/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0844 - val_loss: 9.6416\n",
      "Epoch 7000/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0841 - val_loss: 9.6418\n",
      "Epoch 7001/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0838 - val_loss: 9.6421\n",
      "Epoch 7002/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0835 - val_loss: 9.6423\n",
      "Epoch 7003/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0832 - val_loss: 9.6424\n",
      "Epoch 7004/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0829 - val_loss: 9.6426\n",
      "Epoch 7005/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0826 - val_loss: 9.6429\n",
      "Epoch 7006/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0823 - val_loss: 9.6432\n",
      "Epoch 7007/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0819 - val_loss: 9.6433\n",
      "Epoch 7008/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0816 - val_loss: 9.6436\n",
      "Epoch 7009/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0813 - val_loss: 9.6440\n",
      "Epoch 7010/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0810 - val_loss: 9.6442\n",
      "Epoch 7011/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0807 - val_loss: 9.6443\n",
      "Epoch 7012/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0804 - val_loss: 9.6445\n",
      "Epoch 7013/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0801 - val_loss: 9.6447\n",
      "Epoch 7014/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0798 - val_loss: 9.6449\n",
      "Epoch 7015/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0795 - val_loss: 9.6451\n",
      "Epoch 7016/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0792 - val_loss: 9.6454\n",
      "Epoch 7017/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0789 - val_loss: 9.6456\n",
      "Epoch 7018/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0786 - val_loss: 9.6457\n",
      "Epoch 7019/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0783 - val_loss: 9.6459\n",
      "Epoch 7020/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0780 - val_loss: 9.6461\n",
      "Epoch 7021/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0776 - val_loss: 9.6462\n",
      "Epoch 7022/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0773 - val_loss: 9.6461\n",
      "Epoch 7023/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0770 - val_loss: 9.6462\n",
      "Epoch 7024/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0767 - val_loss: 9.6463\n",
      "Epoch 7025/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0764 - val_loss: 9.6465\n",
      "Epoch 7026/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0761 - val_loss: 9.6467\n",
      "Epoch 7027/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.0758 - val_loss: 9.6469\n",
      "Epoch 7028/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0755 - val_loss: 9.6471\n",
      "Epoch 7029/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0752 - val_loss: 9.6470\n",
      "Epoch 7030/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0749 - val_loss: 9.6470\n",
      "Epoch 7031/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0746 - val_loss: 9.6471\n",
      "Epoch 7032/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0743 - val_loss: 9.6473\n",
      "Epoch 7033/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0740 - val_loss: 9.6475\n",
      "Epoch 7034/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0737 - val_loss: 9.6476\n",
      "Epoch 7035/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0734 - val_loss: 9.6476\n",
      "Epoch 7036/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0730 - val_loss: 9.6476\n",
      "Epoch 7037/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0727 - val_loss: 9.6476\n",
      "Epoch 7038/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0724 - val_loss: 9.6477\n",
      "Epoch 7039/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0721 - val_loss: 9.6478\n",
      "Epoch 7040/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0718 - val_loss: 9.6479\n",
      "Epoch 7041/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0715 - val_loss: 9.6480\n",
      "Epoch 7042/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0712 - val_loss: 9.6480\n",
      "Epoch 7043/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0709 - val_loss: 9.6480\n",
      "Epoch 7044/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0706 - val_loss: 9.6480\n",
      "Epoch 7045/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0703 - val_loss: 9.6480\n",
      "Epoch 7046/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0700 - val_loss: 9.6482\n",
      "Epoch 7047/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0697 - val_loss: 9.6484\n",
      "Epoch 7048/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0694 - val_loss: 9.6486\n",
      "Epoch 7049/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.0691 - val_loss: 9.6488\n",
      "Epoch 7050/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.0688 - val_loss: 9.6489\n",
      "Epoch 7051/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0684 - val_loss: 9.6489\n",
      "Epoch 7052/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0681 - val_loss: 9.6490\n",
      "Epoch 7053/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0678 - val_loss: 9.6492\n",
      "Epoch 7054/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0675 - val_loss: 9.6492\n",
      "Epoch 7055/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0672 - val_loss: 9.6493\n",
      "Epoch 7056/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0669 - val_loss: 9.6493\n",
      "Epoch 7057/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.066 - 0s 29ms/step - loss: 4.0666 - val_loss: 9.6493\n",
      "Epoch 7058/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0663 - val_loss: 9.6494\n",
      "Epoch 7059/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.0660 - val_loss: 9.6496\n",
      "Epoch 7060/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0657 - val_loss: 9.6498\n",
      "Epoch 7061/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0654 - val_loss: 9.6500\n",
      "Epoch 7062/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0651 - val_loss: 9.6501\n",
      "Epoch 7063/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0648 - val_loss: 9.6501\n",
      "Epoch 7064/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0645 - val_loss: 9.6502\n",
      "Epoch 7065/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0641 - val_loss: 9.6503\n",
      "Epoch 7066/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0638 - val_loss: 9.6506\n",
      "Epoch 7067/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0635 - val_loss: 9.6508\n",
      "Epoch 7068/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0632 - val_loss: 9.6511\n",
      "Epoch 7069/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0629 - val_loss: 9.6512\n",
      "Epoch 7070/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0626 - val_loss: 9.6511\n",
      "Epoch 7071/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0623 - val_loss: 9.6510\n",
      "Epoch 7072/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0620 - val_loss: 9.6511\n",
      "Epoch 7073/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0617 - val_loss: 9.6512\n",
      "Epoch 7074/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0614 - val_loss: 9.6515\n",
      "Epoch 7075/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0611 - val_loss: 9.6519\n",
      "Epoch 7076/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0608 - val_loss: 9.6521\n",
      "Epoch 7077/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0605 - val_loss: 9.6521\n",
      "Epoch 7078/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0602 - val_loss: 9.6520\n",
      "Epoch 7079/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0598 - val_loss: 9.6519\n",
      "Epoch 7080/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0595 - val_loss: 9.6519\n",
      "Epoch 7081/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0592 - val_loss: 9.6521\n",
      "Epoch 7082/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0589 - val_loss: 9.6525\n",
      "Epoch 7083/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0586 - val_loss: 9.6529\n",
      "Epoch 7084/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0583 - val_loss: 9.6532\n",
      "Epoch 7085/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0580 - val_loss: 9.6533\n",
      "Epoch 7086/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0577 - val_loss: 9.6533\n",
      "Epoch 7087/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0574 - val_loss: 9.6532\n",
      "Epoch 7088/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0571 - val_loss: 9.6529\n",
      "Epoch 7089/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0568 - val_loss: 9.6530\n",
      "Epoch 7090/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0565 - val_loss: 9.6532\n",
      "Epoch 7091/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0562 - val_loss: 9.6536\n",
      "Epoch 7092/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.0559 - val_loss: 9.6539\n",
      "Epoch 7093/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0555 - val_loss: 9.6542\n",
      "Epoch 7094/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0552 - val_loss: 9.6543\n",
      "Epoch 7095/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0549 - val_loss: 9.6543\n",
      "Epoch 7096/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0546 - val_loss: 9.6542\n",
      "Epoch 7097/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0543 - val_loss: 9.6542\n",
      "Epoch 7098/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0540 - val_loss: 9.6543\n",
      "Epoch 7099/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0537 - val_loss: 9.6547\n",
      "Epoch 7100/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0534 - val_loss: 9.6552\n",
      "Epoch 7101/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0531 - val_loss: 9.6557\n",
      "Epoch 7102/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0528 - val_loss: 9.6561\n",
      "Epoch 7103/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0525 - val_loss: 9.6564\n",
      "Epoch 7104/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0522 - val_loss: 9.6565\n",
      "Epoch 7105/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0519 - val_loss: 9.6565\n",
      "Epoch 7106/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.0515 - val_loss: 9.6565\n",
      "Epoch 7107/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.0512 - val_loss: 9.6566\n",
      "Epoch 7108/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0509 - val_loss: 9.6567\n",
      "Epoch 7109/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0506 - val_loss: 9.6569\n",
      "Epoch 7110/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.0503 - val_loss: 9.6572\n",
      "Epoch 7111/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0500 - val_loss: 9.6575\n",
      "Epoch 7112/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0497 - val_loss: 9.6577\n",
      "Epoch 7113/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0494 - val_loss: 9.6578\n",
      "Epoch 7114/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0491 - val_loss: 9.6579\n",
      "Epoch 7115/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0488 - val_loss: 9.6580\n",
      "Epoch 7116/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0485 - val_loss: 9.6580\n",
      "Epoch 7117/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0482 - val_loss: 9.6581\n",
      "Epoch 7118/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0479 - val_loss: 9.6584\n",
      "Epoch 7119/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0476 - val_loss: 9.6587\n",
      "Epoch 7120/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0473 - val_loss: 9.6590\n",
      "Epoch 7121/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0469 - val_loss: 9.6591\n",
      "Epoch 7122/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0466 - val_loss: 9.6592\n",
      "Epoch 7123/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0463 - val_loss: 9.6592\n",
      "Epoch 7124/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0460 - val_loss: 9.6592\n",
      "Epoch 7125/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0457 - val_loss: 9.6592\n",
      "Epoch 7126/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0454 - val_loss: 9.6594\n",
      "Epoch 7127/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0451 - val_loss: 9.6596\n",
      "Epoch 7128/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0448 - val_loss: 9.6598\n",
      "Epoch 7129/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0445 - val_loss: 9.6599\n",
      "Epoch 7130/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.0442 - val_loss: 9.6600\n",
      "Epoch 7131/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0439 - val_loss: 9.6600\n",
      "Epoch 7132/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0436 - val_loss: 9.6601\n",
      "Epoch 7133/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0433 - val_loss: 9.6603\n",
      "Epoch 7134/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0430 - val_loss: 9.6604\n",
      "Epoch 7135/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0426 - val_loss: 9.6605\n",
      "Epoch 7136/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0423 - val_loss: 9.6607\n",
      "Epoch 7137/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0420 - val_loss: 9.6608\n",
      "Epoch 7138/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0417 - val_loss: 9.6609\n",
      "Epoch 7139/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0414 - val_loss: 9.6612\n",
      "Epoch 7140/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0411 - val_loss: 9.6615\n",
      "Epoch 7141/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0408 - val_loss: 9.6616\n",
      "Epoch 7142/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0405 - val_loss: 9.6616\n",
      "Epoch 7143/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0402 - val_loss: 9.6617\n",
      "Epoch 7144/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0399 - val_loss: 9.6617\n",
      "Epoch 7145/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0396 - val_loss: 9.6617\n",
      "Epoch 7146/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0393 - val_loss: 9.6618\n",
      "Epoch 7147/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0390 - val_loss: 9.6619\n",
      "Epoch 7148/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0387 - val_loss: 9.6620\n",
      "Epoch 7149/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0383 - val_loss: 9.6620\n",
      "Epoch 7150/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0380 - val_loss: 9.6621\n",
      "Epoch 7151/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0377 - val_loss: 9.6620\n",
      "Epoch 7152/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0374 - val_loss: 9.6619\n",
      "Epoch 7153/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0371 - val_loss: 9.6617\n",
      "Epoch 7154/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0368 - val_loss: 9.6615\n",
      "Epoch 7155/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0365 - val_loss: 9.6612\n",
      "Epoch 7156/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0362 - val_loss: 9.6608\n",
      "Epoch 7157/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0359 - val_loss: 9.6606\n",
      "Epoch 7158/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0356 - val_loss: 9.6607\n",
      "Epoch 7159/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0353 - val_loss: 9.6608\n",
      "Epoch 7160/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0350 - val_loss: 9.6609\n",
      "Epoch 7161/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0347 - val_loss: 9.6609\n",
      "Epoch 7162/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0344 - val_loss: 9.6608\n",
      "Epoch 7163/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0341 - val_loss: 9.6605\n",
      "Epoch 7164/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0337 - val_loss: 9.6603\n",
      "Epoch 7165/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0334 - val_loss: 9.6602\n",
      "Epoch 7166/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0331 - val_loss: 9.6602\n",
      "Epoch 7167/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0328 - val_loss: 9.6601\n",
      "Epoch 7168/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0325 - val_loss: 9.6600\n",
      "Epoch 7169/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0322 - val_loss: 9.6599\n",
      "Epoch 7170/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0319 - val_loss: 9.6597\n",
      "Epoch 7171/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0316 - val_loss: 9.6596\n",
      "Epoch 7172/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0313 - val_loss: 9.6594\n",
      "Epoch 7173/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0310 - val_loss: 9.6593\n",
      "Epoch 7174/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0307 - val_loss: 9.6592\n",
      "Epoch 7175/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0304 - val_loss: 9.6592\n",
      "Epoch 7176/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.0301 - val_loss: 9.6592\n",
      "Epoch 7177/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0298 - val_loss: 9.6592\n",
      "Epoch 7178/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0294 - val_loss: 9.6592\n",
      "Epoch 7179/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0291 - val_loss: 9.6592\n",
      "Epoch 7180/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0288 - val_loss: 9.6590\n",
      "Epoch 7181/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0285 - val_loss: 9.6588\n",
      "Epoch 7182/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0282 - val_loss: 9.6586\n",
      "Epoch 7183/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0279 - val_loss: 9.6585\n",
      "Epoch 7184/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0276 - val_loss: 9.6584\n",
      "Epoch 7185/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0273 - val_loss: 9.6585\n",
      "Epoch 7186/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0270 - val_loss: 9.6584\n",
      "Epoch 7187/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0267 - val_loss: 9.6582\n",
      "Epoch 7188/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0264 - val_loss: 9.6581\n",
      "Epoch 7189/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0261 - val_loss: 9.6579\n",
      "Epoch 7190/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0258 - val_loss: 9.6578\n",
      "Epoch 7191/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0255 - val_loss: 9.6578\n",
      "Epoch 7192/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0252 - val_loss: 9.6577\n",
      "Epoch 7193/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0248 - val_loss: 9.6576\n",
      "Epoch 7194/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0245 - val_loss: 9.6575\n",
      "Epoch 7195/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0242 - val_loss: 9.6574\n",
      "Epoch 7196/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0239 - val_loss: 9.6573\n",
      "Epoch 7197/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0236 - val_loss: 9.6573\n",
      "Epoch 7198/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0233 - val_loss: 9.6573\n",
      "Epoch 7199/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0230 - val_loss: 9.6572\n",
      "Epoch 7200/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0227 - val_loss: 9.6570\n",
      "Epoch 7201/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0224 - val_loss: 9.6567\n",
      "Epoch 7202/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0221 - val_loss: 9.6565\n",
      "Epoch 7203/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0218 - val_loss: 9.6564\n",
      "Epoch 7204/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0215 - val_loss: 9.6565\n",
      "Epoch 7205/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0212 - val_loss: 9.6565\n",
      "Epoch 7206/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0209 - val_loss: 9.6565\n",
      "Epoch 7207/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0205 - val_loss: 9.6564\n",
      "Epoch 7208/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0202 - val_loss: 9.6562\n",
      "Epoch 7209/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0199 - val_loss: 9.6560\n",
      "Epoch 7210/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0196 - val_loss: 9.6557\n",
      "Epoch 7211/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0193 - val_loss: 9.6555\n",
      "Epoch 7212/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0190 - val_loss: 9.6555\n",
      "Epoch 7213/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0187 - val_loss: 9.6556\n",
      "Epoch 7214/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0184 - val_loss: 9.6556\n",
      "Epoch 7215/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0181 - val_loss: 9.6556\n",
      "Epoch 7216/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0178 - val_loss: 9.6554\n",
      "Epoch 7217/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0175 - val_loss: 9.6551\n",
      "Epoch 7218/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0172 - val_loss: 9.6548\n",
      "Epoch 7219/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0169 - val_loss: 9.6548\n",
      "Epoch 7220/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0166 - val_loss: 9.6548\n",
      "Epoch 7221/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0162 - val_loss: 9.6548\n",
      "Epoch 7222/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0159 - val_loss: 9.6547\n",
      "Epoch 7223/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0156 - val_loss: 9.6546\n",
      "Epoch 7224/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0153 - val_loss: 9.6543\n",
      "Epoch 7225/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0150 - val_loss: 9.6541\n",
      "Epoch 7226/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0147 - val_loss: 9.6538\n",
      "Epoch 7227/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0144 - val_loss: 9.6537\n",
      "Epoch 7228/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0141 - val_loss: 9.6538\n",
      "Epoch 7229/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0138 - val_loss: 9.6538\n",
      "Epoch 7230/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.0135 - val_loss: 9.6538\n",
      "Epoch 7231/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0132 - val_loss: 9.6536\n",
      "Epoch 7232/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0129 - val_loss: 9.6536\n",
      "Epoch 7233/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.0126 - val_loss: 9.6535\n",
      "Epoch 7234/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0123 - val_loss: 9.6534\n",
      "Epoch 7235/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0119 - val_loss: 9.6532\n",
      "Epoch 7236/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0116 - val_loss: 9.6531\n",
      "Epoch 7237/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0113 - val_loss: 9.6530\n",
      "Epoch 7238/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0110 - val_loss: 9.6529\n",
      "Epoch 7239/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0107 - val_loss: 9.6528\n",
      "Epoch 7240/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0104 - val_loss: 9.6527\n",
      "Epoch 7241/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0101 - val_loss: 9.6527\n",
      "Epoch 7242/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0098 - val_loss: 9.6526\n",
      "Epoch 7243/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0095 - val_loss: 9.6525\n",
      "Epoch 7244/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0092 - val_loss: 9.6525\n",
      "Epoch 7245/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0089 - val_loss: 9.6524\n",
      "Epoch 7246/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0086 - val_loss: 9.6521\n",
      "Epoch 7247/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0083 - val_loss: 9.6520\n",
      "Epoch 7248/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0080 - val_loss: 9.6520\n",
      "Epoch 7249/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0076 - val_loss: 9.6519\n",
      "Epoch 7250/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.0073 - val_loss: 9.6518\n",
      "Epoch 7251/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0070 - val_loss: 9.6518\n",
      "Epoch 7252/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0067 - val_loss: 9.6516\n",
      "Epoch 7253/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0064 - val_loss: 9.6514\n",
      "Epoch 7254/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0061 - val_loss: 9.6512\n",
      "Epoch 7255/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0058 - val_loss: 9.6511\n",
      "Epoch 7256/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0055 - val_loss: 9.6510\n",
      "Epoch 7257/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0052 - val_loss: 9.6509\n",
      "Epoch 7258/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.0049 - val_loss: 9.6509\n",
      "Epoch 7259/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0046 - val_loss: 9.6509\n",
      "Epoch 7260/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0043 - val_loss: 9.6508\n",
      "Epoch 7261/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0040 - val_loss: 9.6506\n",
      "Epoch 7262/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0037 - val_loss: 9.6504\n",
      "Epoch 7263/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0033 - val_loss: 9.6503\n",
      "Epoch 7264/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0030 - val_loss: 9.6503\n",
      "Epoch 7265/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0027 - val_loss: 9.6503\n",
      "Epoch 7266/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0024 - val_loss: 9.6504\n",
      "Epoch 7267/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0021 - val_loss: 9.6503\n",
      "Epoch 7268/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0018 - val_loss: 9.6500\n",
      "Epoch 7269/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0015 - val_loss: 9.6498\n",
      "Epoch 7270/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0012 - val_loss: 9.6497\n",
      "Epoch 7271/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0009 - val_loss: 9.6496\n",
      "Epoch 7272/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0006 - val_loss: 9.6496\n",
      "Epoch 7273/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0003 - val_loss: 9.6495\n",
      "Epoch 7274/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0000 - val_loss: 9.6494\n",
      "Epoch 7275/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.9997 - val_loss: 9.6492\n",
      "Epoch 7276/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9994 - val_loss: 9.6490\n",
      "Epoch 7277/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9990 - val_loss: 9.6490\n",
      "Epoch 7278/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9987 - val_loss: 9.6491\n",
      "Epoch 7279/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9984 - val_loss: 9.6491\n",
      "Epoch 7280/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9981 - val_loss: 9.6490\n",
      "Epoch 7281/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9978 - val_loss: 9.6488\n",
      "Epoch 7282/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9975 - val_loss: 9.6485\n",
      "Epoch 7283/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9972 - val_loss: 9.6482\n",
      "Epoch 7284/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9969 - val_loss: 9.6481\n",
      "Epoch 7285/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9966 - val_loss: 9.6481\n",
      "Epoch 7286/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9963 - val_loss: 9.6481\n",
      "Epoch 7287/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9960 - val_loss: 9.6482\n",
      "Epoch 7288/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9957 - val_loss: 9.6482\n",
      "Epoch 7289/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9954 - val_loss: 9.6480\n",
      "Epoch 7290/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9950 - val_loss: 9.6477\n",
      "Epoch 7291/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9947 - val_loss: 9.6474\n",
      "Epoch 7292/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9944 - val_loss: 9.6472\n",
      "Epoch 7293/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9941 - val_loss: 9.6471\n",
      "Epoch 7294/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9938 - val_loss: 9.6471\n",
      "Epoch 7295/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9935 - val_loss: 9.6471\n",
      "Epoch 7296/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9932 - val_loss: 9.6471\n",
      "Epoch 7297/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9929 - val_loss: 9.6470\n",
      "Epoch 7298/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9926 - val_loss: 9.6468\n",
      "Epoch 7299/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9923 - val_loss: 9.6466\n",
      "Epoch 7300/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9920 - val_loss: 9.6464\n",
      "Epoch 7301/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9917 - val_loss: 9.6463\n",
      "Epoch 7302/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9914 - val_loss: 9.6462\n",
      "Epoch 7303/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9911 - val_loss: 9.6462\n",
      "Epoch 7304/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9907 - val_loss: 9.6462\n",
      "Epoch 7305/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9904 - val_loss: 9.6461\n",
      "Epoch 7306/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9901 - val_loss: 9.6459\n",
      "Epoch 7307/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9898 - val_loss: 9.6457\n",
      "Epoch 7308/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9895 - val_loss: 9.6456\n",
      "Epoch 7309/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9892 - val_loss: 9.6454\n",
      "Epoch 7310/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9889 - val_loss: 9.6453\n",
      "Epoch 7311/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9886 - val_loss: 9.6452\n",
      "Epoch 7312/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9883 - val_loss: 9.6450\n",
      "Epoch 7313/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9880 - val_loss: 9.6448\n",
      "Epoch 7314/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9877 - val_loss: 9.6447\n",
      "Epoch 7315/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9874 - val_loss: 9.6447\n",
      "Epoch 7316/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9871 - val_loss: 9.6447\n",
      "Epoch 7317/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9867 - val_loss: 9.6447\n",
      "Epoch 7318/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9864 - val_loss: 9.6445\n",
      "Epoch 7319/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9861 - val_loss: 9.6443\n",
      "Epoch 7320/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9858 - val_loss: 9.6441\n",
      "Epoch 7321/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9855 - val_loss: 9.6440\n",
      "Epoch 7322/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9852 - val_loss: 9.6438\n",
      "Epoch 7323/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9849 - val_loss: 9.6436\n",
      "Epoch 7324/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9846 - val_loss: 9.6435\n",
      "Epoch 7325/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9843 - val_loss: 9.6435\n",
      "Epoch 7326/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9840 - val_loss: 9.6435\n",
      "Epoch 7327/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9837 - val_loss: 9.6434\n",
      "Epoch 7328/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9834 - val_loss: 9.6434\n",
      "Epoch 7329/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9831 - val_loss: 9.6432\n",
      "Epoch 7330/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9828 - val_loss: 9.6430\n",
      "Epoch 7331/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9824 - val_loss: 9.6427\n",
      "Epoch 7332/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9821 - val_loss: 9.6425\n",
      "Epoch 7333/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9818 - val_loss: 9.6424\n",
      "Epoch 7334/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9815 - val_loss: 9.6422\n",
      "Epoch 7335/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9812 - val_loss: 9.6422\n",
      "Epoch 7336/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9809 - val_loss: 9.6422\n",
      "Epoch 7337/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9806 - val_loss: 9.6421\n",
      "Epoch 7338/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9803 - val_loss: 9.6420\n",
      "Epoch 7339/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9800 - val_loss: 9.6417\n",
      "Epoch 7340/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9797 - val_loss: 9.6415\n",
      "Epoch 7341/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9794 - val_loss: 9.6413\n",
      "Epoch 7342/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9791 - val_loss: 9.6412\n",
      "Epoch 7343/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9787 - val_loss: 9.6412\n",
      "Epoch 7344/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9784 - val_loss: 9.6412\n",
      "Epoch 7345/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9781 - val_loss: 9.6411\n",
      "Epoch 7346/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9778 - val_loss: 9.6409\n",
      "Epoch 7347/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9775 - val_loss: 9.6407\n",
      "Epoch 7348/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9772 - val_loss: 9.6405\n",
      "Epoch 7349/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9769 - val_loss: 9.6405\n",
      "Epoch 7350/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9766 - val_loss: 9.6405\n",
      "Epoch 7351/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9763 - val_loss: 9.6405\n",
      "Epoch 7352/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9760 - val_loss: 9.6403\n",
      "Epoch 7353/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9757 - val_loss: 9.6400\n",
      "Epoch 7354/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9754 - val_loss: 9.6396\n",
      "Epoch 7355/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.9751 - val_loss: 9.6393\n",
      "Epoch 7356/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9747 - val_loss: 9.6392\n",
      "Epoch 7357/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9744 - val_loss: 9.6393\n",
      "Epoch 7358/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9741 - val_loss: 9.6395\n",
      "Epoch 7359/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9738 - val_loss: 9.6396\n",
      "Epoch 7360/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9735 - val_loss: 9.6396\n",
      "Epoch 7361/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9732 - val_loss: 9.6393\n",
      "Epoch 7362/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9729 - val_loss: 9.6388\n",
      "Epoch 7363/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9726 - val_loss: 9.6384\n",
      "Epoch 7364/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9723 - val_loss: 9.6382\n",
      "Epoch 7365/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9720 - val_loss: 9.6381\n",
      "Epoch 7366/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9717 - val_loss: 9.6382\n",
      "Epoch 7367/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9714 - val_loss: 9.6384\n",
      "Epoch 7368/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9711 - val_loss: 9.6384\n",
      "Epoch 7369/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9707 - val_loss: 9.6382\n",
      "Epoch 7370/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9704 - val_loss: 9.6379\n",
      "Epoch 7371/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9701 - val_loss: 9.6375\n",
      "Epoch 7372/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9698 - val_loss: 9.6373\n",
      "Epoch 7373/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9695 - val_loss: 9.6372\n",
      "Epoch 7374/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9692 - val_loss: 9.6372\n",
      "Epoch 7375/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9689 - val_loss: 9.6372\n",
      "Epoch 7376/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9686 - val_loss: 9.6371\n",
      "Epoch 7377/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9683 - val_loss: 9.6370\n",
      "Epoch 7378/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9680 - val_loss: 9.6368\n",
      "Epoch 7379/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9677 - val_loss: 9.6367\n",
      "Epoch 7380/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9674 - val_loss: 9.6365\n",
      "Epoch 7381/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9671 - val_loss: 9.6365\n",
      "Epoch 7382/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9667 - val_loss: 9.6364\n",
      "Epoch 7383/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9664 - val_loss: 9.6364\n",
      "Epoch 7384/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9661 - val_loss: 9.6362\n",
      "Epoch 7385/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9658 - val_loss: 9.6360\n",
      "Epoch 7386/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9655 - val_loss: 9.6357\n",
      "Epoch 7387/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9652 - val_loss: 9.6355\n",
      "Epoch 7388/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9649 - val_loss: 9.6354\n",
      "Epoch 7389/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9646 - val_loss: 9.6354\n",
      "Epoch 7390/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9643 - val_loss: 9.6355\n",
      "Epoch 7391/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9640 - val_loss: 9.6355\n",
      "Epoch 7392/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9637 - val_loss: 9.6353\n",
      "Epoch 7393/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9634 - val_loss: 9.6352\n",
      "Epoch 7394/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9630 - val_loss: 9.6351\n",
      "Epoch 7395/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9627 - val_loss: 9.6347\n",
      "Epoch 7396/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9624 - val_loss: 9.6345\n",
      "Epoch 7397/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9621 - val_loss: 9.6344\n",
      "Epoch 7398/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9618 - val_loss: 9.6344\n",
      "Epoch 7399/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9615 - val_loss: 9.6343\n",
      "Epoch 7400/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9612 - val_loss: 9.6343\n",
      "Epoch 7401/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9609 - val_loss: 9.6343\n",
      "Epoch 7402/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9606 - val_loss: 9.6341\n",
      "Epoch 7403/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9603 - val_loss: 9.6338\n",
      "Epoch 7404/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9600 - val_loss: 9.6336\n",
      "Epoch 7405/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9597 - val_loss: 9.6332\n",
      "Epoch 7406/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9594 - val_loss: 9.6330\n",
      "Epoch 7407/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9590 - val_loss: 9.6331\n",
      "Epoch 7408/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9587 - val_loss: 9.6331\n",
      "Epoch 7409/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9584 - val_loss: 9.6329\n",
      "Epoch 7410/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9581 - val_loss: 9.6328\n",
      "Epoch 7411/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9578 - val_loss: 9.6327\n",
      "Epoch 7412/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9575 - val_loss: 9.6324\n",
      "Epoch 7413/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9572 - val_loss: 9.6320\n",
      "Epoch 7414/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9569 - val_loss: 9.6318\n",
      "Epoch 7415/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9566 - val_loss: 9.6315\n",
      "Epoch 7416/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9563 - val_loss: 9.6311\n",
      "Epoch 7417/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9560 - val_loss: 9.6310\n",
      "Epoch 7418/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9557 - val_loss: 9.6310\n",
      "Epoch 7419/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9554 - val_loss: 9.6309\n",
      "Epoch 7420/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9550 - val_loss: 9.6309\n",
      "Epoch 7421/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9547 - val_loss: 9.6309\n",
      "Epoch 7422/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9544 - val_loss: 9.6307\n",
      "Epoch 7423/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9541 - val_loss: 9.6304\n",
      "Epoch 7424/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9538 - val_loss: 9.6301\n",
      "Epoch 7425/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9535 - val_loss: 9.6298\n",
      "Epoch 7426/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9532 - val_loss: 9.6297\n",
      "Epoch 7427/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9529 - val_loss: 9.6297\n",
      "Epoch 7428/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9526 - val_loss: 9.6299\n",
      "Epoch 7429/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9523 - val_loss: 9.6299\n",
      "Epoch 7430/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9520 - val_loss: 9.6298\n",
      "Epoch 7431/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9517 - val_loss: 9.6296\n",
      "Epoch 7432/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9514 - val_loss: 9.6292\n",
      "Epoch 7433/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9510 - val_loss: 9.6289\n",
      "Epoch 7434/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9507 - val_loss: 9.6289\n",
      "Epoch 7435/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9504 - val_loss: 9.6289\n",
      "Epoch 7436/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9501 - val_loss: 9.6288\n",
      "Epoch 7437/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9498 - val_loss: 9.6286\n",
      "Epoch 7438/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9495 - val_loss: 9.6284\n",
      "Epoch 7439/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9492 - val_loss: 9.6282\n",
      "Epoch 7440/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9489 - val_loss: 9.6280\n",
      "Epoch 7441/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9486 - val_loss: 9.6279\n",
      "Epoch 7442/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9483 - val_loss: 9.6279\n",
      "Epoch 7443/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9480 - val_loss: 9.6279\n",
      "Epoch 7444/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9477 - val_loss: 9.6281\n",
      "Epoch 7445/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9473 - val_loss: 9.6280\n",
      "Epoch 7446/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9470 - val_loss: 9.6276\n",
      "Epoch 7447/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9467 - val_loss: 9.6274\n",
      "Epoch 7448/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9464 - val_loss: 9.6273\n",
      "Epoch 7449/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9461 - val_loss: 9.6272\n",
      "Epoch 7450/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9458 - val_loss: 9.6272\n",
      "Epoch 7451/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9455 - val_loss: 9.6272\n",
      "Epoch 7452/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9452 - val_loss: 9.6270\n",
      "Epoch 7453/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9449 - val_loss: 9.6268\n",
      "Epoch 7454/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9446 - val_loss: 9.6265\n",
      "Epoch 7455/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9443 - val_loss: 9.6263\n",
      "Epoch 7456/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9440 - val_loss: 9.6261\n",
      "Epoch 7457/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9437 - val_loss: 9.6260\n",
      "Epoch 7458/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9433 - val_loss: 9.6261\n",
      "Epoch 7459/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9430 - val_loss: 9.6261\n",
      "Epoch 7460/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9427 - val_loss: 9.6259\n",
      "Epoch 7461/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9424 - val_loss: 9.6257\n",
      "Epoch 7462/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9421 - val_loss: 9.6257\n",
      "Epoch 7463/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9418 - val_loss: 9.6256\n",
      "Epoch 7464/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.9415 - val_loss: 9.6255\n",
      "Epoch 7465/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.9412 - val_loss: 9.6254\n",
      "Epoch 7466/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.9409 - val_loss: 9.6253\n",
      "Epoch 7467/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9406 - val_loss: 9.6251\n",
      "Epoch 7468/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.9403 - val_loss: 9.6250\n",
      "Epoch 7469/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9400 - val_loss: 9.6248\n",
      "Epoch 7470/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9396 - val_loss: 9.6246\n",
      "Epoch 7471/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9393 - val_loss: 9.6245\n",
      "Epoch 7472/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.9390 - val_loss: 9.6244\n",
      "Epoch 7473/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.9387 - val_loss: 9.6244\n",
      "Epoch 7474/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.9384 - val_loss: 9.6243\n",
      "Epoch 7475/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.9381 - val_loss: 9.6242\n",
      "Epoch 7476/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.9378 - val_loss: 9.6241\n",
      "Epoch 7477/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9375 - val_loss: 9.6240\n",
      "Epoch 7478/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9372 - val_loss: 9.6237\n",
      "Epoch 7479/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9369 - val_loss: 9.6236\n",
      "Epoch 7480/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9366 - val_loss: 9.6235\n",
      "Epoch 7481/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9363 - val_loss: 9.6234\n",
      "Epoch 7482/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.936 - 0s 35ms/step - loss: 3.9360 - val_loss: 9.6233\n",
      "Epoch 7483/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.9356 - val_loss: 9.6232\n",
      "Epoch 7484/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9353 - val_loss: 9.6231\n",
      "Epoch 7485/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9350 - val_loss: 9.6230\n",
      "Epoch 7486/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9347 - val_loss: 9.6229\n",
      "Epoch 7487/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9344 - val_loss: 9.6227\n",
      "Epoch 7488/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9341 - val_loss: 9.6226\n",
      "Epoch 7489/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9338 - val_loss: 9.6225\n",
      "Epoch 7490/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.933 - 0s 31ms/step - loss: 3.9335 - val_loss: 9.6226\n",
      "Epoch 7491/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9332 - val_loss: 9.6225\n",
      "Epoch 7492/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9329 - val_loss: 9.6222\n",
      "Epoch 7493/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9326 - val_loss: 9.6220\n",
      "Epoch 7494/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9323 - val_loss: 9.6219\n",
      "Epoch 7495/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9319 - val_loss: 9.6220\n",
      "Epoch 7496/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9316 - val_loss: 9.6220\n",
      "Epoch 7497/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9313 - val_loss: 9.6218\n",
      "Epoch 7498/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9310 - val_loss: 9.6217\n",
      "Epoch 7499/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9307 - val_loss: 9.6215\n",
      "Epoch 7500/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9304 - val_loss: 9.6213\n",
      "Epoch 7501/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9301 - val_loss: 9.6212\n",
      "Epoch 7502/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9298 - val_loss: 9.6210\n",
      "Epoch 7503/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9295 - val_loss: 9.6208\n",
      "Epoch 7504/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9292 - val_loss: 9.6207\n",
      "Epoch 7505/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9289 - val_loss: 9.6207\n",
      "Epoch 7506/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9286 - val_loss: 9.6208\n",
      "Epoch 7507/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9282 - val_loss: 9.6209\n",
      "Epoch 7508/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9279 - val_loss: 9.6207\n",
      "Epoch 7509/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9276 - val_loss: 9.6204\n",
      "Epoch 7510/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9273 - val_loss: 9.6201\n",
      "Epoch 7511/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9270 - val_loss: 9.6199\n",
      "Epoch 7512/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9267 - val_loss: 9.6198\n",
      "Epoch 7513/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9264 - val_loss: 9.6199\n",
      "Epoch 7514/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9261 - val_loss: 9.6200\n",
      "Epoch 7515/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9258 - val_loss: 9.6199\n",
      "Epoch 7516/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9255 - val_loss: 9.6196\n",
      "Epoch 7517/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9252 - val_loss: 9.6193\n",
      "Epoch 7518/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9249 - val_loss: 9.6191\n",
      "Epoch 7519/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9245 - val_loss: 9.6192\n",
      "Epoch 7520/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9242 - val_loss: 9.6192\n",
      "Epoch 7521/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9239 - val_loss: 9.6192\n",
      "Epoch 7522/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9236 - val_loss: 9.6192\n",
      "Epoch 7523/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9233 - val_loss: 9.6192\n",
      "Epoch 7524/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9230 - val_loss: 9.6191\n",
      "Epoch 7525/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9227 - val_loss: 9.6189\n",
      "Epoch 7526/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9224 - val_loss: 9.6186\n",
      "Epoch 7527/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9221 - val_loss: 9.6186\n",
      "Epoch 7528/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9218 - val_loss: 9.6186\n",
      "Epoch 7529/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9215 - val_loss: 9.6187\n",
      "Epoch 7530/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9212 - val_loss: 9.6185\n",
      "Epoch 7531/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9208 - val_loss: 9.6182\n",
      "Epoch 7532/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9205 - val_loss: 9.6179\n",
      "Epoch 7533/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9202 - val_loss: 9.6178\n",
      "Epoch 7534/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9199 - val_loss: 9.6178\n",
      "Epoch 7535/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9196 - val_loss: 9.6177\n",
      "Epoch 7536/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9193 - val_loss: 9.6174\n",
      "Epoch 7537/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9190 - val_loss: 9.6172\n",
      "Epoch 7538/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9187 - val_loss: 9.6170\n",
      "Epoch 7539/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9184 - val_loss: 9.6168\n",
      "Epoch 7540/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9181 - val_loss: 9.6167\n",
      "Epoch 7541/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9178 - val_loss: 9.6167\n",
      "Epoch 7542/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9175 - val_loss: 9.6165\n",
      "Epoch 7543/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9171 - val_loss: 9.6161\n",
      "Epoch 7544/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9168 - val_loss: 9.6159\n",
      "Epoch 7545/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9165 - val_loss: 9.6157\n",
      "Epoch 7546/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9162 - val_loss: 9.6157\n",
      "Epoch 7547/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9159 - val_loss: 9.6158\n",
      "Epoch 7548/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9156 - val_loss: 9.6160\n",
      "Epoch 7549/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9153 - val_loss: 9.6159\n",
      "Epoch 7550/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9150 - val_loss: 9.6156\n",
      "Epoch 7551/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9147 - val_loss: 9.6152\n",
      "Epoch 7552/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9144 - val_loss: 9.6149\n",
      "Epoch 7553/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9141 - val_loss: 9.6146\n",
      "Epoch 7554/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9138 - val_loss: 9.6145\n",
      "Epoch 7555/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9134 - val_loss: 9.6146\n",
      "Epoch 7556/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9131 - val_loss: 9.6148\n",
      "Epoch 7557/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9128 - val_loss: 9.6148\n",
      "Epoch 7558/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9125 - val_loss: 9.6146\n",
      "Epoch 7559/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9122 - val_loss: 9.6142\n",
      "Epoch 7560/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9119 - val_loss: 9.6139\n",
      "Epoch 7561/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9116 - val_loss: 9.6138\n",
      "Epoch 7562/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9113 - val_loss: 9.6137\n",
      "Epoch 7563/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9110 - val_loss: 9.6136\n",
      "Epoch 7564/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9107 - val_loss: 9.6135\n",
      "Epoch 7565/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9104 - val_loss: 9.6133\n",
      "Epoch 7566/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9100 - val_loss: 9.6131\n",
      "Epoch 7567/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9097 - val_loss: 9.6130\n",
      "Epoch 7568/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9094 - val_loss: 9.6129\n",
      "Epoch 7569/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9091 - val_loss: 9.6127\n",
      "Epoch 7570/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9088 - val_loss: 9.6125\n",
      "Epoch 7571/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9085 - val_loss: 9.6123\n",
      "Epoch 7572/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9082 - val_loss: 9.6120\n",
      "Epoch 7573/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9079 - val_loss: 9.6118\n",
      "Epoch 7574/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9076 - val_loss: 9.6119\n",
      "Epoch 7575/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9073 - val_loss: 9.6119\n",
      "Epoch 7576/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9070 - val_loss: 9.6118\n",
      "Epoch 7577/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9067 - val_loss: 9.6116\n",
      "Epoch 7578/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9063 - val_loss: 9.6113\n",
      "Epoch 7579/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9060 - val_loss: 9.6110\n",
      "Epoch 7580/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9057 - val_loss: 9.6109\n",
      "Epoch 7581/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9054 - val_loss: 9.6110\n",
      "Epoch 7582/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9051 - val_loss: 9.6109\n",
      "Epoch 7583/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9048 - val_loss: 9.6109\n",
      "Epoch 7584/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9045 - val_loss: 9.6108\n",
      "Epoch 7585/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9042 - val_loss: 9.6105\n",
      "Epoch 7586/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9039 - val_loss: 9.6103\n",
      "Epoch 7587/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9036 - val_loss: 9.6103\n",
      "Epoch 7588/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9033 - val_loss: 9.6100\n",
      "Epoch 7589/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9029 - val_loss: 9.6097\n",
      "Epoch 7590/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9026 - val_loss: 9.6096\n",
      "Epoch 7591/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9023 - val_loss: 9.6095\n",
      "Epoch 7592/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9020 - val_loss: 9.6093\n",
      "Epoch 7593/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9017 - val_loss: 9.6093\n",
      "Epoch 7594/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9014 - val_loss: 9.6093\n",
      "Epoch 7595/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9011 - val_loss: 9.6092\n",
      "Epoch 7596/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9008 - val_loss: 9.6090\n",
      "Epoch 7597/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9005 - val_loss: 9.6088\n",
      "Epoch 7598/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9002 - val_loss: 9.6087\n",
      "Epoch 7599/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8999 - val_loss: 9.6085\n",
      "Epoch 7600/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8996 - val_loss: 9.6084\n",
      "Epoch 7601/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8992 - val_loss: 9.6083\n",
      "Epoch 7602/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8989 - val_loss: 9.6081\n",
      "Epoch 7603/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8986 - val_loss: 9.6081\n",
      "Epoch 7604/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8983 - val_loss: 9.6081\n",
      "Epoch 7605/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8980 - val_loss: 9.6080\n",
      "Epoch 7606/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8977 - val_loss: 9.6078\n",
      "Epoch 7607/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8974 - val_loss: 9.6076\n",
      "Epoch 7608/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8971 - val_loss: 9.6075\n",
      "Epoch 7609/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8968 - val_loss: 9.6073\n",
      "Epoch 7610/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8965 - val_loss: 9.6071\n",
      "Epoch 7611/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8962 - val_loss: 9.6070\n",
      "Epoch 7612/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8958 - val_loss: 9.6069\n",
      "Epoch 7613/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8955 - val_loss: 9.6067\n",
      "Epoch 7614/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8952 - val_loss: 9.6064\n",
      "Epoch 7615/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8949 - val_loss: 9.6062\n",
      "Epoch 7616/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8946 - val_loss: 9.6062\n",
      "Epoch 7617/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8943 - val_loss: 9.6062\n",
      "Epoch 7618/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.8940 - val_loss: 9.6061\n",
      "Epoch 7619/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8937 - val_loss: 9.6061\n",
      "Epoch 7620/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8934 - val_loss: 9.6061\n",
      "Epoch 7621/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8931 - val_loss: 9.6060\n",
      "Epoch 7622/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8928 - val_loss: 9.6060\n",
      "Epoch 7623/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8925 - val_loss: 9.6059\n",
      "Epoch 7624/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8921 - val_loss: 9.6056\n",
      "Epoch 7625/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8918 - val_loss: 9.6052\n",
      "Epoch 7626/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8915 - val_loss: 9.6050\n",
      "Epoch 7627/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8912 - val_loss: 9.6047\n",
      "Epoch 7628/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8909 - val_loss: 9.6045\n",
      "Epoch 7629/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8906 - val_loss: 9.6046\n",
      "Epoch 7630/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8903 - val_loss: 9.6046\n",
      "Epoch 7631/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8900 - val_loss: 9.6044\n",
      "Epoch 7632/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8897 - val_loss: 9.6041\n",
      "Epoch 7633/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8894 - val_loss: 9.6038\n",
      "Epoch 7634/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8891 - val_loss: 9.6037\n",
      "Epoch 7635/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8887 - val_loss: 9.6037\n",
      "Epoch 7636/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8884 - val_loss: 9.6037\n",
      "Epoch 7637/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8881 - val_loss: 9.6035\n",
      "Epoch 7638/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8878 - val_loss: 9.6032\n",
      "Epoch 7639/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8875 - val_loss: 9.6029\n",
      "Epoch 7640/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8872 - val_loss: 9.6027\n",
      "Epoch 7641/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8869 - val_loss: 9.6027\n",
      "Epoch 7642/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8866 - val_loss: 9.6026\n",
      "Epoch 7643/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8863 - val_loss: 9.6024\n",
      "Epoch 7644/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8860 - val_loss: 9.6021\n",
      "Epoch 7645/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8857 - val_loss: 9.6020\n",
      "Epoch 7646/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8853 - val_loss: 9.6021\n",
      "Epoch 7647/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8850 - val_loss: 9.6020\n",
      "Epoch 7648/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8847 - val_loss: 9.6019\n",
      "Epoch 7649/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8844 - val_loss: 9.6017\n",
      "Epoch 7650/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8841 - val_loss: 9.6013\n",
      "Epoch 7651/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8838 - val_loss: 9.6011\n",
      "Epoch 7652/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8835 - val_loss: 9.6011\n",
      "Epoch 7653/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8832 - val_loss: 9.6009\n",
      "Epoch 7654/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8829 - val_loss: 9.6006\n",
      "Epoch 7655/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8826 - val_loss: 9.6004\n",
      "Epoch 7656/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8823 - val_loss: 9.6002\n",
      "Epoch 7657/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.8819 - val_loss: 9.6000\n",
      "Epoch 7658/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.8816 - val_loss: 9.5999\n",
      "Epoch 7659/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.8813 - val_loss: 9.5998\n",
      "Epoch 7660/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8810 - val_loss: 9.5997\n",
      "Epoch 7661/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8807 - val_loss: 9.5997\n",
      "Epoch 7662/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8804 - val_loss: 9.5997\n",
      "Epoch 7663/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8801 - val_loss: 9.5995\n",
      "Epoch 7664/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8798 - val_loss: 9.5992\n",
      "Epoch 7665/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8795 - val_loss: 9.5990\n",
      "Epoch 7666/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8792 - val_loss: 9.5989\n",
      "Epoch 7667/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8789 - val_loss: 9.5989\n",
      "Epoch 7668/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8786 - val_loss: 9.5988\n",
      "Epoch 7669/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8782 - val_loss: 9.5987\n",
      "Epoch 7670/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8779 - val_loss: 9.5985\n",
      "Epoch 7671/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8776 - val_loss: 9.5980\n",
      "Epoch 7672/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8773 - val_loss: 9.5976\n",
      "Epoch 7673/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8770 - val_loss: 9.5974\n",
      "Epoch 7674/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8767 - val_loss: 9.5972\n",
      "Epoch 7675/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8764 - val_loss: 9.5972\n",
      "Epoch 7676/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.876 - 0s 30ms/step - loss: 3.8761 - val_loss: 9.5975\n",
      "Epoch 7677/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8758 - val_loss: 9.5977\n",
      "Epoch 7678/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8755 - val_loss: 9.5973\n",
      "Epoch 7679/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8752 - val_loss: 9.5967\n",
      "Epoch 7680/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8748 - val_loss: 9.5964\n",
      "Epoch 7681/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8745 - val_loss: 9.5963\n",
      "Epoch 7682/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8742 - val_loss: 9.5964\n",
      "Epoch 7683/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8739 - val_loss: 9.5965\n",
      "Epoch 7684/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8736 - val_loss: 9.5964\n",
      "Epoch 7685/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8733 - val_loss: 9.5960\n",
      "Epoch 7686/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8730 - val_loss: 9.5957\n",
      "Epoch 7687/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8727 - val_loss: 9.5953\n",
      "Epoch 7688/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8724 - val_loss: 9.5950\n",
      "Epoch 7689/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8721 - val_loss: 9.5950\n",
      "Epoch 7690/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8718 - val_loss: 9.5952\n",
      "Epoch 7691/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8715 - val_loss: 9.5950\n",
      "Epoch 7692/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8711 - val_loss: 9.5948\n",
      "Epoch 7693/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8708 - val_loss: 9.5946\n",
      "Epoch 7694/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8705 - val_loss: 9.5942\n",
      "Epoch 7695/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8702 - val_loss: 9.5940\n",
      "Epoch 7696/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8699 - val_loss: 9.5940\n",
      "Epoch 7697/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8696 - val_loss: 9.5941\n",
      "Epoch 7698/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8693 - val_loss: 9.5937\n",
      "Epoch 7699/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8690 - val_loss: 9.5933\n",
      "Epoch 7700/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8687 - val_loss: 9.5932\n",
      "Epoch 7701/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8684 - val_loss: 9.5932\n",
      "Epoch 7702/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8681 - val_loss: 9.5932\n",
      "Epoch 7703/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8677 - val_loss: 9.5931\n",
      "Epoch 7704/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8674 - val_loss: 9.5926\n",
      "Epoch 7705/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8671 - val_loss: 9.5920\n",
      "Epoch 7706/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8668 - val_loss: 9.5916\n",
      "Epoch 7707/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8665 - val_loss: 9.5915\n",
      "Epoch 7708/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8662 - val_loss: 9.5915\n",
      "Epoch 7709/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8659 - val_loss: 9.5916\n",
      "Epoch 7710/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8656 - val_loss: 9.5916\n",
      "Epoch 7711/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8653 - val_loss: 9.5912\n",
      "Epoch 7712/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8650 - val_loss: 9.5906\n",
      "Epoch 7713/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8647 - val_loss: 9.5905\n",
      "Epoch 7714/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8644 - val_loss: 9.5906\n",
      "Epoch 7715/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8640 - val_loss: 9.5904\n",
      "Epoch 7716/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8637 - val_loss: 9.5903\n",
      "Epoch 7717/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.8634 - val_loss: 9.5901\n",
      "Epoch 7718/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8631 - val_loss: 9.5898\n",
      "Epoch 7719/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8628 - val_loss: 9.5897\n",
      "Epoch 7720/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8625 - val_loss: 9.5897\n",
      "Epoch 7721/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.8622 - val_loss: 9.5896\n",
      "Epoch 7722/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8619 - val_loss: 9.5890\n",
      "Epoch 7723/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8616 - val_loss: 9.5886\n",
      "Epoch 7724/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8613 - val_loss: 9.5883\n",
      "Epoch 7725/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8610 - val_loss: 9.5883\n",
      "Epoch 7726/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8606 - val_loss: 9.5883\n",
      "Epoch 7727/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8603 - val_loss: 9.5879\n",
      "Epoch 7728/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8600 - val_loss: 9.5873\n",
      "Epoch 7729/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8597 - val_loss: 9.5868\n",
      "Epoch 7730/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8594 - val_loss: 9.5868\n",
      "Epoch 7731/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8591 - val_loss: 9.5870\n",
      "Epoch 7732/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8588 - val_loss: 9.5872\n",
      "Epoch 7733/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8585 - val_loss: 9.5873\n",
      "Epoch 7734/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8582 - val_loss: 9.5872\n",
      "Epoch 7735/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8579 - val_loss: 9.5868\n",
      "Epoch 7736/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8576 - val_loss: 9.5863\n",
      "Epoch 7737/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8573 - val_loss: 9.5859\n",
      "Epoch 7738/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8569 - val_loss: 9.5855\n",
      "Epoch 7739/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8566 - val_loss: 9.5853\n",
      "Epoch 7740/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8563 - val_loss: 9.5852\n",
      "Epoch 7741/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8560 - val_loss: 9.5850\n",
      "Epoch 7742/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8557 - val_loss: 9.5848\n",
      "Epoch 7743/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8554 - val_loss: 9.5845\n",
      "Epoch 7744/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8551 - val_loss: 9.5841\n",
      "Epoch 7745/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8548 - val_loss: 9.5840\n",
      "Epoch 7746/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8545 - val_loss: 9.5842\n",
      "Epoch 7747/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8542 - val_loss: 9.5843\n",
      "Epoch 7748/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8539 - val_loss: 9.5841\n",
      "Epoch 7749/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8536 - val_loss: 9.5838\n",
      "Epoch 7750/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8532 - val_loss: 9.5833\n",
      "Epoch 7751/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8529 - val_loss: 9.5828\n",
      "Epoch 7752/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8526 - val_loss: 9.5825\n",
      "Epoch 7753/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8523 - val_loss: 9.5825\n",
      "Epoch 7754/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8520 - val_loss: 9.5825\n",
      "Epoch 7755/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8517 - val_loss: 9.5825\n",
      "Epoch 7756/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8514 - val_loss: 9.5821\n",
      "Epoch 7757/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8511 - val_loss: 9.5818\n",
      "Epoch 7758/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8508 - val_loss: 9.5816\n",
      "Epoch 7759/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8505 - val_loss: 9.5813\n",
      "Epoch 7760/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8502 - val_loss: 9.5811\n",
      "Epoch 7761/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8498 - val_loss: 9.5811\n",
      "Epoch 7762/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8495 - val_loss: 9.5810\n",
      "Epoch 7763/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8492 - val_loss: 9.5808\n",
      "Epoch 7764/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8489 - val_loss: 9.5810\n",
      "Epoch 7765/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8486 - val_loss: 9.5807\n",
      "Epoch 7766/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8483 - val_loss: 9.5801\n",
      "Epoch 7767/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8480 - val_loss: 9.5800\n",
      "Epoch 7768/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8477 - val_loss: 9.5800\n",
      "Epoch 7769/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8474 - val_loss: 9.5795\n",
      "Epoch 7770/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8471 - val_loss: 9.5792\n",
      "Epoch 7771/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8468 - val_loss: 9.5789\n",
      "Epoch 7772/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8465 - val_loss: 9.5787\n",
      "Epoch 7773/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8461 - val_loss: 9.5785\n",
      "Epoch 7774/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8458 - val_loss: 9.5785\n",
      "Epoch 7775/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8455 - val_loss: 9.5784\n",
      "Epoch 7776/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8452 - val_loss: 9.5780\n",
      "Epoch 7777/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8449 - val_loss: 9.5777\n",
      "Epoch 7778/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.8446 - val_loss: 9.5777\n",
      "Epoch 7779/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8443 - val_loss: 9.5777\n",
      "Epoch 7780/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8440 - val_loss: 9.5775\n",
      "Epoch 7781/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8437 - val_loss: 9.5771\n",
      "Epoch 7782/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8434 - val_loss: 9.5769\n",
      "Epoch 7783/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8431 - val_loss: 9.5767\n",
      "Epoch 7784/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8428 - val_loss: 9.5767\n",
      "Epoch 7785/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8424 - val_loss: 9.5767\n",
      "Epoch 7786/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8421 - val_loss: 9.5768\n",
      "Epoch 7787/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8418 - val_loss: 9.5766\n",
      "Epoch 7788/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8415 - val_loss: 9.5762\n",
      "Epoch 7789/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8412 - val_loss: 9.5757\n",
      "Epoch 7790/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8409 - val_loss: 9.5754\n",
      "Epoch 7791/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8406 - val_loss: 9.5753\n",
      "Epoch 7792/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8403 - val_loss: 9.5752\n",
      "Epoch 7793/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8400 - val_loss: 9.5751\n",
      "Epoch 7794/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8397 - val_loss: 9.5751\n",
      "Epoch 7795/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8394 - val_loss: 9.5749\n",
      "Epoch 7796/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8391 - val_loss: 9.5744\n",
      "Epoch 7797/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8387 - val_loss: 9.5742\n",
      "Epoch 7798/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8384 - val_loss: 9.5743\n",
      "Epoch 7799/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8381 - val_loss: 9.5743\n",
      "Epoch 7800/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8378 - val_loss: 9.5743\n",
      "Epoch 7801/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8375 - val_loss: 9.5743\n",
      "Epoch 7802/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8372 - val_loss: 9.5739\n",
      "Epoch 7803/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8369 - val_loss: 9.5734\n",
      "Epoch 7804/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8366 - val_loss: 9.5731\n",
      "Epoch 7805/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8363 - val_loss: 9.5729\n",
      "Epoch 7806/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8360 - val_loss: 9.5727\n",
      "Epoch 7807/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8357 - val_loss: 9.5728\n",
      "Epoch 7808/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8353 - val_loss: 9.5728\n",
      "Epoch 7809/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8350 - val_loss: 9.5726\n",
      "Epoch 7810/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8347 - val_loss: 9.5726\n",
      "Epoch 7811/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8344 - val_loss: 9.5726\n",
      "Epoch 7812/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8341 - val_loss: 9.5721\n",
      "Epoch 7813/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8338 - val_loss: 9.5716\n",
      "Epoch 7814/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8335 - val_loss: 9.5714\n",
      "Epoch 7815/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8332 - val_loss: 9.5711\n",
      "Epoch 7816/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8329 - val_loss: 9.5709\n",
      "Epoch 7817/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8326 - val_loss: 9.5709\n",
      "Epoch 7818/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8323 - val_loss: 9.5708\n",
      "Epoch 7819/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8320 - val_loss: 9.5704\n",
      "Epoch 7820/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8316 - val_loss: 9.5703\n",
      "Epoch 7821/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8313 - val_loss: 9.5703\n",
      "Epoch 7822/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8310 - val_loss: 9.5702\n",
      "Epoch 7823/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8307 - val_loss: 9.5702\n",
      "Epoch 7824/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8304 - val_loss: 9.5701\n",
      "Epoch 7825/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8301 - val_loss: 9.5696\n",
      "Epoch 7826/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8298 - val_loss: 9.5693\n",
      "Epoch 7827/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8295 - val_loss: 9.5694\n",
      "Epoch 7828/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8292 - val_loss: 9.5691\n",
      "Epoch 7829/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8289 - val_loss: 9.5685\n",
      "Epoch 7830/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8286 - val_loss: 9.5683\n",
      "Epoch 7831/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8283 - val_loss: 9.5682\n",
      "Epoch 7832/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8279 - val_loss: 9.5684\n",
      "Epoch 7833/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8276 - val_loss: 9.5687\n",
      "Epoch 7834/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8273 - val_loss: 9.5686\n",
      "Epoch 7835/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8270 - val_loss: 9.5679\n",
      "Epoch 7836/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8267 - val_loss: 9.5674\n",
      "Epoch 7837/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8264 - val_loss: 9.5671\n",
      "Epoch 7838/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8261 - val_loss: 9.5669\n",
      "Epoch 7839/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8258 - val_loss: 9.5670\n",
      "Epoch 7840/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8255 - val_loss: 9.5670\n",
      "Epoch 7841/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8252 - val_loss: 9.5666\n",
      "Epoch 7842/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.8249 - val_loss: 9.5665\n",
      "Epoch 7843/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8246 - val_loss: 9.5665\n",
      "Epoch 7844/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8243 - val_loss: 9.5661\n",
      "Epoch 7845/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8239 - val_loss: 9.5657\n",
      "Epoch 7846/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8236 - val_loss: 9.5657\n",
      "Epoch 7847/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8233 - val_loss: 9.5656\n",
      "Epoch 7848/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8230 - val_loss: 9.5653\n",
      "Epoch 7849/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8227 - val_loss: 9.5654\n",
      "Epoch 7850/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8224 - val_loss: 9.5651\n",
      "Epoch 7851/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8221 - val_loss: 9.5645\n",
      "Epoch 7852/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8218 - val_loss: 9.5641\n",
      "Epoch 7853/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8215 - val_loss: 9.5637\n",
      "Epoch 7854/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8212 - val_loss: 9.5632\n",
      "Epoch 7855/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8209 - val_loss: 9.5633\n",
      "Epoch 7856/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8206 - val_loss: 9.5635\n",
      "Epoch 7857/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8203 - val_loss: 9.5631\n",
      "Epoch 7858/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8199 - val_loss: 9.5625\n",
      "Epoch 7859/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8196 - val_loss: 9.5622\n",
      "Epoch 7860/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8193 - val_loss: 9.5618\n",
      "Epoch 7861/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8190 - val_loss: 9.5615\n",
      "Epoch 7862/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8187 - val_loss: 9.5611\n",
      "Epoch 7863/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8184 - val_loss: 9.5605\n",
      "Epoch 7864/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8181 - val_loss: 9.5602\n",
      "Epoch 7865/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8178 - val_loss: 9.5604\n",
      "Epoch 7866/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8175 - val_loss: 9.5607\n",
      "Epoch 7867/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8172 - val_loss: 9.5608\n",
      "Epoch 7868/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8169 - val_loss: 9.5606\n",
      "Epoch 7869/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8166 - val_loss: 9.5601\n",
      "Epoch 7870/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8163 - val_loss: 9.5592\n",
      "Epoch 7871/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8159 - val_loss: 9.5584\n",
      "Epoch 7872/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8156 - val_loss: 9.5579\n",
      "Epoch 7873/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8153 - val_loss: 9.5580\n",
      "Epoch 7874/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8150 - val_loss: 9.5581\n",
      "Epoch 7875/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8147 - val_loss: 9.5580\n",
      "Epoch 7876/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8144 - val_loss: 9.5577\n",
      "Epoch 7877/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8141 - val_loss: 9.5572\n",
      "Epoch 7878/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8138 - val_loss: 9.5568\n",
      "Epoch 7879/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8135 - val_loss: 9.5565\n",
      "Epoch 7880/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8132 - val_loss: 9.5562\n",
      "Epoch 7881/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8129 - val_loss: 9.5558\n",
      "Epoch 7882/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8126 - val_loss: 9.5557\n",
      "Epoch 7883/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8123 - val_loss: 9.5556\n",
      "Epoch 7884/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8120 - val_loss: 9.5553\n",
      "Epoch 7885/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8116 - val_loss: 9.5549\n",
      "Epoch 7886/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8113 - val_loss: 9.5546\n",
      "Epoch 7887/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8110 - val_loss: 9.5542\n",
      "Epoch 7888/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8107 - val_loss: 9.5540\n",
      "Epoch 7889/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8104 - val_loss: 9.5536\n",
      "Epoch 7890/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8101 - val_loss: 9.5529\n",
      "Epoch 7891/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8098 - val_loss: 9.5524\n",
      "Epoch 7892/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8095 - val_loss: 9.5522\n",
      "Epoch 7893/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8092 - val_loss: 9.5524\n",
      "Epoch 7894/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8089 - val_loss: 9.5527\n",
      "Epoch 7895/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8086 - val_loss: 9.5528\n",
      "Epoch 7896/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8083 - val_loss: 9.5524\n",
      "Epoch 7897/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8080 - val_loss: 9.5516\n",
      "Epoch 7898/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8077 - val_loss: 9.5510\n",
      "Epoch 7899/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8073 - val_loss: 9.5506\n",
      "Epoch 7900/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8070 - val_loss: 9.5505\n",
      "Epoch 7901/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8067 - val_loss: 9.5504\n",
      "Epoch 7902/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8064 - val_loss: 9.5503\n",
      "Epoch 7903/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.8061 - val_loss: 9.5502\n",
      "Epoch 7904/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8058 - val_loss: 9.5499\n",
      "Epoch 7905/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.8055 - val_loss: 9.5494\n",
      "Epoch 7906/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.8052 - val_loss: 9.5488\n",
      "Epoch 7907/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8049 - val_loss: 9.5483\n",
      "Epoch 7908/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8046 - val_loss: 9.5480\n",
      "Epoch 7909/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8043 - val_loss: 9.5480\n",
      "Epoch 7910/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8040 - val_loss: 9.5477\n",
      "Epoch 7911/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8037 - val_loss: 9.5476\n",
      "Epoch 7912/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8034 - val_loss: 9.5477\n",
      "Epoch 7913/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8030 - val_loss: 9.5477\n",
      "Epoch 7914/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8027 - val_loss: 9.5472\n",
      "Epoch 7915/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8024 - val_loss: 9.5468\n",
      "Epoch 7916/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8021 - val_loss: 9.5465\n",
      "Epoch 7917/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8018 - val_loss: 9.5462\n",
      "Epoch 7918/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8015 - val_loss: 9.5458\n",
      "Epoch 7919/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8012 - val_loss: 9.5454\n",
      "Epoch 7920/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8009 - val_loss: 9.5449\n",
      "Epoch 7921/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8006 - val_loss: 9.5449\n",
      "Epoch 7922/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8003 - val_loss: 9.5450\n",
      "Epoch 7923/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8000 - val_loss: 9.5448\n",
      "Epoch 7924/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7997 - val_loss: 9.5443\n",
      "Epoch 7925/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7994 - val_loss: 9.5438\n",
      "Epoch 7926/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7991 - val_loss: 9.5435\n",
      "Epoch 7927/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7987 - val_loss: 9.5437\n",
      "Epoch 7928/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7984 - val_loss: 9.5436\n",
      "Epoch 7929/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7981 - val_loss: 9.5432\n",
      "Epoch 7930/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7978 - val_loss: 9.5430\n",
      "Epoch 7931/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7975 - val_loss: 9.5428\n",
      "Epoch 7932/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7972 - val_loss: 9.5425\n",
      "Epoch 7933/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7969 - val_loss: 9.5422\n",
      "Epoch 7934/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7966 - val_loss: 9.5417\n",
      "Epoch 7935/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7963 - val_loss: 9.5412\n",
      "Epoch 7936/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7960 - val_loss: 9.5413\n",
      "Epoch 7937/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7957 - val_loss: 9.5414\n",
      "Epoch 7938/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7954 - val_loss: 9.5411\n",
      "Epoch 7939/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7951 - val_loss: 9.5408\n",
      "Epoch 7940/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7947 - val_loss: 9.5407\n",
      "Epoch 7941/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7944 - val_loss: 9.5404\n",
      "Epoch 7942/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7941 - val_loss: 9.5400\n",
      "Epoch 7943/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7938 - val_loss: 9.5395\n",
      "Epoch 7944/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7935 - val_loss: 9.5392\n",
      "Epoch 7945/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7932 - val_loss: 9.5392\n",
      "Epoch 7946/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7929 - val_loss: 9.5393\n",
      "Epoch 7947/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7926 - val_loss: 9.5387\n",
      "Epoch 7948/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7923 - val_loss: 9.5383\n",
      "Epoch 7949/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7920 - val_loss: 9.5384\n",
      "Epoch 7950/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7917 - val_loss: 9.5383\n",
      "Epoch 7951/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.791 - 0s 30ms/step - loss: 3.7914 - val_loss: 9.5383\n",
      "Epoch 7952/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7911 - val_loss: 9.5379\n",
      "Epoch 7953/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7908 - val_loss: 9.5372\n",
      "Epoch 7954/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7904 - val_loss: 9.5367\n",
      "Epoch 7955/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7901 - val_loss: 9.5367\n",
      "Epoch 7956/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7898 - val_loss: 9.5364\n",
      "Epoch 7957/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7895 - val_loss: 9.5363\n",
      "Epoch 7958/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7892 - val_loss: 9.5362\n",
      "Epoch 7959/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7889 - val_loss: 9.5359\n",
      "Epoch 7960/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7886 - val_loss: 9.5357\n",
      "Epoch 7961/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7883 - val_loss: 9.5357\n",
      "Epoch 7962/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7880 - val_loss: 9.5355\n",
      "Epoch 7963/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7877 - val_loss: 9.5353\n",
      "Epoch 7964/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7874 - val_loss: 9.5348\n",
      "Epoch 7965/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7871 - val_loss: 9.5340\n",
      "Epoch 7966/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.7868 - val_loss: 9.5335\n",
      "Epoch 7967/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.7865 - val_loss: 9.5336\n",
      "Epoch 7968/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.7861 - val_loss: 9.5338\n",
      "Epoch 7969/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7858 - val_loss: 9.5338\n",
      "Epoch 7970/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7855 - val_loss: 9.5336\n",
      "Epoch 7971/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7852 - val_loss: 9.5331\n",
      "Epoch 7972/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7849 - val_loss: 9.5326\n",
      "Epoch 7973/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7846 - val_loss: 9.5321\n",
      "Epoch 7974/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7843 - val_loss: 9.5318\n",
      "Epoch 7975/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7840 - val_loss: 9.5316\n",
      "Epoch 7976/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7837 - val_loss: 9.5315\n",
      "Epoch 7977/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7834 - val_loss: 9.5313\n",
      "Epoch 7978/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7831 - val_loss: 9.5313\n",
      "Epoch 7979/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7828 - val_loss: 9.5314\n",
      "Epoch 7980/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7825 - val_loss: 9.5311\n",
      "Epoch 7981/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7822 - val_loss: 9.5307\n",
      "Epoch 7982/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7818 - val_loss: 9.5305\n",
      "Epoch 7983/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7815 - val_loss: 9.5301\n",
      "Epoch 7984/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7812 - val_loss: 9.5301\n",
      "Epoch 7985/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7809 - val_loss: 9.5300\n",
      "Epoch 7986/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7806 - val_loss: 9.5295\n",
      "Epoch 7987/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7803 - val_loss: 9.5290\n",
      "Epoch 7988/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7800 - val_loss: 9.5288\n",
      "Epoch 7989/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7797 - val_loss: 9.5284\n",
      "Epoch 7990/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7794 - val_loss: 9.5280\n",
      "Epoch 7991/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7791 - val_loss: 9.5279\n",
      "Epoch 7992/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7788 - val_loss: 9.5278\n",
      "Epoch 7993/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7785 - val_loss: 9.5276\n",
      "Epoch 7994/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7782 - val_loss: 9.5274\n",
      "Epoch 7995/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7779 - val_loss: 9.5270\n",
      "Epoch 7996/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7775 - val_loss: 9.5266\n",
      "Epoch 7997/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7772 - val_loss: 9.5265\n",
      "Epoch 7998/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7769 - val_loss: 9.5263\n",
      "Epoch 7999/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7766 - val_loss: 9.5260\n",
      "Epoch 8000/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7763 - val_loss: 9.5259\n",
      "Epoch 8001/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7760 - val_loss: 9.5259\n",
      "Epoch 8002/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7757 - val_loss: 9.5255\n",
      "Epoch 8003/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7754 - val_loss: 9.5249\n",
      "Epoch 8004/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7751 - val_loss: 9.5243\n",
      "Epoch 8005/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7748 - val_loss: 9.5239\n",
      "Epoch 8006/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7745 - val_loss: 9.5238\n",
      "Epoch 8007/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7742 - val_loss: 9.5237\n",
      "Epoch 8008/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7739 - val_loss: 9.5234\n",
      "Epoch 8009/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7736 - val_loss: 9.5230\n",
      "Epoch 8010/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7732 - val_loss: 9.5227\n",
      "Epoch 8011/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7729 - val_loss: 9.5227\n",
      "Epoch 8012/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7726 - val_loss: 9.5227\n",
      "Epoch 8013/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7723 - val_loss: 9.5224\n",
      "Epoch 8014/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7720 - val_loss: 9.5219\n",
      "Epoch 8015/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7717 - val_loss: 9.5214\n",
      "Epoch 8016/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7714 - val_loss: 9.5210\n",
      "Epoch 8017/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7711 - val_loss: 9.5209\n",
      "Epoch 8018/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7708 - val_loss: 9.5206\n",
      "Epoch 8019/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7705 - val_loss: 9.5202\n",
      "Epoch 8020/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7702 - val_loss: 9.5199\n",
      "Epoch 8021/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7699 - val_loss: 9.5194\n",
      "Epoch 8022/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7696 - val_loss: 9.5193\n",
      "Epoch 8023/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7693 - val_loss: 9.5193\n",
      "Epoch 8024/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7689 - val_loss: 9.5189\n",
      "Epoch 8025/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7686 - val_loss: 9.5186\n",
      "Epoch 8026/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7683 - val_loss: 9.5183\n",
      "Epoch 8027/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.7680 - val_loss: 9.5177\n",
      "Epoch 8028/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7677 - val_loss: 9.5174\n",
      "Epoch 8029/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7674 - val_loss: 9.5175\n",
      "Epoch 8030/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7671 - val_loss: 9.5173\n",
      "Epoch 8031/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7668 - val_loss: 9.5171\n",
      "Epoch 8032/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7665 - val_loss: 9.5169\n",
      "Epoch 8033/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7662 - val_loss: 9.5165\n",
      "Epoch 8034/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7659 - val_loss: 9.5159\n",
      "Epoch 8035/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7656 - val_loss: 9.5155\n",
      "Epoch 8036/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7653 - val_loss: 9.5153\n",
      "Epoch 8037/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7650 - val_loss: 9.5151\n",
      "Epoch 8038/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7646 - val_loss: 9.5152\n",
      "Epoch 8039/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7643 - val_loss: 9.5150\n",
      "Epoch 8040/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.7640 - val_loss: 9.5145\n",
      "Epoch 8041/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7637 - val_loss: 9.5140\n",
      "Epoch 8042/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7634 - val_loss: 9.5138\n",
      "Epoch 8043/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7631 - val_loss: 9.5134\n",
      "Epoch 8044/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7628 - val_loss: 9.5132\n",
      "Epoch 8045/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7625 - val_loss: 9.5132\n",
      "Epoch 8046/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7622 - val_loss: 9.5130\n",
      "Epoch 8047/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7619 - val_loss: 9.5125\n",
      "Epoch 8048/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7616 - val_loss: 9.5121\n",
      "Epoch 8049/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7613 - val_loss: 9.5116\n",
      "Epoch 8050/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7610 - val_loss: 9.5112\n",
      "Epoch 8051/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7607 - val_loss: 9.5113\n",
      "Epoch 8052/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7603 - val_loss: 9.5112\n",
      "Epoch 8053/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7600 - val_loss: 9.5109\n",
      "Epoch 8054/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7597 - val_loss: 9.5104\n",
      "Epoch 8055/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7594 - val_loss: 9.5098\n",
      "Epoch 8056/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7591 - val_loss: 9.5095\n",
      "Epoch 8057/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7588 - val_loss: 9.5095\n",
      "Epoch 8058/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7585 - val_loss: 9.5097\n",
      "Epoch 8059/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7582 - val_loss: 9.5094\n",
      "Epoch 8060/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7579 - val_loss: 9.5088\n",
      "Epoch 8061/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7576 - val_loss: 9.5082\n",
      "Epoch 8062/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7573 - val_loss: 9.5079\n",
      "Epoch 8063/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7570 - val_loss: 9.5078\n",
      "Epoch 8064/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7567 - val_loss: 9.5076\n",
      "Epoch 8065/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7564 - val_loss: 9.5073\n",
      "Epoch 8066/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7560 - val_loss: 9.5070\n",
      "Epoch 8067/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7557 - val_loss: 9.5066\n",
      "Epoch 8068/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7554 - val_loss: 9.5064\n",
      "Epoch 8069/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7551 - val_loss: 9.5061\n",
      "Epoch 8070/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7548 - val_loss: 9.5056\n",
      "Epoch 8071/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7545 - val_loss: 9.5054\n",
      "Epoch 8072/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7542 - val_loss: 9.5053\n",
      "Epoch 8073/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7539 - val_loss: 9.5052\n",
      "Epoch 8074/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7536 - val_loss: 9.5050\n",
      "Epoch 8075/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7533 - val_loss: 9.5047\n",
      "Epoch 8076/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7530 - val_loss: 9.5042\n",
      "Epoch 8077/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7527 - val_loss: 9.5039\n",
      "Epoch 8078/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7524 - val_loss: 9.5035\n",
      "Epoch 8079/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7521 - val_loss: 9.5029\n",
      "Epoch 8080/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7517 - val_loss: 9.5026\n",
      "Epoch 8081/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7514 - val_loss: 9.5023\n",
      "Epoch 8082/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7511 - val_loss: 9.5021\n",
      "Epoch 8083/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7508 - val_loss: 9.5017\n",
      "Epoch 8084/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7505 - val_loss: 9.5013\n",
      "Epoch 8085/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7502 - val_loss: 9.5011\n",
      "Epoch 8086/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7499 - val_loss: 9.5010\n",
      "Epoch 8087/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.7496 - val_loss: 9.5010\n",
      "Epoch 8088/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.7493 - val_loss: 9.5008\n",
      "Epoch 8089/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.7490 - val_loss: 9.5003\n",
      "Epoch 8090/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7487 - val_loss: 9.4999\n",
      "Epoch 8091/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7484 - val_loss: 9.4995\n",
      "Epoch 8092/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7481 - val_loss: 9.4991\n",
      "Epoch 8093/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7478 - val_loss: 9.4989\n",
      "Epoch 8094/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7474 - val_loss: 9.4987\n",
      "Epoch 8095/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7471 - val_loss: 9.4982\n",
      "Epoch 8096/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7468 - val_loss: 9.4979\n",
      "Epoch 8097/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7465 - val_loss: 9.4976\n",
      "Epoch 8098/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7462 - val_loss: 9.4971\n",
      "Epoch 8099/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7459 - val_loss: 9.4971\n",
      "Epoch 8100/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7456 - val_loss: 9.4971\n",
      "Epoch 8101/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7453 - val_loss: 9.4967\n",
      "Epoch 8102/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7450 - val_loss: 9.4962\n",
      "Epoch 8103/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7447 - val_loss: 9.4959\n",
      "Epoch 8104/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7444 - val_loss: 9.4956\n",
      "Epoch 8105/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7441 - val_loss: 9.4954\n",
      "Epoch 8106/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7438 - val_loss: 9.4954\n",
      "Epoch 8107/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7435 - val_loss: 9.4953\n",
      "Epoch 8108/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7431 - val_loss: 9.4951\n",
      "Epoch 8109/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7428 - val_loss: 9.4946\n",
      "Epoch 8110/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7425 - val_loss: 9.4938\n",
      "Epoch 8111/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7422 - val_loss: 9.4934\n",
      "Epoch 8112/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7419 - val_loss: 9.4934\n",
      "Epoch 8113/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7416 - val_loss: 9.4933\n",
      "Epoch 8114/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7413 - val_loss: 9.4932\n",
      "Epoch 8115/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7410 - val_loss: 9.4928\n",
      "Epoch 8116/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7407 - val_loss: 9.4920\n",
      "Epoch 8117/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7404 - val_loss: 9.4916\n",
      "Epoch 8118/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7401 - val_loss: 9.4914\n",
      "Epoch 8119/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7398 - val_loss: 9.4912\n",
      "Epoch 8120/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7395 - val_loss: 9.4911\n",
      "Epoch 8121/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7392 - val_loss: 9.4909\n",
      "Epoch 8122/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7389 - val_loss: 9.4907\n",
      "Epoch 8123/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7385 - val_loss: 9.4906\n",
      "Epoch 8124/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7382 - val_loss: 9.4903\n",
      "Epoch 8125/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7379 - val_loss: 9.4898\n",
      "Epoch 8126/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7376 - val_loss: 9.4894\n",
      "Epoch 8127/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7373 - val_loss: 9.4890\n",
      "Epoch 8128/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7370 - val_loss: 9.4884\n",
      "Epoch 8129/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7367 - val_loss: 9.4881\n",
      "Epoch 8130/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7364 - val_loss: 9.4878\n",
      "Epoch 8131/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7361 - val_loss: 9.4877\n",
      "Epoch 8132/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7358 - val_loss: 9.4875\n",
      "Epoch 8133/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7355 - val_loss: 9.4872\n",
      "Epoch 8134/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7352 - val_loss: 9.4869\n",
      "Epoch 8135/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7349 - val_loss: 9.4864\n",
      "Epoch 8136/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7346 - val_loss: 9.4858\n",
      "Epoch 8137/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7342 - val_loss: 9.4856\n",
      "Epoch 8138/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7339 - val_loss: 9.4858\n",
      "Epoch 8139/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7336 - val_loss: 9.4856\n",
      "Epoch 8140/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7333 - val_loss: 9.4852\n",
      "Epoch 8141/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7330 - val_loss: 9.4847\n",
      "Epoch 8142/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7327 - val_loss: 9.4841\n",
      "Epoch 8143/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7324 - val_loss: 9.4838\n",
      "Epoch 8144/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7321 - val_loss: 9.4839\n",
      "Epoch 8145/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7318 - val_loss: 9.4837\n",
      "Epoch 8146/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7315 - val_loss: 9.4833\n",
      "Epoch 8147/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7312 - val_loss: 9.4829\n",
      "Epoch 8148/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7309 - val_loss: 9.4825\n",
      "Epoch 8149/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.7306 - val_loss: 9.4822\n",
      "Epoch 8150/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7303 - val_loss: 9.4820\n",
      "Epoch 8151/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7300 - val_loss: 9.4818\n",
      "Epoch 8152/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.7296 - val_loss: 9.4813\n",
      "Epoch 8153/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7293 - val_loss: 9.4808\n",
      "Epoch 8154/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7290 - val_loss: 9.4805\n",
      "Epoch 8155/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7287 - val_loss: 9.4805\n",
      "Epoch 8156/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7284 - val_loss: 9.4806\n",
      "Epoch 8157/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7281 - val_loss: 9.4804\n",
      "Epoch 8158/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7278 - val_loss: 9.4801\n",
      "Epoch 8159/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7275 - val_loss: 9.4796\n",
      "Epoch 8160/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7272 - val_loss: 9.4792\n",
      "Epoch 8161/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7269 - val_loss: 9.4790\n",
      "Epoch 8162/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7266 - val_loss: 9.4787\n",
      "Epoch 8163/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7263 - val_loss: 9.4782\n",
      "Epoch 8164/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7260 - val_loss: 9.4779\n",
      "Epoch 8165/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7257 - val_loss: 9.4776\n",
      "Epoch 8166/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7254 - val_loss: 9.4774\n",
      "Epoch 8167/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7251 - val_loss: 9.4769\n",
      "Epoch 8168/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7247 - val_loss: 9.4765\n",
      "Epoch 8169/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7244 - val_loss: 9.4762\n",
      "Epoch 8170/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7241 - val_loss: 9.4759\n",
      "Epoch 8171/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7238 - val_loss: 9.4757\n",
      "Epoch 8172/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7235 - val_loss: 9.4755\n",
      "Epoch 8173/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7232 - val_loss: 9.4753\n",
      "Epoch 8174/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7229 - val_loss: 9.4752\n",
      "Epoch 8175/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7226 - val_loss: 9.4750\n",
      "Epoch 8176/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7223 - val_loss: 9.4745\n",
      "Epoch 8177/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7220 - val_loss: 9.4742\n",
      "Epoch 8178/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7217 - val_loss: 9.4738\n",
      "Epoch 8179/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7214 - val_loss: 9.4731\n",
      "Epoch 8180/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7211 - val_loss: 9.4729\n",
      "Epoch 8181/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7208 - val_loss: 9.4729\n",
      "Epoch 8182/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7205 - val_loss: 9.4729\n",
      "Epoch 8183/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7202 - val_loss: 9.4729\n",
      "Epoch 8184/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7198 - val_loss: 9.4723\n",
      "Epoch 8185/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7195 - val_loss: 9.4716\n",
      "Epoch 8186/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7192 - val_loss: 9.4714\n",
      "Epoch 8187/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7189 - val_loss: 9.4710\n",
      "Epoch 8188/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7186 - val_loss: 9.4705\n",
      "Epoch 8189/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7183 - val_loss: 9.4704\n",
      "Epoch 8190/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7180 - val_loss: 9.4702\n",
      "Epoch 8191/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7177 - val_loss: 9.4701\n",
      "Epoch 8192/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7174 - val_loss: 9.4704\n",
      "Epoch 8193/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7171 - val_loss: 9.4702\n",
      "Epoch 8194/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7168 - val_loss: 9.4698\n",
      "Epoch 8195/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7165 - val_loss: 9.4693\n",
      "Epoch 8196/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7162 - val_loss: 9.4685\n",
      "Epoch 8197/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7159 - val_loss: 9.4682\n",
      "Epoch 8198/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7156 - val_loss: 9.4684\n",
      "Epoch 8199/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7152 - val_loss: 9.4681\n",
      "Epoch 8200/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7149 - val_loss: 9.4675\n",
      "Epoch 8201/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7146 - val_loss: 9.4671\n",
      "Epoch 8202/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7143 - val_loss: 9.4667\n",
      "Epoch 8203/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7140 - val_loss: 9.4665\n",
      "Epoch 8204/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7137 - val_loss: 9.4664\n",
      "Epoch 8205/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7134 - val_loss: 9.4659\n",
      "Epoch 8206/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7131 - val_loss: 9.4654\n",
      "Epoch 8207/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7128 - val_loss: 9.4653\n",
      "Epoch 8208/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7125 - val_loss: 9.4651\n",
      "Epoch 8209/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.7122 - val_loss: 9.4649\n",
      "Epoch 8210/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7119 - val_loss: 9.4647\n",
      "Epoch 8211/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7116 - val_loss: 9.4645\n",
      "Epoch 8212/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.7113 - val_loss: 9.4642\n",
      "Epoch 8213/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7110 - val_loss: 9.4635\n",
      "Epoch 8214/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7107 - val_loss: 9.4633\n",
      "Epoch 8215/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7103 - val_loss: 9.4632\n",
      "Epoch 8216/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7100 - val_loss: 9.4631\n",
      "Epoch 8217/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7097 - val_loss: 9.4627\n",
      "Epoch 8218/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7094 - val_loss: 9.4621\n",
      "Epoch 8219/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7091 - val_loss: 9.4614\n",
      "Epoch 8220/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7088 - val_loss: 9.4612\n",
      "Epoch 8221/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7085 - val_loss: 9.4609\n",
      "Epoch 8222/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7082 - val_loss: 9.4605\n",
      "Epoch 8223/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7079 - val_loss: 9.4608\n",
      "Epoch 8224/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7076 - val_loss: 9.4609\n",
      "Epoch 8225/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7073 - val_loss: 9.4606\n",
      "Epoch 8226/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7070 - val_loss: 9.4601\n",
      "Epoch 8227/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7067 - val_loss: 9.4597\n",
      "Epoch 8228/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7064 - val_loss: 9.4595\n",
      "Epoch 8229/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7061 - val_loss: 9.4594\n",
      "Epoch 8230/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7058 - val_loss: 9.4589\n",
      "Epoch 8231/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7054 - val_loss: 9.4583\n",
      "Epoch 8232/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7051 - val_loss: 9.4581\n",
      "Epoch 8233/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7048 - val_loss: 9.4581\n",
      "Epoch 8234/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7045 - val_loss: 9.4578\n",
      "Epoch 8235/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7042 - val_loss: 9.4571\n",
      "Epoch 8236/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.7039 - val_loss: 9.4567\n",
      "Epoch 8237/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.7036 - val_loss: 9.4567\n",
      "Epoch 8238/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.7033 - val_loss: 9.4568\n",
      "Epoch 8239/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7030 - val_loss: 9.4566\n",
      "Epoch 8240/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7027 - val_loss: 9.4562\n",
      "Epoch 8241/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.7024 - val_loss: 9.4556\n",
      "Epoch 8242/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7021 - val_loss: 9.4552\n",
      "Epoch 8243/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7018 - val_loss: 9.4547\n",
      "Epoch 8244/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7015 - val_loss: 9.4546\n",
      "Epoch 8245/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7012 - val_loss: 9.4546\n",
      "Epoch 8246/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.7009 - val_loss: 9.4545\n",
      "Epoch 8247/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7005 - val_loss: 9.4543\n",
      "Epoch 8248/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7002 - val_loss: 9.4538\n",
      "Epoch 8249/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6999 - val_loss: 9.4533\n",
      "Epoch 8250/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6996 - val_loss: 9.4530\n",
      "Epoch 8251/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6993 - val_loss: 9.4525\n",
      "Epoch 8252/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6990 - val_loss: 9.4523\n",
      "Epoch 8253/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6987 - val_loss: 9.4523\n",
      "Epoch 8254/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6984 - val_loss: 9.4520\n",
      "Epoch 8255/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6981 - val_loss: 9.4517\n",
      "Epoch 8256/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6978 - val_loss: 9.4514\n",
      "Epoch 8257/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6975 - val_loss: 9.4511\n",
      "Epoch 8258/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6972 - val_loss: 9.4510\n",
      "Epoch 8259/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6969 - val_loss: 9.4508\n",
      "Epoch 8260/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.6966 - val_loss: 9.4504\n",
      "Epoch 8261/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6963 - val_loss: 9.4500\n",
      "Epoch 8262/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6960 - val_loss: 9.4495\n",
      "Epoch 8263/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6956 - val_loss: 9.4494\n",
      "Epoch 8264/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.6953 - val_loss: 9.4495\n",
      "Epoch 8265/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.6950 - val_loss: 9.4494\n",
      "Epoch 8266/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6947 - val_loss: 9.4490\n",
      "Epoch 8267/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6944 - val_loss: 9.4485\n",
      "Epoch 8268/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6941 - val_loss: 9.4481\n",
      "Epoch 8269/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6938 - val_loss: 9.4476\n",
      "Epoch 8270/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6935 - val_loss: 9.4475\n",
      "Epoch 8271/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6932 - val_loss: 9.4474\n",
      "Epoch 8272/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6929 - val_loss: 9.4470\n",
      "Epoch 8273/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6926 - val_loss: 9.4467\n",
      "Epoch 8274/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6923 - val_loss: 9.4462\n",
      "Epoch 8275/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6920 - val_loss: 9.4458\n",
      "Epoch 8276/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6917 - val_loss: 9.4458\n",
      "Epoch 8277/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6914 - val_loss: 9.4458\n",
      "Epoch 8278/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6911 - val_loss: 9.4456\n",
      "Epoch 8279/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6908 - val_loss: 9.4449\n",
      "Epoch 8280/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6904 - val_loss: 9.4443\n",
      "Epoch 8281/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6901 - val_loss: 9.4442\n",
      "Epoch 8282/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6898 - val_loss: 9.4441\n",
      "Epoch 8283/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6895 - val_loss: 9.4439\n",
      "Epoch 8284/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6892 - val_loss: 9.4437\n",
      "Epoch 8285/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.6889 - val_loss: 9.4434\n",
      "Epoch 8286/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6886 - val_loss: 9.4429\n",
      "Epoch 8287/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6883 - val_loss: 9.4426\n",
      "Epoch 8288/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6880 - val_loss: 9.4423\n",
      "Epoch 8289/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6877 - val_loss: 9.4420\n",
      "Epoch 8290/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6874 - val_loss: 9.4419\n",
      "Epoch 8291/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6871 - val_loss: 9.4416\n",
      "Epoch 8292/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6868 - val_loss: 9.4413\n",
      "Epoch 8293/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6865 - val_loss: 9.4410\n",
      "Epoch 8294/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6862 - val_loss: 9.4404\n",
      "Epoch 8295/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6859 - val_loss: 9.4400\n",
      "Epoch 8296/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6856 - val_loss: 9.4399\n",
      "Epoch 8297/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6852 - val_loss: 9.4398\n",
      "Epoch 8298/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6849 - val_loss: 9.4397\n",
      "Epoch 8299/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6846 - val_loss: 9.4395\n",
      "Epoch 8300/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6843 - val_loss: 9.4392\n",
      "Epoch 8301/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6840 - val_loss: 9.4388\n",
      "Epoch 8302/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6837 - val_loss: 9.4382\n",
      "Epoch 8303/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6834 - val_loss: 9.4378\n",
      "Epoch 8304/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6831 - val_loss: 9.4377\n",
      "Epoch 8305/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6828 - val_loss: 9.4376\n",
      "Epoch 8306/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6825 - val_loss: 9.4373\n",
      "Epoch 8307/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6822 - val_loss: 9.4366\n",
      "Epoch 8308/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6819 - val_loss: 9.4360\n",
      "Epoch 8309/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6816 - val_loss: 9.4359\n",
      "Epoch 8310/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6813 - val_loss: 9.4363\n",
      "Epoch 8311/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6810 - val_loss: 9.4364\n",
      "Epoch 8312/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6807 - val_loss: 9.4359\n",
      "Epoch 8313/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6804 - val_loss: 9.4352\n",
      "Epoch 8314/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.6801 - val_loss: 9.4348\n",
      "Epoch 8315/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6797 - val_loss: 9.4346\n",
      "Epoch 8316/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6794 - val_loss: 9.4346\n",
      "Epoch 8317/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6791 - val_loss: 9.4343\n",
      "Epoch 8318/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6788 - val_loss: 9.4338\n",
      "Epoch 8319/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6785 - val_loss: 9.4335\n",
      "Epoch 8320/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6782 - val_loss: 9.4333\n",
      "Epoch 8321/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6779 - val_loss: 9.4331\n",
      "Epoch 8322/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6776 - val_loss: 9.4327\n",
      "Epoch 8323/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6773 - val_loss: 9.4321\n",
      "Epoch 8324/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.6770 - val_loss: 9.4320\n",
      "Epoch 8325/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6767 - val_loss: 9.4321\n",
      "Epoch 8326/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6764 - val_loss: 9.4319\n",
      "Epoch 8327/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6761 - val_loss: 9.4316\n",
      "Epoch 8328/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6758 - val_loss: 9.4309\n",
      "Epoch 8329/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6755 - val_loss: 9.4305\n",
      "Epoch 8330/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6752 - val_loss: 9.4302\n",
      "Epoch 8331/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6749 - val_loss: 9.4300\n",
      "Epoch 8332/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6745 - val_loss: 9.4300\n",
      "Epoch 8333/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6742 - val_loss: 9.4299\n",
      "Epoch 8334/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6739 - val_loss: 9.4295\n",
      "Epoch 8335/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6736 - val_loss: 9.4291\n",
      "Epoch 8336/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6733 - val_loss: 9.4286\n",
      "Epoch 8337/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6730 - val_loss: 9.4282\n",
      "Epoch 8338/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6727 - val_loss: 9.4280\n",
      "Epoch 8339/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6724 - val_loss: 9.4280\n",
      "Epoch 8340/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6721 - val_loss: 9.4278\n",
      "Epoch 8341/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6718 - val_loss: 9.4275\n",
      "Epoch 8342/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6715 - val_loss: 9.4271\n",
      "Epoch 8343/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6712 - val_loss: 9.4267\n",
      "Epoch 8344/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6709 - val_loss: 9.4264\n",
      "Epoch 8345/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6706 - val_loss: 9.4262\n",
      "Epoch 8346/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6703 - val_loss: 9.4260\n",
      "Epoch 8347/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6700 - val_loss: 9.4257\n",
      "Epoch 8348/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6697 - val_loss: 9.4251\n",
      "Epoch 8349/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6694 - val_loss: 9.4248\n",
      "Epoch 8350/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6690 - val_loss: 9.4247\n",
      "Epoch 8351/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6687 - val_loss: 9.4246\n",
      "Epoch 8352/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6684 - val_loss: 9.4245\n",
      "Epoch 8353/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6681 - val_loss: 9.4239\n",
      "Epoch 8354/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6678 - val_loss: 9.4233\n",
      "Epoch 8355/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6675 - val_loss: 9.4233\n",
      "Epoch 8356/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6672 - val_loss: 9.4232\n",
      "Epoch 8357/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6669 - val_loss: 9.4228\n",
      "Epoch 8358/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.6666 - val_loss: 9.4223\n",
      "Epoch 8359/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.6663 - val_loss: 9.4219\n",
      "Epoch 8360/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.6660 - val_loss: 9.4219\n",
      "Epoch 8361/10000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.6657 - val_loss: 9.4217\n",
      "Epoch 8362/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.6654 - val_loss: 9.4213\n",
      "Epoch 8363/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6651 - val_loss: 9.4211\n",
      "Epoch 8364/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6648 - val_loss: 9.4207\n",
      "Epoch 8365/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6645 - val_loss: 9.4204\n",
      "Epoch 8366/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6642 - val_loss: 9.4201\n",
      "Epoch 8367/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6639 - val_loss: 9.4197\n",
      "Epoch 8368/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6635 - val_loss: 9.4193\n",
      "Epoch 8369/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6632 - val_loss: 9.4189\n",
      "Epoch 8370/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6629 - val_loss: 9.4188\n",
      "Epoch 8371/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6626 - val_loss: 9.4189\n",
      "Epoch 8372/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6623 - val_loss: 9.4188\n",
      "Epoch 8373/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6620 - val_loss: 9.4187\n",
      "Epoch 8374/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6617 - val_loss: 9.4185\n",
      "Epoch 8375/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6614 - val_loss: 9.4180\n",
      "Epoch 8376/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6611 - val_loss: 9.4173\n",
      "Epoch 8377/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6608 - val_loss: 9.4168\n",
      "Epoch 8378/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6605 - val_loss: 9.4169\n",
      "Epoch 8379/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6602 - val_loss: 9.4170\n",
      "Epoch 8380/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6599 - val_loss: 9.4168\n",
      "Epoch 8381/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6596 - val_loss: 9.4163\n",
      "Epoch 8382/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6593 - val_loss: 9.4155\n",
      "Epoch 8383/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6590 - val_loss: 9.4151\n",
      "Epoch 8384/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6587 - val_loss: 9.4150\n",
      "Epoch 8385/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6584 - val_loss: 9.4148\n",
      "Epoch 8386/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6581 - val_loss: 9.4146\n",
      "Epoch 8387/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.6577 - val_loss: 9.4144\n",
      "Epoch 8388/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6574 - val_loss: 9.4140\n",
      "Epoch 8389/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6571 - val_loss: 9.4135\n",
      "Epoch 8390/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6568 - val_loss: 9.4130\n",
      "Epoch 8391/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6565 - val_loss: 9.4127\n",
      "Epoch 8392/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6562 - val_loss: 9.4125\n",
      "Epoch 8393/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6559 - val_loss: 9.4123\n",
      "Epoch 8394/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6556 - val_loss: 9.4120\n",
      "Epoch 8395/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6553 - val_loss: 9.4115\n",
      "Epoch 8396/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6550 - val_loss: 9.4110\n",
      "Epoch 8397/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.6547 - val_loss: 9.4108\n",
      "Epoch 8398/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6544 - val_loss: 9.4105\n",
      "Epoch 8399/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.6541 - val_loss: 9.4103\n",
      "Epoch 8400/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.6538 - val_loss: 9.4100\n",
      "Epoch 8401/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.6535 - val_loss: 9.4097\n",
      "Epoch 8402/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6532 - val_loss: 9.4097\n",
      "Epoch 8403/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.6529 - val_loss: 9.4095\n",
      "Epoch 8404/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6526 - val_loss: 9.4091\n",
      "Epoch 8405/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.6523 - val_loss: 9.4088\n",
      "Epoch 8406/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.6519 - val_loss: 9.4082\n",
      "Epoch 8407/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.6516 - val_loss: 9.4080\n",
      "Epoch 8408/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.6513 - val_loss: 9.4079\n",
      "Epoch 8409/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.6510 - val_loss: 9.4073\n",
      "Epoch 8410/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.6507 - val_loss: 9.4071\n",
      "Epoch 8411/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.6504 - val_loss: 9.4069\n",
      "Epoch 8412/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6501 - val_loss: 9.4067\n",
      "Epoch 8413/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.6498 - val_loss: 9.4065\n",
      "Epoch 8414/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.6495 - val_loss: 9.4058\n",
      "Epoch 8415/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6492 - val_loss: 9.4056\n",
      "Epoch 8416/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6489 - val_loss: 9.4055\n",
      "Epoch 8417/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6486 - val_loss: 9.4052\n",
      "Epoch 8418/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.6483 - val_loss: 9.4052\n",
      "Epoch 8419/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.648 - 0s 44ms/step - loss: 3.6480 - val_loss: 9.4047\n",
      "Epoch 8420/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6477 - val_loss: 9.4044\n",
      "Epoch 8421/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6474 - val_loss: 9.4042\n",
      "Epoch 8422/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6471 - val_loss: 9.4034\n",
      "Epoch 8423/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6468 - val_loss: 9.4031\n",
      "Epoch 8424/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6465 - val_loss: 9.4030\n",
      "Epoch 8425/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6462 - val_loss: 9.4026\n",
      "Epoch 8426/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6459 - val_loss: 9.4024\n",
      "Epoch 8427/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6455 - val_loss: 9.4020\n",
      "Epoch 8428/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6452 - val_loss: 9.4016\n",
      "Epoch 8429/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6449 - val_loss: 9.4015\n",
      "Epoch 8430/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6446 - val_loss: 9.4010\n",
      "Epoch 8431/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6443 - val_loss: 9.4008\n",
      "Epoch 8432/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6440 - val_loss: 9.4005\n",
      "Epoch 8433/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6437 - val_loss: 9.4001\n",
      "Epoch 8434/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6434 - val_loss: 9.4000\n",
      "Epoch 8435/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6431 - val_loss: 9.3996\n",
      "Epoch 8436/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6428 - val_loss: 9.3992\n",
      "Epoch 8437/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6425 - val_loss: 9.3990\n",
      "Epoch 8438/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6422 - val_loss: 9.3985\n",
      "Epoch 8439/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6419 - val_loss: 9.3983\n",
      "Epoch 8440/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6416 - val_loss: 9.3980\n",
      "Epoch 8441/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6413 - val_loss: 9.3978\n",
      "Epoch 8442/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6410 - val_loss: 9.3980\n",
      "Epoch 8443/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6407 - val_loss: 9.3978\n",
      "Epoch 8444/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6404 - val_loss: 9.3971\n",
      "Epoch 8445/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6401 - val_loss: 9.3966\n",
      "Epoch 8446/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.6398 - val_loss: 9.3962\n",
      "Epoch 8447/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.6394 - val_loss: 9.3962\n",
      "Epoch 8448/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.6391 - val_loss: 9.3960\n",
      "Epoch 8449/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6388 - val_loss: 9.3954\n",
      "Epoch 8450/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6385 - val_loss: 9.3954\n",
      "Epoch 8451/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6382 - val_loss: 9.3950\n",
      "Epoch 8452/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6379 - val_loss: 9.3947\n",
      "Epoch 8453/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6376 - val_loss: 9.3943\n",
      "Epoch 8454/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6373 - val_loss: 9.3936\n",
      "Epoch 8455/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6370 - val_loss: 9.3932\n",
      "Epoch 8456/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6367 - val_loss: 9.3931\n",
      "Epoch 8457/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6364 - val_loss: 9.3932\n",
      "Epoch 8458/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6361 - val_loss: 9.3934\n",
      "Epoch 8459/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6358 - val_loss: 9.3930\n",
      "Epoch 8460/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6355 - val_loss: 9.3924\n",
      "Epoch 8461/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6352 - val_loss: 9.3916\n",
      "Epoch 8462/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6349 - val_loss: 9.3912\n",
      "Epoch 8463/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6346 - val_loss: 9.3911\n",
      "Epoch 8464/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6343 - val_loss: 9.3910\n",
      "Epoch 8465/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6340 - val_loss: 9.3912\n",
      "Epoch 8466/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6337 - val_loss: 9.3909\n",
      "Epoch 8467/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6334 - val_loss: 9.3903\n",
      "Epoch 8468/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6331 - val_loss: 9.3900\n",
      "Epoch 8469/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6327 - val_loss: 9.3896\n",
      "Epoch 8470/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6324 - val_loss: 9.3894\n",
      "Epoch 8471/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6321 - val_loss: 9.3889\n",
      "Epoch 8472/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6318 - val_loss: 9.3884\n",
      "Epoch 8473/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.6315 - val_loss: 9.3885\n",
      "Epoch 8474/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.6312 - val_loss: 9.3882\n",
      "Epoch 8475/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6309 - val_loss: 9.3878\n",
      "Epoch 8476/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6306 - val_loss: 9.3875\n",
      "Epoch 8477/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6303 - val_loss: 9.3869\n",
      "Epoch 8478/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6300 - val_loss: 9.3867\n",
      "Epoch 8479/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6297 - val_loss: 9.3863\n",
      "Epoch 8480/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6294 - val_loss: 9.3863\n",
      "Epoch 8481/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6291 - val_loss: 9.3864\n",
      "Epoch 8482/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6288 - val_loss: 9.3861\n",
      "Epoch 8483/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6285 - val_loss: 9.3855\n",
      "Epoch 8484/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6282 - val_loss: 9.3848\n",
      "Epoch 8485/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6279 - val_loss: 9.3846\n",
      "Epoch 8486/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6276 - val_loss: 9.3848\n",
      "Epoch 8487/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6273 - val_loss: 9.3844\n",
      "Epoch 8488/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6270 - val_loss: 9.3840\n",
      "Epoch 8489/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6267 - val_loss: 9.3835\n",
      "Epoch 8490/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6264 - val_loss: 9.3830\n",
      "Epoch 8491/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6261 - val_loss: 9.3830\n",
      "Epoch 8492/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6258 - val_loss: 9.3829\n",
      "Epoch 8493/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6254 - val_loss: 9.3828\n",
      "Epoch 8494/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6251 - val_loss: 9.3822\n",
      "Epoch 8495/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6248 - val_loss: 9.3814\n",
      "Epoch 8496/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6245 - val_loss: 9.3812\n",
      "Epoch 8497/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6242 - val_loss: 9.3810\n",
      "Epoch 8498/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6239 - val_loss: 9.3809\n",
      "Epoch 8499/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6236 - val_loss: 9.3807\n",
      "Epoch 8500/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6233 - val_loss: 9.3800\n",
      "Epoch 8501/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6230 - val_loss: 9.3797\n",
      "Epoch 8502/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6227 - val_loss: 9.3792\n",
      "Epoch 8503/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6224 - val_loss: 9.3790\n",
      "Epoch 8504/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6221 - val_loss: 9.3791\n",
      "Epoch 8505/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6218 - val_loss: 9.3789\n",
      "Epoch 8506/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6215 - val_loss: 9.3787\n",
      "Epoch 8507/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6212 - val_loss: 9.3781\n",
      "Epoch 8508/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6209 - val_loss: 9.3777\n",
      "Epoch 8509/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6206 - val_loss: 9.3776\n",
      "Epoch 8510/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6203 - val_loss: 9.3773\n",
      "Epoch 8511/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6200 - val_loss: 9.3768\n",
      "Epoch 8512/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6197 - val_loss: 9.3765\n",
      "Epoch 8513/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6194 - val_loss: 9.3760\n",
      "Epoch 8514/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6191 - val_loss: 9.3758\n",
      "Epoch 8515/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6188 - val_loss: 9.3754\n",
      "Epoch 8516/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6184 - val_loss: 9.3749\n",
      "Epoch 8517/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6181 - val_loss: 9.3745\n",
      "Epoch 8518/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6178 - val_loss: 9.3742\n",
      "Epoch 8519/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6175 - val_loss: 9.3741\n",
      "Epoch 8520/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.6172 - val_loss: 9.3741\n",
      "Epoch 8521/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6169 - val_loss: 9.3736\n",
      "Epoch 8522/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6166 - val_loss: 9.3730\n",
      "Epoch 8523/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6163 - val_loss: 9.3728\n",
      "Epoch 8524/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6160 - val_loss: 9.3727\n",
      "Epoch 8525/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6157 - val_loss: 9.3725\n",
      "Epoch 8526/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6154 - val_loss: 9.3718\n",
      "Epoch 8527/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6151 - val_loss: 9.3710\n",
      "Epoch 8528/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6148 - val_loss: 9.3706\n",
      "Epoch 8529/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6145 - val_loss: 9.3705\n",
      "Epoch 8530/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6142 - val_loss: 9.3706\n",
      "Epoch 8531/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6139 - val_loss: 9.3702\n",
      "Epoch 8532/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6136 - val_loss: 9.3696\n",
      "Epoch 8533/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6133 - val_loss: 9.3692\n",
      "Epoch 8534/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6130 - val_loss: 9.3689\n",
      "Epoch 8535/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6127 - val_loss: 9.3687\n",
      "Epoch 8536/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6124 - val_loss: 9.3682\n",
      "Epoch 8537/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.6121 - val_loss: 9.3674\n",
      "Epoch 8538/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6118 - val_loss: 9.3672\n",
      "Epoch 8539/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6115 - val_loss: 9.3672\n",
      "Epoch 8540/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6112 - val_loss: 9.3670\n",
      "Epoch 8541/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6109 - val_loss: 9.3667\n",
      "Epoch 8542/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6105 - val_loss: 9.3661\n",
      "Epoch 8543/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6102 - val_loss: 9.3657\n",
      "Epoch 8544/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6099 - val_loss: 9.3657\n",
      "Epoch 8545/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6096 - val_loss: 9.3652\n",
      "Epoch 8546/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6093 - val_loss: 9.3647\n",
      "Epoch 8547/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6090 - val_loss: 9.3641\n",
      "Epoch 8548/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6087 - val_loss: 9.3637\n",
      "Epoch 8549/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6084 - val_loss: 9.3638\n",
      "Epoch 8550/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6081 - val_loss: 9.3638\n",
      "Epoch 8551/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6078 - val_loss: 9.3634\n",
      "Epoch 8552/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6075 - val_loss: 9.3628\n",
      "Epoch 8553/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6072 - val_loss: 9.3618\n",
      "Epoch 8554/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6069 - val_loss: 9.3615\n",
      "Epoch 8555/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6066 - val_loss: 9.3619\n",
      "Epoch 8556/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6063 - val_loss: 9.3620\n",
      "Epoch 8557/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6060 - val_loss: 9.3617\n",
      "Epoch 8558/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6057 - val_loss: 9.3608\n",
      "Epoch 8559/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6054 - val_loss: 9.3602\n",
      "Epoch 8560/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6051 - val_loss: 9.3601\n",
      "Epoch 8561/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6048 - val_loss: 9.3597\n",
      "Epoch 8562/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6045 - val_loss: 9.3594\n",
      "Epoch 8563/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6042 - val_loss: 9.3590\n",
      "Epoch 8564/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6039 - val_loss: 9.3586\n",
      "Epoch 8565/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6036 - val_loss: 9.3586\n",
      "Epoch 8566/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6033 - val_loss: 9.3584\n",
      "Epoch 8567/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6030 - val_loss: 9.3578\n",
      "Epoch 8568/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6026 - val_loss: 9.3575\n",
      "Epoch 8569/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.6023 - val_loss: 9.3572\n",
      "Epoch 8570/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.6020 - val_loss: 9.3573\n",
      "Epoch 8571/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6017 - val_loss: 9.3571\n",
      "Epoch 8572/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6014 - val_loss: 9.3565\n",
      "Epoch 8573/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6011 - val_loss: 9.3560\n",
      "Epoch 8574/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6008 - val_loss: 9.3556\n",
      "Epoch 8575/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6005 - val_loss: 9.3554\n",
      "Epoch 8576/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6002 - val_loss: 9.3553\n",
      "Epoch 8577/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5999 - val_loss: 9.3549\n",
      "Epoch 8578/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5996 - val_loss: 9.3546\n",
      "Epoch 8579/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5993 - val_loss: 9.3543\n",
      "Epoch 8580/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5990 - val_loss: 9.3541\n",
      "Epoch 8581/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5987 - val_loss: 9.3537\n",
      "Epoch 8582/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5984 - val_loss: 9.3530\n",
      "Epoch 8583/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5981 - val_loss: 9.3525\n",
      "Epoch 8584/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5978 - val_loss: 9.3524\n",
      "Epoch 8585/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5975 - val_loss: 9.3524\n",
      "Epoch 8586/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5972 - val_loss: 9.3522\n",
      "Epoch 8587/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5969 - val_loss: 9.3516\n",
      "Epoch 8588/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5966 - val_loss: 9.3508\n",
      "Epoch 8589/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5963 - val_loss: 9.3506\n",
      "Epoch 8590/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5960 - val_loss: 9.3503\n",
      "Epoch 8591/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5957 - val_loss: 9.3502\n",
      "Epoch 8592/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5954 - val_loss: 9.3500\n",
      "Epoch 8593/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5951 - val_loss: 9.3495\n",
      "Epoch 8594/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5947 - val_loss: 9.3497\n",
      "Epoch 8595/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5944 - val_loss: 9.3493\n",
      "Epoch 8596/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5941 - val_loss: 9.3490\n",
      "Epoch 8597/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5938 - val_loss: 9.3485\n",
      "Epoch 8598/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5935 - val_loss: 9.3481\n",
      "Epoch 8599/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5932 - val_loss: 9.3480\n",
      "Epoch 8600/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5929 - val_loss: 9.3476\n",
      "Epoch 8601/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5926 - val_loss: 9.3475\n",
      "Epoch 8602/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5923 - val_loss: 9.3472\n",
      "Epoch 8603/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5920 - val_loss: 9.3465\n",
      "Epoch 8604/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5917 - val_loss: 9.3463\n",
      "Epoch 8605/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5914 - val_loss: 9.3457\n",
      "Epoch 8606/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5911 - val_loss: 9.3457\n",
      "Epoch 8607/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5908 - val_loss: 9.3457\n",
      "Epoch 8608/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5905 - val_loss: 9.3451\n",
      "Epoch 8609/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5902 - val_loss: 9.3448\n",
      "Epoch 8610/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5899 - val_loss: 9.3442\n",
      "Epoch 8611/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5896 - val_loss: 9.3440\n",
      "Epoch 8612/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5893 - val_loss: 9.3440\n",
      "Epoch 8613/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5890 - val_loss: 9.3434\n",
      "Epoch 8614/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5887 - val_loss: 9.3432\n",
      "Epoch 8615/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5884 - val_loss: 9.3426\n",
      "Epoch 8616/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5881 - val_loss: 9.3425\n",
      "Epoch 8617/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5878 - val_loss: 9.3426\n",
      "Epoch 8618/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5875 - val_loss: 9.3421\n",
      "Epoch 8619/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5872 - val_loss: 9.3418\n",
      "Epoch 8620/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5869 - val_loss: 9.3413\n",
      "Epoch 8621/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5866 - val_loss: 9.3412\n",
      "Epoch 8622/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5863 - val_loss: 9.3413\n",
      "Epoch 8623/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5859 - val_loss: 9.3408\n",
      "Epoch 8624/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5856 - val_loss: 9.3405\n",
      "Epoch 8625/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5853 - val_loss: 9.3399\n",
      "Epoch 8626/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5850 - val_loss: 9.3395\n",
      "Epoch 8627/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5847 - val_loss: 9.3394\n",
      "Epoch 8628/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5844 - val_loss: 9.3393\n",
      "Epoch 8629/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5841 - val_loss: 9.3390\n",
      "Epoch 8630/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5838 - val_loss: 9.3387\n",
      "Epoch 8631/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5835 - val_loss: 9.3381\n",
      "Epoch 8632/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5832 - val_loss: 9.3379\n",
      "Epoch 8633/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5829 - val_loss: 9.3380\n",
      "Epoch 8634/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5826 - val_loss: 9.3379\n",
      "Epoch 8635/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5823 - val_loss: 9.3375\n",
      "Epoch 8636/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5820 - val_loss: 9.3369\n",
      "Epoch 8637/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5817 - val_loss: 9.3362\n",
      "Epoch 8638/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5814 - val_loss: 9.3359\n",
      "Epoch 8639/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5811 - val_loss: 9.3361\n",
      "Epoch 8640/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5808 - val_loss: 9.3361\n",
      "Epoch 8641/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5805 - val_loss: 9.3358\n",
      "Epoch 8642/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5802 - val_loss: 9.3352\n",
      "Epoch 8643/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5799 - val_loss: 9.3346\n",
      "Epoch 8644/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5796 - val_loss: 9.3346\n",
      "Epoch 8645/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5793 - val_loss: 9.3343\n",
      "Epoch 8646/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5790 - val_loss: 9.3339\n",
      "Epoch 8647/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5787 - val_loss: 9.3336\n",
      "Epoch 8648/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5784 - val_loss: 9.3333\n",
      "Epoch 8649/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5781 - val_loss: 9.3332\n",
      "Epoch 8650/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5778 - val_loss: 9.3327\n",
      "Epoch 8651/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5775 - val_loss: 9.3322\n",
      "Epoch 8652/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5772 - val_loss: 9.3320\n",
      "Epoch 8653/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5769 - val_loss: 9.3316\n",
      "Epoch 8654/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5766 - val_loss: 9.3314\n",
      "Epoch 8655/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5762 - val_loss: 9.3311\n",
      "Epoch 8656/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5759 - val_loss: 9.3306\n",
      "Epoch 8657/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5756 - val_loss: 9.3303\n",
      "Epoch 8658/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5753 - val_loss: 9.3300\n",
      "Epoch 8659/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5750 - val_loss: 9.3299\n",
      "Epoch 8660/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5747 - val_loss: 9.3297\n",
      "Epoch 8661/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5744 - val_loss: 9.3293\n",
      "Epoch 8662/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5741 - val_loss: 9.3288\n",
      "Epoch 8663/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5738 - val_loss: 9.3285\n",
      "Epoch 8664/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5735 - val_loss: 9.3284\n",
      "Epoch 8665/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5732 - val_loss: 9.3283\n",
      "Epoch 8666/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5729 - val_loss: 9.3281\n",
      "Epoch 8667/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5726 - val_loss: 9.3277\n",
      "Epoch 8668/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5723 - val_loss: 9.3273\n",
      "Epoch 8669/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5720 - val_loss: 9.3271\n",
      "Epoch 8670/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5717 - val_loss: 9.3267\n",
      "Epoch 8671/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5714 - val_loss: 9.3265\n",
      "Epoch 8672/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5711 - val_loss: 9.3263\n",
      "Epoch 8673/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5708 - val_loss: 9.3260\n",
      "Epoch 8674/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5705 - val_loss: 9.3260\n",
      "Epoch 8675/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5702 - val_loss: 9.3255\n",
      "Epoch 8676/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5699 - val_loss: 9.3250\n",
      "Epoch 8677/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5696 - val_loss: 9.3247\n",
      "Epoch 8678/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5693 - val_loss: 9.3242\n",
      "Epoch 8679/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5690 - val_loss: 9.3241\n",
      "Epoch 8680/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5687 - val_loss: 9.3237\n",
      "Epoch 8681/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5684 - val_loss: 9.3234\n",
      "Epoch 8682/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5681 - val_loss: 9.3234\n",
      "Epoch 8683/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5678 - val_loss: 9.3233\n",
      "Epoch 8684/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5675 - val_loss: 9.3232\n",
      "Epoch 8685/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5672 - val_loss: 9.3227\n",
      "Epoch 8686/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5669 - val_loss: 9.3221\n",
      "Epoch 8687/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5666 - val_loss: 9.3222\n",
      "Epoch 8688/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5663 - val_loss: 9.3222\n",
      "Epoch 8689/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5660 - val_loss: 9.3223\n",
      "Epoch 8690/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5657 - val_loss: 9.3216\n",
      "Epoch 8691/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5653 - val_loss: 9.3209\n",
      "Epoch 8692/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5650 - val_loss: 9.3207\n",
      "Epoch 8693/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5647 - val_loss: 9.3204\n",
      "Epoch 8694/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5644 - val_loss: 9.3204\n",
      "Epoch 8695/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5641 - val_loss: 9.3202\n",
      "Epoch 8696/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5638 - val_loss: 9.3198\n",
      "Epoch 8697/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5635 - val_loss: 9.3198\n",
      "Epoch 8698/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5632 - val_loss: 9.3192\n",
      "Epoch 8699/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5629 - val_loss: 9.3190\n",
      "Epoch 8700/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5626 - val_loss: 9.3187\n",
      "Epoch 8701/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5623 - val_loss: 9.3185\n",
      "Epoch 8702/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5620 - val_loss: 9.3187\n",
      "Epoch 8703/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5617 - val_loss: 9.3181\n",
      "Epoch 8704/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5614 - val_loss: 9.3177\n",
      "Epoch 8705/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5611 - val_loss: 9.3172\n",
      "Epoch 8706/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5608 - val_loss: 9.3169\n",
      "Epoch 8707/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5605 - val_loss: 9.3173\n",
      "Epoch 8708/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5602 - val_loss: 9.3169\n",
      "Epoch 8709/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5599 - val_loss: 9.3162\n",
      "Epoch 8710/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.5596 - val_loss: 9.3160\n",
      "Epoch 8711/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.5593 - val_loss: 9.3157\n",
      "Epoch 8712/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5590 - val_loss: 9.3159\n",
      "Epoch 8713/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.5587 - val_loss: 9.3155\n",
      "Epoch 8714/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5584 - val_loss: 9.3147\n",
      "Epoch 8715/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5581 - val_loss: 9.3145\n",
      "Epoch 8716/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5578 - val_loss: 9.3142\n",
      "Epoch 8717/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5575 - val_loss: 9.3144\n",
      "Epoch 8718/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5572 - val_loss: 9.3144\n",
      "Epoch 8719/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5569 - val_loss: 9.3137\n",
      "Epoch 8720/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5566 - val_loss: 9.3136\n",
      "Epoch 8721/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5563 - val_loss: 9.3129\n",
      "Epoch 8722/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5560 - val_loss: 9.3129\n",
      "Epoch 8723/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5557 - val_loss: 9.3129\n",
      "Epoch 8724/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5554 - val_loss: 9.3123\n",
      "Epoch 8725/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5551 - val_loss: 9.3123\n",
      "Epoch 8726/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5548 - val_loss: 9.3118\n",
      "Epoch 8727/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5545 - val_loss: 9.3117\n",
      "Epoch 8728/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5542 - val_loss: 9.3114\n",
      "Epoch 8729/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5539 - val_loss: 9.3109\n",
      "Epoch 8730/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5536 - val_loss: 9.3106\n",
      "Epoch 8731/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5533 - val_loss: 9.3102\n",
      "Epoch 8732/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5530 - val_loss: 9.3103\n",
      "Epoch 8733/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5527 - val_loss: 9.3102\n",
      "Epoch 8734/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5524 - val_loss: 9.3100\n",
      "Epoch 8735/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5521 - val_loss: 9.3097\n",
      "Epoch 8736/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5517 - val_loss: 9.3089\n",
      "Epoch 8737/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5514 - val_loss: 9.3089\n",
      "Epoch 8738/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5511 - val_loss: 9.3085\n",
      "Epoch 8739/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5508 - val_loss: 9.3085\n",
      "Epoch 8740/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5505 - val_loss: 9.3084\n",
      "Epoch 8741/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5502 - val_loss: 9.3079\n",
      "Epoch 8742/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5499 - val_loss: 9.3076\n",
      "Epoch 8743/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5496 - val_loss: 9.3070\n",
      "Epoch 8744/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5493 - val_loss: 9.3072\n",
      "Epoch 8745/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5490 - val_loss: 9.3071\n",
      "Epoch 8746/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5487 - val_loss: 9.3067\n",
      "Epoch 8747/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5484 - val_loss: 9.3067\n",
      "Epoch 8748/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5481 - val_loss: 9.3061\n",
      "Epoch 8749/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5478 - val_loss: 9.3059\n",
      "Epoch 8750/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5475 - val_loss: 9.3054\n",
      "Epoch 8751/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5472 - val_loss: 9.3052\n",
      "Epoch 8752/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5469 - val_loss: 9.3053\n",
      "Epoch 8753/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5466 - val_loss: 9.3049\n",
      "Epoch 8754/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5463 - val_loss: 9.3047\n",
      "Epoch 8755/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5460 - val_loss: 9.3042\n",
      "Epoch 8756/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5457 - val_loss: 9.3040\n",
      "Epoch 8757/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5454 - val_loss: 9.3037\n",
      "Epoch 8758/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5451 - val_loss: 9.3034\n",
      "Epoch 8759/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5448 - val_loss: 9.3032\n",
      "Epoch 8760/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5445 - val_loss: 9.3031\n",
      "Epoch 8761/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5442 - val_loss: 9.3030\n",
      "Epoch 8762/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5439 - val_loss: 9.3023\n",
      "Epoch 8763/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5436 - val_loss: 9.3022\n",
      "Epoch 8764/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5433 - val_loss: 9.3019\n",
      "Epoch 8765/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5430 - val_loss: 9.3018\n",
      "Epoch 8766/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5427 - val_loss: 9.3018\n",
      "Epoch 8767/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5424 - val_loss: 9.3012\n",
      "Epoch 8768/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5421 - val_loss: 9.3011\n",
      "Epoch 8769/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5418 - val_loss: 9.3008\n",
      "Epoch 8770/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5415 - val_loss: 9.3010\n",
      "Epoch 8771/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5412 - val_loss: 9.3009\n",
      "Epoch 8772/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5409 - val_loss: 9.3001\n",
      "Epoch 8773/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5406 - val_loss: 9.2996\n",
      "Epoch 8774/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5403 - val_loss: 9.2991\n",
      "Epoch 8775/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5400 - val_loss: 9.2993\n",
      "Epoch 8776/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5397 - val_loss: 9.2994\n",
      "Epoch 8777/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5394 - val_loss: 9.2987\n",
      "Epoch 8778/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5391 - val_loss: 9.2982\n",
      "Epoch 8779/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5388 - val_loss: 9.2978\n",
      "Epoch 8780/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5385 - val_loss: 9.2980\n",
      "Epoch 8781/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5382 - val_loss: 9.2978\n",
      "Epoch 8782/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5379 - val_loss: 9.2974\n",
      "Epoch 8783/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5376 - val_loss: 9.2968\n",
      "Epoch 8784/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5373 - val_loss: 9.2964\n",
      "Epoch 8785/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5370 - val_loss: 9.2967\n",
      "Epoch 8786/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5367 - val_loss: 9.2968\n",
      "Epoch 8787/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5364 - val_loss: 9.2966\n",
      "Epoch 8788/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5361 - val_loss: 9.2964\n",
      "Epoch 8789/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5358 - val_loss: 9.2955\n",
      "Epoch 8790/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5355 - val_loss: 9.2951\n",
      "Epoch 8791/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5352 - val_loss: 9.2949\n",
      "Epoch 8792/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5349 - val_loss: 9.2949\n",
      "Epoch 8793/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5346 - val_loss: 9.2950\n",
      "Epoch 8794/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5343 - val_loss: 9.2945\n",
      "Epoch 8795/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5340 - val_loss: 9.2942\n",
      "Epoch 8796/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5337 - val_loss: 9.2939\n",
      "Epoch 8797/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5334 - val_loss: 9.2934\n",
      "Epoch 8798/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5331 - val_loss: 9.2934\n",
      "Epoch 8799/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5328 - val_loss: 9.2930\n",
      "Epoch 8800/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5325 - val_loss: 9.2928\n",
      "Epoch 8801/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5322 - val_loss: 9.2922\n",
      "Epoch 8802/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5319 - val_loss: 9.2920\n",
      "Epoch 8803/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5316 - val_loss: 9.2921\n",
      "Epoch 8804/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5313 - val_loss: 9.2919\n",
      "Epoch 8805/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5310 - val_loss: 9.2919\n",
      "Epoch 8806/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5307 - val_loss: 9.2913\n",
      "Epoch 8807/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5304 - val_loss: 9.2906\n",
      "Epoch 8808/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5301 - val_loss: 9.2903\n",
      "Epoch 8809/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5298 - val_loss: 9.2904\n",
      "Epoch 8810/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5295 - val_loss: 9.2906\n",
      "Epoch 8811/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5292 - val_loss: 9.2905\n",
      "Epoch 8812/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5289 - val_loss: 9.2900\n",
      "Epoch 8813/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5286 - val_loss: 9.2895\n",
      "Epoch 8814/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5283 - val_loss: 9.2892\n",
      "Epoch 8815/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5280 - val_loss: 9.2893\n",
      "Epoch 8816/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5277 - val_loss: 9.2891\n",
      "Epoch 8817/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5274 - val_loss: 9.2886\n",
      "Epoch 8818/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5271 - val_loss: 9.2877\n",
      "Epoch 8819/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5268 - val_loss: 9.2872\n",
      "Epoch 8820/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5265 - val_loss: 9.2872\n",
      "Epoch 8821/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5262 - val_loss: 9.2875\n",
      "Epoch 8822/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5259 - val_loss: 9.2877\n",
      "Epoch 8823/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5255 - val_loss: 9.2873\n",
      "Epoch 8824/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5252 - val_loss: 9.2867\n",
      "Epoch 8825/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5249 - val_loss: 9.2865\n",
      "Epoch 8826/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5246 - val_loss: 9.2867\n",
      "Epoch 8827/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5243 - val_loss: 9.2865\n",
      "Epoch 8828/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5240 - val_loss: 9.2863\n",
      "Epoch 8829/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5237 - val_loss: 9.2856\n",
      "Epoch 8830/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5234 - val_loss: 9.2851\n",
      "Epoch 8831/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5231 - val_loss: 9.2851\n",
      "Epoch 8832/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5228 - val_loss: 9.2848\n",
      "Epoch 8833/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5225 - val_loss: 9.2845\n",
      "Epoch 8834/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5222 - val_loss: 9.2843\n",
      "Epoch 8835/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5219 - val_loss: 9.2841\n",
      "Epoch 8836/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5216 - val_loss: 9.2842\n",
      "Epoch 8837/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5213 - val_loss: 9.2838\n",
      "Epoch 8838/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5210 - val_loss: 9.2834\n",
      "Epoch 8839/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5207 - val_loss: 9.2827\n",
      "Epoch 8840/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5204 - val_loss: 9.2825\n",
      "Epoch 8841/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5201 - val_loss: 9.2823\n",
      "Epoch 8842/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5198 - val_loss: 9.2824\n",
      "Epoch 8843/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5195 - val_loss: 9.2821\n",
      "Epoch 8844/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5192 - val_loss: 9.2814\n",
      "Epoch 8845/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5189 - val_loss: 9.2812\n",
      "Epoch 8846/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5186 - val_loss: 9.2814\n",
      "Epoch 8847/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5183 - val_loss: 9.2814\n",
      "Epoch 8848/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5180 - val_loss: 9.2813\n",
      "Epoch 8849/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5177 - val_loss: 9.2804\n",
      "Epoch 8850/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5174 - val_loss: 9.2798\n",
      "Epoch 8851/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5171 - val_loss: 9.2795\n",
      "Epoch 8852/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5168 - val_loss: 9.2797\n",
      "Epoch 8853/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5165 - val_loss: 9.2796\n",
      "Epoch 8854/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5162 - val_loss: 9.2790\n",
      "Epoch 8855/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5159 - val_loss: 9.2785\n",
      "Epoch 8856/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5156 - val_loss: 9.2782\n",
      "Epoch 8857/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5153 - val_loss: 9.2783\n",
      "Epoch 8858/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5150 - val_loss: 9.2783\n",
      "Epoch 8859/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5147 - val_loss: 9.2780\n",
      "Epoch 8860/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5144 - val_loss: 9.2773\n",
      "Epoch 8861/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5141 - val_loss: 9.2773\n",
      "Epoch 8862/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5138 - val_loss: 9.2771\n",
      "Epoch 8863/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5135 - val_loss: 9.2768\n",
      "Epoch 8864/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5132 - val_loss: 9.2763\n",
      "Epoch 8865/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5129 - val_loss: 9.2753\n",
      "Epoch 8866/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5126 - val_loss: 9.2755\n",
      "Epoch 8867/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5123 - val_loss: 9.2754\n",
      "Epoch 8868/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5120 - val_loss: 9.2760\n",
      "Epoch 8869/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5117 - val_loss: 9.2756\n",
      "Epoch 8870/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5114 - val_loss: 9.2750\n",
      "Epoch 8871/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5111 - val_loss: 9.2747\n",
      "Epoch 8872/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5108 - val_loss: 9.2739\n",
      "Epoch 8873/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5105 - val_loss: 9.2739\n",
      "Epoch 8874/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5102 - val_loss: 9.2735\n",
      "Epoch 8875/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5099 - val_loss: 9.2734\n",
      "Epoch 8876/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5096 - val_loss: 9.2735\n",
      "Epoch 8877/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5093 - val_loss: 9.2733\n",
      "Epoch 8878/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5090 - val_loss: 9.2733\n",
      "Epoch 8879/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5087 - val_loss: 9.2726\n",
      "Epoch 8880/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5084 - val_loss: 9.2723\n",
      "Epoch 8881/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5081 - val_loss: 9.2721\n",
      "Epoch 8882/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5078 - val_loss: 9.2718\n",
      "Epoch 8883/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5075 - val_loss: 9.2715\n",
      "Epoch 8884/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5072 - val_loss: 9.2710\n",
      "Epoch 8885/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5069 - val_loss: 9.2708\n",
      "Epoch 8886/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5066 - val_loss: 9.2709\n",
      "Epoch 8887/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5063 - val_loss: 9.2708\n",
      "Epoch 8888/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5060 - val_loss: 9.2705\n",
      "Epoch 8889/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5057 - val_loss: 9.2700\n",
      "Epoch 8890/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5054 - val_loss: 9.2694\n",
      "Epoch 8891/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5051 - val_loss: 9.2691\n",
      "Epoch 8892/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.5048 - val_loss: 9.2693\n",
      "Epoch 8893/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5045 - val_loss: 9.2691\n",
      "Epoch 8894/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5042 - val_loss: 9.2689\n",
      "Epoch 8895/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5039 - val_loss: 9.2684\n",
      "Epoch 8896/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5036 - val_loss: 9.2682\n",
      "Epoch 8897/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5033 - val_loss: 9.2681\n",
      "Epoch 8898/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5030 - val_loss: 9.2679\n",
      "Epoch 8899/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5027 - val_loss: 9.2677\n",
      "Epoch 8900/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5024 - val_loss: 9.2673\n",
      "Epoch 8901/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5021 - val_loss: 9.2668\n",
      "Epoch 8902/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5018 - val_loss: 9.2664\n",
      "Epoch 8903/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5015 - val_loss: 9.2664\n",
      "Epoch 8904/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5012 - val_loss: 9.2662\n",
      "Epoch 8905/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5009 - val_loss: 9.2661\n",
      "Epoch 8906/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5006 - val_loss: 9.2658\n",
      "Epoch 8907/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5003 - val_loss: 9.2654\n",
      "Epoch 8908/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5000 - val_loss: 9.2653\n",
      "Epoch 8909/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4997 - val_loss: 9.2651\n",
      "Epoch 8910/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4994 - val_loss: 9.2653\n",
      "Epoch 8911/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4991 - val_loss: 9.2650\n",
      "Epoch 8912/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4988 - val_loss: 9.2648\n",
      "Epoch 8913/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4985 - val_loss: 9.2643\n",
      "Epoch 8914/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4982 - val_loss: 9.2636\n",
      "Epoch 8915/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4979 - val_loss: 9.2633\n",
      "Epoch 8916/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4976 - val_loss: 9.2631\n",
      "Epoch 8917/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4973 - val_loss: 9.2636\n",
      "Epoch 8918/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4970 - val_loss: 9.2637\n",
      "Epoch 8919/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4967 - val_loss: 9.2633\n",
      "Epoch 8920/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4965 - val_loss: 9.2621\n",
      "Epoch 8921/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4962 - val_loss: 9.2615\n",
      "Epoch 8922/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4959 - val_loss: 9.2618\n",
      "Epoch 8923/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4956 - val_loss: 9.2623\n",
      "Epoch 8924/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4953 - val_loss: 9.2621\n",
      "Epoch 8925/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4950 - val_loss: 9.2615\n",
      "Epoch 8926/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4947 - val_loss: 9.2603\n",
      "Epoch 8927/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4944 - val_loss: 9.2601\n",
      "Epoch 8928/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4941 - val_loss: 9.2599\n",
      "Epoch 8929/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4938 - val_loss: 9.2599\n",
      "Epoch 8930/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4935 - val_loss: 9.2600\n",
      "Epoch 8931/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4932 - val_loss: 9.2597\n",
      "Epoch 8932/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4929 - val_loss: 9.2601\n",
      "Epoch 8933/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4926 - val_loss: 9.2601\n",
      "Epoch 8934/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4923 - val_loss: 9.2597\n",
      "Epoch 8935/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4920 - val_loss: 9.2590\n",
      "Epoch 8936/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4917 - val_loss: 9.2583\n",
      "Epoch 8937/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4914 - val_loss: 9.2588\n",
      "Epoch 8938/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4911 - val_loss: 9.2583\n",
      "Epoch 8939/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4908 - val_loss: 9.2583\n",
      "Epoch 8940/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4905 - val_loss: 9.2572\n",
      "Epoch 8941/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4902 - val_loss: 9.2571\n",
      "Epoch 8942/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4899 - val_loss: 9.2574\n",
      "Epoch 8943/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4896 - val_loss: 9.2570\n",
      "Epoch 8944/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4893 - val_loss: 9.2573\n",
      "Epoch 8945/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4890 - val_loss: 9.2565\n",
      "Epoch 8946/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4887 - val_loss: 9.2563\n",
      "Epoch 8947/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4884 - val_loss: 9.2556\n",
      "Epoch 8948/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4881 - val_loss: 9.2555\n",
      "Epoch 8949/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4878 - val_loss: 9.2557\n",
      "Epoch 8950/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4875 - val_loss: 9.2556\n",
      "Epoch 8951/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4872 - val_loss: 9.2557\n",
      "Epoch 8952/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4869 - val_loss: 9.2548\n",
      "Epoch 8953/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4866 - val_loss: 9.2542\n",
      "Epoch 8954/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4863 - val_loss: 9.2539\n",
      "Epoch 8955/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4860 - val_loss: 9.2544\n",
      "Epoch 8956/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4857 - val_loss: 9.2546\n",
      "Epoch 8957/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4854 - val_loss: 9.2540\n",
      "Epoch 8958/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4851 - val_loss: 9.2538\n",
      "Epoch 8959/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4848 - val_loss: 9.2530\n",
      "Epoch 8960/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4845 - val_loss: 9.2533\n",
      "Epoch 8961/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4842 - val_loss: 9.2528\n",
      "Epoch 8962/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4839 - val_loss: 9.2526\n",
      "Epoch 8963/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4836 - val_loss: 9.2519\n",
      "Epoch 8964/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4833 - val_loss: 9.2520\n",
      "Epoch 8965/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4830 - val_loss: 9.2521\n",
      "Epoch 8966/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4827 - val_loss: 9.2517\n",
      "Epoch 8967/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4824 - val_loss: 9.2513\n",
      "Epoch 8968/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4821 - val_loss: 9.2505\n",
      "Epoch 8969/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4818 - val_loss: 9.2508\n",
      "Epoch 8970/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4815 - val_loss: 9.2506\n",
      "Epoch 8971/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4812 - val_loss: 9.2508\n",
      "Epoch 8972/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4809 - val_loss: 9.2504\n",
      "Epoch 8973/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4806 - val_loss: 9.2499\n",
      "Epoch 8974/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4803 - val_loss: 9.2499\n",
      "Epoch 8975/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4800 - val_loss: 9.2491\n",
      "Epoch 8976/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4797 - val_loss: 9.2495\n",
      "Epoch 8977/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4794 - val_loss: 9.2490\n",
      "Epoch 8978/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4791 - val_loss: 9.2492\n",
      "Epoch 8979/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4788 - val_loss: 9.2484\n",
      "Epoch 8980/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.4785 - val_loss: 9.2480\n",
      "Epoch 8981/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4782 - val_loss: 9.2479\n",
      "Epoch 8982/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4779 - val_loss: 9.2475\n",
      "Epoch 8983/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4776 - val_loss: 9.2480\n",
      "Epoch 8984/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4773 - val_loss: 9.2474\n",
      "Epoch 8985/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4770 - val_loss: 9.2472\n",
      "Epoch 8986/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4768 - val_loss: 9.2467\n",
      "Epoch 8987/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4765 - val_loss: 9.2468\n",
      "Epoch 8988/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4762 - val_loss: 9.2470\n",
      "Epoch 8989/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4759 - val_loss: 9.2467\n",
      "Epoch 8990/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4756 - val_loss: 9.2465\n",
      "Epoch 8991/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4753 - val_loss: 9.2454\n",
      "Epoch 8992/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4750 - val_loss: 9.2456\n",
      "Epoch 8993/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4747 - val_loss: 9.2451\n",
      "Epoch 8994/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4744 - val_loss: 9.2447\n",
      "Epoch 8995/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4741 - val_loss: 9.2445\n",
      "Epoch 8996/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4738 - val_loss: 9.2441\n",
      "Epoch 8997/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4735 - val_loss: 9.2446\n",
      "Epoch 8998/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4732 - val_loss: 9.2442\n",
      "Epoch 8999/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4729 - val_loss: 9.2443\n",
      "Epoch 9000/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.4726 - val_loss: 9.2435\n",
      "Epoch 9001/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4723 - val_loss: 9.2431\n",
      "Epoch 9002/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4720 - val_loss: 9.2428\n",
      "Epoch 9003/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.4717 - val_loss: 9.2426\n",
      "Epoch 9004/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4714 - val_loss: 9.2427\n",
      "Epoch 9005/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4711 - val_loss: 9.2421\n",
      "Epoch 9006/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4708 - val_loss: 9.2421\n",
      "Epoch 9007/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4705 - val_loss: 9.2416\n",
      "Epoch 9008/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4702 - val_loss: 9.2414\n",
      "Epoch 9009/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4699 - val_loss: 9.2407\n",
      "Epoch 9010/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4696 - val_loss: 9.2405\n",
      "Epoch 9011/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4693 - val_loss: 9.2405\n",
      "Epoch 9012/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4690 - val_loss: 9.2405\n",
      "Epoch 9013/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4687 - val_loss: 9.2403\n",
      "Epoch 9014/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4684 - val_loss: 9.2394\n",
      "Epoch 9015/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4681 - val_loss: 9.2393\n",
      "Epoch 9016/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4678 - val_loss: 9.2388\n",
      "Epoch 9017/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4675 - val_loss: 9.2384\n",
      "Epoch 9018/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4672 - val_loss: 9.2383\n",
      "Epoch 9019/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4669 - val_loss: 9.2380\n",
      "Epoch 9020/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4666 - val_loss: 9.2381\n",
      "Epoch 9021/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.4663 - val_loss: 9.2378\n",
      "Epoch 9022/10000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.4660 - val_loss: 9.2375\n",
      "Epoch 9023/10000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.4657 - val_loss: 9.2372\n",
      "Epoch 9024/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.4654 - val_loss: 9.2370\n",
      "Epoch 9025/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4651 - val_loss: 9.2371\n",
      "Epoch 9026/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4649 - val_loss: 9.2368\n",
      "Epoch 9027/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4646 - val_loss: 9.2369\n",
      "Epoch 9028/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4643 - val_loss: 9.2361\n",
      "Epoch 9029/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4640 - val_loss: 9.2354\n",
      "Epoch 9030/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4637 - val_loss: 9.2352\n",
      "Epoch 9031/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4634 - val_loss: 9.2353\n",
      "Epoch 9032/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4631 - val_loss: 9.2353\n",
      "Epoch 9033/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4628 - val_loss: 9.2346\n",
      "Epoch 9034/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4625 - val_loss: 9.2342\n",
      "Epoch 9035/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4622 - val_loss: 9.2336\n",
      "Epoch 9036/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4619 - val_loss: 9.2337\n",
      "Epoch 9037/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4616 - val_loss: 9.2333\n",
      "Epoch 9038/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.4613 - val_loss: 9.2332\n",
      "Epoch 9039/10000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.4610 - val_loss: 9.2331\n",
      "Epoch 9040/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.4607 - val_loss: 9.2327\n",
      "Epoch 9041/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4604 - val_loss: 9.2328\n",
      "Epoch 9042/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4601 - val_loss: 9.2323\n",
      "Epoch 9043/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4598 - val_loss: 9.2321\n",
      "Epoch 9044/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.4595 - val_loss: 9.2313\n",
      "Epoch 9045/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4592 - val_loss: 9.2319\n",
      "Epoch 9046/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4589 - val_loss: 9.2316\n",
      "Epoch 9047/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4586 - val_loss: 9.2318\n",
      "Epoch 9048/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4583 - val_loss: 9.2312\n",
      "Epoch 9049/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4580 - val_loss: 9.2305\n",
      "Epoch 9050/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4577 - val_loss: 9.2303\n",
      "Epoch 9051/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4574 - val_loss: 9.2299\n",
      "Epoch 9052/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4571 - val_loss: 9.2301\n",
      "Epoch 9053/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4568 - val_loss: 9.2296\n",
      "Epoch 9054/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4565 - val_loss: 9.2298\n",
      "Epoch 9055/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.4562 - val_loss: 9.2298\n",
      "Epoch 9056/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.4560 - val_loss: 9.2291\n",
      "Epoch 9057/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4557 - val_loss: 9.2283\n",
      "Epoch 9058/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4554 - val_loss: 9.2276\n",
      "Epoch 9059/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4551 - val_loss: 9.2281\n",
      "Epoch 9060/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4548 - val_loss: 9.2279\n",
      "Epoch 9061/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4545 - val_loss: 9.2279\n",
      "Epoch 9062/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4542 - val_loss: 9.2273\n",
      "Epoch 9063/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4539 - val_loss: 9.2271\n",
      "Epoch 9064/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4536 - val_loss: 9.2268\n",
      "Epoch 9065/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4533 - val_loss: 9.2265\n",
      "Epoch 9066/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4530 - val_loss: 9.2263\n",
      "Epoch 9067/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4527 - val_loss: 9.2262\n",
      "Epoch 9068/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4524 - val_loss: 9.2262\n",
      "Epoch 9069/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4521 - val_loss: 9.2260\n",
      "Epoch 9070/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4518 - val_loss: 9.2253\n",
      "Epoch 9071/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4515 - val_loss: 9.2247\n",
      "Epoch 9072/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4512 - val_loss: 9.2241\n",
      "Epoch 9073/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4509 - val_loss: 9.2245\n",
      "Epoch 9074/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4506 - val_loss: 9.2245\n",
      "Epoch 9075/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.4503 - val_loss: 9.2243\n",
      "Epoch 9076/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4500 - val_loss: 9.2236\n",
      "Epoch 9077/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4497 - val_loss: 9.2238\n",
      "Epoch 9078/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4494 - val_loss: 9.2234\n",
      "Epoch 9079/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.4491 - val_loss: 9.2233\n",
      "Epoch 9080/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4488 - val_loss: 9.2226\n",
      "Epoch 9081/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4485 - val_loss: 9.2224\n",
      "Epoch 9082/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4483 - val_loss: 9.2224\n",
      "Epoch 9083/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4480 - val_loss: 9.2221\n",
      "Epoch 9084/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4477 - val_loss: 9.2220\n",
      "Epoch 9085/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.4474 - val_loss: 9.2212\n",
      "Epoch 9086/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4471 - val_loss: 9.2210\n",
      "Epoch 9087/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4468 - val_loss: 9.2207\n",
      "Epoch 9088/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4465 - val_loss: 9.2209\n",
      "Epoch 9089/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4462 - val_loss: 9.2205\n",
      "Epoch 9090/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4459 - val_loss: 9.2199\n",
      "Epoch 9091/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4456 - val_loss: 9.2194\n",
      "Epoch 9092/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.4453 - val_loss: 9.2196\n",
      "Epoch 9093/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.4450 - val_loss: 9.2194\n",
      "Epoch 9094/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.4447 - val_loss: 9.2191\n",
      "Epoch 9095/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.4444 - val_loss: 9.2183\n",
      "Epoch 9096/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.4441 - val_loss: 9.2184\n",
      "Epoch 9097/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4438 - val_loss: 9.2182\n",
      "Epoch 9098/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4435 - val_loss: 9.2180\n",
      "Epoch 9099/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4432 - val_loss: 9.2174\n",
      "Epoch 9100/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.4429 - val_loss: 9.2171\n",
      "Epoch 9101/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.4426 - val_loss: 9.2170\n",
      "Epoch 9102/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.4423 - val_loss: 9.2171\n",
      "Epoch 9103/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.4420 - val_loss: 9.2167\n",
      "Epoch 9104/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.4417 - val_loss: 9.2158\n",
      "Epoch 9105/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4414 - val_loss: 9.2154\n",
      "Epoch 9106/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.4412 - val_loss: 9.2153\n",
      "Epoch 9107/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4409 - val_loss: 9.2158\n",
      "Epoch 9108/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4406 - val_loss: 9.2153\n",
      "Epoch 9109/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4403 - val_loss: 9.2149\n",
      "Epoch 9110/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4400 - val_loss: 9.2145\n",
      "Epoch 9111/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4397 - val_loss: 9.2144\n",
      "Epoch 9112/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4394 - val_loss: 9.2142\n",
      "Epoch 9113/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4391 - val_loss: 9.2134\n",
      "Epoch 9114/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4388 - val_loss: 9.2130\n",
      "Epoch 9115/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4385 - val_loss: 9.2128\n",
      "Epoch 9116/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4382 - val_loss: 9.2137\n",
      "Epoch 9117/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4379 - val_loss: 9.2134\n",
      "Epoch 9118/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.4376 - val_loss: 9.2126\n",
      "Epoch 9119/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4373 - val_loss: 9.2122\n",
      "Epoch 9120/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4370 - val_loss: 9.2117\n",
      "Epoch 9121/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4367 - val_loss: 9.2127\n",
      "Epoch 9122/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4364 - val_loss: 9.2118\n",
      "Epoch 9123/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4361 - val_loss: 9.2113\n",
      "Epoch 9124/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4358 - val_loss: 9.2102\n",
      "Epoch 9125/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4355 - val_loss: 9.2105\n",
      "Epoch 9126/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4352 - val_loss: 9.2110\n",
      "Epoch 9127/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4350 - val_loss: 9.2109\n",
      "Epoch 9128/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4347 - val_loss: 9.2103\n",
      "Epoch 9129/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4344 - val_loss: 9.2096\n",
      "Epoch 9130/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4341 - val_loss: 9.2101\n",
      "Epoch 9131/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4338 - val_loss: 9.2101\n",
      "Epoch 9132/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4335 - val_loss: 9.2098\n",
      "Epoch 9133/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4332 - val_loss: 9.2086\n",
      "Epoch 9134/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4329 - val_loss: 9.2083\n",
      "Epoch 9135/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4326 - val_loss: 9.2088\n",
      "Epoch 9136/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4323 - val_loss: 9.2087\n",
      "Epoch 9137/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4320 - val_loss: 9.2082\n",
      "Epoch 9138/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4317 - val_loss: 9.2075\n",
      "Epoch 9139/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4314 - val_loss: 9.2077\n",
      "Epoch 9140/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4311 - val_loss: 9.2077\n",
      "Epoch 9141/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4308 - val_loss: 9.2076\n",
      "Epoch 9142/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4305 - val_loss: 9.2068\n",
      "Epoch 9143/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4302 - val_loss: 9.2059\n",
      "Epoch 9144/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4299 - val_loss: 9.2060\n",
      "Epoch 9145/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4296 - val_loss: 9.2065\n",
      "Epoch 9146/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4293 - val_loss: 9.2065\n",
      "Epoch 9147/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4291 - val_loss: 9.2061\n",
      "Epoch 9148/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4288 - val_loss: 9.2052\n",
      "Epoch 9149/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4285 - val_loss: 9.2050\n",
      "Epoch 9150/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4282 - val_loss: 9.2047\n",
      "Epoch 9151/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4279 - val_loss: 9.2050\n",
      "Epoch 9152/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4276 - val_loss: 9.2050\n",
      "Epoch 9153/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4273 - val_loss: 9.2043\n",
      "Epoch 9154/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4270 - val_loss: 9.2042\n",
      "Epoch 9155/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4267 - val_loss: 9.2035\n",
      "Epoch 9156/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.4264 - val_loss: 9.2039\n",
      "Epoch 9157/10000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.4261 - val_loss: 9.2032\n",
      "Epoch 9158/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.4258 - val_loss: 9.2031\n",
      "Epoch 9159/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.4255 - val_loss: 9.2030\n",
      "Epoch 9160/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4252 - val_loss: 9.2029\n",
      "Epoch 9161/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4249 - val_loss: 9.2030\n",
      "Epoch 9162/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4246 - val_loss: 9.2021\n",
      "Epoch 9163/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4243 - val_loss: 9.2020\n",
      "Epoch 9164/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4240 - val_loss: 9.2010\n",
      "Epoch 9165/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4238 - val_loss: 9.2019\n",
      "Epoch 9166/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4235 - val_loss: 9.2014\n",
      "Epoch 9167/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4232 - val_loss: 9.2020\n",
      "Epoch 9168/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4229 - val_loss: 9.2009\n",
      "Epoch 9169/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4226 - val_loss: 9.2003\n",
      "Epoch 9170/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4223 - val_loss: 9.2000\n",
      "Epoch 9171/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4220 - val_loss: 9.2000\n",
      "Epoch 9172/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4217 - val_loss: 9.2007\n",
      "Epoch 9173/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4214 - val_loss: 9.1998\n",
      "Epoch 9174/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4211 - val_loss: 9.1998\n",
      "Epoch 9175/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4208 - val_loss: 9.1992\n",
      "Epoch 9176/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4205 - val_loss: 9.1995\n",
      "Epoch 9177/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4202 - val_loss: 9.1990\n",
      "Epoch 9178/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4199 - val_loss: 9.1987\n",
      "Epoch 9179/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4196 - val_loss: 9.1978\n",
      "Epoch 9180/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4193 - val_loss: 9.1979\n",
      "Epoch 9181/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4190 - val_loss: 9.1983\n",
      "Epoch 9182/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4187 - val_loss: 9.1983\n",
      "Epoch 9183/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4185 - val_loss: 9.1981\n",
      "Epoch 9184/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4182 - val_loss: 9.1973\n",
      "Epoch 9185/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4179 - val_loss: 9.1976\n",
      "Epoch 9186/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4176 - val_loss: 9.1970\n",
      "Epoch 9187/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4173 - val_loss: 9.1972\n",
      "Epoch 9188/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4170 - val_loss: 9.1965\n",
      "Epoch 9189/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4167 - val_loss: 9.1965\n",
      "Epoch 9190/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4164 - val_loss: 9.1959\n",
      "Epoch 9191/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4161 - val_loss: 9.1957\n",
      "Epoch 9192/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4158 - val_loss: 9.1955\n",
      "Epoch 9193/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4155 - val_loss: 9.1949\n",
      "Epoch 9194/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4152 - val_loss: 9.1959\n",
      "Epoch 9195/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4149 - val_loss: 9.1953\n",
      "Epoch 9196/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4146 - val_loss: 9.1960\n",
      "Epoch 9197/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4143 - val_loss: 9.1948\n",
      "Epoch 9198/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4140 - val_loss: 9.1945\n",
      "Epoch 9199/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4138 - val_loss: 9.1944\n",
      "Epoch 9200/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4135 - val_loss: 9.1942\n",
      "Epoch 9201/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4132 - val_loss: 9.1944\n",
      "Epoch 9202/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4129 - val_loss: 9.1941\n",
      "Epoch 9203/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4126 - val_loss: 9.1942\n",
      "Epoch 9204/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4123 - val_loss: 9.1936\n",
      "Epoch 9205/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4120 - val_loss: 9.1936\n",
      "Epoch 9206/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4117 - val_loss: 9.1933\n",
      "Epoch 9207/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4114 - val_loss: 9.1929\n",
      "Epoch 9208/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4111 - val_loss: 9.1928\n",
      "Epoch 9209/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4108 - val_loss: 9.1929\n",
      "Epoch 9210/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4105 - val_loss: 9.1929\n",
      "Epoch 9211/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4102 - val_loss: 9.1927\n",
      "Epoch 9212/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4099 - val_loss: 9.1922\n",
      "Epoch 9213/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4096 - val_loss: 9.1916\n",
      "Epoch 9214/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4094 - val_loss: 9.1919\n",
      "Epoch 9215/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4091 - val_loss: 9.1920\n",
      "Epoch 9216/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4088 - val_loss: 9.1919\n",
      "Epoch 9217/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4085 - val_loss: 9.1917\n",
      "Epoch 9218/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4082 - val_loss: 9.1911\n",
      "Epoch 9219/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4079 - val_loss: 9.1910\n",
      "Epoch 9220/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4076 - val_loss: 9.1904\n",
      "Epoch 9221/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4073 - val_loss: 9.1905\n",
      "Epoch 9222/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4070 - val_loss: 9.1900\n",
      "Epoch 9223/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4067 - val_loss: 9.1904\n",
      "Epoch 9224/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4064 - val_loss: 9.1902\n",
      "Epoch 9225/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4061 - val_loss: 9.1904\n",
      "Epoch 9226/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4058 - val_loss: 9.1896\n",
      "Epoch 9227/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4055 - val_loss: 9.1895\n",
      "Epoch 9228/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4053 - val_loss: 9.1893\n",
      "Epoch 9229/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4050 - val_loss: 9.1894\n",
      "Epoch 9230/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4047 - val_loss: 9.1893\n",
      "Epoch 9231/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4044 - val_loss: 9.1886\n",
      "Epoch 9232/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4041 - val_loss: 9.1890\n",
      "Epoch 9233/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4038 - val_loss: 9.1888\n",
      "Epoch 9234/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4035 - val_loss: 9.1894\n",
      "Epoch 9235/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4032 - val_loss: 9.1883\n",
      "Epoch 9236/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4029 - val_loss: 9.1880\n",
      "Epoch 9237/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4026 - val_loss: 9.1876\n",
      "Epoch 9238/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.4023 - val_loss: 9.1882\n",
      "Epoch 9239/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.4020 - val_loss: 9.1883\n",
      "Epoch 9240/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4017 - val_loss: 9.1876\n",
      "Epoch 9241/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4014 - val_loss: 9.1874\n",
      "Epoch 9242/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4012 - val_loss: 9.1870\n",
      "Epoch 9243/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4009 - val_loss: 9.1876\n",
      "Epoch 9244/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4006 - val_loss: 9.1868\n",
      "Epoch 9245/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4003 - val_loss: 9.1864\n",
      "Epoch 9246/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4000 - val_loss: 9.1861\n",
      "Epoch 9247/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3997 - val_loss: 9.1867\n",
      "Epoch 9248/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3994 - val_loss: 9.1868\n",
      "Epoch 9249/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3991 - val_loss: 9.1863\n",
      "Epoch 9250/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3988 - val_loss: 9.1855\n",
      "Epoch 9251/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3985 - val_loss: 9.1855\n",
      "Epoch 9252/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3982 - val_loss: 9.1854\n",
      "Epoch 9253/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3979 - val_loss: 9.1850\n",
      "Epoch 9254/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3976 - val_loss: 9.1847\n",
      "Epoch 9255/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3974 - val_loss: 9.1845\n",
      "Epoch 9256/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3971 - val_loss: 9.1850\n",
      "Epoch 9257/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3968 - val_loss: 9.1851\n",
      "Epoch 9258/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3965 - val_loss: 9.1848\n",
      "Epoch 9259/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3962 - val_loss: 9.1842\n",
      "Epoch 9260/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3959 - val_loss: 9.1841\n",
      "Epoch 9261/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3956 - val_loss: 9.1840\n",
      "Epoch 9262/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3953 - val_loss: 9.1844\n",
      "Epoch 9263/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3950 - val_loss: 9.1846\n",
      "Epoch 9264/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3947 - val_loss: 9.1843\n",
      "Epoch 9265/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3944 - val_loss: 9.1837\n",
      "Epoch 9266/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3941 - val_loss: 9.1831\n",
      "Epoch 9267/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3938 - val_loss: 9.1828\n",
      "Epoch 9268/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3936 - val_loss: 9.1830\n",
      "Epoch 9269/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3933 - val_loss: 9.1834\n",
      "Epoch 9270/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3930 - val_loss: 9.1833\n",
      "Epoch 9271/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.3927 - val_loss: 9.1829\n",
      "Epoch 9272/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3924 - val_loss: 9.1827\n",
      "Epoch 9273/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3921 - val_loss: 9.1824\n",
      "Epoch 9274/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3918 - val_loss: 9.1827\n",
      "Epoch 9275/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3915 - val_loss: 9.1823\n",
      "Epoch 9276/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3912 - val_loss: 9.1824\n",
      "Epoch 9277/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3909 - val_loss: 9.1818\n",
      "Epoch 9278/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.3906 - val_loss: 9.1818\n",
      "Epoch 9279/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3903 - val_loss: 9.1816\n",
      "Epoch 9280/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3901 - val_loss: 9.1820\n",
      "Epoch 9281/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3898 - val_loss: 9.1813\n",
      "Epoch 9282/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3895 - val_loss: 9.1813\n",
      "Epoch 9283/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3892 - val_loss: 9.1808\n",
      "Epoch 9284/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3889 - val_loss: 9.1811\n",
      "Epoch 9285/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3886 - val_loss: 9.1806\n",
      "Epoch 9286/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3883 - val_loss: 9.1803\n",
      "Epoch 9287/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3880 - val_loss: 9.1803\n",
      "Epoch 9288/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3877 - val_loss: 9.1807\n",
      "Epoch 9289/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3874 - val_loss: 9.1809\n",
      "Epoch 9290/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3871 - val_loss: 9.1801\n",
      "Epoch 9291/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3868 - val_loss: 9.1797\n",
      "Epoch 9292/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3866 - val_loss: 9.1794\n",
      "Epoch 9293/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3863 - val_loss: 9.1799\n",
      "Epoch 9294/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3860 - val_loss: 9.1799\n",
      "Epoch 9295/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3857 - val_loss: 9.1797\n",
      "Epoch 9296/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3854 - val_loss: 9.1793\n",
      "Epoch 9297/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3851 - val_loss: 9.1791\n",
      "Epoch 9298/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3848 - val_loss: 9.1792\n",
      "Epoch 9299/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3845 - val_loss: 9.1787\n",
      "Epoch 9300/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3842 - val_loss: 9.1788\n",
      "Epoch 9301/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.3839 - val_loss: 9.1785\n",
      "Epoch 9302/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3836 - val_loss: 9.1787\n",
      "Epoch 9303/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3833 - val_loss: 9.1785\n",
      "Epoch 9304/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3831 - val_loss: 9.1780\n",
      "Epoch 9305/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3828 - val_loss: 9.1777\n",
      "Epoch 9306/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3825 - val_loss: 9.1778\n",
      "Epoch 9307/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3822 - val_loss: 9.1779\n",
      "Epoch 9308/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3819 - val_loss: 9.1779\n",
      "Epoch 9309/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3816 - val_loss: 9.1774\n",
      "Epoch 9310/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3813 - val_loss: 9.1774\n",
      "Epoch 9311/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3810 - val_loss: 9.1764\n",
      "Epoch 9312/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3807 - val_loss: 9.1764\n",
      "Epoch 9313/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3804 - val_loss: 9.1760\n",
      "Epoch 9314/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3801 - val_loss: 9.1763\n",
      "Epoch 9315/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3798 - val_loss: 9.1762\n",
      "Epoch 9316/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3796 - val_loss: 9.1757\n",
      "Epoch 9317/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3793 - val_loss: 9.1755\n",
      "Epoch 9318/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3790 - val_loss: 9.1752\n",
      "Epoch 9319/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3787 - val_loss: 9.1757\n",
      "Epoch 9320/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3784 - val_loss: 9.1751\n",
      "Epoch 9321/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3781 - val_loss: 9.1754\n",
      "Epoch 9322/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3778 - val_loss: 9.1747\n",
      "Epoch 9323/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.3775 - val_loss: 9.1751\n",
      "Epoch 9324/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3772 - val_loss: 9.1742\n",
      "Epoch 9325/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3769 - val_loss: 9.1743\n",
      "Epoch 9326/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3766 - val_loss: 9.1739\n",
      "Epoch 9327/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3764 - val_loss: 9.1740\n",
      "Epoch 9328/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3761 - val_loss: 9.1736\n",
      "Epoch 9329/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3758 - val_loss: 9.1737\n",
      "Epoch 9330/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3755 - val_loss: 9.1737\n",
      "Epoch 9331/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3752 - val_loss: 9.1734\n",
      "Epoch 9332/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3749 - val_loss: 9.1730\n",
      "Epoch 9333/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3746 - val_loss: 9.1723\n",
      "Epoch 9334/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3743 - val_loss: 9.1721\n",
      "Epoch 9335/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3740 - val_loss: 9.1724\n",
      "Epoch 9336/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3737 - val_loss: 9.1729\n",
      "Epoch 9337/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3734 - val_loss: 9.1728\n",
      "Epoch 9338/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3731 - val_loss: 9.1723\n",
      "Epoch 9339/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3729 - val_loss: 9.1718\n",
      "Epoch 9340/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3726 - val_loss: 9.1716\n",
      "Epoch 9341/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3723 - val_loss: 9.1715\n",
      "Epoch 9342/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3720 - val_loss: 9.1711\n",
      "Epoch 9343/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3717 - val_loss: 9.1712\n",
      "Epoch 9344/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3714 - val_loss: 9.1707\n",
      "Epoch 9345/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3711 - val_loss: 9.1706\n",
      "Epoch 9346/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3708 - val_loss: 9.1703\n",
      "Epoch 9347/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3705 - val_loss: 9.1697\n",
      "Epoch 9348/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3702 - val_loss: 9.1700\n",
      "Epoch 9349/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3699 - val_loss: 9.1695\n",
      "Epoch 9350/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3697 - val_loss: 9.1698\n",
      "Epoch 9351/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3694 - val_loss: 9.1691\n",
      "Epoch 9352/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3691 - val_loss: 9.1696\n",
      "Epoch 9353/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3688 - val_loss: 9.1687\n",
      "Epoch 9354/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3685 - val_loss: 9.1688\n",
      "Epoch 9355/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3682 - val_loss: 9.1682\n",
      "Epoch 9356/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3679 - val_loss: 9.1685\n",
      "Epoch 9357/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3676 - val_loss: 9.1687\n",
      "Epoch 9358/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3673 - val_loss: 9.1682\n",
      "Epoch 9359/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3670 - val_loss: 9.1680\n",
      "Epoch 9360/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3668 - val_loss: 9.1680\n",
      "Epoch 9361/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3665 - val_loss: 9.1687\n",
      "Epoch 9362/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3662 - val_loss: 9.1684\n",
      "Epoch 9363/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3659 - val_loss: 9.1677\n",
      "Epoch 9364/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3656 - val_loss: 9.1669\n",
      "Epoch 9365/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3653 - val_loss: 9.1670\n",
      "Epoch 9366/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3650 - val_loss: 9.1677\n",
      "Epoch 9367/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3647 - val_loss: 9.1671\n",
      "Epoch 9368/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3644 - val_loss: 9.1665\n",
      "Epoch 9369/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3641 - val_loss: 9.1657\n",
      "Epoch 9370/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3639 - val_loss: 9.1666\n",
      "Epoch 9371/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3636 - val_loss: 9.1666\n",
      "Epoch 9372/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3633 - val_loss: 9.1665\n",
      "Epoch 9373/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3630 - val_loss: 9.1650\n",
      "Epoch 9374/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3627 - val_loss: 9.1648\n",
      "Epoch 9375/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3624 - val_loss: 9.1652\n",
      "Epoch 9376/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3621 - val_loss: 9.1654\n",
      "Epoch 9377/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3618 - val_loss: 9.1652\n",
      "Epoch 9378/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3615 - val_loss: 9.1643\n",
      "Epoch 9379/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3612 - val_loss: 9.1646\n",
      "Epoch 9380/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3609 - val_loss: 9.1645\n",
      "Epoch 9381/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3607 - val_loss: 9.1649\n",
      "Epoch 9382/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3604 - val_loss: 9.1637\n",
      "Epoch 9383/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3601 - val_loss: 9.1638\n",
      "Epoch 9384/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3598 - val_loss: 9.1637\n",
      "Epoch 9385/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3595 - val_loss: 9.1643\n",
      "Epoch 9386/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3592 - val_loss: 9.1638\n",
      "Epoch 9387/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3589 - val_loss: 9.1635\n",
      "Epoch 9388/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3586 - val_loss: 9.1630\n",
      "Epoch 9389/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3583 - val_loss: 9.1627\n",
      "Epoch 9390/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3580 - val_loss: 9.1628\n",
      "Epoch 9391/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3578 - val_loss: 9.1624\n",
      "Epoch 9392/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 3.3575 - val_loss: 9.1628\n",
      "Epoch 9393/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3572 - val_loss: 9.1622\n",
      "Epoch 9394/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3569 - val_loss: 9.1626\n",
      "Epoch 9395/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3566 - val_loss: 9.1623\n",
      "Epoch 9396/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3563 - val_loss: 9.1618\n",
      "Epoch 9397/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3560 - val_loss: 9.1612\n",
      "Epoch 9398/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3557 - val_loss: 9.1610\n",
      "Epoch 9399/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3554 - val_loss: 9.1620\n",
      "Epoch 9400/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3551 - val_loss: 9.1619\n",
      "Epoch 9401/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3549 - val_loss: 9.1615\n",
      "Epoch 9402/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3546 - val_loss: 9.1599\n",
      "Epoch 9403/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3543 - val_loss: 9.1604\n",
      "Epoch 9404/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3540 - val_loss: 9.1602\n",
      "Epoch 9405/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3537 - val_loss: 9.1607\n",
      "Epoch 9406/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3534 - val_loss: 9.1596\n",
      "Epoch 9407/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3531 - val_loss: 9.1593\n",
      "Epoch 9408/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3528 - val_loss: 9.1592\n",
      "Epoch 9409/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3525 - val_loss: 9.1595\n",
      "Epoch 9410/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3522 - val_loss: 9.1596\n",
      "Epoch 9411/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3520 - val_loss: 9.1585\n",
      "Epoch 9412/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3517 - val_loss: 9.1586\n",
      "Epoch 9413/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3514 - val_loss: 9.1581\n",
      "Epoch 9414/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3511 - val_loss: 9.1582\n",
      "Epoch 9415/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3508 - val_loss: 9.1574\n",
      "Epoch 9416/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3505 - val_loss: 9.1576\n",
      "Epoch 9417/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.3502 - val_loss: 9.1576\n",
      "Epoch 9418/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3499 - val_loss: 9.1571\n",
      "Epoch 9419/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3496 - val_loss: 9.1570\n",
      "Epoch 9420/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3494 - val_loss: 9.1560\n",
      "Epoch 9421/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3491 - val_loss: 9.1568\n",
      "Epoch 9422/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.3488 - val_loss: 9.1561\n",
      "Epoch 9423/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3485 - val_loss: 9.1562\n",
      "Epoch 9424/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3482 - val_loss: 9.1552\n",
      "Epoch 9425/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3479 - val_loss: 9.1556\n",
      "Epoch 9426/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3476 - val_loss: 9.1555\n",
      "Epoch 9427/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3473 - val_loss: 9.1552\n",
      "Epoch 9428/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3470 - val_loss: 9.1551\n",
      "Epoch 9429/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.3467 - val_loss: 9.1547\n",
      "Epoch 9430/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3465 - val_loss: 9.1550\n",
      "Epoch 9431/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3462 - val_loss: 9.1540\n",
      "Epoch 9432/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3459 - val_loss: 9.1539\n",
      "Epoch 9433/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3456 - val_loss: 9.1536\n",
      "Epoch 9434/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.3453 - val_loss: 9.1541\n",
      "Epoch 9435/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3450 - val_loss: 9.1533\n",
      "Epoch 9436/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3447 - val_loss: 9.1530\n",
      "Epoch 9437/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3444 - val_loss: 9.1525\n",
      "Epoch 9438/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3441 - val_loss: 9.1530\n",
      "Epoch 9439/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3439 - val_loss: 9.1528\n",
      "Epoch 9440/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3436 - val_loss: 9.1526\n",
      "Epoch 9441/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3433 - val_loss: 9.1524\n",
      "Epoch 9442/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3430 - val_loss: 9.1525\n",
      "Epoch 9443/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3427 - val_loss: 9.1525\n",
      "Epoch 9444/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3424 - val_loss: 9.1519\n",
      "Epoch 9445/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3421 - val_loss: 9.1515\n",
      "Epoch 9446/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3418 - val_loss: 9.1514\n",
      "Epoch 9447/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3415 - val_loss: 9.1512\n",
      "Epoch 9448/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3412 - val_loss: 9.1507\n",
      "Epoch 9449/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3410 - val_loss: 9.1501\n",
      "Epoch 9450/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3407 - val_loss: 9.1500\n",
      "Epoch 9451/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3404 - val_loss: 9.1501\n",
      "Epoch 9452/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3401 - val_loss: 9.1503\n",
      "Epoch 9453/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3398 - val_loss: 9.1498\n",
      "Epoch 9454/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.3395 - val_loss: 9.1493\n",
      "Epoch 9455/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3392 - val_loss: 9.1491\n",
      "Epoch 9456/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3389 - val_loss: 9.1493\n",
      "Epoch 9457/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3386 - val_loss: 9.1495\n",
      "Epoch 9458/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3384 - val_loss: 9.1491\n",
      "Epoch 9459/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3381 - val_loss: 9.1489\n",
      "Epoch 9460/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3378 - val_loss: 9.1481\n",
      "Epoch 9461/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3375 - val_loss: 9.1481\n",
      "Epoch 9462/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3372 - val_loss: 9.1474\n",
      "Epoch 9463/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3369 - val_loss: 9.1473\n",
      "Epoch 9464/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3366 - val_loss: 9.1469\n",
      "Epoch 9465/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3363 - val_loss: 9.1471\n",
      "Epoch 9466/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3360 - val_loss: 9.1470\n",
      "Epoch 9467/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3358 - val_loss: 9.1467\n",
      "Epoch 9468/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3355 - val_loss: 9.1463\n",
      "Epoch 9469/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3352 - val_loss: 9.1456\n",
      "Epoch 9470/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3349 - val_loss: 9.1458\n",
      "Epoch 9471/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3346 - val_loss: 9.1459\n",
      "Epoch 9472/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3343 - val_loss: 9.1462\n",
      "Epoch 9473/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3340 - val_loss: 9.1456\n",
      "Epoch 9474/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3337 - val_loss: 9.1457\n",
      "Epoch 9475/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3334 - val_loss: 9.1448\n",
      "Epoch 9476/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3332 - val_loss: 9.1449\n",
      "Epoch 9477/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3329 - val_loss: 9.1443\n",
      "Epoch 9478/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3326 - val_loss: 9.1443\n",
      "Epoch 9479/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3323 - val_loss: 9.1439\n",
      "Epoch 9480/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3320 - val_loss: 9.1438\n",
      "Epoch 9481/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3317 - val_loss: 9.1438\n",
      "Epoch 9482/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3314 - val_loss: 9.1435\n",
      "Epoch 9483/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3311 - val_loss: 9.1436\n",
      "Epoch 9484/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3309 - val_loss: 9.1425\n",
      "Epoch 9485/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3306 - val_loss: 9.1429\n",
      "Epoch 9486/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3303 - val_loss: 9.1422\n",
      "Epoch 9487/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3300 - val_loss: 9.1428\n",
      "Epoch 9488/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3297 - val_loss: 9.1421\n",
      "Epoch 9489/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3294 - val_loss: 9.1425\n",
      "Epoch 9490/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3291 - val_loss: 9.1416\n",
      "Epoch 9491/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3288 - val_loss: 9.1416\n",
      "Epoch 9492/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3285 - val_loss: 9.1414\n",
      "Epoch 9493/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3283 - val_loss: 9.1412\n",
      "Epoch 9494/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3280 - val_loss: 9.1412\n",
      "Epoch 9495/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3277 - val_loss: 9.1410\n",
      "Epoch 9496/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3274 - val_loss: 9.1411\n",
      "Epoch 9497/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3271 - val_loss: 9.1407\n",
      "Epoch 9498/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3268 - val_loss: 9.1404\n",
      "Epoch 9499/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3265 - val_loss: 9.1401\n",
      "Epoch 9500/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3262 - val_loss: 9.1402\n",
      "Epoch 9501/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3260 - val_loss: 9.1401\n",
      "Epoch 9502/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3257 - val_loss: 9.1394\n",
      "Epoch 9503/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3254 - val_loss: 9.1395\n",
      "Epoch 9504/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3251 - val_loss: 9.1395\n",
      "Epoch 9505/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3248 - val_loss: 9.1395\n",
      "Epoch 9506/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3245 - val_loss: 9.1390\n",
      "Epoch 9507/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3242 - val_loss: 9.1383\n",
      "Epoch 9508/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3239 - val_loss: 9.1385\n",
      "Epoch 9509/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3237 - val_loss: 9.1381\n",
      "Epoch 9510/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3234 - val_loss: 9.1379\n",
      "Epoch 9511/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3231 - val_loss: 9.1372\n",
      "Epoch 9512/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3228 - val_loss: 9.1376\n",
      "Epoch 9513/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3225 - val_loss: 9.1377\n",
      "Epoch 9514/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.3222 - val_loss: 9.1375\n",
      "Epoch 9515/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3219 - val_loss: 9.1370\n",
      "Epoch 9516/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3216 - val_loss: 9.1366\n",
      "Epoch 9517/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3213 - val_loss: 9.1366\n",
      "Epoch 9518/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3211 - val_loss: 9.1365\n",
      "Epoch 9519/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3208 - val_loss: 9.1361\n",
      "Epoch 9520/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3205 - val_loss: 9.1357\n",
      "Epoch 9521/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3202 - val_loss: 9.1359\n",
      "Epoch 9522/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3199 - val_loss: 9.1355\n",
      "Epoch 9523/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3196 - val_loss: 9.1354\n",
      "Epoch 9524/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3193 - val_loss: 9.1348\n",
      "Epoch 9525/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3190 - val_loss: 9.1351\n",
      "Epoch 9526/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3188 - val_loss: 9.1349\n",
      "Epoch 9527/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3185 - val_loss: 9.1350\n",
      "Epoch 9528/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3182 - val_loss: 9.1346\n",
      "Epoch 9529/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3179 - val_loss: 9.1337\n",
      "Epoch 9530/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3176 - val_loss: 9.1340\n",
      "Epoch 9531/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3173 - val_loss: 9.1333\n",
      "Epoch 9532/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3170 - val_loss: 9.1341\n",
      "Epoch 9533/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3168 - val_loss: 9.1327\n",
      "Epoch 9534/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.3165 - val_loss: 9.1327\n",
      "Epoch 9535/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3162 - val_loss: 9.1316\n",
      "Epoch 9536/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.3159 - val_loss: 9.1322\n",
      "Epoch 9537/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3156 - val_loss: 9.1319\n",
      "Epoch 9538/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3153 - val_loss: 9.1313\n",
      "Epoch 9539/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3150 - val_loss: 9.1311\n",
      "Epoch 9540/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3147 - val_loss: 9.1308\n",
      "Epoch 9541/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3145 - val_loss: 9.1310\n",
      "Epoch 9542/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3142 - val_loss: 9.1296\n",
      "Epoch 9543/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3139 - val_loss: 9.1297\n",
      "Epoch 9544/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3136 - val_loss: 9.1299\n",
      "Epoch 9545/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3133 - val_loss: 9.1306\n",
      "Epoch 9546/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3130 - val_loss: 9.1295\n",
      "Epoch 9547/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3127 - val_loss: 9.1283\n",
      "Epoch 9548/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3124 - val_loss: 9.1286\n",
      "Epoch 9549/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3122 - val_loss: 9.1292\n",
      "Epoch 9550/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3119 - val_loss: 9.1296\n",
      "Epoch 9551/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3116 - val_loss: 9.1282\n",
      "Epoch 9552/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3113 - val_loss: 9.1273\n",
      "Epoch 9553/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3110 - val_loss: 9.1274\n",
      "Epoch 9554/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3107 - val_loss: 9.1279\n",
      "Epoch 9555/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3104 - val_loss: 9.1278\n",
      "Epoch 9556/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3102 - val_loss: 9.1272\n",
      "Epoch 9557/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3099 - val_loss: 9.1266\n",
      "Epoch 9558/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3096 - val_loss: 9.1263\n",
      "Epoch 9559/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3093 - val_loss: 9.1263\n",
      "Epoch 9560/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3090 - val_loss: 9.1261\n",
      "Epoch 9561/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3087 - val_loss: 9.1264\n",
      "Epoch 9562/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3084 - val_loss: 9.1257\n",
      "Epoch 9563/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3081 - val_loss: 9.1255\n",
      "Epoch 9564/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3079 - val_loss: 9.1247\n",
      "Epoch 9565/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3076 - val_loss: 9.1252\n",
      "Epoch 9566/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3073 - val_loss: 9.1248\n",
      "Epoch 9567/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3070 - val_loss: 9.1246\n",
      "Epoch 9568/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3067 - val_loss: 9.1237\n",
      "Epoch 9569/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3064 - val_loss: 9.1236\n",
      "Epoch 9570/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3061 - val_loss: 9.1230\n",
      "Epoch 9571/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3059 - val_loss: 9.1231\n",
      "Epoch 9572/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3056 - val_loss: 9.1228\n",
      "Epoch 9573/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3053 - val_loss: 9.1229\n",
      "Epoch 9574/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3050 - val_loss: 9.1221\n",
      "Epoch 9575/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3047 - val_loss: 9.1219\n",
      "Epoch 9576/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3044 - val_loss: 9.1217\n",
      "Epoch 9577/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3041 - val_loss: 9.1214\n",
      "Epoch 9578/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3039 - val_loss: 9.1208\n",
      "Epoch 9579/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3036 - val_loss: 9.1207\n",
      "Epoch 9580/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.3033 - val_loss: 9.1207\n",
      "Epoch 9581/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.3030 - val_loss: 9.1207\n",
      "Epoch 9582/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3027 - val_loss: 9.1194\n",
      "Epoch 9583/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3024 - val_loss: 9.1192\n",
      "Epoch 9584/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3021 - val_loss: 9.1188\n",
      "Epoch 9585/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3019 - val_loss: 9.1194\n",
      "Epoch 9586/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3016 - val_loss: 9.1184\n",
      "Epoch 9587/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3013 - val_loss: 9.1188\n",
      "Epoch 9588/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3010 - val_loss: 9.1180\n",
      "Epoch 9589/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3007 - val_loss: 9.1186\n",
      "Epoch 9590/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3004 - val_loss: 9.1176\n",
      "Epoch 9591/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3001 - val_loss: 9.1172\n",
      "Epoch 9592/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2998 - val_loss: 9.1166\n",
      "Epoch 9593/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2996 - val_loss: 9.1164\n",
      "Epoch 9594/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2993 - val_loss: 9.1159\n",
      "Epoch 9595/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2990 - val_loss: 9.1154\n",
      "Epoch 9596/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2987 - val_loss: 9.1155\n",
      "Epoch 9597/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2984 - val_loss: 9.1158\n",
      "Epoch 9598/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2981 - val_loss: 9.1157\n",
      "Epoch 9599/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2978 - val_loss: 9.1148\n",
      "Epoch 9600/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2976 - val_loss: 9.1146\n",
      "Epoch 9601/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2973 - val_loss: 9.1143\n",
      "Epoch 9602/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2970 - val_loss: 9.1141\n",
      "Epoch 9603/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2967 - val_loss: 9.1131\n",
      "Epoch 9604/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2964 - val_loss: 9.1134\n",
      "Epoch 9605/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2961 - val_loss: 9.1129\n",
      "Epoch 9606/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2959 - val_loss: 9.1130\n",
      "Epoch 9607/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.2956 - val_loss: 9.1122\n",
      "Epoch 9608/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2953 - val_loss: 9.1119\n",
      "Epoch 9609/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2950 - val_loss: 9.1109\n",
      "Epoch 9610/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2947 - val_loss: 9.1108\n",
      "Epoch 9611/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2944 - val_loss: 9.1105\n",
      "Epoch 9612/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2941 - val_loss: 9.1105\n",
      "Epoch 9613/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2939 - val_loss: 9.1098\n",
      "Epoch 9614/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2936 - val_loss: 9.1094\n",
      "Epoch 9615/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2933 - val_loss: 9.1089\n",
      "Epoch 9616/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2930 - val_loss: 9.1085\n",
      "Epoch 9617/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2927 - val_loss: 9.1080\n",
      "Epoch 9618/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2924 - val_loss: 9.1077\n",
      "Epoch 9619/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2921 - val_loss: 9.1077\n",
      "Epoch 9620/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2919 - val_loss: 9.1074\n",
      "Epoch 9621/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2916 - val_loss: 9.1068\n",
      "Epoch 9622/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.2913 - val_loss: 9.1061\n",
      "Epoch 9623/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2910 - val_loss: 9.1062\n",
      "Epoch 9624/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2907 - val_loss: 9.1061\n",
      "Epoch 9625/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2904 - val_loss: 9.1059\n",
      "Epoch 9626/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2901 - val_loss: 9.1044\n",
      "Epoch 9627/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2899 - val_loss: 9.1040\n",
      "Epoch 9628/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2896 - val_loss: 9.1036\n",
      "Epoch 9629/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2893 - val_loss: 9.1043\n",
      "Epoch 9630/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2890 - val_loss: 9.1038\n",
      "Epoch 9631/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2887 - val_loss: 9.1035\n",
      "Epoch 9632/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2884 - val_loss: 9.1029\n",
      "Epoch 9633/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2882 - val_loss: 9.1026\n",
      "Epoch 9634/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2879 - val_loss: 9.1021\n",
      "Epoch 9635/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2876 - val_loss: 9.1019\n",
      "Epoch 9636/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2873 - val_loss: 9.1016\n",
      "Epoch 9637/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2870 - val_loss: 9.1020\n",
      "Epoch 9638/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2867 - val_loss: 9.1017\n",
      "Epoch 9639/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2864 - val_loss: 9.1008\n",
      "Epoch 9640/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2862 - val_loss: 9.1001\n",
      "Epoch 9641/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2859 - val_loss: 9.1005\n",
      "Epoch 9642/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2856 - val_loss: 9.1005\n",
      "Epoch 9643/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.2853 - val_loss: 9.1004\n",
      "Epoch 9644/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2850 - val_loss: 9.0990\n",
      "Epoch 9645/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2847 - val_loss: 9.0987\n",
      "Epoch 9646/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2845 - val_loss: 9.0982\n",
      "Epoch 9647/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2842 - val_loss: 9.0984\n",
      "Epoch 9648/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2839 - val_loss: 9.0978\n",
      "Epoch 9649/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2836 - val_loss: 9.0981\n",
      "Epoch 9650/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2833 - val_loss: 9.0977\n",
      "Epoch 9651/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2830 - val_loss: 9.0974\n",
      "Epoch 9652/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2827 - val_loss: 9.0965\n",
      "Epoch 9653/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2825 - val_loss: 9.0961\n",
      "Epoch 9654/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.2822 - val_loss: 9.0956\n",
      "Epoch 9655/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2819 - val_loss: 9.0949\n",
      "Epoch 9656/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2816 - val_loss: 9.0950\n",
      "Epoch 9657/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2813 - val_loss: 9.0950\n",
      "Epoch 9658/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2810 - val_loss: 9.0953\n",
      "Epoch 9659/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2808 - val_loss: 9.0941\n",
      "Epoch 9660/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2805 - val_loss: 9.0941\n",
      "Epoch 9661/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2802 - val_loss: 9.0933\n",
      "Epoch 9662/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2799 - val_loss: 9.0936\n",
      "Epoch 9663/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2796 - val_loss: 9.0927\n",
      "Epoch 9664/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2793 - val_loss: 9.0927\n",
      "Epoch 9665/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.2791 - val_loss: 9.0917\n",
      "Epoch 9666/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2788 - val_loss: 9.0918\n",
      "Epoch 9667/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2785 - val_loss: 9.0914\n",
      "Epoch 9668/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2782 - val_loss: 9.0917\n",
      "Epoch 9669/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2779 - val_loss: 9.0915\n",
      "Epoch 9670/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2776 - val_loss: 9.0904\n",
      "Epoch 9671/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2773 - val_loss: 9.0902\n",
      "Epoch 9672/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2771 - val_loss: 9.0898\n",
      "Epoch 9673/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2768 - val_loss: 9.0906\n",
      "Epoch 9674/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2765 - val_loss: 9.0898\n",
      "Epoch 9675/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2762 - val_loss: 9.0894\n",
      "Epoch 9676/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.2759 - val_loss: 9.0884\n",
      "Epoch 9677/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2756 - val_loss: 9.0888\n",
      "Epoch 9678/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2754 - val_loss: 9.0884\n",
      "Epoch 9679/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2751 - val_loss: 9.0876\n",
      "Epoch 9680/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2748 - val_loss: 9.0865\n",
      "Epoch 9681/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2745 - val_loss: 9.0869\n",
      "Epoch 9682/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2742 - val_loss: 9.0875\n",
      "Epoch 9683/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2739 - val_loss: 9.0867\n",
      "Epoch 9684/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2737 - val_loss: 9.0856\n",
      "Epoch 9685/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2734 - val_loss: 9.0849\n",
      "Epoch 9686/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2731 - val_loss: 9.0861\n",
      "Epoch 9687/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2728 - val_loss: 9.0853\n",
      "Epoch 9688/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2725 - val_loss: 9.0850\n",
      "Epoch 9689/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2722 - val_loss: 9.0833\n",
      "Epoch 9690/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2720 - val_loss: 9.0843\n",
      "Epoch 9691/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2717 - val_loss: 9.0839\n",
      "Epoch 9692/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2714 - val_loss: 9.0841\n",
      "Epoch 9693/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2711 - val_loss: 9.0829\n",
      "Epoch 9694/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2708 - val_loss: 9.0831\n",
      "Epoch 9695/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2705 - val_loss: 9.0829\n",
      "Epoch 9696/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2703 - val_loss: 9.0818\n",
      "Epoch 9697/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2700 - val_loss: 9.0813\n",
      "Epoch 9698/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2697 - val_loss: 9.0805\n",
      "Epoch 9699/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2694 - val_loss: 9.0812\n",
      "Epoch 9700/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2691 - val_loss: 9.0803\n",
      "Epoch 9701/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2688 - val_loss: 9.0804\n",
      "Epoch 9702/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2686 - val_loss: 9.0795\n",
      "Epoch 9703/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2683 - val_loss: 9.0796\n",
      "Epoch 9704/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2680 - val_loss: 9.0794\n",
      "Epoch 9705/10000\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.267 - 0s 32ms/step - loss: 3.2677 - val_loss: 9.0790\n",
      "Epoch 9706/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2674 - val_loss: 9.0787\n",
      "Epoch 9707/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2672 - val_loss: 9.0777\n",
      "Epoch 9708/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2669 - val_loss: 9.0781\n",
      "Epoch 9709/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2666 - val_loss: 9.0775\n",
      "Epoch 9710/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2663 - val_loss: 9.0776\n",
      "Epoch 9711/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2660 - val_loss: 9.0764\n",
      "Epoch 9712/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2657 - val_loss: 9.0764\n",
      "Epoch 9713/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2655 - val_loss: 9.0761\n",
      "Epoch 9714/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2652 - val_loss: 9.0755\n",
      "Epoch 9715/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2649 - val_loss: 9.0749\n",
      "Epoch 9716/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2646 - val_loss: 9.0742\n",
      "Epoch 9717/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2643 - val_loss: 9.0747\n",
      "Epoch 9718/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2640 - val_loss: 9.0746\n",
      "Epoch 9719/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2638 - val_loss: 9.0743\n",
      "Epoch 9720/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2635 - val_loss: 9.0731\n",
      "Epoch 9721/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2632 - val_loss: 9.0733\n",
      "Epoch 9722/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2629 - val_loss: 9.0733\n",
      "Epoch 9723/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2626 - val_loss: 9.0731\n",
      "Epoch 9724/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2623 - val_loss: 9.0725\n",
      "Epoch 9725/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2621 - val_loss: 9.0718\n",
      "Epoch 9726/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2618 - val_loss: 9.0716\n",
      "Epoch 9727/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2615 - val_loss: 9.0710\n",
      "Epoch 9728/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2612 - val_loss: 9.0714\n",
      "Epoch 9729/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2609 - val_loss: 9.0709\n",
      "Epoch 9730/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2607 - val_loss: 9.0705\n",
      "Epoch 9731/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2604 - val_loss: 9.0694\n",
      "Epoch 9732/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2601 - val_loss: 9.0690\n",
      "Epoch 9733/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2598 - val_loss: 9.0692\n",
      "Epoch 9734/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2595 - val_loss: 9.0689\n",
      "Epoch 9735/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2592 - val_loss: 9.0688\n",
      "Epoch 9736/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2590 - val_loss: 9.0682\n",
      "Epoch 9737/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2587 - val_loss: 9.0679\n",
      "Epoch 9738/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2584 - val_loss: 9.0671\n",
      "Epoch 9739/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2581 - val_loss: 9.0671\n",
      "Epoch 9740/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2578 - val_loss: 9.0669\n",
      "Epoch 9741/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2576 - val_loss: 9.0669\n",
      "Epoch 9742/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2573 - val_loss: 9.0662\n",
      "Epoch 9743/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2570 - val_loss: 9.0653\n",
      "Epoch 9744/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2567 - val_loss: 9.0654\n",
      "Epoch 9745/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2564 - val_loss: 9.0655\n",
      "Epoch 9746/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2561 - val_loss: 9.0654\n",
      "Epoch 9747/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2559 - val_loss: 9.0645\n",
      "Epoch 9748/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2556 - val_loss: 9.0642\n",
      "Epoch 9749/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2553 - val_loss: 9.0639\n",
      "Epoch 9750/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2550 - val_loss: 9.0639\n",
      "Epoch 9751/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2547 - val_loss: 9.0635\n",
      "Epoch 9752/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2545 - val_loss: 9.0629\n",
      "Epoch 9753/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2542 - val_loss: 9.0631\n",
      "Epoch 9754/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2539 - val_loss: 9.0621\n",
      "Epoch 9755/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2536 - val_loss: 9.0618\n",
      "Epoch 9756/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2533 - val_loss: 9.0606\n",
      "Epoch 9757/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2530 - val_loss: 9.0610\n",
      "Epoch 9758/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2528 - val_loss: 9.0604\n",
      "Epoch 9759/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2525 - val_loss: 9.0604\n",
      "Epoch 9760/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2522 - val_loss: 9.0596\n",
      "Epoch 9761/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2519 - val_loss: 9.0594\n",
      "Epoch 9762/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2516 - val_loss: 9.0590\n",
      "Epoch 9763/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2514 - val_loss: 9.0587\n",
      "Epoch 9764/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2511 - val_loss: 9.0588\n",
      "Epoch 9765/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2508 - val_loss: 9.0580\n",
      "Epoch 9766/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2505 - val_loss: 9.0583\n",
      "Epoch 9767/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2502 - val_loss: 9.0565\n",
      "Epoch 9768/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2500 - val_loss: 9.0571\n",
      "Epoch 9769/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2497 - val_loss: 9.0565\n",
      "Epoch 9770/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2494 - val_loss: 9.0567\n",
      "Epoch 9771/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2491 - val_loss: 9.0552\n",
      "Epoch 9772/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2488 - val_loss: 9.0546\n",
      "Epoch 9773/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2485 - val_loss: 9.0550\n",
      "Epoch 9774/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2483 - val_loss: 9.0550\n",
      "Epoch 9775/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2480 - val_loss: 9.0550\n",
      "Epoch 9776/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2477 - val_loss: 9.0532\n",
      "Epoch 9777/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2474 - val_loss: 9.0539\n",
      "Epoch 9778/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2471 - val_loss: 9.0534\n",
      "Epoch 9779/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2469 - val_loss: 9.0536\n",
      "Epoch 9780/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2466 - val_loss: 9.0520\n",
      "Epoch 9781/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2463 - val_loss: 9.0513\n",
      "Epoch 9782/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2460 - val_loss: 9.0517\n",
      "Epoch 9783/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2457 - val_loss: 9.0515\n",
      "Epoch 9784/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2455 - val_loss: 9.0514\n",
      "Epoch 9785/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2452 - val_loss: 9.0499\n",
      "Epoch 9786/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2449 - val_loss: 9.0504\n",
      "Epoch 9787/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2446 - val_loss: 9.0502\n",
      "Epoch 9788/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2443 - val_loss: 9.0497\n",
      "Epoch 9789/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2440 - val_loss: 9.0483\n",
      "Epoch 9790/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2438 - val_loss: 9.0477\n",
      "Epoch 9791/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2435 - val_loss: 9.0486\n",
      "Epoch 9792/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2432 - val_loss: 9.0479\n",
      "Epoch 9793/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2429 - val_loss: 9.0478\n",
      "Epoch 9794/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2426 - val_loss: 9.0464\n",
      "Epoch 9795/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2424 - val_loss: 9.0472\n",
      "Epoch 9796/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2421 - val_loss: 9.0463\n",
      "Epoch 9797/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2418 - val_loss: 9.0457\n",
      "Epoch 9798/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2415 - val_loss: 9.0450\n",
      "Epoch 9799/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2412 - val_loss: 9.0449\n",
      "Epoch 9800/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2410 - val_loss: 9.0455\n",
      "Epoch 9801/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2407 - val_loss: 9.0443\n",
      "Epoch 9802/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2404 - val_loss: 9.0439\n",
      "Epoch 9803/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2401 - val_loss: 9.0432\n",
      "Epoch 9804/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2398 - val_loss: 9.0440\n",
      "Epoch 9805/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2396 - val_loss: 9.0432\n",
      "Epoch 9806/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2393 - val_loss: 9.0421\n",
      "Epoch 9807/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2390 - val_loss: 9.0415\n",
      "Epoch 9808/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2387 - val_loss: 9.0419\n",
      "Epoch 9809/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2384 - val_loss: 9.0423\n",
      "Epoch 9810/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2381 - val_loss: 9.0413\n",
      "Epoch 9811/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2379 - val_loss: 9.0401\n",
      "Epoch 9812/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2376 - val_loss: 9.0398\n",
      "Epoch 9813/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2373 - val_loss: 9.0396\n",
      "Epoch 9814/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2370 - val_loss: 9.0397\n",
      "Epoch 9815/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2367 - val_loss: 9.0390\n",
      "Epoch 9816/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2365 - val_loss: 9.0392\n",
      "Epoch 9817/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2362 - val_loss: 9.0383\n",
      "Epoch 9818/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2359 - val_loss: 9.0379\n",
      "Epoch 9819/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2356 - val_loss: 9.0375\n",
      "Epoch 9820/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2353 - val_loss: 9.0371\n",
      "Epoch 9821/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2351 - val_loss: 9.0369\n",
      "Epoch 9822/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2348 - val_loss: 9.0365\n",
      "Epoch 9823/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2345 - val_loss: 9.0360\n",
      "Epoch 9824/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2342 - val_loss: 9.0355\n",
      "Epoch 9825/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2339 - val_loss: 9.0350\n",
      "Epoch 9826/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2337 - val_loss: 9.0351\n",
      "Epoch 9827/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2334 - val_loss: 9.0349\n",
      "Epoch 9828/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2331 - val_loss: 9.0350\n",
      "Epoch 9829/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2328 - val_loss: 9.0335\n",
      "Epoch 9830/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2325 - val_loss: 9.0327\n",
      "Epoch 9831/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2323 - val_loss: 9.0324\n",
      "Epoch 9832/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2320 - val_loss: 9.0330\n",
      "Epoch 9833/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2317 - val_loss: 9.0331\n",
      "Epoch 9834/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2314 - val_loss: 9.0321\n",
      "Epoch 9835/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2311 - val_loss: 9.0318\n",
      "Epoch 9836/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2309 - val_loss: 9.0312\n",
      "Epoch 9837/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2306 - val_loss: 9.0312\n",
      "Epoch 9838/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2303 - val_loss: 9.0301\n",
      "Epoch 9839/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2300 - val_loss: 9.0300\n",
      "Epoch 9840/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2297 - val_loss: 9.0296\n",
      "Epoch 9841/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2295 - val_loss: 9.0293\n",
      "Epoch 9842/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2292 - val_loss: 9.0291\n",
      "Epoch 9843/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2289 - val_loss: 9.0288\n",
      "Epoch 9844/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2286 - val_loss: 9.0289\n",
      "Epoch 9845/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2283 - val_loss: 9.0276\n",
      "Epoch 9846/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2281 - val_loss: 9.0277\n",
      "Epoch 9847/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2278 - val_loss: 9.0272\n",
      "Epoch 9848/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2275 - val_loss: 9.0275\n",
      "Epoch 9849/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2272 - val_loss: 9.0261\n",
      "Epoch 9850/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2270 - val_loss: 9.0256\n",
      "Epoch 9851/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2267 - val_loss: 9.0254\n",
      "Epoch 9852/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2264 - val_loss: 9.0259\n",
      "Epoch 9853/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2261 - val_loss: 9.0255\n",
      "Epoch 9854/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2258 - val_loss: 9.0243\n",
      "Epoch 9855/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2256 - val_loss: 9.0244\n",
      "Epoch 9856/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2253 - val_loss: 9.0241\n",
      "Epoch 9857/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2250 - val_loss: 9.0241\n",
      "Epoch 9858/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.2247 - val_loss: 9.0228\n",
      "Epoch 9859/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2244 - val_loss: 9.0228\n",
      "Epoch 9860/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2242 - val_loss: 9.0227\n",
      "Epoch 9861/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2239 - val_loss: 9.0230\n",
      "Epoch 9862/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2236 - val_loss: 9.0217\n",
      "Epoch 9863/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2233 - val_loss: 9.0209\n",
      "Epoch 9864/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.2230 - val_loss: 9.0209\n",
      "Epoch 9865/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2228 - val_loss: 9.0210\n",
      "Epoch 9866/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2225 - val_loss: 9.0214\n",
      "Epoch 9867/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2222 - val_loss: 9.0201\n",
      "Epoch 9868/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2219 - val_loss: 9.0202\n",
      "Epoch 9869/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2216 - val_loss: 9.0191\n",
      "Epoch 9870/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2214 - val_loss: 9.0193\n",
      "Epoch 9871/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2211 - val_loss: 9.0188\n",
      "Epoch 9872/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2208 - val_loss: 9.0189\n",
      "Epoch 9873/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2205 - val_loss: 9.0182\n",
      "Epoch 9874/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2203 - val_loss: 9.0179\n",
      "Epoch 9875/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2200 - val_loss: 9.0177\n",
      "Epoch 9876/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2197 - val_loss: 9.0175\n",
      "Epoch 9877/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2194 - val_loss: 9.0171\n",
      "Epoch 9878/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2191 - val_loss: 9.0162\n",
      "Epoch 9879/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2189 - val_loss: 9.0162\n",
      "Epoch 9880/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2186 - val_loss: 9.0162\n",
      "Epoch 9881/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2183 - val_loss: 9.0159\n",
      "Epoch 9882/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2180 - val_loss: 9.0152\n",
      "Epoch 9883/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.2177 - val_loss: 9.0145\n",
      "Epoch 9884/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2175 - val_loss: 9.0144\n",
      "Epoch 9885/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2172 - val_loss: 9.0138\n",
      "Epoch 9886/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2169 - val_loss: 9.0137\n",
      "Epoch 9887/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2166 - val_loss: 9.0130\n",
      "Epoch 9888/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2164 - val_loss: 9.0129\n",
      "Epoch 9889/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2161 - val_loss: 9.0125\n",
      "Epoch 9890/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2158 - val_loss: 9.0122\n",
      "Epoch 9891/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2155 - val_loss: 9.0118\n",
      "Epoch 9892/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2152 - val_loss: 9.0118\n",
      "Epoch 9893/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2150 - val_loss: 9.0112\n",
      "Epoch 9894/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2147 - val_loss: 9.0106\n",
      "Epoch 9895/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2144 - val_loss: 9.0103\n",
      "Epoch 9896/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2141 - val_loss: 9.0106\n",
      "Epoch 9897/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2138 - val_loss: 9.0106\n",
      "Epoch 9898/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2136 - val_loss: 9.0098\n",
      "Epoch 9899/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2133 - val_loss: 9.0087\n",
      "Epoch 9900/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2130 - val_loss: 9.0081\n",
      "Epoch 9901/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2127 - val_loss: 9.0087\n",
      "Epoch 9902/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2125 - val_loss: 9.0086\n",
      "Epoch 9903/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2122 - val_loss: 9.0080\n",
      "Epoch 9904/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2119 - val_loss: 9.0073\n",
      "Epoch 9905/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2116 - val_loss: 9.0071\n",
      "Epoch 9906/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2113 - val_loss: 9.0071\n",
      "Epoch 9907/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2111 - val_loss: 9.0060\n",
      "Epoch 9908/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2108 - val_loss: 9.0060\n",
      "Epoch 9909/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2105 - val_loss: 9.0054\n",
      "Epoch 9910/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2102 - val_loss: 9.0059\n",
      "Epoch 9911/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2100 - val_loss: 9.0044\n",
      "Epoch 9912/10000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.2097 - val_loss: 9.0040\n",
      "Epoch 9913/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2094 - val_loss: 9.0032\n",
      "Epoch 9914/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2091 - val_loss: 9.0044\n",
      "Epoch 9915/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2088 - val_loss: 9.0040\n",
      "Epoch 9916/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2086 - val_loss: 9.0036\n",
      "Epoch 9917/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2083 - val_loss: 9.0023\n",
      "Epoch 9918/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2080 - val_loss: 9.0016\n",
      "Epoch 9919/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2077 - val_loss: 9.0022\n",
      "Epoch 9920/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2074 - val_loss: 9.0019\n",
      "Epoch 9921/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2072 - val_loss: 9.0017\n",
      "Epoch 9922/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2069 - val_loss: 9.0003\n",
      "Epoch 9923/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2066 - val_loss: 9.0003\n",
      "Epoch 9924/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2063 - val_loss: 9.0003\n",
      "Epoch 9925/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2061 - val_loss: 9.0004\n",
      "Epoch 9926/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.2058 - val_loss: 8.9993\n",
      "Epoch 9927/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2055 - val_loss: 8.9987\n",
      "Epoch 9928/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2052 - val_loss: 8.9992\n",
      "Epoch 9929/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2049 - val_loss: 8.9990\n",
      "Epoch 9930/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2047 - val_loss: 8.9978\n",
      "Epoch 9931/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2044 - val_loss: 8.9963\n",
      "Epoch 9932/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2041 - val_loss: 8.9967\n",
      "Epoch 9933/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2038 - val_loss: 8.9972\n",
      "Epoch 9934/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2036 - val_loss: 8.9971\n",
      "Epoch 9935/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2033 - val_loss: 8.9959\n",
      "Epoch 9936/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2030 - val_loss: 8.9955\n",
      "Epoch 9937/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2027 - val_loss: 8.9958\n",
      "Epoch 9938/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2024 - val_loss: 8.9954\n",
      "Epoch 9939/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2022 - val_loss: 8.9945\n",
      "Epoch 9940/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2019 - val_loss: 8.9935\n",
      "Epoch 9941/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2016 - val_loss: 8.9939\n",
      "Epoch 9942/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2013 - val_loss: 8.9936\n",
      "Epoch 9943/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2011 - val_loss: 8.9930\n",
      "Epoch 9944/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2008 - val_loss: 8.9916\n",
      "Epoch 9945/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2005 - val_loss: 8.9919\n",
      "Epoch 9946/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2002 - val_loss: 8.9919\n",
      "Epoch 9947/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.2000 - val_loss: 8.9916\n",
      "Epoch 9948/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1997 - val_loss: 8.9903\n",
      "Epoch 9949/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1994 - val_loss: 8.9900\n",
      "Epoch 9950/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.1991 - val_loss: 8.9900\n",
      "Epoch 9951/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1988 - val_loss: 8.9898\n",
      "Epoch 9952/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1986 - val_loss: 8.9885\n",
      "Epoch 9953/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1983 - val_loss: 8.9886\n",
      "Epoch 9954/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1980 - val_loss: 8.9887\n",
      "Epoch 9955/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1977 - val_loss: 8.9884\n",
      "Epoch 9956/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.1975 - val_loss: 8.9869\n",
      "Epoch 9957/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.1972 - val_loss: 8.9869\n",
      "Epoch 9958/10000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.1969 - val_loss: 8.9869\n",
      "Epoch 9959/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1966 - val_loss: 8.9873\n",
      "Epoch 9960/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1963 - val_loss: 8.9858\n",
      "Epoch 9961/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1961 - val_loss: 8.9853\n",
      "Epoch 9962/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1958 - val_loss: 8.9847\n",
      "Epoch 9963/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1955 - val_loss: 8.9852\n",
      "Epoch 9964/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.1952 - val_loss: 8.9846\n",
      "Epoch 9965/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1950 - val_loss: 8.9841\n",
      "Epoch 9966/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1947 - val_loss: 8.9836\n",
      "Epoch 9967/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1944 - val_loss: 8.9827\n",
      "Epoch 9968/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.1941 - val_loss: 8.9832\n",
      "Epoch 9969/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.1939 - val_loss: 8.9823\n",
      "Epoch 9970/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.1936 - val_loss: 8.9826\n",
      "Epoch 9971/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.1933 - val_loss: 8.9810\n",
      "Epoch 9972/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1930 - val_loss: 8.9814\n",
      "Epoch 9973/10000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.1928 - val_loss: 8.9806\n",
      "Epoch 9974/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1925 - val_loss: 8.9805\n",
      "Epoch 9975/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1922 - val_loss: 8.9802\n",
      "Epoch 9976/10000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.1919 - val_loss: 8.9794\n",
      "Epoch 9977/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1916 - val_loss: 8.9797\n",
      "Epoch 9978/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1914 - val_loss: 8.9784\n",
      "Epoch 9979/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1911 - val_loss: 8.9789\n",
      "Epoch 9980/10000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1908 - val_loss: 8.9780\n",
      "Epoch 9981/10000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1905 - val_loss: 8.9782\n",
      "Epoch 9982/10000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.1903 - val_loss: 8.9773\n",
      "Epoch 9983/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1900 - val_loss: 8.9766\n",
      "Epoch 9984/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1897 - val_loss: 8.9760\n",
      "Epoch 9985/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1894 - val_loss: 8.9751\n",
      "Epoch 9986/10000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1892 - val_loss: 8.9753\n",
      "Epoch 9987/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1889 - val_loss: 8.9753\n",
      "Epoch 9988/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1886 - val_loss: 8.9755\n",
      "Epoch 9989/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1883 - val_loss: 8.9738\n",
      "Epoch 9990/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1881 - val_loss: 8.9730\n",
      "Epoch 9991/10000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.1878 - val_loss: 8.9731\n",
      "Epoch 9992/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1875 - val_loss: 8.9737\n",
      "Epoch 9993/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1872 - val_loss: 8.9734\n",
      "Epoch 9994/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1870 - val_loss: 8.9722\n",
      "Epoch 9995/10000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1867 - val_loss: 8.9720\n",
      "Epoch 9996/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1864 - val_loss: 8.9719\n",
      "Epoch 9997/10000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1861 - val_loss: 8.9713\n",
      "Epoch 9998/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1858 - val_loss: 8.9708\n",
      "Epoch 9999/10000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1856 - val_loss: 8.9703\n",
      "Epoch 10000/10000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1853 - val_loss: 8.9712\n",
      "0.12260234 0.34560734\n",
      "-0.024967017 0.1538652\n",
      "0.47946787 0.13704045\n"
     ]
    }
   ],
   "source": [
    "#前面的模型是只放开最后一层优化模型参数，这个模型是放开所有的参数进行微调\n",
    "model.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),loss='mse')\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=y_train.shape[0], epochs=10000, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    validation_freq=1,\n",
    "                    callbacks=[cp_callback]\n",
    "#                     ,callbacks=[reduce_lr]\n",
    "                   )\n",
    "layer0 = model.layers[0].get_weights()\n",
    "layer2 = model.layers[2].get_weights()\n",
    "layer3 = model.layers[3].get_weights()\n",
    "print(layer0[0][0,0],layer0[1][0])\n",
    "print(layer2[0][0,0],layer2[1][0])\n",
    "print(layer3[0][0,0],layer3[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()\n",
    "#history.history.get('loss')[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"704.5454392748434\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.epoch, history.history.get('loss'), label='loss')\n",
    "plt.plot(history.epoch, history.history.get('val_loss'), label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig('loss.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17395844 0.31290776\n",
      "-0.027283685 0.11891915\n",
      "0.4376273 0.10317\n"
     ]
    }
   ],
   "source": [
    "#模型训练结束后，预测是基于最终的一组参数，但可能效果最好的参数是前面的某一组，这里读取效果最好的参数进行预测\n",
    "model.load_weights(checkpoint_save_path_transfer_free)\n",
    "layer0 = model.layers[0].get_weights()\n",
    "layer2 = model.layers[2].get_weights()\n",
    "layer3 = model.layers[3].get_weights()\n",
    "print(layer0[0][0,0],layer0[1][0])\n",
    "print(layer2[0][0,0],layer2[1][0])\n",
    "print(layer3[0][0,0],layer3[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = model.predict(x_train)\n",
    "y_train_predict = np.array(y_train_predict).flatten()\n",
    "y_test_predict = model.predict(x_test)\n",
    "y_test_predict = np.array(y_test_predict).flatten()\n",
    "# print(y_train.shape)\n",
    "# print(y_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"879.9999809265141\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "scale = 1\n",
    "plt.xlim(min(y_train)-scale,max(y_train)+scale)\n",
    "plt.ylim(min(y_train)-scale,max(y_train)+scale)\n",
    "\n",
    "plt.scatter(y_train,y_train, color='black', s=16\n",
    "#             ,linestyle='dotted'\n",
    "#             ,label='DFT'\n",
    "           )\n",
    "plt.scatter(y_train, y_train_predict, s=28, alpha=0.4,color='darkorange'\n",
    "#             ,label='NN_transform'\n",
    "           )\n",
    "\n",
    "plt.xlabel('DFT_Eads(Kcal/mol)',fontsize=18)\n",
    "plt.ylabel('NN_Eads(Kcal/mol)',fontsize=18)\n",
    "\n",
    "x1 = np.arange(min(y_train),max(y_train),0.5)\n",
    "# plt.plot(x1,x1-3.6,label='y=x-3.6')\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(fontsize=18,rotation=0)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend()\n",
    "plt.savefig('./Fe-C-O_angel_train.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"549.9999880790713\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=3,figsize=(5,5))\n",
    "plt.rc('font',family='Times New Roman') \n",
    "scale = 1\n",
    "plt.xlim(min(y_train)-scale,max(y_train)+scale)\n",
    "plt.ylim(min(y_train)-scale,max(y_train)+scale)\n",
    "\n",
    "\n",
    "plt.scatter(y_test,y_test, color='black', s=36\n",
    "#             ,linestyle='dotted'\n",
    "#             ,label='DFT'\n",
    "           )\n",
    "plt.scatter(y_test,y_test_predict, s=88, alpha=0.6,color='red'\n",
    "#             ,label='NN_transform'\n",
    "           )\n",
    "\n",
    "# plt.xlabel('DFT_Eads(Kcal/mol)',fontsize=18)\n",
    "# plt.ylabel('NN_Eads(Kcal/mol)',fontsize=18)\n",
    "\n",
    "x1 = np.arange(min(y_test),max(y_test),0.5)\n",
    "# plt.plot(x1,x1-3.6,label='y=x-3.6')\n",
    "\n",
    "plt.xticks(np.arange(160,181,9),fontsize=24,rotation=0)\n",
    "plt.yticks(np.arange(160,181,9),fontsize=24)\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Fe-C-O_angel_test.png', dpi=168, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集------MAE:  0.6185792439648444\n",
      "测试集------MAE:  1.4523795321484356\n",
      "训练集------MSE:  0.6204643246934772\n",
      "测试集------MSE:  3.6303101075847923\n",
      "训练集------RMSE:  0.7876955786936202\n",
      "测试集------RMSE::  1.9053372687229924\n",
      "训练集------R2_score:  0.9693604877959473\n",
      "测试集------R2_score::  0.8499564701891091\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集------MAE: \",sm.mean_absolute_error(y_train,y_train_predict))\n",
    "print(\"测试集------MAE: \",sm.mean_absolute_error(y_test,y_test_predict))\n",
    "print(\"训练集------MSE: \",sm.mean_squared_error(y_train,y_train_predict))\n",
    "print(\"测试集------MSE: \",sm.mean_squared_error(y_test,y_test_predict))\n",
    "print(\"训练集------RMSE: \",np.sqrt(sm.mean_squared_error(y_train,y_train_predict)))\n",
    "print(\"测试集------RMSE:: \",np.sqrt(sm.mean_squared_error(y_test,y_test_predict)))\n",
    "print(\"训练集------R2_score: \",sm.r2_score(y_train,y_train_predict))\n",
    "print(\"测试集------R2_score:: \",sm.r2_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
